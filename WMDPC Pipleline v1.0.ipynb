{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries / Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:46:44.005520Z",
     "start_time": "2020-05-22T02:46:44.001525Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, Input, models\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPool2D, Dropout, Flatten, Activation, concatenate, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.metrics import f1_score,precision_recall_fscore_support\n",
    "from matplotlib import gridspec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:46:44.361170Z",
     "start_time": "2020-05-22T02:46:44.352195Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def plot_history(history):\n",
    "    # accuracy plot \n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    # loss plot\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_cm(y_true, y_hat, label_list):\n",
    "    cnf_matrix = confusion_matrix(y_true, y_hat)\n",
    "    np.set_printoptions(precision=2)\n",
    "    from matplotlib import gridspec\n",
    "    fig = plt.figure(figsize=(15, 8)) \n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[1, 1]) \n",
    "    plt.subplot(gs[0])\n",
    "    plot_confusion_matrix(cnf_matrix, title='Confusion matrix')\n",
    "    plt.subplot(gs[1])\n",
    "    plot_confusion_matrix(cnf_matrix, normalize=True, title='Normalized confusion matrix')\n",
    "    print(\"F1 Macro:\", f1_score(y_true, y_hat, label_list, average='macro'))\n",
    "    print(\"F1 Micro:\", f1_score(y_true, y_hat, label_list, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:46:44.644444Z",
     "start_time": "2020-05-22T02:46:44.641460Z"
    }
   },
   "outputs": [],
   "source": [
    "patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:46:49.325325Z",
     "start_time": "2020-05-22T02:46:45.344499Z"
    }
   },
   "outputs": [],
   "source": [
    "dim = 64\n",
    "import pickle\n",
    "with open('features_fe.pickle','rb') as f:\n",
    "    X_fe = pickle.load(f)\n",
    "with open('X_cnn_64.pickle','rb') as f:\n",
    "    X_cnn = pickle.load(f)\n",
    "X_cnn = X_cnn.reshape(-1,dim,dim,1)\n",
    "with open('y.pickle','rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:46:50.419328Z",
     "start_time": "2020-05-22T02:46:50.416372Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - CNN only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:46:51.284054Z",
     "start_time": "2020-05-22T02:46:51.272083Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model1():\n",
    "    dim = 64\n",
    "    input_wbm_tensor = Input((dim, dim, 1))\n",
    "    conv_1 = Conv2D(16, (3,3), activation='relu', padding='same')(input_wbm_tensor)\n",
    "    pool_1 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_1)\n",
    "    conv_2 = Conv2D(32, (3,3), activation='relu', padding='same')(pool_1)\n",
    "    pool_2 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_2)\n",
    "    conv_3 = Conv2D(64, (3,3), activation='relu', padding='same')(pool_2)\n",
    "    pool_3 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_3)\n",
    "    conv_4 = Conv2D(128, (3,3), activation='relu', padding='same')(pool_3)\n",
    "    pool_4 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_4)\n",
    "    conv_5 = Conv2D(256, (3,3), activation='relu', padding='same')(pool_4)\n",
    "    pool_5 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_5)\n",
    "    GAP = GlobalAveragePooling2D()(pool_5)\n",
    "    dense_1 = Dense(128, activation='tanh')(GAP)\n",
    "    dense_2 = Dense(128, activation='tanh')(dense_1)\n",
    "    prediction = Dense(9, activation='softmax')(dense_2)\n",
    "\n",
    "    model = models.Model(input_wbm_tensor, prediction)\n",
    "    model.compile(optimizer=Adam(lr=lr),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model1(model, X_train, y_train, X_val, y_val):\n",
    "    epoch=1000\n",
    "    batch_size = 32\n",
    "    es = EarlyStopping(monitor='val_loss', patience=patience, mode='auto', restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train,\n",
    "         validation_data=[X_val, y_val],\n",
    "         epochs=epoch,\n",
    "         batch_size=batch_size,callbacks=[es]\n",
    "         )\n",
    "    return model, list(set(np.argmax(y_train, axis=1)))\n",
    "\n",
    "def evaluate_model1(model, X_test, y_test, label_list, filename, result_dict, plot=True):\n",
    "    y_hat=model.predict(X_test)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "    y_test_label = np.argmax(y_test,axis=1)\n",
    "    result_dict['macro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='macro'))\n",
    "    result_dict['micro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='micro'))\n",
    "    cm = confusion_matrix(y_test_label, y_hat)\n",
    "    plot_cm(y_test_label, y_hat, label_list)\n",
    "    plt.savefig(filename)\n",
    "    if plot != True:\n",
    "        plt.close()\n",
    "    return result_dict, cm\n",
    "\n",
    "def create_model1(X_train_cnn, y_train, X_val_cnn, y_val, X_test_cnn, y_test, result_dict, n_trnval, rep):\n",
    "    print('\\n'+'*'*10+'model1'+'*'*10+'\\n')\n",
    "    modelname = 'model1'\n",
    "    filename = fn.format(ts=n_trnval, rep=rep, model=modelname)\n",
    "    model1 = build_model1()\n",
    "    model1, label_list = train_model1(model1, X_train_cnn, y_train, X_val_cnn, y_val)\n",
    "    result_dict, cm = evaluate_model1(model1, X_test_cnn, y_test, label_list, filename, result_dict,plot=False)\n",
    "    return result_dict, cm, model1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - FE+RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:46:51.643652Z",
     "start_time": "2020-05-22T02:46:51.635645Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model2():\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    return model\n",
    "\n",
    "def train_model2(model, X_trainval, y_trainval):\n",
    "    y_trainval_label = np.argmax(y_trainval, axis=1)\n",
    "    model.fit(X_trainval, y_trainval_label)\n",
    "    return model, list(set(np.argmax(y_trainval, axis=1)))\n",
    "\n",
    "def evaluate_model2(model, X_test_fe, y_test, label_list, filename, result_dict, plot=True):\n",
    "    y_hat = model.predict(X_test_fe)\n",
    "    y_test_label = np.argmax(y_test,axis=1)\n",
    "    result_dict['macro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='macro'))\n",
    "    result_dict['micro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='micro'))\n",
    "    cm = confusion_matrix(y_test_label, y_hat)\n",
    "    plot_cm(y_test_label, y_hat, label_list)\n",
    "    plt.savefig(filename)\n",
    "    if plot != True:\n",
    "        plt.close()\n",
    "    return result_dict, cm\n",
    "\n",
    "def create_model2(X_trainval_fe, y_trainval, X_test_fe, y_test, result_dict, n_trnval, rep):\n",
    "    print('\\n'+'*'*10+'model2'+'*'*10+'\\n')\n",
    "    modelname = 'model2'\n",
    "    filename = fn.format(ts=n_trnval, rep=rep, model=modelname)\n",
    "    model2 = build_model2()\n",
    "    model2, label_list = train_model2(model2, X_trainval_fe, y_trainval)\n",
    "    result_dict, cm = evaluate_model2(model2, X_test_fe, y_test, label_list, filename, result_dict,plot=False)\n",
    "    return result_dict, cm, model2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - FE+NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:46:51.965789Z",
     "start_time": "2020-05-22T02:46:51.956812Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model3():\n",
    "    input_feature_vector = Input((59,))\n",
    "    hidden_1 = Dense(128, activation='tanh')(input_feature_vector)\n",
    "    hidden_2= Dense(128, activation='tanh')(hidden_1)\n",
    "    prediction = layers.Dense(9, activation='softmax')(hidden_2)\n",
    "\n",
    "    model = models.Model(input_feature_vector, prediction)\n",
    "    model.compile(optimizer=Adam(lr=lr),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model3(model, X_train, y_train, X_val, y_val):\n",
    "    epoch=1000\n",
    "    batch_size = 32\n",
    "    es = EarlyStopping(monitor='val_loss', patience=patience, mode='auto', restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train,\n",
    "         validation_data=[X_val, y_val],\n",
    "         epochs=epoch,\n",
    "         batch_size=batch_size,callbacks=[es]\n",
    "         )\n",
    "    return model, list(set(np.argmax(y_train, axis=1)))\n",
    "\n",
    "def evaluate_model3(model, X_test, y_test, label_list, filename, result_dict, plot=True):\n",
    "    y_hat=model.predict(X_test)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "    y_test_label = np.argmax(y_test,axis=1)\n",
    "    result_dict['macro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='macro'))\n",
    "    result_dict['micro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='micro'))\n",
    "    cm = confusion_matrix(y_test_label, y_hat)\n",
    "    plot_cm(y_test_label, y_hat, label_list)\n",
    "    plt.savefig(filename)\n",
    "    if plot != True:\n",
    "        plt.close()\n",
    "    return result_dict, cm\n",
    "\n",
    "def create_model3(X_train_fe_n, y_train, X_val_fe_n, y_val, X_test_fe_n, y_test, result_dict, n_trnval, rep):\n",
    "    print('\\n'+'*'*10+'model3'+'*'*10+'\\n')\n",
    "    modelname = 'model3'\n",
    "    filename = fn.format(ts=n_trnval, rep=rep, model=modelname)\n",
    "    model3 = build_model3()\n",
    "    model3, label_list = train_model3(model3, X_train_fe_n, y_train,  X_val_fe_n, y_val)\n",
    "    result_dict, cm = evaluate_model3(model3, X_test_fe_n, y_test, label_list, filename, result_dict, plot=False)\n",
    "    return result_dict, cm, model3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 - Joint Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:46:52.299236Z",
     "start_time": "2020-05-22T02:46:52.285302Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model4():\n",
    "    dim = 64\n",
    "    input_wbm_tensor = Input((dim, dim, 1))\n",
    "    conv_1 = Conv2D(16, (3,3), activation='relu', padding='same')(input_wbm_tensor)\n",
    "    pool_1 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_1)\n",
    "    conv_2 = Conv2D(32, (3,3), activation='relu', padding='same')(pool_1)\n",
    "    pool_2 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_2)\n",
    "    conv_3 = Conv2D(64, (3,3), activation='relu', padding='same')(pool_2)\n",
    "    pool_3 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_3)\n",
    "    conv_4 = Conv2D(128, (3,3), activation='relu', padding='same')(pool_3)\n",
    "    pool_4 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_4)\n",
    "    conv_5 = Conv2D(256, (3,3), activation='relu', padding='same')(pool_4)\n",
    "    pool_5 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_5)\n",
    "    GAP = GlobalAveragePooling2D()(pool_5)\n",
    "\n",
    "    input_feature_vector = Input((59,))\n",
    "\n",
    "    concat_vector = concatenate([GAP, input_feature_vector])\n",
    "\n",
    "    concat_hidden_1 = layers.Dense(128, activation='tanh')(concat_vector)\n",
    "    concat_hidden_2 = layers.Dense(128, activation='tanh')(concat_hidden_1)\n",
    "    prediction = layers.Dense(9, activation='softmax')(concat_hidden_2)\n",
    "\n",
    "    model = models.Model([input_wbm_tensor, input_feature_vector], prediction)\n",
    "    model.compile(optimizer=Adam(lr=lr),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model4(model, X_train, y_train, X_val, y_val):\n",
    "    epoch=1000\n",
    "    batch_size = 32\n",
    "    es = EarlyStopping(monitor='val_loss', patience=patience, mode='auto', restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train,\n",
    "             validation_data=[X_val, y_val],\n",
    "             epochs=epoch,\n",
    "             batch_size=batch_size,callbacks=[es]\n",
    "             )\n",
    "    return model, list(set(np.argmax(y_train, axis=1)))\n",
    "\n",
    "def evaluate_model4(model, X_test, y_test, label_list, filename, result_dict, plot=True):\n",
    "    y_hat=model.predict(X_test)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "    y_test_label = np.argmax(y_test,axis=1)\n",
    "    result_dict['macro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='macro'))\n",
    "    result_dict['micro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='micro'))\n",
    "    cm = confusion_matrix(y_test_label, y_hat)\n",
    "    plot_cm(y_test_label, y_hat, label_list)\n",
    "    plt.savefig(filename)\n",
    "    if plot != True:\n",
    "        plt.close()\n",
    "    return result_dict, cm\n",
    "\n",
    "\n",
    "def create_model4(X_train_cnn, X_train_fe_n, y_train, X_val_cnn, X_val_fe_n, y_val, \n",
    "           X_test_cnn, X_test_fe_n, y_test, result_dict, n_trnval, rep):\n",
    "    print('\\n'+'*'*10+'model4'+'*'*10+'\\n')\n",
    "    modelname = 'model4'\n",
    "    filename = fn.format(ts=n_trnval, rep=rep, model=modelname)\n",
    "    model4 = build_model4()\n",
    "    model4, label_list = train_model4(model4, [X_train_cnn, X_train_fe_n], y_train, [X_val_cnn, X_val_fe_n], y_val)\n",
    "    result_dict, cm = evaluate_model4(model4, [X_test_cnn, X_test_fe_n], y_test, label_list, filename, result_dict,plot=False)\n",
    "    return result_dict, cm, model4\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5 - Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:46:52.585183Z",
     "start_time": "2020-05-22T02:46:52.576208Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model5():\n",
    "    from sklearn.linear_model import Ridge\n",
    "    model = Ridge(alpha=0.0001, fit_intercept=False)\n",
    "    return model\n",
    "\n",
    "def train_model5_val(model5, model1, model2, X_val_cnn, X_val_fe, X_test_cnn, X_test_fe, \n",
    "                 y_val, y_test):\n",
    "    prob_val_cnn = model1.predict(X_val_cnn) \n",
    "    prob_test_cnn = model1.predict(X_test_cnn)\n",
    "    \n",
    "    prob_val_fe = model2.predict_proba(X_val_fe) \n",
    "    prob_test_fe = model2.predict_proba(X_test_fe)\n",
    "    \n",
    "    y_val_label = np.argmax(y_val, axis=1)\n",
    "    y_test_label = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    prob_val_concat = np.concatenate((prob_val_cnn, prob_val_fe), axis=1)\n",
    "    prob_test_concat = np.concatenate((prob_test_cnn, prob_test_fe), axis=1)\n",
    "    model5.fit(prob_val_concat, y_val)\n",
    "    return model5, prob_test_concat, list(set(np.argmax(y_val, axis=1)))\n",
    "\n",
    "def evaluate_model5(model, prob_test_concat, y_test, label_list, filename, result_dict, plot=True):\n",
    "    prob = model.predict(prob_test_concat)\n",
    "    y_hat = np.argmax(prob, axis=1)\n",
    "    y_test_label = np.argmax(y_test,axis=1)\n",
    "    result_dict['macro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='macro'))\n",
    "    result_dict['micro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='micro'))\n",
    "    cm = confusion_matrix(y_test_label, y_hat)\n",
    "    plot_cm(y_test_label, y_hat, label_list)\n",
    "    plt.savefig(filename)\n",
    "    if plot != True:\n",
    "        plt.close()\n",
    "    return result_dict, cm\n",
    "\n",
    "\n",
    "def create_model5(model_1, model_2, X_val_cnn, X_val_fe, y_val,\n",
    "           X_test_cnn, X_test_fe, y_test, result_dict, n_trnval, rep):\n",
    "    print('\\n'+'*'*10+'model5'+'*'*10+'\\n')\n",
    "    modelname = 'model5'\n",
    "    filename = fn.format(ts=n_trnval, rep=rep, model=modelname)\n",
    "    model5 = build_model5()\n",
    "    model5, prob_test_concat5, label_list =train_model5_val(model5, model_1, model_2, X_val_cnn, X_val_fe, \n",
    "                                     X_test_cnn, X_test_fe, y_val, y_test)\n",
    "    result_dict, cm = evaluate_model5(model5, prob_test_concat5, y_test, label_list,\n",
    "                                      filename, result_dict,plot=False)\n",
    "    return result_dict, cm, model5, prob_test_concat5\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:46:53.019294Z",
     "start_time": "2020-05-22T02:46:53.010292Z"
    }
   },
   "outputs": [],
   "source": [
    "# train, val이 나눠짐\n",
    "def build_model6():\n",
    "    from sklearn.linear_model import Ridge\n",
    "    model = Ridge(alpha=0.0001, fit_intercept=False)\n",
    "    return model\n",
    "\n",
    "def train_model6_val(model6, model1, model3, X_val_cnn, X_val_fe_n, X_test_cnn, \n",
    "                 X_test_fe_n, y_val,y_test):\n",
    "    prob_val_cnn = model1.predict(X_val_cnn) \n",
    "    prob_test_cnn = model1.predict(X_test_cnn)\n",
    "    \n",
    "    prob_val_fnn = model3.predict(X_val_fe_n) \n",
    "    prob_test_fnn = model3.predict(X_test_fe_n)\n",
    "    \n",
    "    y_val_label = np.argmax(y_val, axis=1)\n",
    "    y_test_label = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    prob_val_concat = np.concatenate((prob_val_cnn, prob_val_fnn), axis=1)\n",
    "    prob_test_concat = np.concatenate((prob_test_cnn, prob_test_fnn), axis=1)\n",
    "    model6.fit(prob_val_concat, y_val)\n",
    "    return model6, prob_test_concat, list(set(np.argmax(y_val, axis=1)))\n",
    "\n",
    "def evaluate_model6(model, prob_test_concat, y_test, label_list, filename, result_dict, plot=True):\n",
    "    prob = model.predict(prob_test_concat)\n",
    "    y_hat = np.argmax(prob, axis=1)\n",
    "    y_test_label = np.argmax(y_test,axis=1)\n",
    "    result_dict['macro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='macro'))\n",
    "    result_dict['micro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='micro'))\n",
    "    cm = confusion_matrix(y_test_label, y_hat)\n",
    "    plot_cm(y_test_label, y_hat, label_list)\n",
    "    plt.savefig(filename)\n",
    "    if plot != True:\n",
    "        plt.close()\n",
    "    return result_dict, cm\n",
    "\n",
    "\n",
    "def create_model6_val(model_1, model_3, X_val_cnn, X_val_fe_n, y_val,\n",
    "           X_test_cnn, X_test_fe_n, y_test, result_dict, n_trnval, rep):\n",
    "    print('\\n'+'*'*10+'model6'+'*'*10+'\\n')\n",
    "    modelname = 'model6'\n",
    "    filename = fn.format(ts=n_trnval, rep=rep, model=modelname)\n",
    "    model6 = build_model6()\n",
    "    model6, prob_test_concat6, label_list =train_model6_val(model6, model_1, model_3, X_val_cnn, \n",
    "                                         X_val_fe_n, X_test_cnn, X_test_fe_n, y_val, y_test)\n",
    "    result_dict, cm = evaluate_model6(model6, prob_test_concat6, y_test, label_list,\n",
    "                                      filename, result_dict,plot=False)\n",
    "    return result_dict, cm, model6.coef_, model6, prob_test_concat6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:46:53.586752Z",
     "start_time": "2020-05-22T02:46:53.576781Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model6():\n",
    "    from sklearn.linear_model import Ridge\n",
    "    model = Ridge(alpha=0.1, fit_intercept=False)\n",
    "    return model\n",
    "\n",
    "def train_model6(model6, model1, model3, X_trainval_cnn, X_trainval_fe_normalized, X_test_cnn, \n",
    "                 X_test_fe_normalized, y_trainval,y_test):\n",
    "    prob_trainval_cnn = model1.predict(X_trainval_cnn) \n",
    "    prob_test_cnn = model1.predict(X_test_cnn)\n",
    "    \n",
    "    prob_trainval_fnn = model3.predict(X_trainval_fe_normalized) \n",
    "    prob_test_fnn = model3.predict(X_test_fe_normalized)\n",
    "    \n",
    "    y_trainval_label = np.argmax(y_trainval, axis=1)\n",
    "    y_test_label = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    prob_trainval_concat = np.concatenate((prob_trainval_cnn, prob_trainval_fnn), axis=1)\n",
    "    prob_test_concat = np.concatenate((prob_test_cnn, prob_test_fnn), axis=1)\n",
    "    model6.fit(prob_trainval_concat, y_trainval)\n",
    "    return model6, prob_test_concat, list(set(np.argmax(y_trainval, axis=1)))\n",
    "\n",
    "def evaluate_model6(model, prob_test_concat, y_test, label_list, filename, result_dict, plot=True):\n",
    "    prob = model.predict(prob_test_concat)\n",
    "    y_hat = np.argmax(prob, axis=1)\n",
    "    y_test_label = np.argmax(y_test,axis=1)\n",
    "    result_dict['macro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='macro'))\n",
    "    result_dict['micro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='micro'))\n",
    "    cm = confusion_matrix(y_test_label, y_hat)\n",
    "    plot_cm(y_test_label, y_hat, label_list)\n",
    "    plt.savefig(filename)\n",
    "    if plot != True:\n",
    "        plt.close()\n",
    "    return result_dict, cm\n",
    "\n",
    "\n",
    "def create_model6(model_1, model_3, X_trainval_cnn, X_trainval_fe_n, y_trainval,\n",
    "           X_test_cnn, X_test_fe_n, y_test, result_dict, n_trnval, rep):\n",
    "    print('\\n'+'*'*10+'model6'+'*'*10+'\\n')\n",
    "    modelname = 'model6'\n",
    "    filename = fn.format(ts=n_trnval, rep=rep, model=modelname)\n",
    "    model6 = build_model6()\n",
    "    model6, prob_test_concat6, label_list =train_model6(model6, model_1, model_3, X_trainval_cnn, \n",
    "                                         X_trainval_fe_n, X_test_cnn, X_test_fe_n, y_trainval, y_test)\n",
    "    result_dict, cm = evaluate_model6(model6, prob_test_concat6, y_test, label_list,\n",
    "                                      filename, result_dict,plot=False)\n",
    "    return result_dict, cm, model6.coef_, model6, prob_test_concat6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:46:54.745254Z",
     "start_time": "2020-05-22T02:46:54.721305Z"
    }
   },
   "outputs": [],
   "source": [
    "def experiment(savefile, replication=5, random_seed=3):\n",
    "    model_list = ['model1', 'model2', 'model3', 'model4', 'model5','model6']\n",
    "    pattern_list = [0, 1, 2, 3, 4, 5, 6, 7 ,8]\n",
    "    n_trnval_list = [500,5000,50000,162946]\n",
    "    f1_dict = {}\n",
    "    model6_list = []\n",
    "    for t in n_trnval_list:\n",
    "        f1_dict[t] = {}\n",
    "        for label in pattern_list:\n",
    "            f1_dict[t][label] = {}\n",
    "            for model in model_list:\n",
    "                f1_dict[t][label][str(model)] = []\n",
    "    \n",
    "    with open(savefile+'.csv', 'w', newline='') as csvfile:\n",
    "                fieldnames = ['training_size', \n",
    "                              'model1_macro','model2_macro','model3_macro','model4_macro','model5_macro','model6_macro',\n",
    "                              'model1_micro','model2_micro','model3_micro','model4_micro','model5_micro','model6_micro']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "    with open(savefile+'2.csv', 'w', newline='') as csvfile:\n",
    "                fieldnames = ['training_size', \n",
    "                              'model1','model2','model3','model4','model5','model6']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "    if not os.path.exists('./savefile'):\n",
    "        os.makedirs('./'+savefile)\n",
    "    for rep in range(replication):\n",
    "        RANDON_STATE = 20200321+rep+random_seed\n",
    "        X_trainval_cnn_big, X_test_cnn, y_trainval_big, y_test = train_test_split(X_cnn, y, \n",
    "                                       test_size=10000, random_state=RANDON_STATE,stratify=y)\n",
    "        X_trainval_fe_big, X_test_fe = train_test_split(X_fe, test_size=10000, \n",
    "                                                        random_state=RANDON_STATE,stratify=y)\n",
    "        start_time = time.time()\n",
    "        print('\\n','&'*20,rep+1,'replication','&'*20,'\\n\\n')\n",
    "        idx_list = [np.where(np.argmax(y_test,axis=1)==i)[0] for i in range(9)]\n",
    "        for n_trnval in n_trnval_list:\n",
    "            # Sampling\n",
    "            print('\\n','@'*20,rep+1,'replication',n_trnval,'@'*20,'\\n\\n')\n",
    "            global fn\n",
    "            fn = './'+savefile+'/result_{rep}_{ts:04d}_{model}.png'\n",
    "            np.random.seed(20200321+n_trnval*(rep+random_seed))\n",
    "            rand_id = np.random.choice(len(X_trainval_fe_big), n_trnval, replace=False)\n",
    "            X_trainval_cnn = X_trainval_cnn_big[rand_id]\n",
    "            X_trainval_fe = X_trainval_fe_big[rand_id]\n",
    "\n",
    "            y_trainval = y_trainval_big[rand_id]\n",
    "            # Split\n",
    "            X_train_cnn, X_val_cnn, y_train, y_val= train_test_split(X_trainval_cnn, \n",
    "                                                    y_trainval, test_size=0.2, random_state=RANDON_STATE)\n",
    "            X_train_fe, X_val_fe = train_test_split(X_trainval_fe, test_size=0.2, random_state=RANDON_STATE)\n",
    "            \n",
    "            mean, std = np.mean(X_train_fe,axis=0), np.std(X_train_fe,axis=0)\n",
    "            X_train_fe_n, X_val_fe_n, X_test_fe_n, X_trainval_fe_n = (X_train_fe-mean)/std, (X_val_fe-mean)/std, (X_test_fe-mean)/std, (X_trainval_fe-mean)/std\n",
    "            \n",
    "            # Train and Evaluate Each Model\n",
    "            result_dict = {'macro':[],'micro':[]}\n",
    "            label_list = list(set(np.argmax(y_trainval,axis=1)))\n",
    "            print('label_list',list(set(np.argmax(y_trainval,axis=1))))\n",
    "            print('label_list',list(set(np.argmax(y_train,axis=1))))\n",
    "\n",
    "            result_dict, cm, model1 = create_model1(X_train_cnn, y_train, X_val_cnn, y_val, \n",
    "                                              X_test_cnn, y_test,result_dict, n_trnval, rep)\n",
    "            result_dict, cm, model2 = create_model2(X_trainval_fe, y_trainval, \n",
    "                                              X_test_fe, y_test, result_dict, n_trnval, rep)\n",
    "            result_dict, cm ,model3= create_model3(X_train_fe_n, y_train, X_val_fe_n, y_val, \n",
    "                                             X_test_fe_n, y_test, result_dict,  n_trnval, rep)\n",
    "            result_dict, cm, model4= create_model4(X_train_cnn, X_train_fe_n, y_train, X_val_cnn, X_val_fe_n, y_val, \n",
    "                                             X_test_cnn, X_test_fe_n, y_test, result_dict, n_trnval, rep)\n",
    "            result_dict, cm, model5, prob_test_concat5 = create_model5(model1, model2, X_val_cnn, X_val_fe, y_trainval, \n",
    "                                             X_test_cnn, X_test_fe, y_test, result_dict, n_trnval, rep)\n",
    "            result_dict, cm, coeff, model6, prob_test_concat6 = create_model6(model1, model3, X_val_cnn, \n",
    "                        X_val_fe_n, y_val, X_test_cnn, X_test_fe_n, y_test, result_dict, n_trnval, rep)\n",
    "            \n",
    "            for pattern_num in pattern_list:\n",
    "                for model in model_list:\n",
    "                    if model == 'model2':\n",
    "                        y_hat = np.argmax(model2.predict_proba(X_test_fe[idx_list[pattern_num]]),axis=1)\n",
    "                    elif model == 'model4':\n",
    "                        y_hat = np.argmax(model4.predict([X_test_cnn[idx_list[pattern_num]], \n",
    "                                       X_test_fe_n[idx_list[pattern_num]]]),axis=1)\n",
    "                    elif model == 'model6':\n",
    "                        y_hat = np.argmax(model6.predict(prob_test_concat6[idx_list[pattern_num]]),axis=1)    \n",
    "                    elif model =='model1':\n",
    "                        y_hat = np.argmax(model1.predict(X_test_cnn[idx_list[pattern_num]]),axis=1)\n",
    "                    elif model == 'model3':\n",
    "                        y_hat = np.argmax(model3.predict(X_test_fe_n[idx_list[pattern_num]]),axis=1)\n",
    "                    elif model == 'model5':\n",
    "                        y_hat = np.argmax(model5.predict(prob_test_concat5[idx_list[pattern_num]]),axis=1)\n",
    "                    y_true = np.argmax(y_test[idx_list[pattern_num]],axis=1)\n",
    "                    fscore = np.max(f1_score(y_true, y_hat, average=None))\n",
    "                    f1_dict[n_trnval][pattern_num][str(model)].append(fscore)\n",
    "            \n",
    "            model6_list.append(model6)\n",
    "            # Record result\n",
    "            with open(savefile+'.csv', 'a', newline='') as csvfile:\n",
    "                fieldnames = ['training_size', \n",
    "                              'model1_macro','model2_macro','model3_macro','model4_macro','model5_macro',\n",
    "                              'model6_macro',\n",
    "                              'model1_micro','model2_micro','model3_micro','model4_micro','model5_micro',\n",
    "                              'model6_micro']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writerow({'training_size': n_trnval, \n",
    "                                 'model1_macro': result_dict['macro'][0],'model2_macro': result_dict['macro'][1],\n",
    "                                 'model3_macro': result_dict['macro'][2],'model4_macro': result_dict['macro'][3],\n",
    "                                 'model5_macro': result_dict['macro'][4],'model6_macro': result_dict['macro'][5],\n",
    "                                 'model1_micro': result_dict['micro'][0],'model2_micro': result_dict['micro'][1],\n",
    "                                 'model3_micro': result_dict['micro'][2],'model4_micro': result_dict['micro'][3],\n",
    "                                 'model5_micro': result_dict['micro'][4],'model6_micro': result_dict['micro'][5],\n",
    "                                 })\n",
    "        \n",
    "        print('\\n\\n',(time.time()-start_time)/60,'min per replication\\n\\n')\n",
    "    for n_trnval in n_trnval_list:\n",
    "        for pattern in pattern_list:\n",
    "            for model in model_list:\n",
    "                f1_dict[n_trnval][pattern][model] = np.mean(f1_dict[n_trnval][pattern][model])\n",
    "    with open(savefile+'_2.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['pattern', \n",
    "                      'model1','model2','model3','model4','model5','model6']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        for n_trnval in n_trnval_list:\n",
    "            writer.writerow({'pattern':n_trnval})\n",
    "            for pattern in pattern_list:\n",
    "                writer.writerow({'pattern': pattern,\n",
    "                                 'model1':f1_dict[n_trnval][pattern]['model1'],\n",
    "                                 'model2':f1_dict[n_trnval][pattern]['model2'],\n",
    "                                 'model3':f1_dict[n_trnval][pattern]['model3'],\n",
    "                                 'model4':f1_dict[n_trnval][pattern]['model4'],\n",
    "                                 'model5':f1_dict[n_trnval][pattern]['model5'],\n",
    "                                 'model6':f1_dict[n_trnval][pattern]['model6']})\n",
    "    return model6_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T07:57:17.835660Z",
     "start_time": "2020-05-22T23:24:43.265324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 1 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 1 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 2, 3, 4, 5, 6, 8]\n",
      "label_list [0, 2, 3, 4, 5, 6, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 1.8631 - accuracy: 0.8675 - val_loss: 1.3769 - val_accuracy: 0.8700\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.9443 - accuracy: 0.8675 - val_loss: 0.7273 - val_accuracy: 0.8700\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.7450 - accuracy: 0.8675 - val_loss: 0.6914 - val_accuracy: 0.8700\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.6651 - accuracy: 0.8675 - val_loss: 0.6265 - val_accuracy: 0.8700\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.6536 - accuracy: 0.8675 - val_loss: 0.6171 - val_accuracy: 0.8700\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.6243 - accuracy: 0.8675 - val_loss: 0.6102 - val_accuracy: 0.8700\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.6142 - accuracy: 0.8675 - val_loss: 0.5958 - val_accuracy: 0.8700\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.6035 - accuracy: 0.8675 - val_loss: 0.5881 - val_accuracy: 0.8700\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 203us/step - loss: 0.5973 - accuracy: 0.8675 - val_loss: 0.5829 - val_accuracy: 0.8700\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.5932 - accuracy: 0.8675 - val_loss: 0.5774 - val_accuracy: 0.8700\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.5820 - accuracy: 0.86 - 0s 190us/step - loss: 0.5862 - accuracy: 0.8675 - val_loss: 0.5732 - val_accuracy: 0.8700\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.5869 - accuracy: 0.8675 - val_loss: 0.5709 - val_accuracy: 0.8700\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 208us/step - loss: 0.5832 - accuracy: 0.8675 - val_loss: 0.5638 - val_accuracy: 0.8700\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.5731 - accuracy: 0.8675 - val_loss: 0.5592 - val_accuracy: 0.8700\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.5710 - accuracy: 0.8675 - val_loss: 0.5541 - val_accuracy: 0.8700\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.5710 - accuracy: 0.8675 - val_loss: 0.5553 - val_accuracy: 0.8700\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 194us/step - loss: 0.5675 - accuracy: 0.8675 - val_loss: 0.5497 - val_accuracy: 0.8700\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 194us/step - loss: 0.5676 - accuracy: 0.8675 - val_loss: 0.5455 - val_accuracy: 0.8700\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 192us/step - loss: 0.5520 - accuracy: 0.8675 - val_loss: 0.5399 - val_accuracy: 0.8700\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.5513 - accuracy: 0.8675 - val_loss: 0.5370 - val_accuracy: 0.8700\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.5399 - accuracy: 0.8675 - val_loss: 0.5250 - val_accuracy: 0.8700\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5313 - accuracy: 0.8675 - val_loss: 0.5278 - val_accuracy: 0.8700\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.5246 - accuracy: 0.8675 - val_loss: 0.5125 - val_accuracy: 0.8700\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.5153 - accuracy: 0.8675 - val_loss: 0.4991 - val_accuracy: 0.8700\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.5027 - accuracy: 0.8675 - val_loss: 0.4965 - val_accuracy: 0.8700\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.4969 - accuracy: 0.8675 - val_loss: 0.5044 - val_accuracy: 0.8700\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.4926 - accuracy: 0.8675 - val_loss: 0.4761 - val_accuracy: 0.8700\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.4864 - accuracy: 0.8700 - val_loss: 0.4715 - val_accuracy: 0.8800\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.4627 - accuracy: 0.8725 - val_loss: 0.4646 - val_accuracy: 0.8700\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.4430 - accuracy: 0.8800 - val_loss: 0.4802 - val_accuracy: 0.8700\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.4310 - accuracy: 0.8900 - val_loss: 0.4839 - val_accuracy: 0.8700\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.4389 - accuracy: 0.8850 - val_loss: 0.4712 - val_accuracy: 0.8700\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3986 - accuracy: 0.9025 - val_loss: 0.4540 - val_accuracy: 0.8700\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 193us/step - loss: 0.4084 - accuracy: 0.8975 - val_loss: 0.4488 - val_accuracy: 0.8800\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 185us/step - loss: 0.3786 - accuracy: 0.9050 - val_loss: 0.4099 - val_accuracy: 0.9100\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 202us/step - loss: 0.3975 - accuracy: 0.9025 - val_loss: 0.4097 - val_accuracy: 0.9100\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.3642 - accuracy: 0.9100 - val_loss: 0.3781 - val_accuracy: 0.8900\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.3399 - accuracy: 0.9125 - val_loss: 0.3620 - val_accuracy: 0.9100\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.3365 - accuracy: 0.9100 - val_loss: 0.3679 - val_accuracy: 0.9100\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.3319 - accuracy: 0.9125 - val_loss: 0.3873 - val_accuracy: 0.8900\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.3190 - accuracy: 0.9150 - val_loss: 0.3738 - val_accuracy: 0.9000\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.3115 - accuracy: 0.9175 - val_loss: 0.3456 - val_accuracy: 0.9000\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 192us/step - loss: 0.3027 - accuracy: 0.9200 - val_loss: 0.3487 - val_accuracy: 0.9100\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.2948 - accuracy: 0.9200 - val_loss: 0.3410 - val_accuracy: 0.9100\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.2898 - accuracy: 0.9150 - val_loss: 0.3335 - val_accuracy: 0.9200\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.2760 - accuracy: 0.9200 - val_loss: 0.3167 - val_accuracy: 0.9200\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.2891 - accuracy: 0.9200 - val_loss: 0.3530 - val_accuracy: 0.9100\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.2736 - accuracy: 0.9175 - val_loss: 0.3539 - val_accuracy: 0.9100\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.2599 - accuracy: 0.9325 - val_loss: 0.3301 - val_accuracy: 0.9200\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.2742 - accuracy: 0.9275 - val_loss: 0.3757 - val_accuracy: 0.9000\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 191us/step - loss: 0.2743 - accuracy: 0.9250 - val_loss: 0.3891 - val_accuracy: 0.9100\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 187us/step - loss: 0.2502 - accuracy: 0.9300 - val_loss: 0.3240 - val_accuracy: 0.9100\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.2332 - accuracy: 0.9325 - val_loss: 0.3071 - val_accuracy: 0.9300\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.2449 - accuracy: 0.9325 - val_loss: 0.2984 - val_accuracy: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 201us/step - loss: 0.2508 - accuracy: 0.9300 - val_loss: 0.3071 - val_accuracy: 0.9200\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 202us/step - loss: 0.2381 - accuracy: 0.9325 - val_loss: 0.3759 - val_accuracy: 0.9100\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.2294 - accuracy: 0.9275 - val_loss: 0.4039 - val_accuracy: 0.9000\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.2239 - accuracy: 0.9350 - val_loss: 0.4702 - val_accuracy: 0.9000\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2351 - accuracy: 0.9275 - val_loss: 0.3261 - val_accuracy: 0.9100\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 192us/step - loss: 0.2073 - accuracy: 0.9350 - val_loss: 0.3700 - val_accuracy: 0.9100\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 196us/step - loss: 0.2058 - accuracy: 0.9425 - val_loss: 0.4828 - val_accuracy: 0.9000\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.2331 - accuracy: 0.9250 - val_loss: 0.3868 - val_accuracy: 0.9000\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.1920 - accuracy: 0.9425 - val_loss: 0.3042 - val_accuracy: 0.9200\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.2260 - accuracy: 0.9350 - val_loss: 0.2911 - val_accuracy: 0.9300\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.2517 - accuracy: 0.9275 - val_loss: 0.3045 - val_accuracy: 0.9300\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.1975 - accuracy: 0.9400 - val_loss: 0.2780 - val_accuracy: 0.9300\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.1840 - accuracy: 0.9550 - val_loss: 0.3255 - val_accuracy: 0.9200\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 194us/step - loss: 0.1803 - accuracy: 0.9500 - val_loss: 0.3852 - val_accuracy: 0.9000\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 191us/step - loss: 0.1699 - accuracy: 0.9575 - val_loss: 0.3262 - val_accuracy: 0.9200\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.1773 - accuracy: 0.9550 - val_loss: 0.4102 - val_accuracy: 0.9100\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1585 - accuracy: 0.9600 - val_loss: 0.2746 - val_accuracy: 0.9300\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1589 - accuracy: 0.9600 - val_loss: 0.3404 - val_accuracy: 0.9200\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.1491 - accuracy: 0.9625 - val_loss: 0.2933 - val_accuracy: 0.9200\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 185us/step - loss: 0.1512 - accuracy: 0.9650 - val_loss: 0.2962 - val_accuracy: 0.9200\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 196us/step - loss: 0.1595 - accuracy: 0.9550 - val_loss: 0.2957 - val_accuracy: 0.9200\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.1529 - accuracy: 0.9550 - val_loss: 0.3187 - val_accuracy: 0.9200\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1420 - accuracy: 0.9625 - val_loss: 0.2870 - val_accuracy: 0.9100\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.1371 - accuracy: 0.9650 - val_loss: 0.3096 - val_accuracy: 0.9100\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.1283 - accuracy: 0.9625 - val_loss: 0.3243 - val_accuracy: 0.9100\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 185us/step - loss: 0.1224 - accuracy: 0.9750 - val_loss: 0.3350 - val_accuracy: 0.9200\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.1192 - accuracy: 0.9675 - val_loss: 0.3758 - val_accuracy: 0.9200\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.1257 - accuracy: 0.9675 - val_loss: 0.4177 - val_accuracy: 0.9000\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.1263 - accuracy: 0.9700 - val_loss: 0.4803 - val_accuracy: 0.9000\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.1164 - accuracy: 0.9700 - val_loss: 0.4754 - val_accuracy: 0.9000\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 180us/step - loss: 0.1261 - accuracy: 0.9625 - val_loss: 0.3796 - val_accuracy: 0.9000\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 196us/step - loss: 0.1334 - accuracy: 0.9600 - val_loss: 0.3755 - val_accuracy: 0.9200\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1032 - accuracy: 0.9725 - val_loss: 0.2913 - val_accuracy: 0.9200\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1118 - accuracy: 0.9700 - val_loss: 0.3184 - val_accuracy: 0.9100\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0942 - accuracy: 0.9800 - val_loss: 0.3148 - val_accuracy: 0.9100\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0993 - accuracy: 0.9750 - val_loss: 0.2884 - val_accuracy: 0.9200\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 193us/step - loss: 0.1311 - accuracy: 0.9700 - val_loss: 0.3149 - val_accuracy: 0.9100\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.483539156300143\n",
      "F1 Micro: 0.9243950097700285\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5477918863728121\n",
      "F1 Micro: 0.9333132922491106\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 290us/step - loss: 2.2955 - accuracy: 0.0700 - val_loss: 2.1055 - val_accuracy: 0.1200\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 2.0516 - accuracy: 0.2875 - val_loss: 1.8505 - val_accuracy: 0.4600\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 1.8775 - accuracy: 0.5000 - val_loss: 1.6866 - val_accuracy: 0.5800\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.7701 - accuracy: 0.5425 - val_loss: 1.5801 - val_accuracy: 0.6500\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 1.6937 - accuracy: 0.5850 - val_loss: 1.5088 - val_accuracy: 0.6500\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 1.6333 - accuracy: 0.6050 - val_loss: 1.4545 - val_accuracy: 0.6700\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 1.5778 - accuracy: 0.6225 - val_loss: 1.4043 - val_accuracy: 0.6700\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 1.5241 - accuracy: 0.6325 - val_loss: 1.3557 - val_accuracy: 0.6900\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 1.4709 - accuracy: 0.6425 - val_loss: 1.3087 - val_accuracy: 0.7000\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 1.4175 - accuracy: 0.6550 - val_loss: 1.2626 - val_accuracy: 0.7000\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 1.3630 - accuracy: 0.6700 - val_loss: 1.2169 - val_accuracy: 0.7000\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 1.3057 - accuracy: 0.6925 - val_loss: 1.1703 - val_accuracy: 0.7400\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 71us/step - loss: 1.2500 - accuracy: 0.7225 - val_loss: 1.1242 - val_accuracy: 0.7600\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 1.1907 - accuracy: 0.7625 - val_loss: 1.0765 - val_accuracy: 0.7900\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 1.1303 - accuracy: 0.7825 - val_loss: 1.0257 - val_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 1.0694 - accuracy: 0.8025 - val_loss: 0.9779 - val_accuracy: 0.8100\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 70us/step - loss: 1.0100 - accuracy: 0.8125 - val_loss: 0.9326 - val_accuracy: 0.8600\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.9483 - accuracy: 0.8325 - val_loss: 0.8844 - val_accuracy: 0.8700\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.8895 - accuracy: 0.8625 - val_loss: 0.8400 - val_accuracy: 0.8800\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.8317 - accuracy: 0.8850 - val_loss: 0.7981 - val_accuracy: 0.8800\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 71us/step - loss: 0.7755 - accuracy: 0.8900 - val_loss: 0.7534 - val_accuracy: 0.9000\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.7216 - accuracy: 0.9000 - val_loss: 0.7125 - val_accuracy: 0.9100\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.6715 - accuracy: 0.9100 - val_loss: 0.6752 - val_accuracy: 0.9100\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.6243 - accuracy: 0.9250 - val_loss: 0.6395 - val_accuracy: 0.9100\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.5794 - accuracy: 0.9350 - val_loss: 0.6063 - val_accuracy: 0.9100\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.5377 - accuracy: 0.9425 - val_loss: 0.5745 - val_accuracy: 0.9300\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.5001 - accuracy: 0.9450 - val_loss: 0.5455 - val_accuracy: 0.9300\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.4652 - accuracy: 0.9550 - val_loss: 0.5218 - val_accuracy: 0.9300\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.4327 - accuracy: 0.9625 - val_loss: 0.4985 - val_accuracy: 0.9400\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.4060 - accuracy: 0.9650 - val_loss: 0.4781 - val_accuracy: 0.9400\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.3768 - accuracy: 0.9675 - val_loss: 0.4559 - val_accuracy: 0.9400\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.3529 - accuracy: 0.9700 - val_loss: 0.4379 - val_accuracy: 0.9400\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.3310 - accuracy: 0.9700 - val_loss: 0.4215 - val_accuracy: 0.9500\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.3105 - accuracy: 0.9700 - val_loss: 0.4067 - val_accuracy: 0.9500\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2923 - accuracy: 0.9700 - val_loss: 0.3927 - val_accuracy: 0.9500\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.2760 - accuracy: 0.9750 - val_loss: 0.3798 - val_accuracy: 0.9500\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2608 - accuracy: 0.9750 - val_loss: 0.3695 - val_accuracy: 0.9500\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2474 - accuracy: 0.9775 - val_loss: 0.3579 - val_accuracy: 0.9500\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2347 - accuracy: 0.9800 - val_loss: 0.3481 - val_accuracy: 0.9500\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2233 - accuracy: 0.9800 - val_loss: 0.3399 - val_accuracy: 0.9500\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2132 - accuracy: 0.9800 - val_loss: 0.3329 - val_accuracy: 0.9500\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.2038 - accuracy: 0.9800 - val_loss: 0.3262 - val_accuracy: 0.9500\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.1953 - accuracy: 0.9800 - val_loss: 0.3188 - val_accuracy: 0.9500\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.1870 - accuracy: 0.9800 - val_loss: 0.3130 - val_accuracy: 0.9500\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1802 - accuracy: 0.9800 - val_loss: 0.3075 - val_accuracy: 0.9500\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.1733 - accuracy: 0.9800 - val_loss: 0.3028 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.1672 - accuracy: 0.9800 - val_loss: 0.2979 - val_accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 1.00 - 0s 70us/step - loss: 0.1615 - accuracy: 0.9800 - val_loss: 0.2936 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.1560 - accuracy: 0.9800 - val_loss: 0.2893 - val_accuracy: 0.9500\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1508 - accuracy: 0.9800 - val_loss: 0.2856 - val_accuracy: 0.9500\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1461 - accuracy: 0.9800 - val_loss: 0.2823 - val_accuracy: 0.9500\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1414 - accuracy: 0.9800 - val_loss: 0.2785 - val_accuracy: 0.9500\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.1377 - accuracy: 0.9800 - val_loss: 0.2759 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.1334 - accuracy: 0.9800 - val_loss: 0.2734 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.1298 - accuracy: 0.9800 - val_loss: 0.2709 - val_accuracy: 0.9500\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1264 - accuracy: 0.9800 - val_loss: 0.2685 - val_accuracy: 0.9500\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1229 - accuracy: 0.9825 - val_loss: 0.2662 - val_accuracy: 0.9500\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1198 - accuracy: 0.9825 - val_loss: 0.2647 - val_accuracy: 0.9400\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1167 - accuracy: 0.9825 - val_loss: 0.2620 - val_accuracy: 0.9400\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.1139 - accuracy: 0.9825 - val_loss: 0.2601 - val_accuracy: 0.9400\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1111 - accuracy: 0.9825 - val_loss: 0.2586 - val_accuracy: 0.9400\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1084 - accuracy: 0.9825 - val_loss: 0.2566 - val_accuracy: 0.9400\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.1058 - accuracy: 0.9825 - val_loss: 0.2545 - val_accuracy: 0.9400\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.1034 - accuracy: 0.9825 - val_loss: 0.2534 - val_accuracy: 0.9400\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.96 - 0s 80us/step - loss: 0.1011 - accuracy: 0.9825 - val_loss: 0.2518 - val_accuracy: 0.9400\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0990 - accuracy: 0.9825 - val_loss: 0.2503 - val_accuracy: 0.9400\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0966 - accuracy: 0.9825 - val_loss: 0.2494 - val_accuracy: 0.9400\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0948 - accuracy: 0.9825 - val_loss: 0.2480 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0924 - accuracy: 0.9825 - val_loss: 0.2470 - val_accuracy: 0.9500\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0910 - accuracy: 0.9825 - val_loss: 0.2458 - val_accuracy: 0.9400\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0890 - accuracy: 0.9825 - val_loss: 0.2444 - val_accuracy: 0.9500\n",
      "Epoch 72/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 85us/step - loss: 0.0870 - accuracy: 0.9825 - val_loss: 0.2433 - val_accuracy: 0.9500\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 66us/step - loss: 0.0852 - accuracy: 0.9850 - val_loss: 0.2428 - val_accuracy: 0.9500\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0835 - accuracy: 0.9850 - val_loss: 0.2415 - val_accuracy: 0.9500\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0820 - accuracy: 0.9850 - val_loss: 0.2419 - val_accuracy: 0.9500\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0802 - accuracy: 0.9875 - val_loss: 0.2407 - val_accuracy: 0.9500\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.93 - 0s 70us/step - loss: 0.0786 - accuracy: 0.9875 - val_loss: 0.2396 - val_accuracy: 0.9500\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0771 - accuracy: 0.9875 - val_loss: 0.2393 - val_accuracy: 0.9500\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0756 - accuracy: 0.9875 - val_loss: 0.2377 - val_accuracy: 0.9500\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0742 - accuracy: 0.9900 - val_loss: 0.2373 - val_accuracy: 0.9500\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0726 - accuracy: 0.9900 - val_loss: 0.2360 - val_accuracy: 0.9500\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0712 - accuracy: 0.9900 - val_loss: 0.2354 - val_accuracy: 0.9500\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 71us/step - loss: 0.0698 - accuracy: 0.9900 - val_loss: 0.2354 - val_accuracy: 0.9500\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0686 - accuracy: 0.9900 - val_loss: 0.2350 - val_accuracy: 0.9500\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0674 - accuracy: 0.9900 - val_loss: 0.2352 - val_accuracy: 0.9500\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0662 - accuracy: 0.9900 - val_loss: 0.2353 - val_accuracy: 0.9500\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0648 - accuracy: 0.9925 - val_loss: 0.2348 - val_accuracy: 0.9500\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0635 - accuracy: 0.9925 - val_loss: 0.2345 - val_accuracy: 0.9500\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0628 - accuracy: 0.9900 - val_loss: 0.2340 - val_accuracy: 0.9500\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0612 - accuracy: 0.9900 - val_loss: 0.2331 - val_accuracy: 0.9500\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0602 - accuracy: 0.9925 - val_loss: 0.2324 - val_accuracy: 0.9500\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0591 - accuracy: 0.9925 - val_loss: 0.2322 - val_accuracy: 0.9500\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0580 - accuracy: 0.9925 - val_loss: 0.2321 - val_accuracy: 0.9500\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0572 - accuracy: 0.9950 - val_loss: 0.2322 - val_accuracy: 0.9500\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0561 - accuracy: 0.9950 - val_loss: 0.2315 - val_accuracy: 0.9500\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0550 - accuracy: 0.9950 - val_loss: 0.2321 - val_accuracy: 0.9500\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0540 - accuracy: 0.9950 - val_loss: 0.2310 - val_accuracy: 0.9500\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0531 - accuracy: 0.9950 - val_loss: 0.2310 - val_accuracy: 0.9500\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0521 - accuracy: 0.9950 - val_loss: 0.2306 - val_accuracy: 0.9500\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0513 - accuracy: 0.9950 - val_loss: 0.2309 - val_accuracy: 0.9500\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0505 - accuracy: 0.9925 - val_loss: 0.2305 - val_accuracy: 0.9500\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0496 - accuracy: 0.9950 - val_loss: 0.2297 - val_accuracy: 0.9500\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0489 - accuracy: 0.9950 - val_loss: 0.2297 - val_accuracy: 0.9500\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0478 - accuracy: 0.9950 - val_loss: 0.2294 - val_accuracy: 0.9500\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0469 - accuracy: 0.9950 - val_loss: 0.2296 - val_accuracy: 0.9500\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0463 - accuracy: 0.9950 - val_loss: 0.2303 - val_accuracy: 0.9500\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0454 - accuracy: 0.9975 - val_loss: 0.2299 - val_accuracy: 0.9500\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0447 - accuracy: 0.9975 - val_loss: 0.2296 - val_accuracy: 0.9500\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0440 - accuracy: 0.9975 - val_loss: 0.2295 - val_accuracy: 0.9500\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0434 - accuracy: 0.9950 - val_loss: 0.2299 - val_accuracy: 0.9500\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0426 - accuracy: 0.9975 - val_loss: 0.2307 - val_accuracy: 0.9500\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0418 - accuracy: 0.9975 - val_loss: 0.2303 - val_accuracy: 0.9500\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0411 - accuracy: 0.9975 - val_loss: 0.2304 - val_accuracy: 0.9500\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0404 - accuracy: 0.9975 - val_loss: 0.2304 - val_accuracy: 0.9500\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 64us/step - loss: 0.0399 - accuracy: 0.9975 - val_loss: 0.2305 - val_accuracy: 0.9500\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0393 - accuracy: 0.9975 - val_loss: 0.2303 - val_accuracy: 0.9500\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0386 - accuracy: 0.9975 - val_loss: 0.2301 - val_accuracy: 0.9500\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0378 - accuracy: 0.9975 - val_loss: 0.2303 - val_accuracy: 0.9500\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0372 - accuracy: 0.9975 - val_loss: 0.2302 - val_accuracy: 0.9500\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0370 - accuracy: 0.9975 - val_loss: 0.2305 - val_accuracy: 0.9500\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0361 - accuracy: 0.9975 - val_loss: 0.2312 - val_accuracy: 0.9500\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0355 - accuracy: 0.9975 - val_loss: 0.2309 - val_accuracy: 0.9500\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0349 - accuracy: 0.9975 - val_loss: 0.2312 - val_accuracy: 0.9500\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0343 - accuracy: 0.9975 - val_loss: 0.2307 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5854971408538189\n",
      "F1 Micro: 0.9392254120947945\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 733us/step - loss: 1.8233 - accuracy: 0.5500 - val_loss: 1.3563 - val_accuracy: 0.8000\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 208us/step - loss: 0.9658 - accuracy: 0.8400 - val_loss: 0.5091 - val_accuracy: 0.9000\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.4676 - accuracy: 0.8775 - val_loss: 0.5006 - val_accuracy: 0.8700\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.4321 - accuracy: 0.8825 - val_loss: 0.4100 - val_accuracy: 0.9000\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.3726 - accuracy: 0.9075 - val_loss: 0.3830 - val_accuracy: 0.9000\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.3525 - accuracy: 0.9150 - val_loss: 0.3635 - val_accuracy: 0.9000\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.3325 - accuracy: 0.9150 - val_loss: 0.3512 - val_accuracy: 0.9000\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.3167 - accuracy: 0.9200 - val_loss: 0.3378 - val_accuracy: 0.9000\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.3012 - accuracy: 0.9250 - val_loss: 0.3292 - val_accuracy: 0.9000\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.2903 - accuracy: 0.9275 - val_loss: 0.3217 - val_accuracy: 0.9000\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.2755 - accuracy: 0.9325 - val_loss: 0.3104 - val_accuracy: 0.9100\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.2663 - accuracy: 0.9325 - val_loss: 0.3056 - val_accuracy: 0.9000\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.2536 - accuracy: 0.9325 - val_loss: 0.2987 - val_accuracy: 0.9200\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.2466 - accuracy: 0.9375 - val_loss: 0.2925 - val_accuracy: 0.9300\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.2349 - accuracy: 0.9400 - val_loss: 0.2919 - val_accuracy: 0.9100\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.2285 - accuracy: 0.9450 - val_loss: 0.2884 - val_accuracy: 0.9200\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.2206 - accuracy: 0.9500 - val_loss: 0.2778 - val_accuracy: 0.9400\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.2128 - accuracy: 0.9475 - val_loss: 0.2778 - val_accuracy: 0.9400\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.2065 - accuracy: 0.9500 - val_loss: 0.2712 - val_accuracy: 0.9400\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.1991 - accuracy: 0.9525 - val_loss: 0.2716 - val_accuracy: 0.9300\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.1925 - accuracy: 0.9525 - val_loss: 0.2650 - val_accuracy: 0.9400\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 202us/step - loss: 0.1870 - accuracy: 0.9525 - val_loss: 0.2628 - val_accuracy: 0.9400\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.1837 - accuracy: 0.9575 - val_loss: 0.2655 - val_accuracy: 0.9400\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.1807 - accuracy: 0.9500 - val_loss: 0.2642 - val_accuracy: 0.9400\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.1790 - accuracy: 0.9600 - val_loss: 0.2520 - val_accuracy: 0.9400\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 202us/step - loss: 0.1743 - accuracy: 0.9500 - val_loss: 0.2543 - val_accuracy: 0.9400\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1628 - accuracy: 0.9625 - val_loss: 0.2481 - val_accuracy: 0.9400\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.1584 - accuracy: 0.9625 - val_loss: 0.2471 - val_accuracy: 0.9400\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.1546 - accuracy: 0.9650 - val_loss: 0.2455 - val_accuracy: 0.9400\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.1521 - accuracy: 0.9625 - val_loss: 0.2490 - val_accuracy: 0.9400\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.1510 - accuracy: 0.9675 - val_loss: 0.2416 - val_accuracy: 0.9400\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.1444 - accuracy: 0.9650 - val_loss: 0.2451 - val_accuracy: 0.9400\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 202us/step - loss: 0.1390 - accuracy: 0.9675 - val_loss: 0.2373 - val_accuracy: 0.9400\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 192us/step - loss: 0.1361 - accuracy: 0.9650 - val_loss: 0.2401 - val_accuracy: 0.9400\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.1323 - accuracy: 0.9675 - val_loss: 0.2329 - val_accuracy: 0.9500\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.1321 - accuracy: 0.9650 - val_loss: 0.2395 - val_accuracy: 0.9400\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.1249 - accuracy: 0.9725 - val_loss: 0.2296 - val_accuracy: 0.9500\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 208us/step - loss: 0.1222 - accuracy: 0.9725 - val_loss: 0.2355 - val_accuracy: 0.9400\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1196 - accuracy: 0.9675 - val_loss: 0.2343 - val_accuracy: 0.9500\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1166 - accuracy: 0.9725 - val_loss: 0.2275 - val_accuracy: 0.9400\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1147 - accuracy: 0.9750 - val_loss: 0.2339 - val_accuracy: 0.9500\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1119 - accuracy: 0.9725 - val_loss: 0.2244 - val_accuracy: 0.9500\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.1084 - accuracy: 0.9750 - val_loss: 0.2282 - val_accuracy: 0.9500\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.1081 - accuracy: 0.9700 - val_loss: 0.2296 - val_accuracy: 0.9500\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.1055 - accuracy: 0.9800 - val_loss: 0.2271 - val_accuracy: 0.9500\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0999 - accuracy: 0.9750 - val_loss: 0.2236 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.0974 - accuracy: 0.9800 - val_loss: 0.2284 - val_accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0954 - accuracy: 0.9750 - val_loss: 0.2274 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0922 - accuracy: 0.9775 - val_loss: 0.2252 - val_accuracy: 0.9500\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 193us/step - loss: 0.0919 - accuracy: 0.9775 - val_loss: 0.2302 - val_accuracy: 0.9500\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0878 - accuracy: 0.9825 - val_loss: 0.2231 - val_accuracy: 0.9500\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.0848 - accuracy: 0.9800 - val_loss: 0.2262 - val_accuracy: 0.9500\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0825 - accuracy: 0.9800 - val_loss: 0.2201 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.0798 - accuracy: 0.9850 - val_loss: 0.2259 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.0776 - accuracy: 0.9850 - val_loss: 0.2252 - val_accuracy: 0.9600\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0771 - accuracy: 0.9800 - val_loss: 0.2227 - val_accuracy: 0.9500\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0741 - accuracy: 0.9875 - val_loss: 0.2281 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0728 - accuracy: 0.9875 - val_loss: 0.2276 - val_accuracy: 0.9600\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0694 - accuracy: 0.9875 - val_loss: 0.2284 - val_accuracy: 0.9500\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0677 - accuracy: 0.9875 - val_loss: 0.2246 - val_accuracy: 0.9600\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0656 - accuracy: 0.9900 - val_loss: 0.2271 - val_accuracy: 0.9500\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.0638 - accuracy: 0.9900 - val_loss: 0.2139 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.0625 - accuracy: 0.9925 - val_loss: 0.2491 - val_accuracy: 0.9600\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.0621 - accuracy: 0.9875 - val_loss: 0.2252 - val_accuracy: 0.9500\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0598 - accuracy: 0.9875 - val_loss: 0.2196 - val_accuracy: 0.9500\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.0585 - accuracy: 0.9925 - val_loss: 0.2516 - val_accuracy: 0.9600\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.0597 - accuracy: 0.9900 - val_loss: 0.2251 - val_accuracy: 0.9500\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0548 - accuracy: 0.9900 - val_loss: 0.2204 - val_accuracy: 0.9600\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.0520 - accuracy: 0.9900 - val_loss: 0.2323 - val_accuracy: 0.9600\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 203us/step - loss: 0.0503 - accuracy: 0.9925 - val_loss: 0.2417 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0500 - accuracy: 0.9950 - val_loss: 0.2389 - val_accuracy: 0.9600\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 201us/step - loss: 0.0467 - accuracy: 0.9925 - val_loss: 0.2391 - val_accuracy: 0.9600\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0464 - accuracy: 0.9925 - val_loss: 0.2140 - val_accuracy: 0.9500\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 203us/step - loss: 0.0488 - accuracy: 0.9900 - val_loss: 0.2499 - val_accuracy: 0.9600\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 206us/step - loss: 0.0458 - accuracy: 0.9925 - val_loss: 0.2416 - val_accuracy: 0.9600\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 201us/step - loss: 0.0446 - accuracy: 0.9925 - val_loss: 0.2217 - val_accuracy: 0.9500\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.0413 - accuracy: 0.9950 - val_loss: 0.2490 - val_accuracy: 0.9600\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0384 - accuracy: 0.9975 - val_loss: 0.2378 - val_accuracy: 0.9600\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0381 - accuracy: 0.9950 - val_loss: 0.2401 - val_accuracy: 0.9600\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0378 - accuracy: 0.9975 - val_loss: 0.2637 - val_accuracy: 0.9600\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0354 - accuracy: 0.9975 - val_loss: 0.2332 - val_accuracy: 0.9500\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 202us/step - loss: 0.0344 - accuracy: 0.9975 - val_loss: 0.2503 - val_accuracy: 0.9600\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5583896426076104\n",
      "F1 Micro: 0.9375219199358684\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6047468856149599\n",
      "F1 Micro: 0.9376221253569818\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5924438361411358\n",
      "F1 Micro: 0.9402274663059271\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 1 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 229us/step - loss: 0.8226 - accuracy: 0.8600 - val_loss: 0.6188 - val_accuracy: 0.8620\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.6266 - accuracy: 0.8602 - val_loss: 0.5951 - val_accuracy: 0.8620\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.5823 - accuracy: 0.8602 - val_loss: 0.5287 - val_accuracy: 0.8620\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.4684 - accuracy: 0.8742 - val_loss: 0.4087 - val_accuracy: 0.8880\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.3760 - accuracy: 0.9057 - val_loss: 0.3549 - val_accuracy: 0.9150\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.3288 - accuracy: 0.9178 - val_loss: 0.3312 - val_accuracy: 0.9170\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.2966 - accuracy: 0.9225 - val_loss: 0.2955 - val_accuracy: 0.9200\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.2719 - accuracy: 0.9273 - val_loss: 0.2885 - val_accuracy: 0.9250\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.2499 - accuracy: 0.9302 - val_loss: 0.2652 - val_accuracy: 0.9210\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.2240 - accuracy: 0.9385 - val_loss: 0.2719 - val_accuracy: 0.9300\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.2130 - accuracy: 0.9430 - val_loss: 0.2259 - val_accuracy: 0.9340\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.1907 - accuracy: 0.9470 - val_loss: 0.2202 - val_accuracy: 0.9340\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.1833 - accuracy: 0.9505 - val_loss: 0.2077 - val_accuracy: 0.9400\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.1612 - accuracy: 0.9545 - val_loss: 0.2415 - val_accuracy: 0.9360\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.1571 - accuracy: 0.9553 - val_loss: 0.2029 - val_accuracy: 0.9370\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.1505 - accuracy: 0.9590 - val_loss: 0.1847 - val_accuracy: 0.9450\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.1476 - accuracy: 0.9603 - val_loss: 0.2106 - val_accuracy: 0.9440\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.1386 - accuracy: 0.9610 - val_loss: 0.1702 - val_accuracy: 0.9460\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.1223 - accuracy: 0.9650 - val_loss: 0.1811 - val_accuracy: 0.9430\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.1245 - accuracy: 0.9650 - val_loss: 0.1794 - val_accuracy: 0.9500\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.1155 - accuracy: 0.9665 - val_loss: 0.1986 - val_accuracy: 0.9430\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.1123 - accuracy: 0.9650 - val_loss: 0.1635 - val_accuracy: 0.9500\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.1001 - accuracy: 0.9715 - val_loss: 0.1715 - val_accuracy: 0.9510\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.1070 - accuracy: 0.9695 - val_loss: 0.1637 - val_accuracy: 0.9440\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.0946 - accuracy: 0.9720 - val_loss: 0.1734 - val_accuracy: 0.9460\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0868 - accuracy: 0.9747 - val_loss: 0.1573 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.0825 - accuracy: 0.9755 - val_loss: 0.1534 - val_accuracy: 0.9550\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0886 - accuracy: 0.9737 - val_loss: 0.1474 - val_accuracy: 0.9570\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0745 - accuracy: 0.9797 - val_loss: 0.1501 - val_accuracy: 0.9520\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.0963 - accuracy: 0.9712 - val_loss: 0.1645 - val_accuracy: 0.9510\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0709 - accuracy: 0.9783 - val_loss: 0.1521 - val_accuracy: 0.9570\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0670 - accuracy: 0.9818 - val_loss: 0.1461 - val_accuracy: 0.9570\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0679 - accuracy: 0.9797 - val_loss: 0.1501 - val_accuracy: 0.9520\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0607 - accuracy: 0.9812 - val_loss: 0.1594 - val_accuracy: 0.9530\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0557 - accuracy: 0.9818 - val_loss: 0.1457 - val_accuracy: 0.9530\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0549 - accuracy: 0.9837 - val_loss: 0.1670 - val_accuracy: 0.9550\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0516 - accuracy: 0.9830 - val_loss: 0.1589 - val_accuracy: 0.9570\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.0491 - accuracy: 0.9862 - val_loss: 0.2223 - val_accuracy: 0.9500\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0578 - accuracy: 0.9843 - val_loss: 0.1413 - val_accuracy: 0.9590\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0521 - accuracy: 0.9845 - val_loss: 0.1416 - val_accuracy: 0.9560\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0391 - accuracy: 0.9887 - val_loss: 0.1581 - val_accuracy: 0.9510\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0419 - accuracy: 0.9875 - val_loss: 0.1648 - val_accuracy: 0.9440\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0342 - accuracy: 0.9908 - val_loss: 0.1514 - val_accuracy: 0.9560\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0354 - accuracy: 0.9908 - val_loss: 0.1555 - val_accuracy: 0.9520\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.0378 - accuracy: 0.9870 - val_loss: 0.1542 - val_accuracy: 0.9570\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.0274 - accuracy: 0.9920 - val_loss: 0.1562 - val_accuracy: 0.9550\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.1537 - val_accuracy: 0.9590\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0193 - accuracy: 0.9962 - val_loss: 0.1560 - val_accuracy: 0.9560\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0206 - accuracy: 0.9948 - val_loss: 0.1605 - val_accuracy: 0.9570\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0383 - accuracy: 0.9883 - val_loss: 0.1616 - val_accuracy: 0.9620\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0289 - accuracy: 0.9923 - val_loss: 0.1614 - val_accuracy: 0.9490\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0142 - accuracy: 0.9983 - val_loss: 0.1712 - val_accuracy: 0.9540\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 0.1694 - val_accuracy: 0.9560\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.0114 - accuracy: 0.9983 - val_loss: 0.1715 - val_accuracy: 0.9570\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0096 - accuracy: 0.9990 - val_loss: 0.1674 - val_accuracy: 0.9580\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.1865 - val_accuracy: 0.9520\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 0.1902 - val_accuracy: 0.9560\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.1736 - val_accuracy: 0.9570\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.1798 - val_accuracy: 0.9520\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6953071364700778\n",
      "F1 Micro: 0.9568\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6613123946675388\n",
      "F1 Micro: 0.9528\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 88us/step - loss: 1.6784 - accuracy: 0.5583 - val_loss: 1.3501 - val_accuracy: 0.6930\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 1.0788 - accuracy: 0.7845 - val_loss: 0.8074 - val_accuracy: 0.8650\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.6155 - accuracy: 0.8988 - val_loss: 0.4596 - val_accuracy: 0.9190\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.3677 - accuracy: 0.9420 - val_loss: 0.3164 - val_accuracy: 0.9340\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.2601 - accuracy: 0.9513 - val_loss: 0.2546 - val_accuracy: 0.9410\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.2092 - accuracy: 0.9567 - val_loss: 0.2271 - val_accuracy: 0.9420\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1808 - accuracy: 0.9622 - val_loss: 0.2114 - val_accuracy: 0.9460\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1627 - accuracy: 0.9638 - val_loss: 0.2005 - val_accuracy: 0.9460\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1508 - accuracy: 0.9643 - val_loss: 0.1947 - val_accuracy: 0.9460\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1409 - accuracy: 0.9653 - val_loss: 0.1900 - val_accuracy: 0.9460\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1334 - accuracy: 0.9660 - val_loss: 0.1858 - val_accuracy: 0.9460\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1271 - accuracy: 0.9663 - val_loss: 0.1839 - val_accuracy: 0.9480\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1222 - accuracy: 0.9675 - val_loss: 0.1808 - val_accuracy: 0.9470\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1174 - accuracy: 0.9685 - val_loss: 0.1795 - val_accuracy: 0.9500\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.1132 - accuracy: 0.9710 - val_loss: 0.1760 - val_accuracy: 0.9490\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1100 - accuracy: 0.9715 - val_loss: 0.1744 - val_accuracy: 0.9510\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1066 - accuracy: 0.9725 - val_loss: 0.1736 - val_accuracy: 0.9520\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1037 - accuracy: 0.9737 - val_loss: 0.1727 - val_accuracy: 0.9510\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1014 - accuracy: 0.9735 - val_loss: 0.1706 - val_accuracy: 0.9510\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0986 - accuracy: 0.9735 - val_loss: 0.1701 - val_accuracy: 0.9510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0964 - accuracy: 0.9743 - val_loss: 0.1699 - val_accuracy: 0.9530\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0941 - accuracy: 0.9762 - val_loss: 0.1684 - val_accuracy: 0.9520\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0922 - accuracy: 0.9750 - val_loss: 0.1660 - val_accuracy: 0.9530\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0898 - accuracy: 0.9770 - val_loss: 0.1674 - val_accuracy: 0.9550\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0889 - accuracy: 0.9765 - val_loss: 0.1683 - val_accuracy: 0.9530\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0863 - accuracy: 0.9775 - val_loss: 0.1681 - val_accuracy: 0.9520\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0849 - accuracy: 0.9775 - val_loss: 0.1657 - val_accuracy: 0.9540\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0828 - accuracy: 0.9783 - val_loss: 0.1655 - val_accuracy: 0.9530\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0818 - accuracy: 0.9795 - val_loss: 0.1661 - val_accuracy: 0.9530\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0801 - accuracy: 0.9800 - val_loss: 0.1643 - val_accuracy: 0.9530\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0792 - accuracy: 0.9790 - val_loss: 0.1635 - val_accuracy: 0.9520\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0777 - accuracy: 0.9800 - val_loss: 0.1665 - val_accuracy: 0.9510\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0765 - accuracy: 0.9805 - val_loss: 0.1641 - val_accuracy: 0.9520\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0748 - accuracy: 0.9812 - val_loss: 0.1640 - val_accuracy: 0.9510\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0731 - accuracy: 0.9820 - val_loss: 0.1654 - val_accuracy: 0.9530\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0722 - accuracy: 0.9812 - val_loss: 0.1647 - val_accuracy: 0.9510\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0713 - accuracy: 0.9812 - val_loss: 0.1652 - val_accuracy: 0.9520\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0696 - accuracy: 0.9837 - val_loss: 0.1637 - val_accuracy: 0.9530\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0688 - accuracy: 0.9830 - val_loss: 0.1635 - val_accuracy: 0.9520\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.98 - 0s 73us/step - loss: 0.0675 - accuracy: 0.9833 - val_loss: 0.1645 - val_accuracy: 0.9520\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0667 - accuracy: 0.9837 - val_loss: 0.1645 - val_accuracy: 0.9530\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0652 - accuracy: 0.9837 - val_loss: 0.1656 - val_accuracy: 0.9530\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0640 - accuracy: 0.9852 - val_loss: 0.1633 - val_accuracy: 0.9540\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0636 - accuracy: 0.9847 - val_loss: 0.1635 - val_accuracy: 0.9550\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0618 - accuracy: 0.9852 - val_loss: 0.1630 - val_accuracy: 0.9550\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0615 - accuracy: 0.9835 - val_loss: 0.1643 - val_accuracy: 0.9550\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0604 - accuracy: 0.9852 - val_loss: 0.1644 - val_accuracy: 0.9530\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0598 - accuracy: 0.9862 - val_loss: 0.1626 - val_accuracy: 0.9560\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0583 - accuracy: 0.9855 - val_loss: 0.1640 - val_accuracy: 0.9540\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0577 - accuracy: 0.9858 - val_loss: 0.1624 - val_accuracy: 0.9560\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0566 - accuracy: 0.9858 - val_loss: 0.1644 - val_accuracy: 0.9540\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0562 - accuracy: 0.9855 - val_loss: 0.1619 - val_accuracy: 0.9550\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0555 - accuracy: 0.9850 - val_loss: 0.1633 - val_accuracy: 0.9550\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0543 - accuracy: 0.9855 - val_loss: 0.1643 - val_accuracy: 0.9540\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0534 - accuracy: 0.9865 - val_loss: 0.1637 - val_accuracy: 0.9550\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0522 - accuracy: 0.9862 - val_loss: 0.1626 - val_accuracy: 0.9560\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0516 - accuracy: 0.9865 - val_loss: 0.1632 - val_accuracy: 0.9540\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0507 - accuracy: 0.9868 - val_loss: 0.1641 - val_accuracy: 0.9570\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0503 - accuracy: 0.9862 - val_loss: 0.1659 - val_accuracy: 0.9520\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0497 - accuracy: 0.9877 - val_loss: 0.1645 - val_accuracy: 0.9540\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0479 - accuracy: 0.9883 - val_loss: 0.1646 - val_accuracy: 0.9560\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0476 - accuracy: 0.9868 - val_loss: 0.1655 - val_accuracy: 0.9550\n",
      "Epoch 63/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0467 - accuracy: 0.9887 - val_loss: 0.1647 - val_accuracy: 0.9570\n",
      "Epoch 64/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0465 - accuracy: 0.9875 - val_loss: 0.1658 - val_accuracy: 0.9540\n",
      "Epoch 65/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0453 - accuracy: 0.9883 - val_loss: 0.1665 - val_accuracy: 0.9530\n",
      "Epoch 66/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0452 - accuracy: 0.9875 - val_loss: 0.1640 - val_accuracy: 0.9550\n",
      "Epoch 67/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0443 - accuracy: 0.9880 - val_loss: 0.1646 - val_accuracy: 0.9550\n",
      "Epoch 68/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0433 - accuracy: 0.9893 - val_loss: 0.1658 - val_accuracy: 0.9540\n",
      "Epoch 69/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0426 - accuracy: 0.9890 - val_loss: 0.1676 - val_accuracy: 0.9530\n",
      "Epoch 70/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0427 - accuracy: 0.9895 - val_loss: 0.1661 - val_accuracy: 0.9580\n",
      "Epoch 71/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0415 - accuracy: 0.9900 - val_loss: 0.1662 - val_accuracy: 0.9550\n",
      "Epoch 72/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0406 - accuracy: 0.9908 - val_loss: 0.1678 - val_accuracy: 0.9540\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7073940299099882\n",
      "F1 Micro: 0.9578\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 235us/step - loss: 0.6193 - accuracy: 0.8400 - val_loss: 0.3400 - val_accuracy: 0.9130\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.2997 - accuracy: 0.9227 - val_loss: 0.2876 - val_accuracy: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.2499 - accuracy: 0.9367 - val_loss: 0.2491 - val_accuracy: 0.9310\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.2164 - accuracy: 0.9438 - val_loss: 0.2260 - val_accuracy: 0.9380\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1911 - accuracy: 0.9470 - val_loss: 0.2120 - val_accuracy: 0.9390\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1763 - accuracy: 0.9513 - val_loss: 0.1978 - val_accuracy: 0.9450\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1618 - accuracy: 0.9525 - val_loss: 0.1935 - val_accuracy: 0.9410\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1538 - accuracy: 0.9572 - val_loss: 0.1838 - val_accuracy: 0.9430\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1437 - accuracy: 0.9605 - val_loss: 0.1847 - val_accuracy: 0.9470\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1379 - accuracy: 0.9620 - val_loss: 0.1712 - val_accuracy: 0.9510\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1338 - accuracy: 0.9630 - val_loss: 0.1741 - val_accuracy: 0.9490\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1265 - accuracy: 0.9653 - val_loss: 0.1758 - val_accuracy: 0.9470\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1217 - accuracy: 0.9680 - val_loss: 0.1651 - val_accuracy: 0.9490\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1172 - accuracy: 0.9690 - val_loss: 0.1671 - val_accuracy: 0.9490\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1130 - accuracy: 0.9693 - val_loss: 0.1589 - val_accuracy: 0.9490\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1081 - accuracy: 0.9710 - val_loss: 0.1603 - val_accuracy: 0.9500\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1062 - accuracy: 0.9730 - val_loss: 0.1579 - val_accuracy: 0.9530\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1026 - accuracy: 0.9730 - val_loss: 0.1606 - val_accuracy: 0.9480\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0986 - accuracy: 0.9745 - val_loss: 0.1558 - val_accuracy: 0.9520\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0966 - accuracy: 0.9758 - val_loss: 0.1574 - val_accuracy: 0.9560\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0934 - accuracy: 0.9762 - val_loss: 0.1535 - val_accuracy: 0.9540\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0907 - accuracy: 0.9760 - val_loss: 0.1537 - val_accuracy: 0.9550\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0882 - accuracy: 0.9765 - val_loss: 0.1479 - val_accuracy: 0.9600\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0852 - accuracy: 0.9765 - val_loss: 0.1536 - val_accuracy: 0.9570\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0851 - accuracy: 0.9783 - val_loss: 0.1538 - val_accuracy: 0.9560\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0788 - accuracy: 0.9770 - val_loss: 0.1480 - val_accuracy: 0.9570\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0758 - accuracy: 0.9800 - val_loss: 0.1463 - val_accuracy: 0.9580\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0734 - accuracy: 0.9803 - val_loss: 0.1478 - val_accuracy: 0.9590\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0673 - accuracy: 0.9820 - val_loss: 0.1681 - val_accuracy: 0.9560\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0682 - accuracy: 0.9818 - val_loss: 0.1537 - val_accuracy: 0.9570\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0605 - accuracy: 0.9837 - val_loss: 0.1539 - val_accuracy: 0.9580\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0579 - accuracy: 0.9852 - val_loss: 0.1463 - val_accuracy: 0.9580\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0544 - accuracy: 0.9855 - val_loss: 0.1426 - val_accuracy: 0.9580\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0472 - accuracy: 0.9880 - val_loss: 0.1463 - val_accuracy: 0.9570\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0421 - accuracy: 0.9887 - val_loss: 0.1745 - val_accuracy: 0.9590\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0385 - accuracy: 0.9910 - val_loss: 0.1511 - val_accuracy: 0.9540\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0328 - accuracy: 0.9925 - val_loss: 0.1511 - val_accuracy: 0.9570\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0317 - accuracy: 0.9918 - val_loss: 0.1576 - val_accuracy: 0.9550\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0251 - accuracy: 0.9952 - val_loss: 0.1533 - val_accuracy: 0.9580\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0235 - accuracy: 0.9962 - val_loss: 0.1701 - val_accuracy: 0.9590\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0202 - accuracy: 0.9960 - val_loss: 0.1559 - val_accuracy: 0.9570\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0181 - accuracy: 0.9962 - val_loss: 0.1629 - val_accuracy: 0.9560\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0158 - accuracy: 0.9983 - val_loss: 0.1777 - val_accuracy: 0.9520\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0145 - accuracy: 0.9977 - val_loss: 0.1723 - val_accuracy: 0.9600\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0131 - accuracy: 0.9983 - val_loss: 0.2088 - val_accuracy: 0.9590\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0121 - accuracy: 0.9987 - val_loss: 0.1777 - val_accuracy: 0.9570\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0102 - accuracy: 0.9990 - val_loss: 0.1754 - val_accuracy: 0.9590\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0095 - accuracy: 0.9990 - val_loss: 0.1710 - val_accuracy: 0.9580\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0088 - accuracy: 0.9992 - val_loss: 0.2176 - val_accuracy: 0.9570\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 0.1958 - val_accuracy: 0.9560\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.1992 - val_accuracy: 0.9560\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9570\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9570\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7288745272602785\n",
      "F1 Micro: 0.9607\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6775317564069382\n",
      "F1 Micro: 0.9547\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7521088632358676\n",
      "F1 Micro: 0.9613\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 1 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.3917 - accuracy: 0.9040 - val_loss: 0.2259 - val_accuracy: 0.9344\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.1793 - accuracy: 0.9475 - val_loss: 0.1509 - val_accuracy: 0.9533\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1433 - accuracy: 0.9562 - val_loss: 0.1297 - val_accuracy: 0.9592\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1255 - accuracy: 0.9610 - val_loss: 0.1126 - val_accuracy: 0.9641\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1141 - accuracy: 0.9639 - val_loss: 0.1104 - val_accuracy: 0.9654\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1064 - accuracy: 0.9672 - val_loss: 0.1734 - val_accuracy: 0.9506\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0997 - accuracy: 0.9688 - val_loss: 0.1206 - val_accuracy: 0.9617\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0926 - accuracy: 0.9707 - val_loss: 0.0975 - val_accuracy: 0.9698\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0877 - accuracy: 0.9709 - val_loss: 0.0958 - val_accuracy: 0.9696\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0833 - accuracy: 0.9726 - val_loss: 0.0939 - val_accuracy: 0.9703\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0782 - accuracy: 0.9738 - val_loss: 0.0996 - val_accuracy: 0.9678\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0746 - accuracy: 0.9754 - val_loss: 0.1113 - val_accuracy: 0.9635\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0694 - accuracy: 0.9770 - val_loss: 0.0919 - val_accuracy: 0.9712\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0649 - accuracy: 0.9785 - val_loss: 0.0967 - val_accuracy: 0.9703\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0602 - accuracy: 0.9798 - val_loss: 0.1041 - val_accuracy: 0.9679\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0559 - accuracy: 0.9811 - val_loss: 0.0925 - val_accuracy: 0.9710\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0522 - accuracy: 0.9824 - val_loss: 0.0910 - val_accuracy: 0.9724\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 0.0481 - accuracy: 0.9834 - val_loss: 0.1204 - val_accuracy: 0.9648\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0427 - accuracy: 0.9857 - val_loss: 0.0930 - val_accuracy: 0.9713\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0367 - accuracy: 0.9875 - val_loss: 0.0915 - val_accuracy: 0.9744\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0308 - accuracy: 0.9895 - val_loss: 0.0951 - val_accuracy: 0.9720\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0278 - accuracy: 0.9903 - val_loss: 0.0931 - val_accuracy: 0.9735\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.1075 - val_accuracy: 0.9709\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.1120 - val_accuracy: 0.9701\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.1094 - val_accuracy: 0.9721\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.1235 - val_accuracy: 0.9724\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.1198 - val_accuracy: 0.9734\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.1264 - val_accuracy: 0.9732\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.1604 - val_accuracy: 0.9688\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.1251 - val_accuracy: 0.9733\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.1526 - val_accuracy: 0.9703\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.1367 - val_accuracy: 0.9716\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.1327 - val_accuracy: 0.9711\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.1413 - val_accuracy: 0.9685\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1483 - val_accuracy: 0.9673\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.1463 - val_accuracy: 0.9729\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.1855 - val_accuracy: 0.9636\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8240597938092504\n",
      "F1 Micro: 0.9699\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7726914024055205\n",
      "F1 Micro: 0.9629\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.5039 - accuracy: 0.8852 - val_loss: 0.1600 - val_accuracy: 0.9552\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1415 - accuracy: 0.9586 - val_loss: 0.1318 - val_accuracy: 0.9628\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1239 - accuracy: 0.9631 - val_loss: 0.1213 - val_accuracy: 0.9638\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1152 - accuracy: 0.9653 - val_loss: 0.1155 - val_accuracy: 0.9647\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1102 - accuracy: 0.9663 - val_loss: 0.1117 - val_accuracy: 0.9649y: \n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1060 - accuracy: 0.9676 - val_loss: 0.1092 - val_accuracy: 0.9651\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1029 - accuracy: 0.9686 - val_loss: 0.1060 - val_accuracy: 0.9654\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0996 - accuracy: 0.9695 - val_loss: 0.1058 - val_accuracy: 0.9666\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0974 - accuracy: 0.9700 - val_loss: 0.1033 - val_accuracy: 0.9672\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0952 - accuracy: 0.9707 - val_loss: 0.1020 - val_accuracy: 0.9680\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0933 - accuracy: 0.9716 - val_loss: 0.1021 - val_accuracy: 0.9674\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0916 - accuracy: 0.9722 - val_loss: 0.0986 - val_accuracy: 0.9685\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0897 - accuracy: 0.9726 - val_loss: 0.0986 - val_accuracy: 0.9681\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0886 - accuracy: 0.9725 - val_loss: 0.0982 - val_accuracy: 0.9682\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0868 - accuracy: 0.9736 - val_loss: 0.0981 - val_accuracy: 0.9685\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0853 - accuracy: 0.9736 - val_loss: 0.0974 - val_accuracy: 0.9677\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0843 - accuracy: 0.9737 - val_loss: 0.0975 - val_accuracy: 0.9681\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0832 - accuracy: 0.9742 - val_loss: 0.0974 - val_accuracy: 0.9681ccuracy\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0820 - accuracy: 0.9745 - val_loss: 0.0965 - val_accuracy: 0.9692\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0811 - accuracy: 0.9748 - val_loss: 0.0964 - val_accuracy: 0.9691\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0799 - accuracy: 0.9755 - val_loss: 0.0978 - val_accuracy: 0.9682\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0788 - accuracy: 0.9754 - val_loss: 0.0971 - val_accuracy: 0.9691\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0779 - accuracy: 0.9757 - val_loss: 0.0950 - val_accuracy: 0.9693\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0768 - accuracy: 0.9760 - val_loss: 0.0943 - val_accuracy: 0.9688\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0760 - accuracy: 0.9761 - val_loss: 0.0951 - val_accuracy: 0.9694\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0748 - accuracy: 0.9764 - val_loss: 0.0944 - val_accuracy: 0.9692\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0737 - accuracy: 0.9768 - val_loss: 0.0947 - val_accuracy: 0.9699\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0731 - accuracy: 0.9767 - val_loss: 0.0948 - val_accuracy: 0.9689\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0724 - accuracy: 0.9770 - val_loss: 0.0949 - val_accuracy: 0.9692\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0712 - accuracy: 0.9778 - val_loss: 0.0965 - val_accuracy: 0.9692\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0705 - accuracy: 0.9780 - val_loss: 0.0952 - val_accuracy: 0.9686\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0696 - accuracy: 0.9782 - val_loss: 0.0947 - val_accuracy: 0.9697\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0689 - accuracy: 0.9783 - val_loss: 0.0963 - val_accuracy: 0.9680\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0682 - accuracy: 0.9789 - val_loss: 0.0949 - val_accuracy: 0.9691\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0674 - accuracy: 0.9789 - val_loss: 0.0939 - val_accuracy: 0.9693\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0664 - accuracy: 0.9787 - val_loss: 0.0947 - val_accuracy: 0.9690\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0658 - accuracy: 0.9796 - val_loss: 0.0955 - val_accuracy: 0.9701\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0648 - accuracy: 0.9800 - val_loss: 0.0933 - val_accuracy: 0.9705\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0642 - accuracy: 0.9798 - val_loss: 0.0955 - val_accuracy: 0.9688\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0632 - accuracy: 0.9801 - val_loss: 0.0950 - val_accuracy: 0.9690\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0627 - accuracy: 0.9807 - val_loss: 0.0959 - val_accuracy: 0.9687\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0623 - accuracy: 0.9807 - val_loss: 0.0958 - val_accuracy: 0.9688\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0614 - accuracy: 0.9808 - val_loss: 0.0958 - val_accuracy: 0.9690\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0608 - accuracy: 0.9814 - val_loss: 0.0949 - val_accuracy: 0.9701\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0601 - accuracy: 0.9811 - val_loss: 0.0980 - val_accuracy: 0.9689\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0593 - accuracy: 0.9819 - val_loss: 0.0937 - val_accuracy: 0.9695\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0588 - accuracy: 0.9819 - val_loss: 0.0950 - val_accuracy: 0.9690 0s - loss: 0.0582 - ac\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0580 - accuracy: 0.9820 - val_loss: 0.0962 - val_accuracy: 0.9691\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0572 - accuracy: 0.9825 - val_loss: 0.0953 - val_accuracy: 0.9699\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0567 - accuracy: 0.9827 - val_loss: 0.0978 - val_accuracy: 0.9688\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0561 - accuracy: 0.9828 - val_loss: 0.0956 - val_accuracy: 0.9693\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0553 - accuracy: 0.9831 - val_loss: 0.0970 - val_accuracy: 0.9693\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0550 - accuracy: 0.9831 - val_loss: 0.0965 - val_accuracy: 0.9688\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0540 - accuracy: 0.9833 - val_loss: 0.0962 - val_accuracy: 0.9701\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0535 - accuracy: 0.9833 - val_loss: 0.0963 - val_accuracy: 0.9697\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0528 - accuracy: 0.9838 - val_loss: 0.0961 - val_accuracy: 0.9693\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0521 - accuracy: 0.9840 - val_loss: 0.0977 - val_accuracy: 0.9696\n",
      "Epoch 58/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0518 - accuracy: 0.9839 - val_loss: 0.0972 - val_accuracy: 0.9686loss: 0.0500 - accuracy: 0.98 - ETA: 0s - los\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8292931739227112\n",
      "F1 Micro: 0.968\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.2545 - accuracy: 0.9310 - val_loss: 0.1639 - val_accuracy: 0.9490\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1434 - accuracy: 0.9570 - val_loss: 0.1332 - val_accuracy: 0.9581\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.1236 - accuracy: 0.9618 - val_loss: 0.1233 - val_accuracy: 0.9604\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1137 - accuracy: 0.9644 - val_loss: 0.1118 - val_accuracy: 0.9644\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.1063 - accuracy: 0.9670 - val_loss: 0.1072 - val_accuracy: 0.9658\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0999 - accuracy: 0.9685 - val_loss: 0.1022 - val_accuracy: 0.9668\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0945 - accuracy: 0.9701 - val_loss: 0.1007 - val_accuracy: 0.9679\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0897 - accuracy: 0.9713 - val_loss: 0.0964 - val_accuracy: 0.9695\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0836 - accuracy: 0.9726 - val_loss: 0.1010 - val_accuracy: 0.9664\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0780 - accuracy: 0.9744 - val_loss: 0.0933 - val_accuracy: 0.9690\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0721 - accuracy: 0.9768 - val_loss: 0.0883 - val_accuracy: 0.9705\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0664 - accuracy: 0.9787 - val_loss: 0.0868 - val_accuracy: 0.9709\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0618 - accuracy: 0.9803 - val_loss: 0.0865 - val_accuracy: 0.9697\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0550 - accuracy: 0.9823 - val_loss: 0.0872 - val_accuracy: 0.9713\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0474 - accuracy: 0.9844 - val_loss: 0.0899 - val_accuracy: 0.9705\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0417 - accuracy: 0.9869 - val_loss: 0.1041 - val_accuracy: 0.9694\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 0.0924 - val_accuracy: 0.9722\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.1043 - val_accuracy: 0.9707\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0236 - accuracy: 0.9931 - val_loss: 0.1015 - val_accuracy: 0.9723\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.1039 - val_accuracy: 0.9711\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.1283 - val_accuracy: 0.9635\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0128 - accuracy: 0.9966 - val_loss: 0.1855 - val_accuracy: 0.9647\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.1346 - val_accuracy: 0.9688\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.1305 - val_accuracy: 0.9689\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.1336 - val_accuracy: 0.9709\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.1708 - val_accuracy: 0.9694\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.1490 - val_accuracy: 0.9714\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.1951 - val_accuracy: 0.9678\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.1462 - val_accuracy: 0.9694\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.1374 - val_accuracy: 0.9695\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.1528 - val_accuracy: 0.9710\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.1582 - val_accuracy: 0.9709\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.1499 - val_accuracy: 0.9694\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8276338682446844\n",
      "F1 Micro: 0.9698\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7824766698105198\n",
      "F1 Micro: 0.9632\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8369328808640353\n",
      "F1 Micro: 0.972\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 1 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.2381 - accuracy: 0.9354 - val_loss: 0.1685 - val_accuracy: 0.9506\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.1181 - accuracy: 0.9626 - val_loss: 0.1095 - val_accuracy: 0.9660\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0995 - accuracy: 0.9679 - val_loss: 0.0998 - val_accuracy: 0.9678\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0889 - accuracy: 0.9707 - val_loss: 0.0876 - val_accuracy: 0.9714\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0806 - accuracy: 0.9736 - val_loss: 0.0811 - val_accuracy: 0.9734\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0732 - accuracy: 0.9754 - val_loss: 0.0767 - val_accuracy: 0.9741\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0673 - accuracy: 0.9771 - val_loss: 0.0772 - val_accuracy: 0.9732\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0621 - accuracy: 0.9785 - val_loss: 0.0736 - val_accuracy: 0.9758\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0575 - accuracy: 0.9798 - val_loss: 0.0678 - val_accuracy: 0.9766\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0531 - accuracy: 0.9813 - val_loss: 0.0710 - val_accuracy: 0.9757\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0498 - accuracy: 0.9822 - val_loss: 0.0659 - val_accuracy: 0.9774\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0463 - accuracy: 0.9833 - val_loss: 0.0689 - val_accuracy: 0.9752\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0422 - accuracy: 0.9850 - val_loss: 0.0737 - val_accuracy: 0.9750\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0381 - accuracy: 0.9864 - val_loss: 0.0728 - val_accuracy: 0.9762\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0349 - accuracy: 0.9873 - val_loss: 0.0691 - val_accuracy: 0.9775\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0314 - accuracy: 0.9886 - val_loss: 0.0810 - val_accuracy: 0.9745\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0273 - accuracy: 0.9901 - val_loss: 0.0769 - val_accuracy: 0.9751\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0237 - accuracy: 0.9915 - val_loss: 0.0788 - val_accuracy: 0.9750\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 0.0878 - val_accuracy: 0.9740\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.1042 - val_accuracy: 0.9752\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.0909 - val_accuracy: 0.9762\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0996 - val_accuracy: 0.9762\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.1302 - val_accuracy: 0.9747\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.1221 - val_accuracy: 0.9730\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.1219 - val_accuracy: 0.9720\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.1131 - val_accuracy: 0.9755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.1220 - val_accuracy: 0.9765\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.1363 - val_accuracy: 0.9751\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.1193 - val_accuracy: 0.9743\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1232 - val_accuracy: 0.9765\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.1556 - val_accuracy: 0.9743\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8561444312138897\n",
      "F1 Micro: 0.9769\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8211700426165062\n",
      "F1 Micro: 0.9673\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.2370 - accuracy: 0.9385 - val_loss: 0.1237 - val_accuracy: 0.9623\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.1119 - accuracy: 0.9659 - val_loss: 0.1101 - val_accuracy: 0.96560s - loss: 0.1123 - accu\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.1022 - accuracy: 0.9680 - val_loss: 0.1037 - val_accuracy: 0.9673\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0966 - accuracy: 0.9698 - val_loss: 0.1000 - val_accuracy: 0.9677\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0928 - accuracy: 0.9708 - val_loss: 0.0976 - val_accuracy: 0.9678\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0896 - accuracy: 0.9719 - val_loss: 0.0964 - val_accuracy: 0.9689\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0871 - accuracy: 0.9723 - val_loss: 0.0945 - val_accuracy: 0.9696\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0852 - accuracy: 0.9728 - val_loss: 0.0930 - val_accuracy: 0.9693\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0833 - accuracy: 0.9735 - val_loss: 0.0914 - val_accuracy: 0.9700\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0816 - accuracy: 0.9738 - val_loss: 0.0908 - val_accuracy: 0.9700\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0801 - accuracy: 0.9742 - val_loss: 0.0914 - val_accuracy: 0.9701\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0788 - accuracy: 0.9748 - val_loss: 0.0904 - val_accuracy: 0.9709\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0775 - accuracy: 0.9753 - val_loss: 0.0898 - val_accuracy: 0.9705\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0763 - accuracy: 0.9758 - val_loss: 0.0876 - val_accuracy: 0.9712\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0753 - accuracy: 0.9759 - val_loss: 0.0886 - val_accuracy: 0.9710\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0743 - accuracy: 0.9760 - val_loss: 0.0884 - val_accuracy: 0.9708\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0734 - accuracy: 0.9766 - val_loss: 0.0866 - val_accuracy: 0.9717\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0723 - accuracy: 0.9767 - val_loss: 0.0877 - val_accuracy: 0.9708\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0714 - accuracy: 0.9768 - val_loss: 0.0865 - val_accuracy: 0.9710TA: 0s - loss:\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0707 - accuracy: 0.9772 - val_loss: 0.0863 - val_accuracy: 0.9720\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0699 - accuracy: 0.9773 - val_loss: 0.0861 - val_accuracy: 0.9713\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0690 - accuracy: 0.9778 - val_loss: 0.0855 - val_accuracy: 0.9719\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0684 - accuracy: 0.9779 - val_loss: 0.0848 - val_accuracy: 0.9716\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0676 - accuracy: 0.9781 - val_loss: 0.0872 - val_accuracy: 0.9715\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0668 - accuracy: 0.9782 - val_loss: 0.0868 - val_accuracy: 0.9715\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0662 - accuracy: 0.9786 - val_loss: 0.0846 - val_accuracy: 0.9723\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0655 - accuracy: 0.9789 - val_loss: 0.0850 - val_accuracy: 0.9718\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0647 - accuracy: 0.9793 - val_loss: 0.0842 - val_accuracy: 0.9721\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0642 - accuracy: 0.9794 - val_loss: 0.0845 - val_accuracy: 0.9726\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0635 - accuracy: 0.9794 - val_loss: 0.0862 - val_accuracy: 0.9713\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0630 - accuracy: 0.9797 - val_loss: 0.0854 - val_accuracy: 0.9732\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0624 - accuracy: 0.9798 - val_loss: 0.0848 - val_accuracy: 0.9722\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0617 - accuracy: 0.9799 - val_loss: 0.0847 - val_accuracy: 0.9723\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0610 - accuracy: 0.9802 - val_loss: 0.0840 - val_accuracy: 0.9729\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0606 - accuracy: 0.9804 - val_loss: 0.0857 - val_accuracy: 0.9724\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0600 - accuracy: 0.9805 - val_loss: 0.0855 - val_accuracy: 0.9720\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0593 - accuracy: 0.9807 - val_loss: 0.0853 - val_accuracy: 0.9726\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0858 - val_accuracy: 0.9727\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0583 - accuracy: 0.9810 - val_loss: 0.0852 - val_accuracy: 0.9725\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0578 - accuracy: 0.9810 - val_loss: 0.0879 - val_accuracy: 0.9712\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0571 - accuracy: 0.9816 - val_loss: 0.0857 - val_accuracy: 0.9729\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0566 - accuracy: 0.9817 - val_loss: 0.0862 - val_accuracy: 0.9720\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0560 - accuracy: 0.9817 - val_loss: 0.0865 - val_accuracy: 0.9727\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0556 - accuracy: 0.9818 - val_loss: 0.0853 - val_accuracy: 0.9730\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0551 - accuracy: 0.9821 - val_loss: 0.0863 - val_accuracy: 0.9727\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0544 - accuracy: 0.9825 - val_loss: 0.0867 - val_accuracy: 0.9727\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0540 - accuracy: 0.9823 - val_loss: 0.0863 - val_accuracy: 0.9728\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0534 - accuracy: 0.9826 - val_loss: 0.0872 - val_accuracy: 0.9725\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0529 - accuracy: 0.9827 - val_loss: 0.0871 - val_accuracy: 0.9719\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0524 - accuracy: 0.9829 - val_loss: 0.0869 - val_accuracy: 0.9724\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0519 - accuracy: 0.9831 - val_loss: 0.0877 - val_accuracy: 0.9716\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0511 - accuracy: 0.9833 - val_loss: 0.0895 - val_accuracy: 0.9712\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0508 - accuracy: 0.9835 - val_loss: 0.0882 - val_accuracy: 0.9722\n",
      "Epoch 54/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0504 - accuracy: 0.9837 - val_loss: 0.0872 - val_accuracy: 0.9721\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8432313355342782\n",
      "F1 Micro: 0.971\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.1710 - accuracy: 0.9506 - val_loss: 0.1249 - val_accuracy: 0.9610\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.1034 - accuracy: 0.9673 - val_loss: 0.1028 - val_accuracy: 0.9664\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0871 - accuracy: 0.9718 - val_loss: 0.0890 - val_accuracy: 0.9709\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0783 - accuracy: 0.9744 - val_loss: 0.0905 - val_accuracy: 0.9694\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0718 - accuracy: 0.9762 - val_loss: 0.0779 - val_accuracy: 0.9740\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0659 - accuracy: 0.9781 - val_loss: 0.0745 - val_accuracy: 0.9757\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0603 - accuracy: 0.9800 - val_loss: 0.0735 - val_accuracy: 0.9761\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0544 - accuracy: 0.9817 - val_loss: 0.0736 - val_accuracy: 0.9751\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0481 - accuracy: 0.9838 - val_loss: 0.0702 - val_accuracy: 0.9765\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0415 - accuracy: 0.9860 - val_loss: 0.0813 - val_accuracy: 0.9750\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0340 - accuracy: 0.9884 - val_loss: 0.0764 - val_accuracy: 0.9753\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0273 - accuracy: 0.9907 - val_loss: 0.0816 - val_accuracy: 0.9747\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.0926 - val_accuracy: 0.9760\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0967 - val_accuracy: 0.9756\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0998 - val_accuracy: 0.9737\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.1052 - val_accuracy: 0.9736\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.1197 - val_accuracy: 0.9763\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1208 - val_accuracy: 0.9739\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.1354 - val_accuracy: 0.9751\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1275 - val_accuracy: 0.9749\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.1355 - val_accuracy: 0.9732\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1373 - val_accuracy: 0.9752\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1444 - val_accuracy: 0.9744\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1362 - val_accuracy: 0.9737\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1404 - val_accuracy: 0.9717\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1388 - val_accuracy: 0.9750\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1525 - val_accuracy: 0.9755\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1510 - val_accuracy: 0.9742\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1445 - val_accuracy: 0.9736\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8774537233760251\n",
      "F1 Micro: 0.9759\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8220779450807222\n",
      "F1 Micro: 0.9676\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8852755764480368\n",
      "F1 Micro: 0.9787\n",
      "\n",
      "\n",
      " 51.29745511611303 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 2 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 2 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 692us/step - loss: 2.0412 - accuracy: 0.6950 - val_loss: 1.6944 - val_accuracy: 0.8600\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 1.2506 - accuracy: 0.8425 - val_loss: 0.7307 - val_accuracy: 0.8600\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.8169 - accuracy: 0.8425 - val_loss: 0.7023 - val_accuracy: 0.8600\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7677 - accuracy: 0.8425 - val_loss: 0.6289 - val_accuracy: 0.8600\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7375 - accuracy: 0.8425 - val_loss: 0.6267 - val_accuracy: 0.8600\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.7253 - accuracy: 0.8425 - val_loss: 0.6105 - val_accuracy: 0.8600\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7181 - accuracy: 0.8425 - val_loss: 0.6049 - val_accuracy: 0.8600\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7113 - accuracy: 0.8425 - val_loss: 0.5964 - val_accuracy: 0.8600\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7058 - accuracy: 0.8425 - val_loss: 0.5854 - val_accuracy: 0.8600\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7020 - accuracy: 0.8425 - val_loss: 0.5844 - val_accuracy: 0.8600\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6987 - accuracy: 0.8425 - val_loss: 0.5837 - val_accuracy: 0.8600\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 195us/step - loss: 0.6964 - accuracy: 0.8425 - val_loss: 0.5742 - val_accuracy: 0.8600\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6925 - accuracy: 0.8425 - val_loss: 0.5738 - val_accuracy: 0.8600\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6884 - accuracy: 0.8425 - val_loss: 0.5674 - val_accuracy: 0.8600\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6820 - accuracy: 0.8425 - val_loss: 0.5636 - val_accuracy: 0.8600\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6818 - accuracy: 0.8425 - val_loss: 0.5652 - val_accuracy: 0.8600\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6795 - accuracy: 0.8425 - val_loss: 0.5617 - val_accuracy: 0.8600\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6750 - accuracy: 0.8425 - val_loss: 0.5477 - val_accuracy: 0.8600\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 176us/step - loss: 0.6707 - accuracy: 0.8425 - val_loss: 0.5521 - val_accuracy: 0.8600\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6633 - accuracy: 0.8425 - val_loss: 0.5345 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6520 - accuracy: 0.8425 - val_loss: 0.5297 - val_accuracy: 0.8600\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6450 - accuracy: 0.8425 - val_loss: 0.5159 - val_accuracy: 0.8600\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6316 - accuracy: 0.8425 - val_loss: 0.5122 - val_accuracy: 0.8600\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6201 - accuracy: 0.8425 - val_loss: 0.4845 - val_accuracy: 0.8600\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6040 - accuracy: 0.8425 - val_loss: 0.4541 - val_accuracy: 0.8600\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5930 - accuracy: 0.8425 - val_loss: 0.4766 - val_accuracy: 0.8600\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5795 - accuracy: 0.8475 - val_loss: 0.4144 - val_accuracy: 0.8600\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5633 - accuracy: 0.8500 - val_loss: 0.4159 - val_accuracy: 0.8600\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5471 - accuracy: 0.8550 - val_loss: 0.3962 - val_accuracy: 0.9000\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5146 - accuracy: 0.8600 - val_loss: 0.3756 - val_accuracy: 0.9200\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4815 - accuracy: 0.8700 - val_loss: 0.3367 - val_accuracy: 0.9000\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 162us/step - loss: 0.4603 - accuracy: 0.8700 - val_loss: 0.3201 - val_accuracy: 0.9200\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4441 - accuracy: 0.8850 - val_loss: 0.3906 - val_accuracy: 0.9300\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4313 - accuracy: 0.8850 - val_loss: 0.2873 - val_accuracy: 0.9200\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4193 - accuracy: 0.8850 - val_loss: 0.3067 - val_accuracy: 0.9100\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4110 - accuracy: 0.8900 - val_loss: 0.3692 - val_accuracy: 0.9200\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4100 - accuracy: 0.8975 - val_loss: 0.2565 - val_accuracy: 0.9300\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3793 - accuracy: 0.9000 - val_loss: 0.2531 - val_accuracy: 0.9200\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3819 - accuracy: 0.9000 - val_loss: 0.2476 - val_accuracy: 0.9200\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3742 - accuracy: 0.9000 - val_loss: 0.2424 - val_accuracy: 0.9200\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3633 - accuracy: 0.9025 - val_loss: 0.2407 - val_accuracy: 0.9200\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3635 - accuracy: 0.9000 - val_loss: 0.3012 - val_accuracy: 0.9300\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3688 - accuracy: 0.9000 - val_loss: 0.3747 - val_accuracy: 0.9300\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3952 - accuracy: 0.9025 - val_loss: 0.2646 - val_accuracy: 0.9200\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 203us/step - loss: 0.3383 - accuracy: 0.9100 - val_loss: 0.3059 - val_accuracy: 0.9300\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3455 - accuracy: 0.9100 - val_loss: 0.2317 - val_accuracy: 0.9200\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3363 - accuracy: 0.9100 - val_loss: 0.2148 - val_accuracy: 0.9200\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3177 - accuracy: 0.9100 - val_loss: 0.2709 - val_accuracy: 0.9300\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2996 - accuracy: 0.9175 - val_loss: 0.2016 - val_accuracy: 0.9300\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3236 - accuracy: 0.9075 - val_loss: 0.2103 - val_accuracy: 0.9400\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3261 - accuracy: 0.9100 - val_loss: 0.1951 - val_accuracy: 0.9300\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3108 - accuracy: 0.9100 - val_loss: 0.2034 - val_accuracy: 0.9300\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3482 - accuracy: 0.9000 - val_loss: 0.2112 - val_accuracy: 0.9300\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3162 - accuracy: 0.9175 - val_loss: 0.1957 - val_accuracy: 0.9300\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2921 - accuracy: 0.9125 - val_loss: 0.2057 - val_accuracy: 0.9400\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2880 - accuracy: 0.9175 - val_loss: 0.2270 - val_accuracy: 0.9300\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 206us/step - loss: 0.2860 - accuracy: 0.9150 - val_loss: 0.2669 - val_accuracy: 0.9400\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2804 - accuracy: 0.9150 - val_loss: 0.2439 - val_accuracy: 0.9300\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2942 - accuracy: 0.9225 - val_loss: 0.3280 - val_accuracy: 0.9200\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3246 - accuracy: 0.9050 - val_loss: 0.2511 - val_accuracy: 0.9300\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2974 - accuracy: 0.9075 - val_loss: 0.2072 - val_accuracy: 0.9600\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2581 - accuracy: 0.9225 - val_loss: 0.1705 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2634 - accuracy: 0.9175 - val_loss: 0.2153 - val_accuracy: 0.9400\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2602 - accuracy: 0.9300 - val_loss: 0.2029 - val_accuracy: 0.9600\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2438 - accuracy: 0.9275 - val_loss: 0.1771 - val_accuracy: 0.9600\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2506 - accuracy: 0.9225 - val_loss: 0.2163 - val_accuracy: 0.9500\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2448 - accuracy: 0.9150 - val_loss: 0.2100 - val_accuracy: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2311 - accuracy: 0.9275 - val_loss: 0.2121 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 206us/step - loss: 0.2229 - accuracy: 0.9300 - val_loss: 0.1697 - val_accuracy: 0.9600\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2311 - accuracy: 0.9300 - val_loss: 0.1679 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2310 - accuracy: 0.9275 - val_loss: 0.1699 - val_accuracy: 0.9600\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2165 - accuracy: 0.9250 - val_loss: 0.2020 - val_accuracy: 0.9300\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2121 - accuracy: 0.9450 - val_loss: 0.1652 - val_accuracy: 0.9700\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1979 - accuracy: 0.9450 - val_loss: 0.1645 - val_accuracy: 0.9600\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1951 - accuracy: 0.9475 - val_loss: 0.1543 - val_accuracy: 0.9700\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1944 - accuracy: 0.9375 - val_loss: 0.1634 - val_accuracy: 0.9600\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2008 - accuracy: 0.9350 - val_loss: 0.1607 - val_accuracy: 0.9600\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1792 - accuracy: 0.9500 - val_loss: 0.1730 - val_accuracy: 0.9500\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1808 - accuracy: 0.9450 - val_loss: 0.1880 - val_accuracy: 0.9400\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1854 - accuracy: 0.9550 - val_loss: 0.1678 - val_accuracy: 0.9700\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1764 - accuracy: 0.9500 - val_loss: 0.1648 - val_accuracy: 0.9600\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.1775 - accuracy: 0.9425 - val_loss: 0.1889 - val_accuracy: 0.9500\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1855 - accuracy: 0.9350 - val_loss: 0.1561 - val_accuracy: 0.9500\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1585 - accuracy: 0.9525 - val_loss: 0.1717 - val_accuracy: 0.9600\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1591 - accuracy: 0.9650 - val_loss: 0.1845 - val_accuracy: 0.9600\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1504 - accuracy: 0.9550 - val_loss: 0.1541 - val_accuracy: 0.9500\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1568 - accuracy: 0.9550 - val_loss: 0.1742 - val_accuracy: 0.9600\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1710 - accuracy: 0.9375 - val_loss: 0.1481 - val_accuracy: 0.9600\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1452 - accuracy: 0.9500 - val_loss: 0.1715 - val_accuracy: 0.9600\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1498 - accuracy: 0.9550 - val_loss: 0.1752 - val_accuracy: 0.9500\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1502 - accuracy: 0.9550 - val_loss: 0.1612 - val_accuracy: 0.9500\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1357 - accuracy: 0.9600 - val_loss: 0.1954 - val_accuracy: 0.9500\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1433 - accuracy: 0.9500 - val_loss: 0.1525 - val_accuracy: 0.9500\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.1386 - accuracy: 0.9575 - val_loss: 0.1686 - val_accuracy: 0.9600\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 160us/step - loss: 0.1199 - accuracy: 0.9675 - val_loss: 0.1691 - val_accuracy: 0.9400\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1228 - accuracy: 0.9600 - val_loss: 0.2718 - val_accuracy: 0.8800\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1505 - accuracy: 0.9575 - val_loss: 0.1676 - val_accuracy: 0.9600\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1215 - accuracy: 0.9725 - val_loss: 0.1706 - val_accuracy: 0.9500\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1224 - accuracy: 0.9675 - val_loss: 0.1583 - val_accuracy: 0.9600\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1129 - accuracy: 0.9725 - val_loss: 0.1669 - val_accuracy: 0.9500\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1276 - accuracy: 0.9675 - val_loss: 0.1719 - val_accuracy: 0.9600\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1289 - accuracy: 0.9500 - val_loss: 0.1543 - val_accuracy: 0.9600\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1093 - accuracy: 0.9625 - val_loss: 0.1921 - val_accuracy: 0.9600\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1182 - accuracy: 0.9650 - val_loss: 0.1583 - val_accuracy: 0.9600\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0943 - accuracy: 0.9750 - val_loss: 0.1652 - val_accuracy: 0.9600\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.9800 - val_loss: 0.1648 - val_accuracy: 0.9600\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0975 - accuracy: 0.9775 - val_loss: 0.1709 - val_accuracy: 0.9500\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0920 - accuracy: 0.9775 - val_loss: 0.1590 - val_accuracy: 0.9600\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.38262878553146645\n",
      "F1 Micro: 0.9182\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.42376033921574063\n",
      "F1 Micro: 0.9345\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 248us/step - loss: 2.0486 - accuracy: 0.2725 - val_loss: 1.8908 - val_accuracy: 0.5100\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.8452 - accuracy: 0.5300 - val_loss: 1.7367 - val_accuracy: 0.6200\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.7178 - accuracy: 0.5800 - val_loss: 1.6410 - val_accuracy: 0.6900\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.6332 - accuracy: 0.6050 - val_loss: 1.5703 - val_accuracy: 0.7100\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.5650 - accuracy: 0.6225 - val_loss: 1.5117 - val_accuracy: 0.7200\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.4991 - accuracy: 0.6400 - val_loss: 1.4575 - val_accuracy: 0.7300\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.4344 - accuracy: 0.6600 - val_loss: 1.4025 - val_accuracy: 0.7300\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.3688 - accuracy: 0.6925 - val_loss: 1.3500 - val_accuracy: 0.7400\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.3067 - accuracy: 0.7075 - val_loss: 1.2957 - val_accuracy: 0.7500\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.2400 - accuracy: 0.7275 - val_loss: 1.2432 - val_accuracy: 0.7400\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1745 - accuracy: 0.7525 - val_loss: 1.1907 - val_accuracy: 0.7400\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1085 - accuracy: 0.7775 - val_loss: 1.1378 - val_accuracy: 0.7700\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 78us/step - loss: 1.0437 - accuracy: 0.8050 - val_loss: 1.0872 - val_accuracy: 0.7800\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.9811 - accuracy: 0.8200 - val_loss: 1.0340 - val_accuracy: 0.7900\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.9186 - accuracy: 0.8350 - val_loss: 0.9822 - val_accuracy: 0.8100\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8611 - accuracy: 0.8650 - val_loss: 0.9319 - val_accuracy: 0.8200\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8047 - accuracy: 0.8750 - val_loss: 0.8820 - val_accuracy: 0.8500\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7517 - accuracy: 0.8900 - val_loss: 0.8326 - val_accuracy: 0.8600\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7026 - accuracy: 0.8950 - val_loss: 0.7876 - val_accuracy: 0.8600\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.6575 - accuracy: 0.9100 - val_loss: 0.7474 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.6167 - accuracy: 0.9175 - val_loss: 0.7062 - val_accuracy: 0.8900\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5789 - accuracy: 0.9175 - val_loss: 0.6669 - val_accuracy: 0.8900\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.5441 - accuracy: 0.9200 - val_loss: 0.6309 - val_accuracy: 0.9000\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5125 - accuracy: 0.9275 - val_loss: 0.5981 - val_accuracy: 0.9000\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.4849 - accuracy: 0.9300 - val_loss: 0.5656 - val_accuracy: 0.9000\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 53us/step - loss: 0.4576 - accuracy: 0.9300 - val_loss: 0.5382 - val_accuracy: 0.9100\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4357 - accuracy: 0.9300 - val_loss: 0.5112 - val_accuracy: 0.9100\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4111 - accuracy: 0.9300 - val_loss: 0.4870 - val_accuracy: 0.9300\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3905 - accuracy: 0.9375 - val_loss: 0.4659 - val_accuracy: 0.9300\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3727 - accuracy: 0.9375 - val_loss: 0.4441 - val_accuracy: 0.9300\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3547 - accuracy: 0.9400 - val_loss: 0.4240 - val_accuracy: 0.9300\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3388 - accuracy: 0.9400 - val_loss: 0.4050 - val_accuracy: 0.9300\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3238 - accuracy: 0.9425 - val_loss: 0.3862 - val_accuracy: 0.9300\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3103 - accuracy: 0.9425 - val_loss: 0.3723 - val_accuracy: 0.9300\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2981 - accuracy: 0.9425 - val_loss: 0.3570 - val_accuracy: 0.9300\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2859 - accuracy: 0.9450 - val_loss: 0.3435 - val_accuracy: 0.9400\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2742 - accuracy: 0.9450 - val_loss: 0.3300 - val_accuracy: 0.9400\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2650 - accuracy: 0.9575 - val_loss: 0.3171 - val_accuracy: 0.9400\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2544 - accuracy: 0.9600 - val_loss: 0.3061 - val_accuracy: 0.9400\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2454 - accuracy: 0.9600 - val_loss: 0.2965 - val_accuracy: 0.9500\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2368 - accuracy: 0.9625 - val_loss: 0.2863 - val_accuracy: 0.9500\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2290 - accuracy: 0.9650 - val_loss: 0.2744 - val_accuracy: 0.9500\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2210 - accuracy: 0.9675 - val_loss: 0.2663 - val_accuracy: 0.9600\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2139 - accuracy: 0.9700 - val_loss: 0.2584 - val_accuracy: 0.9600\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2072 - accuracy: 0.9700 - val_loss: 0.2519 - val_accuracy: 0.9500\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 71us/step - loss: 0.2021 - accuracy: 0.9700 - val_loss: 0.2459 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.1947 - accuracy: 0.9700 - val_loss: 0.2364 - val_accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1890 - accuracy: 0.9725 - val_loss: 0.2305 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1833 - accuracy: 0.9750 - val_loss: 0.2237 - val_accuracy: 0.9500\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1783 - accuracy: 0.9725 - val_loss: 0.2162 - val_accuracy: 0.9500\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1731 - accuracy: 0.9750 - val_loss: 0.2128 - val_accuracy: 0.9500\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1685 - accuracy: 0.9750 - val_loss: 0.2075 - val_accuracy: 0.9500\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1638 - accuracy: 0.9750 - val_loss: 0.2016 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1591 - accuracy: 0.9725 - val_loss: 0.1970 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1548 - accuracy: 0.9750 - val_loss: 0.1926 - val_accuracy: 0.9500\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1513 - accuracy: 0.9750 - val_loss: 0.1892 - val_accuracy: 0.9600\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.96 - 0s 78us/step - loss: 0.1478 - accuracy: 0.9750 - val_loss: 0.1839 - val_accuracy: 0.9600\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 97us/step - loss: 0.1439 - accuracy: 0.9750 - val_loss: 0.1807 - val_accuracy: 0.9600\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1399 - accuracy: 0.9775 - val_loss: 0.1783 - val_accuracy: 0.9600\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1363 - accuracy: 0.9825 - val_loss: 0.1747 - val_accuracy: 0.9600\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1332 - accuracy: 0.9825 - val_loss: 0.1718 - val_accuracy: 0.9600\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1296 - accuracy: 0.9825 - val_loss: 0.1683 - val_accuracy: 0.9600\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1269 - accuracy: 0.9825 - val_loss: 0.1651 - val_accuracy: 0.9600\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1239 - accuracy: 0.9850 - val_loss: 0.1632 - val_accuracy: 0.9600\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1207 - accuracy: 0.9825 - val_loss: 0.1599 - val_accuracy: 0.9600\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1199 - accuracy: 0.9825 - val_loss: 0.1558 - val_accuracy: 0.9700\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1158 - accuracy: 0.9800 - val_loss: 0.1561 - val_accuracy: 0.9600\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1128 - accuracy: 0.9850 - val_loss: 0.1531 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1105 - accuracy: 0.9850 - val_loss: 0.1524 - val_accuracy: 0.9600\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1080 - accuracy: 0.9850 - val_loss: 0.1502 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1055 - accuracy: 0.9850 - val_loss: 0.1464 - val_accuracy: 0.9600\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1033 - accuracy: 0.9850 - val_loss: 0.1442 - val_accuracy: 0.9600\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1019 - accuracy: 0.9850 - val_loss: 0.1418 - val_accuracy: 0.9700\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0990 - accuracy: 0.9875 - val_loss: 0.1425 - val_accuracy: 0.9600\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0972 - accuracy: 0.9875 - val_loss: 0.1408 - val_accuracy: 0.9600\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0953 - accuracy: 0.9875 - val_loss: 0.1395 - val_accuracy: 0.9600\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0935 - accuracy: 0.9900 - val_loss: 0.1371 - val_accuracy: 0.9600\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0911 - accuracy: 0.9875 - val_loss: 0.1343 - val_accuracy: 0.9700\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0895 - accuracy: 0.9900 - val_loss: 0.1344 - val_accuracy: 0.9700\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0879 - accuracy: 0.9900 - val_loss: 0.1334 - val_accuracy: 0.9700\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0859 - accuracy: 0.9900 - val_loss: 0.1327 - val_accuracy: 0.9700\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0846 - accuracy: 0.9925 - val_loss: 0.1335 - val_accuracy: 0.9600\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.0827 - accuracy: 0.9925 - val_loss: 0.1305 - val_accuracy: 0.9700\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0812 - accuracy: 0.9925 - val_loss: 0.1281 - val_accuracy: 0.9700\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0797 - accuracy: 0.9925 - val_loss: 0.1280 - val_accuracy: 0.9700\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0781 - accuracy: 0.9925 - val_loss: 0.1268 - val_accuracy: 0.9700\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0767 - accuracy: 0.9925 - val_loss: 0.1262 - val_accuracy: 0.9700\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0754 - accuracy: 0.9925 - val_loss: 0.1257 - val_accuracy: 0.9700\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 50us/step - loss: 0.0741 - accuracy: 0.9925 - val_loss: 0.1241 - val_accuracy: 0.9700\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0728 - accuracy: 0.9925 - val_loss: 0.1224 - val_accuracy: 0.9700\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0716 - accuracy: 0.9925 - val_loss: 0.1236 - val_accuracy: 0.9700\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0705 - accuracy: 0.9925 - val_loss: 0.1215 - val_accuracy: 0.9700\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0689 - accuracy: 0.9925 - val_loss: 0.1208 - val_accuracy: 0.9700\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0681 - accuracy: 0.9925 - val_loss: 0.1205 - val_accuracy: 0.9700\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0668 - accuracy: 0.9925 - val_loss: 0.1184 - val_accuracy: 0.9700\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0655 - accuracy: 0.9925 - val_loss: 0.1182 - val_accuracy: 0.9700\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.0643 - accuracy: 0.9925 - val_loss: 0.1184 - val_accuracy: 0.9700\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0632 - accuracy: 0.9925 - val_loss: 0.1182 - val_accuracy: 0.9700\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0620 - accuracy: 0.9925 - val_loss: 0.1165 - val_accuracy: 0.9700\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0611 - accuracy: 0.9925 - val_loss: 0.1170 - val_accuracy: 0.9700\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0601 - accuracy: 0.9925 - val_loss: 0.1167 - val_accuracy: 0.9700\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0588 - accuracy: 0.9925 - val_loss: 0.1158 - val_accuracy: 0.9700\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0581 - accuracy: 0.9925 - val_loss: 0.1166 - val_accuracy: 0.9700\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0571 - accuracy: 0.9925 - val_loss: 0.1167 - val_accuracy: 0.9700\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0560 - accuracy: 0.9925 - val_loss: 0.1159 - val_accuracy: 0.9700\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0552 - accuracy: 0.9925 - val_loss: 0.1152 - val_accuracy: 0.9700\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0541 - accuracy: 0.9925 - val_loss: 0.1140 - val_accuracy: 0.9700\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0532 - accuracy: 0.9950 - val_loss: 0.1131 - val_accuracy: 0.9700\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0526 - accuracy: 0.9950 - val_loss: 0.1128 - val_accuracy: 0.9700\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0516 - accuracy: 0.9950 - val_loss: 0.1133 - val_accuracy: 0.9700\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0507 - accuracy: 0.9950 - val_loss: 0.1131 - val_accuracy: 0.9700\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0499 - accuracy: 0.9950 - val_loss: 0.1125 - val_accuracy: 0.9700\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0491 - accuracy: 0.9950 - val_loss: 0.1119 - val_accuracy: 0.9700\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0484 - accuracy: 0.9950 - val_loss: 0.1108 - val_accuracy: 0.9700\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0476 - accuracy: 0.9950 - val_loss: 0.1104 - val_accuracy: 0.9700\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0470 - accuracy: 0.9950 - val_loss: 0.1108 - val_accuracy: 0.9700\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0462 - accuracy: 0.9950 - val_loss: 0.1112 - val_accuracy: 0.9700\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0454 - accuracy: 0.9950 - val_loss: 0.1112 - val_accuracy: 0.9700\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0447 - accuracy: 0.9950 - val_loss: 0.1107 - val_accuracy: 0.9700\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.0441 - accuracy: 0.9950 - val_loss: 0.1107 - val_accuracy: 0.9700\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0434 - accuracy: 0.9950 - val_loss: 0.1106 - val_accuracy: 0.9700\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0428 - accuracy: 0.9950 - val_loss: 0.1096 - val_accuracy: 0.9700\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0423 - accuracy: 0.9950 - val_loss: 0.1091 - val_accuracy: 0.9700\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 95us/step - loss: 0.0415 - accuracy: 0.9950 - val_loss: 0.1102 - val_accuracy: 0.9700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0408 - accuracy: 0.9950 - val_loss: 0.1099 - val_accuracy: 0.9700\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 64us/step - loss: 0.0402 - accuracy: 0.9950 - val_loss: 0.1097 - val_accuracy: 0.9700\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0397 - accuracy: 0.9950 - val_loss: 0.1093 - val_accuracy: 0.9700\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0391 - accuracy: 0.9950 - val_loss: 0.1095 - val_accuracy: 0.9700\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0385 - accuracy: 0.9950 - val_loss: 0.1086 - val_accuracy: 0.9700\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0378 - accuracy: 0.9950 - val_loss: 0.1091 - val_accuracy: 0.9700\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0373 - accuracy: 0.9950 - val_loss: 0.1092 - val_accuracy: 0.9700\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0368 - accuracy: 0.9950 - val_loss: 0.1096 - val_accuracy: 0.9700\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0365 - accuracy: 0.9950 - val_loss: 0.1092 - val_accuracy: 0.9700\n",
      "Epoch 134/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0357 - accuracy: 0.9950 - val_loss: 0.1098 - val_accuracy: 0.9700\n",
      "Epoch 135/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0352 - accuracy: 0.9950 - val_loss: 0.1092 - val_accuracy: 0.9700\n",
      "Epoch 136/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0348 - accuracy: 0.9950 - val_loss: 0.1086 - val_accuracy: 0.9700\n",
      "Epoch 137/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0341 - accuracy: 0.9950 - val_loss: 0.1083 - val_accuracy: 0.9700\n",
      "Epoch 138/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0336 - accuracy: 0.9950 - val_loss: 0.1084 - val_accuracy: 0.9700\n",
      "Epoch 139/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.96 - 0s 78us/step - loss: 0.0331 - accuracy: 0.9950 - val_loss: 0.1088 - val_accuracy: 0.9700\n",
      "Epoch 140/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0328 - accuracy: 0.9950 - val_loss: 0.1076 - val_accuracy: 0.9700\n",
      "Epoch 141/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0321 - accuracy: 0.9950 - val_loss: 0.1092 - val_accuracy: 0.9700\n",
      "Epoch 142/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0317 - accuracy: 0.9975 - val_loss: 0.1104 - val_accuracy: 0.9700\n",
      "Epoch 143/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0311 - accuracy: 0.9975 - val_loss: 0.1097 - val_accuracy: 0.9700\n",
      "Epoch 144/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0306 - accuracy: 0.9975 - val_loss: 0.1097 - val_accuracy: 0.9700\n",
      "Epoch 145/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0303 - accuracy: 0.9975 - val_loss: 0.1091 - val_accuracy: 0.9700\n",
      "Epoch 146/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0299 - accuracy: 0.9975 - val_loss: 0.1099 - val_accuracy: 0.9600\n",
      "Epoch 147/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0294 - accuracy: 0.9975 - val_loss: 0.1093 - val_accuracy: 0.9600\n",
      "Epoch 148/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0290 - accuracy: 0.9975 - val_loss: 0.1088 - val_accuracy: 0.9700\n",
      "Epoch 149/1000\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0284 - accuracy: 0.9975 - val_loss: 0.1090 - val_accuracy: 0.9700\n",
      "Epoch 150/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0281 - accuracy: 0.9975 - val_loss: 0.1084 - val_accuracy: 0.9700\n",
      "Epoch 151/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0277 - accuracy: 0.9975 - val_loss: 0.1087 - val_accuracy: 0.9700\n",
      "Epoch 152/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0273 - accuracy: 0.9975 - val_loss: 0.1084 - val_accuracy: 0.9700\n",
      "Epoch 153/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.0269 - accuracy: 0.9975 - val_loss: 0.1087 - val_accuracy: 0.9700\n",
      "Epoch 154/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0265 - accuracy: 0.9975 - val_loss: 0.1091 - val_accuracy: 0.9600\n",
      "Epoch 155/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0261 - accuracy: 0.9975 - val_loss: 0.1085 - val_accuracy: 0.9700\n",
      "Epoch 156/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0257 - accuracy: 0.9975 - val_loss: 0.1079 - val_accuracy: 0.9700\n",
      "Epoch 157/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0254 - accuracy: 0.9975 - val_loss: 0.1077 - val_accuracy: 0.9700\n",
      "Epoch 158/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0251 - accuracy: 0.9975 - val_loss: 0.1077 - val_accuracy: 0.9700\n",
      "Epoch 159/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0247 - accuracy: 0.9975 - val_loss: 0.1080 - val_accuracy: 0.9700\n",
      "Epoch 160/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0244 - accuracy: 0.9975 - val_loss: 0.1078 - val_accuracy: 0.9700\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5345430559500249\n",
      "F1 Micro: 0.9345\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 664us/step - loss: 2.0690 - accuracy: 0.4375 - val_loss: 1.7378 - val_accuracy: 0.6300\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 1.4259 - accuracy: 0.6675 - val_loss: 0.8217 - val_accuracy: 0.8200\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6557 - accuracy: 0.8350 - val_loss: 0.4339 - val_accuracy: 0.8600\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5595 - accuracy: 0.8475 - val_loss: 0.3556 - val_accuracy: 0.8800\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4808 - accuracy: 0.8575 - val_loss: 0.3539 - val_accuracy: 0.9200\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.4485 - accuracy: 0.86 - 0s 195us/step - loss: 0.4599 - accuracy: 0.8600 - val_loss: 0.2929 - val_accuracy: 0.9200\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4285 - accuracy: 0.8675 - val_loss: 0.2753 - val_accuracy: 0.9200\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4059 - accuracy: 0.8800 - val_loss: 0.2580 - val_accuracy: 0.9300\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3895 - accuracy: 0.8925 - val_loss: 0.2439 - val_accuracy: 0.9300\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3724 - accuracy: 0.8925 - val_loss: 0.2168 - val_accuracy: 0.9400\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3608 - accuracy: 0.9025 - val_loss: 0.2242 - val_accuracy: 0.9500\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3455 - accuracy: 0.9000 - val_loss: 0.2048 - val_accuracy: 0.9500\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3324 - accuracy: 0.9100 - val_loss: 0.2065 - val_accuracy: 0.9600\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3215 - accuracy: 0.9100 - val_loss: 0.1957 - val_accuracy: 0.9700\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 176us/step - loss: 0.3115 - accuracy: 0.9125 - val_loss: 0.1871 - val_accuracy: 0.9800\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3055 - accuracy: 0.9125 - val_loss: 0.1856 - val_accuracy: 0.9900\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2923 - accuracy: 0.9150 - val_loss: 0.1741 - val_accuracy: 0.9900\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2851 - accuracy: 0.9150 - val_loss: 0.1650 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2748 - accuracy: 0.9175 - val_loss: 0.1745 - val_accuracy: 0.9900\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2694 - accuracy: 0.9225 - val_loss: 0.1575 - val_accuracy: 0.9900\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2651 - accuracy: 0.9225 - val_loss: 0.1727 - val_accuracy: 0.9800\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.2550 - accuracy: 0.9175 - val_loss: 0.1474 - val_accuracy: 0.9900\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2463 - accuracy: 0.9250 - val_loss: 0.1621 - val_accuracy: 0.9900\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2405 - accuracy: 0.9275 - val_loss: 0.1476 - val_accuracy: 0.9900\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2347 - accuracy: 0.9275 - val_loss: 0.1510 - val_accuracy: 0.9800\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2284 - accuracy: 0.9225 - val_loss: 0.1449 - val_accuracy: 0.9800\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2225 - accuracy: 0.9375 - val_loss: 0.1482 - val_accuracy: 0.9800\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2178 - accuracy: 0.9350 - val_loss: 0.1477 - val_accuracy: 0.9800\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.2112 - accuracy: 0.9350 - val_loss: 0.1425 - val_accuracy: 0.9800\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2060 - accuracy: 0.9375 - val_loss: 0.1423 - val_accuracy: 0.9800\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2006 - accuracy: 0.9450 - val_loss: 0.1386 - val_accuracy: 0.9800\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1951 - accuracy: 0.9450 - val_loss: 0.1314 - val_accuracy: 0.9800\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1914 - accuracy: 0.9475 - val_loss: 0.1349 - val_accuracy: 0.9800\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1884 - accuracy: 0.9475 - val_loss: 0.1234 - val_accuracy: 0.9800\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1821 - accuracy: 0.9475 - val_loss: 0.1313 - val_accuracy: 0.9800\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1813 - accuracy: 0.9475 - val_loss: 0.1413 - val_accuracy: 0.9800\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1757 - accuracy: 0.9550 - val_loss: 0.1175 - val_accuracy: 0.9800\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1708 - accuracy: 0.9475 - val_loss: 0.1243 - val_accuracy: 0.9800\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.1677 - accuracy: 0.9550 - val_loss: 0.1229 - val_accuracy: 0.9800\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1616 - accuracy: 0.9525 - val_loss: 0.1137 - val_accuracy: 0.9800\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1583 - accuracy: 0.9550 - val_loss: 0.1288 - val_accuracy: 0.9800\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1545 - accuracy: 0.9525 - val_loss: 0.1122 - val_accuracy: 0.9900\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1506 - accuracy: 0.9575 - val_loss: 0.1207 - val_accuracy: 0.9700\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1495 - accuracy: 0.9550 - val_loss: 0.1288 - val_accuracy: 0.9700\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1452 - accuracy: 0.9650 - val_loss: 0.1132 - val_accuracy: 0.9800\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1403 - accuracy: 0.9575 - val_loss: 0.1141 - val_accuracy: 0.9700\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1389 - accuracy: 0.9725 - val_loss: 0.1065 - val_accuracy: 0.9800\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1367 - accuracy: 0.9575 - val_loss: 0.1112 - val_accuracy: 0.9800\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1309 - accuracy: 0.9650 - val_loss: 0.1100 - val_accuracy: 0.9800\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1281 - accuracy: 0.9600 - val_loss: 0.1131 - val_accuracy: 0.9800\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1269 - accuracy: 0.9725 - val_loss: 0.1025 - val_accuracy: 0.9800\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1265 - accuracy: 0.9825 - val_loss: 0.0959 - val_accuracy: 0.9800\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1272 - accuracy: 0.9625 - val_loss: 0.1352 - val_accuracy: 0.9700\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1200 - accuracy: 0.9800 - val_loss: 0.0934 - val_accuracy: 0.9800\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1163 - accuracy: 0.9725 - val_loss: 0.1065 - val_accuracy: 0.9800\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1144 - accuracy: 0.9700 - val_loss: 0.1012 - val_accuracy: 0.9800\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1116 - accuracy: 0.9800 - val_loss: 0.1000 - val_accuracy: 0.9800\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1112 - accuracy: 0.9725 - val_loss: 0.1142 - val_accuracy: 0.9800\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1099 - accuracy: 0.9800 - val_loss: 0.0877 - val_accuracy: 0.9800\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1061 - accuracy: 0.9675 - val_loss: 0.1367 - val_accuracy: 0.9800\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1013 - accuracy: 0.9825 - val_loss: 0.0864 - val_accuracy: 0.9800\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.0976 - accuracy: 0.9825 - val_loss: 0.1086 - val_accuracy: 0.9800\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0957 - accuracy: 0.9800 - val_loss: 0.0949 - val_accuracy: 0.9800\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0975 - accuracy: 0.9850 - val_loss: 0.0844 - val_accuracy: 0.9800\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0943 - accuracy: 0.9725 - val_loss: 0.1269 - val_accuracy: 0.9700\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0916 - accuracy: 0.9850 - val_loss: 0.0775 - val_accuracy: 0.9700\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1102 - accuracy: 0.9675 - val_loss: 0.1226 - val_accuracy: 0.9800\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0844 - accuracy: 0.9925 - val_loss: 0.0815 - val_accuracy: 0.9800\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0893 - accuracy: 0.9875 - val_loss: 0.0884 - val_accuracy: 0.9700\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0895 - accuracy: 0.9775 - val_loss: 0.1044 - val_accuracy: 0.9800\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0843 - accuracy: 0.9900 - val_loss: 0.0838 - val_accuracy: 0.9700\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0776 - accuracy: 0.9875 - val_loss: 0.1012 - val_accuracy: 0.9700\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0774 - accuracy: 0.9900 - val_loss: 0.0837 - val_accuracy: 0.9700\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 238us/step - loss: 0.0757 - accuracy: 0.9925 - val_loss: 0.0950 - val_accuracy: 0.9700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.0717 - accuracy: 0.9925 - val_loss: 0.0885 - val_accuracy: 0.9700\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0701 - accuracy: 0.9925 - val_loss: 0.0895 - val_accuracy: 0.9700\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0676 - accuracy: 0.9925 - val_loss: 0.0933 - val_accuracy: 0.9700\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0657 - accuracy: 0.9925 - val_loss: 0.0840 - val_accuracy: 0.9700\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0657 - accuracy: 0.9925 - val_loss: 0.0886 - val_accuracy: 0.9700\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0634 - accuracy: 0.9925 - val_loss: 0.0896 - val_accuracy: 0.9700\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0612 - accuracy: 0.9925 - val_loss: 0.0857 - val_accuracy: 0.9700\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0600 - accuracy: 0.9925 - val_loss: 0.0865 - val_accuracy: 0.9700\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0592 - accuracy: 0.9925 - val_loss: 0.0973 - val_accuracy: 0.9700\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0648 - accuracy: 0.9900 - val_loss: 0.0769 - val_accuracy: 0.9700\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0612 - accuracy: 0.9875 - val_loss: 0.1243 - val_accuracy: 0.9600\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0655 - accuracy: 0.9850 - val_loss: 0.0842 - val_accuracy: 0.9700\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.0553 - accuracy: 0.9925 - val_loss: 0.0786 - val_accuracy: 0.9700\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0567 - accuracy: 0.9925 - val_loss: 0.1036 - val_accuracy: 0.9700\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0502 - accuracy: 0.9925 - val_loss: 0.0804 - val_accuracy: 0.9700\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0483 - accuracy: 0.9925 - val_loss: 0.0927 - val_accuracy: 0.9700\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0468 - accuracy: 0.9950 - val_loss: 0.0771 - val_accuracy: 0.9700\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0468 - accuracy: 0.9925 - val_loss: 0.0842 - val_accuracy: 0.9700\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0438 - accuracy: 0.9925 - val_loss: 0.0837 - val_accuracy: 0.9700\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0419 - accuracy: 0.9925 - val_loss: 0.0771 - val_accuracy: 0.9700\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0431 - accuracy: 0.9925 - val_loss: 0.0845 - val_accuracy: 0.9700\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0393 - accuracy: 0.9925 - val_loss: 0.0828 - val_accuracy: 0.9700\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0378 - accuracy: 0.9950 - val_loss: 0.0810 - val_accuracy: 0.9700\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0376 - accuracy: 0.9950 - val_loss: 0.0844 - val_accuracy: 0.9700\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 196us/step - loss: 0.0388 - accuracy: 0.9950 - val_loss: 0.0811 - val_accuracy: 0.9700\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0341 - accuracy: 0.9950 - val_loss: 0.0901 - val_accuracy: 0.9700\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0334 - accuracy: 0.9950 - val_loss: 0.0894 - val_accuracy: 0.9700\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0332 - accuracy: 0.9950 - val_loss: 0.0841 - val_accuracy: 0.9700\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0319 - accuracy: 0.9950 - val_loss: 0.0917 - val_accuracy: 0.9700\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0308 - accuracy: 0.9950 - val_loss: 0.0931 - val_accuracy: 0.9700\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5238596673971541\n",
      "F1 Micro: 0.9348\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.4383398995236619\n",
      "F1 Micro: 0.9325\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5361686301245758\n",
      "F1 Micro: 0.9345\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 2 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 225us/step - loss: 0.8316 - accuracy: 0.8482 - val_loss: 0.5810 - val_accuracy: 0.8690\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 0.6041 - accuracy: 0.8555 - val_loss: 0.5094 - val_accuracy: 0.8690\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 173us/step - loss: 0.4774 - accuracy: 0.8790 - val_loss: 0.3970 - val_accuracy: 0.9000\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 177us/step - loss: 0.3673 - accuracy: 0.9060 - val_loss: 0.3219 - val_accuracy: 0.9120\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.2952 - accuracy: 0.9235 - val_loss: 0.2704 - val_accuracy: 0.9280\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.2562 - accuracy: 0.9317 - val_loss: 0.2261 - val_accuracy: 0.9380\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.2177 - accuracy: 0.9410 - val_loss: 0.2104 - val_accuracy: 0.9400\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 175us/step - loss: 0.2037 - accuracy: 0.9450 - val_loss: 0.2479 - val_accuracy: 0.9410\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 173us/step - loss: 0.1938 - accuracy: 0.9467 - val_loss: 0.1828 - val_accuracy: 0.9470\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.1701 - accuracy: 0.9513 - val_loss: 0.1755 - val_accuracy: 0.9470\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 0.1662 - accuracy: 0.9523 - val_loss: 0.1729 - val_accuracy: 0.9480\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.1600 - accuracy: 0.9538 - val_loss: 0.1668 - val_accuracy: 0.9500\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.1470 - accuracy: 0.9578 - val_loss: 0.1773 - val_accuracy: 0.9500\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 175us/step - loss: 0.1397 - accuracy: 0.9588 - val_loss: 0.1734 - val_accuracy: 0.9500\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.1402 - accuracy: 0.9560 - val_loss: 0.1779 - val_accuracy: 0.9520\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.1345 - accuracy: 0.9613 - val_loss: 0.1585 - val_accuracy: 0.9540\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 0.1285 - accuracy: 0.9620 - val_loss: 0.1415 - val_accuracy: 0.9620\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.1196 - accuracy: 0.9628 - val_loss: 0.1529 - val_accuracy: 0.9560\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 0.1181 - accuracy: 0.9647 - val_loss: 0.1318 - val_accuracy: 0.9640\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.1068 - accuracy: 0.9688 - val_loss: 0.1415 - val_accuracy: 0.9600\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.1029 - accuracy: 0.9700 - val_loss: 0.1433 - val_accuracy: 0.9610\n",
      "Epoch 22/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.0954 - accuracy: 0.9735 - val_loss: 0.1755 - val_accuracy: 0.9510\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.1121 - accuracy: 0.9672 - val_loss: 0.1379 - val_accuracy: 0.9620\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 0.0935 - accuracy: 0.9735 - val_loss: 0.1326 - val_accuracy: 0.9610\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.0897 - accuracy: 0.9725 - val_loss: 0.1314 - val_accuracy: 0.9620\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 0.0897 - accuracy: 0.9732 - val_loss: 0.1331 - val_accuracy: 0.9640\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.0795 - accuracy: 0.9743 - val_loss: 0.1357 - val_accuracy: 0.9600\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 177us/step - loss: 0.0770 - accuracy: 0.9775 - val_loss: 0.1282 - val_accuracy: 0.9630\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.0663 - accuracy: 0.9827 - val_loss: 0.1344 - val_accuracy: 0.9610\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.0727 - accuracy: 0.9775 - val_loss: 0.1600 - val_accuracy: 0.9540\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 0.0702 - accuracy: 0.9808 - val_loss: 0.1890 - val_accuracy: 0.95400s - loss: 0.0711 - accuracy: 0.98\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.0671 - accuracy: 0.9787 - val_loss: 0.1549 - val_accuracy: 0.9570\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 177us/step - loss: 0.0601 - accuracy: 0.9830 - val_loss: 0.1428 - val_accuracy: 0.9590\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.0545 - accuracy: 0.9845 - val_loss: 0.1346 - val_accuracy: 0.9620\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 177us/step - loss: 0.0561 - accuracy: 0.9835 - val_loss: 0.1297 - val_accuracy: 0.9650\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 0.0454 - accuracy: 0.9877 - val_loss: 0.1384 - val_accuracy: 0.9590\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.0453 - accuracy: 0.9872 - val_loss: 0.1541 - val_accuracy: 0.9560\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 0.0535 - accuracy: 0.9833 - val_loss: 0.1379 - val_accuracy: 0.9680\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.0355 - accuracy: 0.9905 - val_loss: 0.1404 - val_accuracy: 0.9660\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 177us/step - loss: 0.0441 - accuracy: 0.9872 - val_loss: 0.1434 - val_accuracy: 0.9620\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 0.0351 - accuracy: 0.9905 - val_loss: 0.1497 - val_accuracy: 0.9640\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.0303 - accuracy: 0.9933 - val_loss: 0.1435 - val_accuracy: 0.9670\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.0270 - accuracy: 0.9945 - val_loss: 0.1332 - val_accuracy: 0.9590\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.0225 - accuracy: 0.9962 - val_loss: 0.1681 - val_accuracy: 0.9580\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.0278 - accuracy: 0.9930 - val_loss: 0.1749 - val_accuracy: 0.9610\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 0.0414 - accuracy: 0.9855 - val_loss: 0.1388 - val_accuracy: 0.9660\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.0210 - accuracy: 0.9962 - val_loss: 0.1506 - val_accuracy: 0.9610\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 0.0184 - accuracy: 0.9958 - val_loss: 0.1670 - val_accuracy: 0.9600\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6535611068656532\n",
      "F1 Micro: 0.9566\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6857675377859219\n",
      "F1 Micro: 0.9539\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 84us/step - loss: 1.6804 - accuracy: 0.5510 - val_loss: 1.3336 - val_accuracy: 0.6830\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 64us/step - loss: 1.0832 - accuracy: 0.7780 - val_loss: 0.8346 - val_accuracy: 0.8390\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.6410 - accuracy: 0.8850 - val_loss: 0.4962 - val_accuracy: 0.9150\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.3913 - accuracy: 0.9293 - val_loss: 0.3256 - val_accuracy: 0.9400\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.2732 - accuracy: 0.9435 - val_loss: 0.2450 - val_accuracy: 0.9410\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.2156 - accuracy: 0.9510 - val_loss: 0.2001 - val_accuracy: 0.9500\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1842 - accuracy: 0.9545 - val_loss: 0.1750 - val_accuracy: 0.9520\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1652 - accuracy: 0.9580 - val_loss: 0.1599 - val_accuracy: 0.9540\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1518 - accuracy: 0.9605 - val_loss: 0.1493 - val_accuracy: 0.9590\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1419 - accuracy: 0.9625 - val_loss: 0.1419 - val_accuracy: 0.9570\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1349 - accuracy: 0.9617 - val_loss: 0.1364 - val_accuracy: 0.9590\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1280 - accuracy: 0.9647 - val_loss: 0.1323 - val_accuracy: 0.9590\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1227 - accuracy: 0.9657 - val_loss: 0.1274 - val_accuracy: 0.9610\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1179 - accuracy: 0.9670 - val_loss: 0.1267 - val_accuracy: 0.9600\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1134 - accuracy: 0.9688 - val_loss: 0.1214 - val_accuracy: 0.9620\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1105 - accuracy: 0.9682 - val_loss: 0.1211 - val_accuracy: 0.9640\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1072 - accuracy: 0.9690 - val_loss: 0.1184 - val_accuracy: 0.9640\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1048 - accuracy: 0.9690 - val_loss: 0.1173 - val_accuracy: 0.9640\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1018 - accuracy: 0.9700 - val_loss: 0.1168 - val_accuracy: 0.9640\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0991 - accuracy: 0.9707 - val_loss: 0.1133 - val_accuracy: 0.9670\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0969 - accuracy: 0.9712 - val_loss: 0.1152 - val_accuracy: 0.9660\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0949 - accuracy: 0.9725 - val_loss: 0.1121 - val_accuracy: 0.9670\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0927 - accuracy: 0.9735 - val_loss: 0.1104 - val_accuracy: 0.9650\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.0905 - accuracy: 0.9743 - val_loss: 0.1109 - val_accuracy: 0.9660\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0887 - accuracy: 0.9740 - val_loss: 0.1106 - val_accuracy: 0.9660\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0870 - accuracy: 0.9753 - val_loss: 0.1083 - val_accuracy: 0.9660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.0856 - accuracy: 0.9743 - val_loss: 0.1080 - val_accuracy: 0.9670\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.0837 - accuracy: 0.9753 - val_loss: 0.1059 - val_accuracy: 0.9670\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0816 - accuracy: 0.9768 - val_loss: 0.1061 - val_accuracy: 0.9680\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0805 - accuracy: 0.9762 - val_loss: 0.1060 - val_accuracy: 0.9680\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0794 - accuracy: 0.9768 - val_loss: 0.1056 - val_accuracy: 0.9670\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.1040 - val_accuracy: 0.9670\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0756 - accuracy: 0.9797 - val_loss: 0.1045 - val_accuracy: 0.9670\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0750 - accuracy: 0.9793 - val_loss: 0.1028 - val_accuracy: 0.9670\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0732 - accuracy: 0.9790 - val_loss: 0.1058 - val_accuracy: 0.9670\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0722 - accuracy: 0.9810 - val_loss: 0.1023 - val_accuracy: 0.9670\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.0709 - accuracy: 0.9800 - val_loss: 0.1010 - val_accuracy: 0.9660\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.0694 - accuracy: 0.9803 - val_loss: 0.1011 - val_accuracy: 0.9680\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0682 - accuracy: 0.9825 - val_loss: 0.1047 - val_accuracy: 0.9680\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0681 - accuracy: 0.9818 - val_loss: 0.1028 - val_accuracy: 0.9660\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0660 - accuracy: 0.9833 - val_loss: 0.1031 - val_accuracy: 0.9670\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0653 - accuracy: 0.9818 - val_loss: 0.0999 - val_accuracy: 0.9680\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0639 - accuracy: 0.9835 - val_loss: 0.1003 - val_accuracy: 0.9670\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0632 - accuracy: 0.9833 - val_loss: 0.1014 - val_accuracy: 0.9670\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0619 - accuracy: 0.9837 - val_loss: 0.1003 - val_accuracy: 0.9690\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0612 - accuracy: 0.9835 - val_loss: 0.0999 - val_accuracy: 0.9680\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0599 - accuracy: 0.9847 - val_loss: 0.0995 - val_accuracy: 0.9670\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0589 - accuracy: 0.9845 - val_loss: 0.1047 - val_accuracy: 0.9670\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0590 - accuracy: 0.9852 - val_loss: 0.0995 - val_accuracy: 0.9670\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0568 - accuracy: 0.9850 - val_loss: 0.0993 - val_accuracy: 0.9680\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0565 - accuracy: 0.9865 - val_loss: 0.0980 - val_accuracy: 0.9680\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0549 - accuracy: 0.9850 - val_loss: 0.1006 - val_accuracy: 0.9680\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0541 - accuracy: 0.9862 - val_loss: 0.0979 - val_accuracy: 0.9670\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0538 - accuracy: 0.9865 - val_loss: 0.0979 - val_accuracy: 0.9690\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0523 - accuracy: 0.9877 - val_loss: 0.0981 - val_accuracy: 0.9680\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0519 - accuracy: 0.9877 - val_loss: 0.0997 - val_accuracy: 0.9680\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0509 - accuracy: 0.9870 - val_loss: 0.0989 - val_accuracy: 0.9700\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0496 - accuracy: 0.9880 - val_loss: 0.0975 - val_accuracy: 0.9670\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0490 - accuracy: 0.9875 - val_loss: 0.1008 - val_accuracy: 0.9700\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0487 - accuracy: 0.9880 - val_loss: 0.0994 - val_accuracy: 0.9690\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0475 - accuracy: 0.9883 - val_loss: 0.0981 - val_accuracy: 0.9670\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0466 - accuracy: 0.9880 - val_loss: 0.0980 - val_accuracy: 0.9700\n",
      "Epoch 63/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0455 - accuracy: 0.9887 - val_loss: 0.0997 - val_accuracy: 0.9690\n",
      "Epoch 64/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0453 - accuracy: 0.9890 - val_loss: 0.0986 - val_accuracy: 0.9700\n",
      "Epoch 65/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0444 - accuracy: 0.9890 - val_loss: 0.0986 - val_accuracy: 0.9700\n",
      "Epoch 66/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0437 - accuracy: 0.9893 - val_loss: 0.0984 - val_accuracy: 0.9700\n",
      "Epoch 67/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0429 - accuracy: 0.9893 - val_loss: 0.0982 - val_accuracy: 0.9700\n",
      "Epoch 68/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0418 - accuracy: 0.9900 - val_loss: 0.0998 - val_accuracy: 0.9720\n",
      "Epoch 69/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0417 - accuracy: 0.9895 - val_loss: 0.0981 - val_accuracy: 0.9700\n",
      "Epoch 70/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0412 - accuracy: 0.9898 - val_loss: 0.1002 - val_accuracy: 0.9710\n",
      "Epoch 71/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0402 - accuracy: 0.9900 - val_loss: 0.0993 - val_accuracy: 0.9700\n",
      "Epoch 72/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0394 - accuracy: 0.9900 - val_loss: 0.1021 - val_accuracy: 0.9700\n",
      "Epoch 73/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0381 - accuracy: 0.9902 - val_loss: 0.1034 - val_accuracy: 0.9720\n",
      "Epoch 74/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0379 - accuracy: 0.9905 - val_loss: 0.1029 - val_accuracy: 0.9700\n",
      "Epoch 75/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0373 - accuracy: 0.9910 - val_loss: 0.1004 - val_accuracy: 0.9710\n",
      "Epoch 76/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0365 - accuracy: 0.9915 - val_loss: 0.1007 - val_accuracy: 0.9710\n",
      "Epoch 77/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0357 - accuracy: 0.9915 - val_loss: 0.1000 - val_accuracy: 0.9720\n",
      "Epoch 78/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0354 - accuracy: 0.9920 - val_loss: 0.1019 - val_accuracy: 0.9730\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7283894336849159\n",
      "F1 Micro: 0.9583\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 240us/step - loss: 0.6507 - accuracy: 0.8238 - val_loss: 0.3375 - val_accuracy: 0.9050\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.3112 - accuracy: 0.9175 - val_loss: 0.2747 - val_accuracy: 0.9270\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.2534 - accuracy: 0.9327 - val_loss: 0.2352 - val_accuracy: 0.9430\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.2195 - accuracy: 0.9395 - val_loss: 0.2053 - val_accuracy: 0.9440\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1945 - accuracy: 0.9445 - val_loss: 0.1892 - val_accuracy: 0.9480\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1796 - accuracy: 0.9485 - val_loss: 0.1838 - val_accuracy: 0.9460\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1631 - accuracy: 0.9510 - val_loss: 0.1686 - val_accuracy: 0.9490\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1525 - accuracy: 0.9557 - val_loss: 0.1585 - val_accuracy: 0.9590\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1439 - accuracy: 0.9578 - val_loss: 0.1506 - val_accuracy: 0.9570\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1372 - accuracy: 0.9590 - val_loss: 0.1475 - val_accuracy: 0.9550\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1291 - accuracy: 0.9615 - val_loss: 0.1454 - val_accuracy: 0.9580\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1241 - accuracy: 0.9628 - val_loss: 0.1381 - val_accuracy: 0.9570\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1227 - accuracy: 0.9632 - val_loss: 0.1454 - val_accuracy: 0.9540\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1144 - accuracy: 0.9653 - val_loss: 0.1336 - val_accuracy: 0.9610\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1100 - accuracy: 0.9675 - val_loss: 0.1345 - val_accuracy: 0.9600\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1046 - accuracy: 0.9685 - val_loss: 0.1308 - val_accuracy: 0.9580\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1004 - accuracy: 0.9697 - val_loss: 0.1282 - val_accuracy: 0.9610\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0944 - accuracy: 0.9712 - val_loss: 0.1283 - val_accuracy: 0.9610\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0930 - accuracy: 0.9707 - val_loss: 0.1219 - val_accuracy: 0.9620\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0877 - accuracy: 0.9737 - val_loss: 0.1254 - val_accuracy: 0.9610\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.0837 - accuracy: 0.9758 - val_loss: 0.1175 - val_accuracy: 0.9640\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0805 - accuracy: 0.9762 - val_loss: 0.1204 - val_accuracy: 0.9650\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0723 - accuracy: 0.9762 - val_loss: 0.1201 - val_accuracy: 0.9630\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0685 - accuracy: 0.9765 - val_loss: 0.1206 - val_accuracy: 0.9600\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0641 - accuracy: 0.9810 - val_loss: 0.1431 - val_accuracy: 0.9610\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0648 - accuracy: 0.9793 - val_loss: 0.1166 - val_accuracy: 0.9610\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0530 - accuracy: 0.9837 - val_loss: 0.1172 - val_accuracy: 0.9650\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0516 - accuracy: 0.9837 - val_loss: 0.1222 - val_accuracy: 0.9680\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0452 - accuracy: 0.9885 - val_loss: 0.1214 - val_accuracy: 0.9680\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0451 - accuracy: 0.9870 - val_loss: 0.1232 - val_accuracy: 0.9610\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0379 - accuracy: 0.9900 - val_loss: 0.1244 - val_accuracy: 0.9640\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0410 - accuracy: 0.9887 - val_loss: 0.1252 - val_accuracy: 0.9660\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0312 - accuracy: 0.9948 - val_loss: 0.1499 - val_accuracy: 0.9700\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0292 - accuracy: 0.9950 - val_loss: 0.1356 - val_accuracy: 0.9680\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0266 - accuracy: 0.9942 - val_loss: 0.1469 - val_accuracy: 0.9660\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0240 - accuracy: 0.9960 - val_loss: 0.1332 - val_accuracy: 0.9640\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0207 - accuracy: 0.9965 - val_loss: 0.1432 - val_accuracy: 0.9650\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0191 - accuracy: 0.9965 - val_loss: 0.1430 - val_accuracy: 0.9690\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0228 - accuracy: 0.9948 - val_loss: 0.1531 - val_accuracy: 0.9720\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0157 - accuracy: 0.9975 - val_loss: 0.1557 - val_accuracy: 0.9690\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0138 - accuracy: 0.9987 - val_loss: 0.1557 - val_accuracy: 0.9690\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0118 - accuracy: 0.9990 - val_loss: 0.1435 - val_accuracy: 0.9650\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0111 - accuracy: 0.9990 - val_loss: 0.1899 - val_accuracy: 0.9650\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0120 - accuracy: 0.9990 - val_loss: 0.1513 - val_accuracy: 0.9660\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 0.1584 - val_accuracy: 0.9690\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9680\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7410927953860281\n",
      "F1 Micro: 0.9583\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6944092381521142\n",
      "F1 Micro: 0.954\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7529811499785699\n",
      "F1 Micro: 0.9622\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 2 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.4126 - accuracy: 0.9000 - val_loss: 0.2778 - val_accuracy: 0.9246\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.1881 - accuracy: 0.9452 - val_loss: 0.1545 - val_accuracy: 0.9522\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.1479 - accuracy: 0.9539 - val_loss: 0.1363 - val_accuracy: 0.9570\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1304 - accuracy: 0.9588 - val_loss: 0.1247 - val_accuracy: 0.9601\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1199 - accuracy: 0.9618 - val_loss: 0.1265 - val_accuracy: 0.9581\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.1118 - accuracy: 0.9643 - val_loss: 0.1154 - val_accuracy: 0.9625\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1038 - accuracy: 0.9670 - val_loss: 0.1152 - val_accuracy: 0.9651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0981 - accuracy: 0.9689 - val_loss: 0.1087 - val_accuracy: 0.9641\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0933 - accuracy: 0.9700 - val_loss: 0.0986 - val_accuracy: 0.9687\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0852 - accuracy: 0.9717 - val_loss: 0.0990 - val_accuracy: 0.9681\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0811 - accuracy: 0.9724 - val_loss: 0.0987 - val_accuracy: 0.9664\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0748 - accuracy: 0.9746 - val_loss: 0.0952 - val_accuracy: 0.9688\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0680 - accuracy: 0.9771 - val_loss: 0.0927 - val_accuracy: 0.9693\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0630 - accuracy: 0.9782 - val_loss: 0.1055 - val_accuracy: 0.9683\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0579 - accuracy: 0.9801 - val_loss: 0.0982 - val_accuracy: 0.9666\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0521 - accuracy: 0.9813 - val_loss: 0.0944 - val_accuracy: 0.9705\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0494 - accuracy: 0.9817 - val_loss: 0.1003 - val_accuracy: 0.9708\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0405 - accuracy: 0.9858 - val_loss: 0.1078 - val_accuracy: 0.9638\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0363 - accuracy: 0.9870 - val_loss: 0.1071 - val_accuracy: 0.9663\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0325 - accuracy: 0.9885 - val_loss: 0.1089 - val_accuracy: 0.9676\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 0.1082 - val_accuracy: 0.9708\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.1088 - val_accuracy: 0.9689\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.1216 - val_accuracy: 0.9655\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.1226 - val_accuracy: 0.9645\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.1323 - val_accuracy: 0.9690\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.1228 - val_accuracy: 0.9714\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.1727 - val_accuracy: 0.9684\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.1425 - val_accuracy: 0.9693\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.1469 - val_accuracy: 0.9677\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.1354 - val_accuracy: 0.9704\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.1640 - val_accuracy: 0.9624\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.1566 - val_accuracy: 0.9656\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1518 - val_accuracy: 0.9694\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8280338550938859\n",
      "F1 Micro: 0.969\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8034970099132815\n",
      "F1 Micro: 0.965\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.5218 - accuracy: 0.8771 - val_loss: 0.1645 - val_accuracy: 0.9510\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1460 - accuracy: 0.9577 - val_loss: 0.1369 - val_accuracy: 0.9567\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1283 - accuracy: 0.9612 - val_loss: 0.1274 - val_accuracy: 0.9609 0s - loss: 0.1278 - accura\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1190 - accuracy: 0.9639 - val_loss: 0.1222 - val_accuracy: 0.9626\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.1131 - accuracy: 0.9651 - val_loss: 0.1156 - val_accuracy: 0.9650\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1088 - accuracy: 0.9660 - val_loss: 0.1120 - val_accuracy: 0.9652\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1053 - accuracy: 0.9675 - val_loss: 0.1094 - val_accuracy: 0.9649\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1022 - accuracy: 0.9677 - val_loss: 0.1077 - val_accuracy: 0.9656\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0998 - accuracy: 0.9683 - val_loss: 0.1053 - val_accuracy: 0.9664\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0975 - accuracy: 0.9692 - val_loss: 0.1033 - val_accuracy: 0.9675\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0956 - accuracy: 0.9695 - val_loss: 0.1026 - val_accuracy: 0.9668\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0936 - accuracy: 0.9699 - val_loss: 0.1006 - val_accuracy: 0.9673\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0917 - accuracy: 0.9705 - val_loss: 0.1010 - val_accuracy: 0.9679\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0904 - accuracy: 0.9715 - val_loss: 0.0987 - val_accuracy: 0.9687\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0888 - accuracy: 0.9715 - val_loss: 0.0984 - val_accuracy: 0.9688\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0876 - accuracy: 0.9720 - val_loss: 0.0970 - val_accuracy: 0.9689\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0864 - accuracy: 0.9721 - val_loss: 0.0974 - val_accuracy: 0.9685\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0848 - accuracy: 0.9723 - val_loss: 0.0984 - val_accuracy: 0.9689\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0840 - accuracy: 0.9728 - val_loss: 0.0973 - val_accuracy: 0.9687\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0826 - accuracy: 0.9732 - val_loss: 0.0973 - val_accuracy: 0.9687\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0815 - accuracy: 0.9740 - val_loss: 0.0949 - val_accuracy: 0.9698\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0807 - accuracy: 0.9743 - val_loss: 0.0959 - val_accuracy: 0.9702\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0797 - accuracy: 0.9741 - val_loss: 0.0938 - val_accuracy: 0.9706\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0789 - accuracy: 0.9743 - val_loss: 0.0935 - val_accuracy: 0.9708\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0776 - accuracy: 0.9750 - val_loss: 0.0932 - val_accuracy: 0.9700\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0771 - accuracy: 0.9753 - val_loss: 0.0925 - val_accuracy: 0.9709\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0760 - accuracy: 0.9756 - val_loss: 0.0937 - val_accuracy: 0.9701\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0749 - accuracy: 0.9760 - val_loss: 0.0929 - val_accuracy: 0.9703\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0744 - accuracy: 0.9761 - val_loss: 0.0930 - val_accuracy: 0.9709\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0734 - accuracy: 0.9761 - val_loss: 0.0927 - val_accuracy: 0.9698\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0723 - accuracy: 0.9769 - val_loss: 0.0927 - val_accuracy: 0.9705\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0717 - accuracy: 0.9772 - val_loss: 0.0934 - val_accuracy: 0.9692\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0708 - accuracy: 0.9768 - val_loss: 0.0921 - val_accuracy: 0.9702\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0703 - accuracy: 0.9772 - val_loss: 0.0915 - val_accuracy: 0.9712\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0698 - accuracy: 0.9779 - val_loss: 0.0915 - val_accuracy: 0.9700\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0687 - accuracy: 0.9782 - val_loss: 0.0939 - val_accuracy: 0.9694\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0680 - accuracy: 0.9783 - val_loss: 0.0907 - val_accuracy: 0.9699\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0672 - accuracy: 0.9784 - val_loss: 0.0917 - val_accuracy: 0.9709\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0662 - accuracy: 0.9793 - val_loss: 0.0910 - val_accuracy: 0.9720\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0658 - accuracy: 0.9794 - val_loss: 0.0915 - val_accuracy: 0.9705 0s - loss: 0.0669 - accu\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0650 - accuracy: 0.9793 - val_loss: 0.0915 - val_accuracy: 0.9709\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0642 - accuracy: 0.9797 - val_loss: 0.0941 - val_accuracy: 0.9690\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0637 - accuracy: 0.9794 - val_loss: 0.0916 - val_accuracy: 0.9700\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0627 - accuracy: 0.9801 - val_loss: 0.0920 - val_accuracy: 0.9704\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0621 - accuracy: 0.9805 - val_loss: 0.0923 - val_accuracy: 0.9706\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0617 - accuracy: 0.9804 - val_loss: 0.0897 - val_accuracy: 0.9714\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0608 - accuracy: 0.9812 - val_loss: 0.0921 - val_accuracy: 0.9709\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0600 - accuracy: 0.9810 - val_loss: 0.0919 - val_accuracy: 0.9695\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0595 - accuracy: 0.9807 - val_loss: 0.0925 - val_accuracy: 0.96958 - ETA: 0s - loss: 0.0595 - accuracy\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0591 - accuracy: 0.9819 - val_loss: 0.0923 - val_accuracy: 0.9692\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0583 - accuracy: 0.9815 - val_loss: 0.0923 - val_accuracy: 0.9699\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0575 - accuracy: 0.9818 - val_loss: 0.0927 - val_accuracy: 0.9699\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0567 - accuracy: 0.9821 - val_loss: 0.0929 - val_accuracy: 0.9692\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0561 - accuracy: 0.9825 - val_loss: 0.0945 - val_accuracy: 0.9695\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0560 - accuracy: 0.9825 - val_loss: 0.0920 - val_accuracy: 0.9703\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0551 - accuracy: 0.9829 - val_loss: 0.0928 - val_accuracy: 0.9710\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0541 - accuracy: 0.9834 - val_loss: 0.0942 - val_accuracy: 0.9702\n",
      "Epoch 58/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0539 - accuracy: 0.9832 - val_loss: 0.0936 - val_accuracy: 0.9699\n",
      "Epoch 59/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0532 - accuracy: 0.9836 - val_loss: 0.0936 - val_accuracy: 0.9703\n",
      "Epoch 60/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0525 - accuracy: 0.9838 - val_loss: 0.0944 - val_accuracy: 0.9697\n",
      "Epoch 61/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0519 - accuracy: 0.9841 - val_loss: 0.0938 - val_accuracy: 0.9699\n",
      "Epoch 62/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0514 - accuracy: 0.9840 - val_loss: 0.0930 - val_accuracy: 0.9707\n",
      "Epoch 63/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0506 - accuracy: 0.9841 - val_loss: 0.0953 - val_accuracy: 0.9703\n",
      "Epoch 64/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0505 - accuracy: 0.9839 - val_loss: 0.0954 - val_accuracy: 0.9692\n",
      "Epoch 65/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0494 - accuracy: 0.9849 - val_loss: 0.0956 - val_accuracy: 0.9698\n",
      "Epoch 66/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0492 - accuracy: 0.9850 - val_loss: 0.0951 - val_accuracy: 0.9699\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8498616984118835\n",
      "F1 Micro: 0.969\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.2524 - accuracy: 0.9312 - val_loss: 0.1635 - val_accuracy: 0.9498\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.1456 - accuracy: 0.9561 - val_loss: 0.1369 - val_accuracy: 0.9581\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.1262 - accuracy: 0.9620 - val_loss: 0.1256 - val_accuracy: 0.9596\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.1151 - accuracy: 0.9640 - val_loss: 0.1312 - val_accuracy: 0.9611\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.1083 - accuracy: 0.9665 - val_loss: 0.1093 - val_accuracy: 0.9654\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1025 - accuracy: 0.9675 - val_loss: 0.1045 - val_accuracy: 0.9667\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0974 - accuracy: 0.9689 - val_loss: 0.0993 - val_accuracy: 0.9672\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0926 - accuracy: 0.9704 - val_loss: 0.0975 - val_accuracy: 0.9684\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0876 - accuracy: 0.9718 - val_loss: 0.0914 - val_accuracy: 0.9699\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0822 - accuracy: 0.9741 - val_loss: 0.0900 - val_accuracy: 0.9708\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0769 - accuracy: 0.9751 - val_loss: 0.0906 - val_accuracy: 0.9715\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0727 - accuracy: 0.9767 - val_loss: 0.0883 - val_accuracy: 0.9714\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0675 - accuracy: 0.9779 - val_loss: 0.0893 - val_accuracy: 0.9712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0616 - accuracy: 0.9802 - val_loss: 0.0880 - val_accuracy: 0.9727\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0566 - accuracy: 0.9814 - val_loss: 0.0873 - val_accuracy: 0.9726\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0505 - accuracy: 0.9841 - val_loss: 0.0911 - val_accuracy: 0.9717\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0441 - accuracy: 0.9860 - val_loss: 0.0946 - val_accuracy: 0.9694\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0380 - accuracy: 0.9880 - val_loss: 0.1019 - val_accuracy: 0.9701\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0305 - accuracy: 0.9913 - val_loss: 0.0986 - val_accuracy: 0.9728\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0260 - accuracy: 0.9926 - val_loss: 0.1010 - val_accuracy: 0.9714\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0203 - accuracy: 0.9944 - val_loss: 0.1072 - val_accuracy: 0.9719\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.1131 - val_accuracy: 0.9720\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.1216 - val_accuracy: 0.9711\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.1250 - val_accuracy: 0.9679\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.1287 - val_accuracy: 0.9702\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.1315 - val_accuracy: 0.9684\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.1430 - val_accuracy: 0.9693\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.1362 - val_accuracy: 0.9706\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.2489 - val_accuracy: 0.9651\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.1507 - val_accuracy: 0.9716\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.1993 - val_accuracy: 0.9693\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1626 - val_accuracy: 0.9706\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.1476 - val_accuracy: 0.9712\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.1476 - val_accuracy: 0.9718\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.1493 - val_accuracy: 0.9701\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.852796879538611\n",
      "F1 Micro: 0.9719\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8106698063991948\n",
      "F1 Micro: 0.9645\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8670094775072745\n",
      "F1 Micro: 0.9734\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 2 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.2367 - accuracy: 0.9362 - val_loss: 0.1379 - val_accuracy: 0.9580\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.1178 - accuracy: 0.9631 - val_loss: 0.1032 - val_accuracy: 0.9675\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.1006 - accuracy: 0.9677 - val_loss: 0.1040 - val_accuracy: 0.9679\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0901 - accuracy: 0.9702 - val_loss: 0.0863 - val_accuracy: 0.9723\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0812 - accuracy: 0.9727 - val_loss: 0.0798 - val_accuracy: 0.9736\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0730 - accuracy: 0.9756 - val_loss: 0.0838 - val_accuracy: 0.9732\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0670 - accuracy: 0.9768 - val_loss: 0.0774 - val_accuracy: 0.9746\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0602 - accuracy: 0.9790 - val_loss: 0.0696 - val_accuracy: 0.9763\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0556 - accuracy: 0.9805 - val_loss: 0.0710 - val_accuracy: 0.9754\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0517 - accuracy: 0.9817 - val_loss: 0.0712 - val_accuracy: 0.9764\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0474 - accuracy: 0.9833 - val_loss: 0.0797 - val_accuracy: 0.9753\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0432 - accuracy: 0.9842 - val_loss: 0.0770 - val_accuracy: 0.9765\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0382 - accuracy: 0.9863 - val_loss: 0.0758 - val_accuracy: 0.9759\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0338 - accuracy: 0.9878 - val_loss: 0.0862 - val_accuracy: 0.9716\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0295 - accuracy: 0.9894 - val_loss: 0.0805 - val_accuracy: 0.97490.0296 - ac\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 0.0833 - val_accuracy: 0.9760\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.0933 - val_accuracy: 0.9755\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.1035 - val_accuracy: 0.9731\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.1172 - val_accuracy: 0.9752\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0139 - accuracy: 0.9950 - val_loss: 0.1093 - val_accuracy: 0.9751\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.1184 - val_accuracy: 0.9716\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.1292 - val_accuracy: 0.9753\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.1302 - val_accuracy: 0.9741\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.1224 - val_accuracy: 0.9750\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.1535 - val_accuracy: 0.9664\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.1285 - val_accuracy: 0.9759\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1302 - val_accuracy: 0.9742\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.1496 - val_accuracy: 0.9749\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8719882025036527\n",
      "F1 Micro: 0.9759\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8448856051464122\n",
      "F1 Micro: 0.9696\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.2483 - accuracy: 0.9364 - val_loss: 0.1234 - val_accuracy: 0.9624\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.1122 - accuracy: 0.9652 - val_loss: 0.1092 - val_accuracy: 0.9663\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.1026 - accuracy: 0.9680 - val_loss: 0.1031 - val_accuracy: 0.9685\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0972 - accuracy: 0.9694 - val_loss: 0.0996 - val_accuracy: 0.9694\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0934 - accuracy: 0.9705 - val_loss: 0.0974 - val_accuracy: 0.9699\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0903 - accuracy: 0.9715 - val_loss: 0.0946 - val_accuracy: 0.9708\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0880 - accuracy: 0.9719 - val_loss: 0.0934 - val_accuracy: 0.9712\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0859 - accuracy: 0.9723 - val_loss: 0.0932 - val_accuracy: 0.9713\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0841 - accuracy: 0.9729 - val_loss: 0.0915 - val_accuracy: 0.9720\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0825 - accuracy: 0.9737 - val_loss: 0.0906 - val_accuracy: 0.9715\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0813 - accuracy: 0.9738 - val_loss: 0.0886 - val_accuracy: 0.9717\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0798 - accuracy: 0.9743 - val_loss: 0.0878 - val_accuracy: 0.9724- loss: 0.0799 - accuracy:  - ETA: 0s - loss: 0.0798 - accuracy: 0.97\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0785 - accuracy: 0.9745 - val_loss: 0.0874 - val_accuracy: 0.9729- loss: 0.0786 \n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0774 - accuracy: 0.9749 - val_loss: 0.0873 - val_accuracy: 0.9725\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0764 - accuracy: 0.9754 - val_loss: 0.0875 - val_accuracy: 0.9720\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0753 - accuracy: 0.9755 - val_loss: 0.0859 - val_accuracy: 0.9727\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0744 - accuracy: 0.9760 - val_loss: 0.0867 - val_accuracy: 0.9720\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0735 - accuracy: 0.9762 - val_loss: 0.0858 - val_accuracy: 0.9733\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0725 - accuracy: 0.9764 - val_loss: 0.0859 - val_accuracy: 0.9727\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0717 - accuracy: 0.9770 - val_loss: 0.0854 - val_accuracy: 0.9725\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0709 - accuracy: 0.9770 - val_loss: 0.0861 - val_accuracy: 0.9727\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0702 - accuracy: 0.9772 - val_loss: 0.0850 - val_accuracy: 0.9731\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0694 - accuracy: 0.9775 - val_loss: 0.0848 - val_accuracy: 0.9728\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0687 - accuracy: 0.9778 - val_loss: 0.0845 - val_accuracy: 0.9728\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0679 - accuracy: 0.9780 - val_loss: 0.0842 - val_accuracy: 0.9726\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0672 - accuracy: 0.9784 - val_loss: 0.0851 - val_accuracy: 0.9732\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0665 - accuracy: 0.9784 - val_loss: 0.0848 - val_accuracy: 0.9730\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0660 - accuracy: 0.9787 - val_loss: 0.0841 - val_accuracy: 0.9728\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0652 - accuracy: 0.9788 - val_loss: 0.0847 - val_accuracy: 0.9731\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0645 - accuracy: 0.9790 - val_loss: 0.0836 - val_accuracy: 0.9731\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0639 - accuracy: 0.9793 - val_loss: 0.0850 - val_accuracy: 0.9725\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0632 - accuracy: 0.9794 - val_loss: 0.0840 - val_accuracy: 0.9735\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0627 - accuracy: 0.9797 - val_loss: 0.0836 - val_accuracy: 0.9739\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0619 - accuracy: 0.9801 - val_loss: 0.0837 - val_accuracy: 0.9732\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0613 - accuracy: 0.9798 - val_loss: 0.0862 - val_accuracy: 0.9719s - loss: 0.0611 - accura\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0608 - accuracy: 0.9803 - val_loss: 0.0852 - val_accuracy: 0.9722\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0603 - accuracy: 0.9805 - val_loss: 0.0841 - val_accuracy: 0.9724\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0595 - accuracy: 0.9805 - val_loss: 0.0845 - val_accuracy: 0.9728\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0590 - accuracy: 0.9808 - val_loss: 0.0830 - val_accuracy: 0.9732\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0585 - accuracy: 0.9811 - val_loss: 0.0846 - val_accuracy: 0.9722ccura\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0578 - accuracy: 0.9811 - val_loss: 0.0840 - val_accuracy: 0.9738\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0571 - accuracy: 0.9812 - val_loss: 0.0837 - val_accuracy: 0.9732 0s - loss: 0.0570 - accu\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0567 - accuracy: 0.9815 - val_loss: 0.0850 - val_accuracy: 0.9727\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0562 - accuracy: 0.9815 - val_loss: 0.0843 - val_accuracy: 0.9727\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0557 - accuracy: 0.9818 - val_loss: 0.0848 - val_accuracy: 0.9728\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0550 - accuracy: 0.9823 - val_loss: 0.0848 - val_accuracy: 0.9735\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0544 - accuracy: 0.9825 - val_loss: 0.0865 - val_accuracy: 0.9728\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0541 - accuracy: 0.9824 - val_loss: 0.0857 - val_accuracy: 0.9724\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0537 - accuracy: 0.9828 - val_loss: 0.0852 - val_accuracy: 0.9729\n",
      "Epoch 50/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0530 - accuracy: 0.9828 - val_loss: 0.0853 - val_accuracy: 0.9729\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0525 - accuracy: 0.9831 - val_loss: 0.0857 - val_accuracy: 0.9725\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0519 - accuracy: 0.9831 - val_loss: 0.0858 - val_accuracy: 0.9727\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0514 - accuracy: 0.9832 - val_loss: 0.0864 - val_accuracy: 0.9723\n",
      "Epoch 54/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0509 - accuracy: 0.9835 - val_loss: 0.0869 - val_accuracy: 0.9721\n",
      "Epoch 55/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0502 - accuracy: 0.9840 - val_loss: 0.0865 - val_accuracy: 0.9724\n",
      "Epoch 56/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0498 - accuracy: 0.9839 - val_loss: 0.0862 - val_accuracy: 0.9725\n",
      "Epoch 57/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0494 - accuracy: 0.9841 - val_loss: 0.0862 - val_accuracy: 0.9727\n",
      "Epoch 58/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0489 - accuracy: 0.9842 - val_loss: 0.0861 - val_accuracy: 0.9728\n",
      "Epoch 59/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0484 - accuracy: 0.9843 - val_loss: 0.0867 - val_accuracy: 0.9723\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8766594599867379\n",
      "F1 Micro: 0.9729\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.1710 - accuracy: 0.9501 - val_loss: 0.1179 - val_accuracy: 0.9636\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.1063 - accuracy: 0.9659 - val_loss: 0.1001 - val_accuracy: 0.9679\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0910 - accuracy: 0.9707 - val_loss: 0.0922 - val_accuracy: 0.9701\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0814 - accuracy: 0.9734 - val_loss: 0.0840 - val_accuracy: 0.9724\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0742 - accuracy: 0.9757 - val_loss: 0.0837 - val_accuracy: 0.9727\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0683 - accuracy: 0.9771 - val_loss: 0.0802 - val_accuracy: 0.9722\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0625 - accuracy: 0.9789 - val_loss: 0.0780 - val_accuracy: 0.9736\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0571 - accuracy: 0.9812 - val_loss: 0.0717 - val_accuracy: 0.9768\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0513 - accuracy: 0.9826 - val_loss: 0.0754 - val_accuracy: 0.9749\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0450 - accuracy: 0.9845 - val_loss: 0.0739 - val_accuracy: 0.9764\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0391 - accuracy: 0.9868 - val_loss: 0.0799 - val_accuracy: 0.9758\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0317 - accuracy: 0.9890 - val_loss: 0.0822 - val_accuracy: 0.9760\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.0901 - val_accuracy: 0.9761\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.0926 - val_accuracy: 0.9759\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.1144 - val_accuracy: 0.9747\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.1068 - val_accuracy: 0.9734\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.1322 - val_accuracy: 0.9758\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.1207 - val_accuracy: 0.9731\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.1135 - val_accuracy: 0.9747\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1300 - val_accuracy: 0.9721\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.1352 - val_accuracy: 0.9750\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1363 - val_accuracy: 0.9743\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1473 - val_accuracy: 0.9726\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.1667 - val_accuracy: 0.9737\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.1679 - val_accuracy: 0.9704\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.1462 - val_accuracy: 0.9753\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.1484 - val_accuracy: 0.9759\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1578 - val_accuracy: 0.9764\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8871003927640598\n",
      "F1 Micro: 0.9766\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8397721329798935\n",
      "F1 Micro: 0.9673\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.9035348011026405\n",
      "F1 Micro: 0.9785\n",
      "\n",
      "\n",
      " 50.15371952454249 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 3 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 3 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 703us/step - loss: 1.8450 - accuracy: 0.7450 - val_loss: 1.2444 - val_accuracy: 0.8700\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 1.0366 - accuracy: 0.8075 - val_loss: 0.6602 - val_accuracy: 0.8700\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.9320 - accuracy: 0.8075 - val_loss: 0.5998 - val_accuracy: 0.8700\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.8437 - accuracy: 0.8075 - val_loss: 0.6124 - val_accuracy: 0.8700\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.8192 - accuracy: 0.8075 - val_loss: 0.5753 - val_accuracy: 0.8700\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7897 - accuracy: 0.8075 - val_loss: 0.5912 - val_accuracy: 0.8700\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 196us/step - loss: 0.7803 - accuracy: 0.8075 - val_loss: 0.5696 - val_accuracy: 0.8700\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.7654 - accuracy: 0.8075 - val_loss: 0.5720 - val_accuracy: 0.8700\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7527 - accuracy: 0.8075 - val_loss: 0.5635 - val_accuracy: 0.8700\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.7372 - accuracy: 0.8075 - val_loss: 0.5356 - val_accuracy: 0.8700\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 195us/step - loss: 0.7175 - accuracy: 0.8075 - val_loss: 0.5455 - val_accuracy: 0.8700\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7046 - accuracy: 0.8075 - val_loss: 0.5092 - val_accuracy: 0.8700\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6830 - accuracy: 0.8075 - val_loss: 0.5115 - val_accuracy: 0.8700\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6589 - accuracy: 0.8125 - val_loss: 0.4964 - val_accuracy: 0.8700\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6269 - accuracy: 0.8175 - val_loss: 0.4737 - val_accuracy: 0.8700\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5993 - accuracy: 0.8275 - val_loss: 0.4520 - val_accuracy: 0.8800\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 175us/step - loss: 0.5743 - accuracy: 0.8300 - val_loss: 0.4311 - val_accuracy: 0.8700\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5519 - accuracy: 0.8275 - val_loss: 0.3990 - val_accuracy: 0.8800\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5123 - accuracy: 0.8375 - val_loss: 0.3852 - val_accuracy: 0.9100\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4730 - accuracy: 0.8575 - val_loss: 0.3440 - val_accuracy: 0.9200\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4767 - accuracy: 0.8750 - val_loss: 0.4071 - val_accuracy: 0.8700\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4906 - accuracy: 0.8600 - val_loss: 0.4055 - val_accuracy: 0.8700\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4742 - accuracy: 0.8775 - val_loss: 0.3736 - val_accuracy: 0.8900\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4452 - accuracy: 0.8950 - val_loss: 0.2875 - val_accuracy: 0.9200\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4077 - accuracy: 0.8825 - val_loss: 0.2748 - val_accuracy: 0.9300\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3559 - accuracy: 0.9025 - val_loss: 0.2757 - val_accuracy: 0.9500\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3707 - accuracy: 0.9050 - val_loss: 0.2609 - val_accuracy: 0.9500\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3339 - accuracy: 0.9125 - val_loss: 0.2479 - val_accuracy: 0.9300\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3193 - accuracy: 0.9200 - val_loss: 0.2597 - val_accuracy: 0.9300\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.3016 - accuracy: 0.9300 - val_loss: 0.2376 - val_accuracy: 0.9300\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2956 - accuracy: 0.9225 - val_loss: 0.2479 - val_accuracy: 0.9300\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2914 - accuracy: 0.9225 - val_loss: 0.2222 - val_accuracy: 0.9300\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2763 - accuracy: 0.9275 - val_loss: 0.2732 - val_accuracy: 0.9300\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2660 - accuracy: 0.9200 - val_loss: 0.2538 - val_accuracy: 0.9300\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2771 - accuracy: 0.9250 - val_loss: 0.2226 - val_accuracy: 0.9400\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2645 - accuracy: 0.9275 - val_loss: 0.2422 - val_accuracy: 0.9300\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2579 - accuracy: 0.9300 - val_loss: 0.1989 - val_accuracy: 0.9500\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2487 - accuracy: 0.9325 - val_loss: 0.1932 - val_accuracy: 0.9500\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2327 - accuracy: 0.9325 - val_loss: 0.1893 - val_accuracy: 0.9500\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2437 - accuracy: 0.9325 - val_loss: 0.1869 - val_accuracy: 0.9500\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2316 - accuracy: 0.9325 - val_loss: 0.1954 - val_accuracy: 0.9500\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.2483 - accuracy: 0.9250 - val_loss: 0.2400 - val_accuracy: 0.9600\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 160us/step - loss: 0.2586 - accuracy: 0.9300 - val_loss: 0.1862 - val_accuracy: 0.9500\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2287 - accuracy: 0.9400 - val_loss: 0.2025 - val_accuracy: 0.9400\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2231 - accuracy: 0.9350 - val_loss: 0.2208 - val_accuracy: 0.9400\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2042 - accuracy: 0.9425 - val_loss: 0.1859 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2100 - accuracy: 0.9400 - val_loss: 0.1732 - val_accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1987 - accuracy: 0.9400 - val_loss: 0.2128 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2120 - accuracy: 0.9325 - val_loss: 0.1962 - val_accuracy: 0.9400\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1904 - accuracy: 0.9400 - val_loss: 0.2348 - val_accuracy: 0.9300\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1897 - accuracy: 0.9475 - val_loss: 0.1792 - val_accuracy: 0.9500\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1871 - accuracy: 0.9525 - val_loss: 0.1789 - val_accuracy: 0.9600\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1979 - accuracy: 0.9525 - val_loss: 0.2018 - val_accuracy: 0.9400\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1911 - accuracy: 0.9425 - val_loss: 0.1698 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1880 - accuracy: 0.9525 - val_loss: 0.1730 - val_accuracy: 0.9400\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.2374 - accuracy: 0.9325 - val_loss: 0.1771 - val_accuracy: 0.9600\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1921 - accuracy: 0.9450 - val_loss: 0.1613 - val_accuracy: 0.9500\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1978 - accuracy: 0.9475 - val_loss: 0.1767 - val_accuracy: 0.9500\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1865 - accuracy: 0.9450 - val_loss: 0.1871 - val_accuracy: 0.9600\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2170 - accuracy: 0.9350 - val_loss: 0.1870 - val_accuracy: 0.9600\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2334 - accuracy: 0.9400 - val_loss: 0.1718 - val_accuracy: 0.9500\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.2046 - accuracy: 0.9475 - val_loss: 0.1655 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1620 - accuracy: 0.9600 - val_loss: 0.1680 - val_accuracy: 0.9500\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1575 - accuracy: 0.9575 - val_loss: 0.1792 - val_accuracy: 0.9500\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1501 - accuracy: 0.9600 - val_loss: 0.2492 - val_accuracy: 0.9300\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1606 - accuracy: 0.9525 - val_loss: 0.1925 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1627 - accuracy: 0.9525 - val_loss: 0.2018 - val_accuracy: 0.9400\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1514 - accuracy: 0.9550 - val_loss: 0.2051 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 160us/step - loss: 0.1617 - accuracy: 0.9550 - val_loss: 0.1606 - val_accuracy: 0.9500\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1427 - accuracy: 0.9550 - val_loss: 0.1646 - val_accuracy: 0.9500\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.1353 - accuracy: 0.9650 - val_loss: 0.1655 - val_accuracy: 0.9500\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1398 - accuracy: 0.9600 - val_loss: 0.1526 - val_accuracy: 0.9500\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1269 - accuracy: 0.9675 - val_loss: 0.1629 - val_accuracy: 0.9500\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1468 - accuracy: 0.9550 - val_loss: 0.1468 - val_accuracy: 0.9500\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1295 - accuracy: 0.9575 - val_loss: 0.1610 - val_accuracy: 0.9500\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1155 - accuracy: 0.9725 - val_loss: 0.1767 - val_accuracy: 0.9600\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1149 - accuracy: 0.9725 - val_loss: 0.2113 - val_accuracy: 0.9500\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1320 - accuracy: 0.9600 - val_loss: 0.2045 - val_accuracy: 0.9500\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1333 - accuracy: 0.9600 - val_loss: 0.1808 - val_accuracy: 0.9500\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1369 - accuracy: 0.9625 - val_loss: 0.1434 - val_accuracy: 0.9600\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1433 - accuracy: 0.9550 - val_loss: 0.1868 - val_accuracy: 0.9500\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 159us/step - loss: 0.2426 - accuracy: 0.9300 - val_loss: 0.1468 - val_accuracy: 0.9500\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1830 - accuracy: 0.9475 - val_loss: 0.1561 - val_accuracy: 0.9500\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1259 - accuracy: 0.9625 - val_loss: 0.1459 - val_accuracy: 0.9600\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1141 - accuracy: 0.9675 - val_loss: 0.1526 - val_accuracy: 0.9600\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1149 - accuracy: 0.9725 - val_loss: 0.1418 - val_accuracy: 0.9600\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1104 - accuracy: 0.9650 - val_loss: 0.1458 - val_accuracy: 0.9600\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1093 - accuracy: 0.9725 - val_loss: 0.1539 - val_accuracy: 0.9600\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1027 - accuracy: 0.9725 - val_loss: 0.1660 - val_accuracy: 0.9600\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0948 - accuracy: 0.9725 - val_loss: 0.1898 - val_accuracy: 0.9600\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0867 - accuracy: 0.9750 - val_loss: 0.1373 - val_accuracy: 0.9700\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0943 - accuracy: 0.9775 - val_loss: 0.1684 - val_accuracy: 0.9600\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0828 - accuracy: 0.9725 - val_loss: 0.1592 - val_accuracy: 0.9600\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0792 - accuracy: 0.9800 - val_loss: 0.1531 - val_accuracy: 0.9600\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 201us/step - loss: 0.0815 - accuracy: 0.9725 - val_loss: 0.1538 - val_accuracy: 0.9600\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0844 - accuracy: 0.9775 - val_loss: 0.1358 - val_accuracy: 0.9600\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0781 - accuracy: 0.9750 - val_loss: 0.2152 - val_accuracy: 0.9500\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0785 - accuracy: 0.9775 - val_loss: 0.1403 - val_accuracy: 0.9600\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0838 - accuracy: 0.9750 - val_loss: 0.1458 - val_accuracy: 0.9600\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0776 - accuracy: 0.9775 - val_loss: 0.1787 - val_accuracy: 0.9600\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0691 - accuracy: 0.9800 - val_loss: 0.1752 - val_accuracy: 0.9600\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0746 - accuracy: 0.9850 - val_loss: 0.1728 - val_accuracy: 0.9600\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0708 - accuracy: 0.9825 - val_loss: 0.1962 - val_accuracy: 0.9600\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0884 - accuracy: 0.9750 - val_loss: 0.1833 - val_accuracy: 0.9600\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0968 - accuracy: 0.9625 - val_loss: 0.1880 - val_accuracy: 0.9600\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0807 - accuracy: 0.9750 - val_loss: 0.1643 - val_accuracy: 0.9600\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0666 - accuracy: 0.9850 - val_loss: 0.1622 - val_accuracy: 0.9600\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.0619 - accuracy: 0.9875 - val_loss: 0.1599 - val_accuracy: 0.9600\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0635 - accuracy: 0.9875 - val_loss: 0.1516 - val_accuracy: 0.9600\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0514 - accuracy: 0.9900 - val_loss: 0.1827 - val_accuracy: 0.9600\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0505 - accuracy: 0.9900 - val_loss: 0.1776 - val_accuracy: 0.9600\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0503 - accuracy: 0.9825 - val_loss: 0.1628 - val_accuracy: 0.9600\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0669 - accuracy: 0.9750 - val_loss: 0.1295 - val_accuracy: 0.9600\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0619 - accuracy: 0.9850 - val_loss: 0.1448 - val_accuracy: 0.9600\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0799 - accuracy: 0.9775 - val_loss: 0.1715 - val_accuracy: 0.9600\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0558 - accuracy: 0.9800 - val_loss: 0.1862 - val_accuracy: 0.9600\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0463 - accuracy: 0.9925 - val_loss: 0.1959 - val_accuracy: 0.9500\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0432 - accuracy: 0.9900 - val_loss: 0.1406 - val_accuracy: 0.9600\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0455 - accuracy: 0.9875 - val_loss: 0.1337 - val_accuracy: 0.9600\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 180us/step - loss: 0.0489 - accuracy: 0.9875 - val_loss: 0.1504 - val_accuracy: 0.9600\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0413 - accuracy: 0.9925 - val_loss: 0.1702 - val_accuracy: 0.9600\n",
      "Epoch 122/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 195us/step - loss: 0.0373 - accuracy: 0.9925 - val_loss: 0.1551 - val_accuracy: 0.9600\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0412 - accuracy: 0.9900 - val_loss: 0.1363 - val_accuracy: 0.9600\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0406 - accuracy: 0.9875 - val_loss: 0.1482 - val_accuracy: 0.9600\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0358 - accuracy: 0.9925 - val_loss: 0.1314 - val_accuracy: 0.9700\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0568 - accuracy: 0.9850 - val_loss: 0.1378 - val_accuracy: 0.9600\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0370 - accuracy: 0.9900 - val_loss: 0.1596 - val_accuracy: 0.9600\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0290 - accuracy: 0.9975 - val_loss: 0.1805 - val_accuracy: 0.9600\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0308 - accuracy: 0.9975 - val_loss: 0.2024 - val_accuracy: 0.9500\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9500\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0293 - accuracy: 0.9950 - val_loss: 0.2435 - val_accuracy: 0.9500\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0293 - accuracy: 0.9975 - val_loss: 0.2342 - val_accuracy: 0.9500\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0319 - accuracy: 0.9950 - val_loss: 0.2685 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.4002898428691837\n",
      "F1 Micro: 0.9183\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.47612181064763753\n",
      "F1 Micro: 0.9385\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 280us/step - loss: 2.1792 - accuracy: 0.1325 - val_loss: 1.9053 - val_accuracy: 0.4400\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 41us/step - loss: 1.8936 - accuracy: 0.4500 - val_loss: 1.6272 - val_accuracy: 0.6700\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 1.6884 - accuracy: 0.5425 - val_loss: 1.4334 - val_accuracy: 0.7000\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 1.5534 - accuracy: 0.6000 - val_loss: 1.3072 - val_accuracy: 0.7300\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 1.4572 - accuracy: 0.6425 - val_loss: 1.2203 - val_accuracy: 0.7500\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 1.3783 - accuracy: 0.6725 - val_loss: 1.1540 - val_accuracy: 0.7600\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 1.3125 - accuracy: 0.7000 - val_loss: 1.0932 - val_accuracy: 0.7800\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 1.2477 - accuracy: 0.7175 - val_loss: 1.0462 - val_accuracy: 0.7700\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1859 - accuracy: 0.7325 - val_loss: 0.9928 - val_accuracy: 0.7900\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1269 - accuracy: 0.7550 - val_loss: 0.9441 - val_accuracy: 0.7900\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0680 - accuracy: 0.7750 - val_loss: 0.8980 - val_accuracy: 0.8100\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0104 - accuracy: 0.7850 - val_loss: 0.8545 - val_accuracy: 0.8200\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.9554 - accuracy: 0.8050 - val_loss: 0.8113 - val_accuracy: 0.8500\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.9017 - accuracy: 0.8150 - val_loss: 0.7644 - val_accuracy: 0.8600\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8499 - accuracy: 0.8300 - val_loss: 0.7200 - val_accuracy: 0.8700\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8008 - accuracy: 0.8400 - val_loss: 0.6849 - val_accuracy: 0.8700\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7516 - accuracy: 0.8650 - val_loss: 0.6480 - val_accuracy: 0.8800\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7071 - accuracy: 0.8675 - val_loss: 0.6156 - val_accuracy: 0.9000\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.6643 - accuracy: 0.8725 - val_loss: 0.5826 - val_accuracy: 0.9000\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6320 - accuracy: 0.87 - 0s 78us/step - loss: 0.6245 - accuracy: 0.8850 - val_loss: 0.5474 - val_accuracy: 0.9000\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5893 - accuracy: 0.8950 - val_loss: 0.5215 - val_accuracy: 0.9100\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5531 - accuracy: 0.9075 - val_loss: 0.4935 - val_accuracy: 0.9100\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5229 - accuracy: 0.9125 - val_loss: 0.4723 - val_accuracy: 0.9100\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4927 - accuracy: 0.9125 - val_loss: 0.4501 - val_accuracy: 0.9200\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4655 - accuracy: 0.9175 - val_loss: 0.4270 - val_accuracy: 0.9200\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4411 - accuracy: 0.9250 - val_loss: 0.4105 - val_accuracy: 0.9300\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4175 - accuracy: 0.9325 - val_loss: 0.3959 - val_accuracy: 0.9400\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.3962 - accuracy: 0.9375 - val_loss: 0.3798 - val_accuracy: 0.9400\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3754 - accuracy: 0.9425 - val_loss: 0.3670 - val_accuracy: 0.9400\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3566 - accuracy: 0.9425 - val_loss: 0.3543 - val_accuracy: 0.9400\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3397 - accuracy: 0.9425 - val_loss: 0.3425 - val_accuracy: 0.9400\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3235 - accuracy: 0.9450 - val_loss: 0.3305 - val_accuracy: 0.9400\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3088 - accuracy: 0.9525 - val_loss: 0.3207 - val_accuracy: 0.9400\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2943 - accuracy: 0.9575 - val_loss: 0.3121 - val_accuracy: 0.9400\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2809 - accuracy: 0.9550 - val_loss: 0.3063 - val_accuracy: 0.9400\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2687 - accuracy: 0.9575 - val_loss: 0.2979 - val_accuracy: 0.9400\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2571 - accuracy: 0.9600 - val_loss: 0.2897 - val_accuracy: 0.9400\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2460 - accuracy: 0.9625 - val_loss: 0.2828 - val_accuracy: 0.9400\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2356 - accuracy: 0.9650 - val_loss: 0.2774 - val_accuracy: 0.9400\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2266 - accuracy: 0.9650 - val_loss: 0.2714 - val_accuracy: 0.9500\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2173 - accuracy: 0.9650 - val_loss: 0.2670 - val_accuracy: 0.9500\n",
      "Epoch 42/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 39us/step - loss: 0.2086 - accuracy: 0.9700 - val_loss: 0.2655 - val_accuracy: 0.9500\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2007 - accuracy: 0.9700 - val_loss: 0.2593 - val_accuracy: 0.9500\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1935 - accuracy: 0.9675 - val_loss: 0.2548 - val_accuracy: 0.9500\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1864 - accuracy: 0.9700 - val_loss: 0.2490 - val_accuracy: 0.9500\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1793 - accuracy: 0.9675 - val_loss: 0.2457 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1737 - accuracy: 0.9700 - val_loss: 0.2405 - val_accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1688 - accuracy: 0.9675 - val_loss: 0.2396 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1623 - accuracy: 0.9700 - val_loss: 0.2359 - val_accuracy: 0.9500\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1569 - accuracy: 0.9725 - val_loss: 0.2326 - val_accuracy: 0.9500\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1519 - accuracy: 0.9700 - val_loss: 0.2303 - val_accuracy: 0.9500\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1479 - accuracy: 0.9700 - val_loss: 0.2296 - val_accuracy: 0.9500\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1438 - accuracy: 0.9700 - val_loss: 0.2246 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1388 - accuracy: 0.9725 - val_loss: 0.2248 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1348 - accuracy: 0.9700 - val_loss: 0.2230 - val_accuracy: 0.9500\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1308 - accuracy: 0.9700 - val_loss: 0.2202 - val_accuracy: 0.9500\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1275 - accuracy: 0.9725 - val_loss: 0.2169 - val_accuracy: 0.9500\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1241 - accuracy: 0.9750 - val_loss: 0.2166 - val_accuracy: 0.9500\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1205 - accuracy: 0.9725 - val_loss: 0.2154 - val_accuracy: 0.9500\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 88us/step - loss: 0.1179 - accuracy: 0.9800 - val_loss: 0.2124 - val_accuracy: 0.9500\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 42us/step - loss: 0.1149 - accuracy: 0.9775 - val_loss: 0.2127 - val_accuracy: 0.9500\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1117 - accuracy: 0.9800 - val_loss: 0.2106 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1091 - accuracy: 0.9800 - val_loss: 0.2094 - val_accuracy: 0.9500\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1066 - accuracy: 0.9800 - val_loss: 0.2088 - val_accuracy: 0.9500\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1042 - accuracy: 0.9825 - val_loss: 0.2063 - val_accuracy: 0.9500\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1014 - accuracy: 0.9825 - val_loss: 0.2056 - val_accuracy: 0.9500\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.96 - 0s 78us/step - loss: 0.0991 - accuracy: 0.9850 - val_loss: 0.2060 - val_accuracy: 0.9500\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0971 - accuracy: 0.9850 - val_loss: 0.2050 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0948 - accuracy: 0.9825 - val_loss: 0.2051 - val_accuracy: 0.9500\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0925 - accuracy: 0.9825 - val_loss: 0.2036 - val_accuracy: 0.9500\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0909 - accuracy: 0.9850 - val_loss: 0.2025 - val_accuracy: 0.9500\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0899 - accuracy: 0.9825 - val_loss: 0.1998 - val_accuracy: 0.9500\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0867 - accuracy: 0.9875 - val_loss: 0.2001 - val_accuracy: 0.9500\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0847 - accuracy: 0.9900 - val_loss: 0.2014 - val_accuracy: 0.9500\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0837 - accuracy: 0.9875 - val_loss: 0.2016 - val_accuracy: 0.9500\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0819 - accuracy: 0.9900 - val_loss: 0.1981 - val_accuracy: 0.9500\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0797 - accuracy: 0.9900 - val_loss: 0.1979 - val_accuracy: 0.9500\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0781 - accuracy: 0.9900 - val_loss: 0.1977 - val_accuracy: 0.9500\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0765 - accuracy: 0.9900 - val_loss: 0.1969 - val_accuracy: 0.9500\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0748 - accuracy: 0.9900 - val_loss: 0.1967 - val_accuracy: 0.9500\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0734 - accuracy: 0.9900 - val_loss: 0.1964 - val_accuracy: 0.9500\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0723 - accuracy: 0.9900 - val_loss: 0.1974 - val_accuracy: 0.9500\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0706 - accuracy: 0.9900 - val_loss: 0.1959 - val_accuracy: 0.9500\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0689 - accuracy: 0.9900 - val_loss: 0.1956 - val_accuracy: 0.9500\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0677 - accuracy: 0.9900 - val_loss: 0.1953 - val_accuracy: 0.9500\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.96 - 0s 78us/step - loss: 0.0666 - accuracy: 0.9900 - val_loss: 0.1941 - val_accuracy: 0.9500\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0652 - accuracy: 0.9900 - val_loss: 0.1937 - val_accuracy: 0.9500\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0647 - accuracy: 0.9900 - val_loss: 0.1946 - val_accuracy: 0.9500\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 1.00 - 0s 78us/step - loss: 0.0626 - accuracy: 0.9900 - val_loss: 0.1925 - val_accuracy: 0.9500\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0616 - accuracy: 0.9925 - val_loss: 0.1916 - val_accuracy: 0.9500\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0604 - accuracy: 0.9925 - val_loss: 0.1918 - val_accuracy: 0.9500\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.0596 - accuracy: 0.9925 - val_loss: 0.1921 - val_accuracy: 0.9500\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 42us/step - loss: 0.0581 - accuracy: 0.9925 - val_loss: 0.1914 - val_accuracy: 0.9500\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0571 - accuracy: 0.9950 - val_loss: 0.1909 - val_accuracy: 0.9500\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0561 - accuracy: 0.9950 - val_loss: 0.1906 - val_accuracy: 0.9500\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0551 - accuracy: 0.9950 - val_loss: 0.1905 - val_accuracy: 0.9500\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 78us/step - loss: 0.0543 - accuracy: 0.9950 - val_loss: 0.1908 - val_accuracy: 0.9500\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0533 - accuracy: 0.9950 - val_loss: 0.1889 - val_accuracy: 0.9500\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0526 - accuracy: 0.9950 - val_loss: 0.1900 - val_accuracy: 0.9500\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0514 - accuracy: 0.9950 - val_loss: 0.1894 - val_accuracy: 0.9500\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0503 - accuracy: 0.9950 - val_loss: 0.1890 - val_accuracy: 0.9500\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0495 - accuracy: 0.9950 - val_loss: 0.1887 - val_accuracy: 0.9500\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0484 - accuracy: 0.9950 - val_loss: 0.1891 - val_accuracy: 0.9500\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0479 - accuracy: 0.9950 - val_loss: 0.1897 - val_accuracy: 0.9500\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0468 - accuracy: 0.9950 - val_loss: 0.1891 - val_accuracy: 0.9500\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0461 - accuracy: 0.9950 - val_loss: 0.1888 - val_accuracy: 0.9500\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 1.00 - 0s 78us/step - loss: 0.0453 - accuracy: 0.9950 - val_loss: 0.1889 - val_accuracy: 0.9500\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0445 - accuracy: 0.9950 - val_loss: 0.1876 - val_accuracy: 0.9500\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0438 - accuracy: 0.9950 - val_loss: 0.1876 - val_accuracy: 0.9500\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0431 - accuracy: 0.9950 - val_loss: 0.1881 - val_accuracy: 0.9500\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0421 - accuracy: 0.9950 - val_loss: 0.1880 - val_accuracy: 0.9500\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0416 - accuracy: 0.9950 - val_loss: 0.1873 - val_accuracy: 0.9500\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0408 - accuracy: 0.9950 - val_loss: 0.1873 - val_accuracy: 0.9500\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0401 - accuracy: 0.9975 - val_loss: 0.1866 - val_accuracy: 0.9500\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0396 - accuracy: 0.9975 - val_loss: 0.1863 - val_accuracy: 0.9500\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0387 - accuracy: 0.9975 - val_loss: 0.1871 - val_accuracy: 0.9500\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0381 - accuracy: 0.9975 - val_loss: 0.1871 - val_accuracy: 0.9500\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0375 - accuracy: 0.9975 - val_loss: 0.1877 - val_accuracy: 0.9500\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0369 - accuracy: 0.9975 - val_loss: 0.1867 - val_accuracy: 0.9500\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0361 - accuracy: 0.9975 - val_loss: 0.1866 - val_accuracy: 0.9500\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0355 - accuracy: 0.9975 - val_loss: 0.1865 - val_accuracy: 0.9500\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0349 - accuracy: 0.9975 - val_loss: 0.1862 - val_accuracy: 0.9500\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0343 - accuracy: 0.9975 - val_loss: 0.1869 - val_accuracy: 0.9500\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 67us/step - loss: 0.0339 - accuracy: 0.9975 - val_loss: 0.1860 - val_accuracy: 0.9500\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0333 - accuracy: 0.9975 - val_loss: 0.1864 - val_accuracy: 0.9500\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0327 - accuracy: 0.9975 - val_loss: 0.1855 - val_accuracy: 0.9500\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0322 - accuracy: 0.9975 - val_loss: 0.1857 - val_accuracy: 0.9500\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0319 - accuracy: 0.9975 - val_loss: 0.1861 - val_accuracy: 0.9500\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0311 - accuracy: 0.9975 - val_loss: 0.1854 - val_accuracy: 0.9500\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0306 - accuracy: 0.9975 - val_loss: 0.1854 - val_accuracy: 0.9500\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0304 - accuracy: 0.9975 - val_loss: 0.1845 - val_accuracy: 0.9500\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0299 - accuracy: 0.9975 - val_loss: 0.1852 - val_accuracy: 0.9500\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0291 - accuracy: 0.9975 - val_loss: 0.1852 - val_accuracy: 0.9500\n",
      "Epoch 134/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0286 - accuracy: 0.9975 - val_loss: 0.1849 - val_accuracy: 0.9500\n",
      "Epoch 135/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0282 - accuracy: 0.9975 - val_loss: 0.1849 - val_accuracy: 0.9500\n",
      "Epoch 136/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0278 - accuracy: 0.9975 - val_loss: 0.1853 - val_accuracy: 0.9500\n",
      "Epoch 137/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0274 - accuracy: 0.9975 - val_loss: 0.1851 - val_accuracy: 0.9500\n",
      "Epoch 138/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0271 - accuracy: 0.9975 - val_loss: 0.1855 - val_accuracy: 0.9500\n",
      "Epoch 139/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0266 - accuracy: 0.9975 - val_loss: 0.1849 - val_accuracy: 0.9500\n",
      "Epoch 140/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0261 - accuracy: 0.9975 - val_loss: 0.1853 - val_accuracy: 0.9500\n",
      "Epoch 141/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0257 - accuracy: 0.9975 - val_loss: 0.1852 - val_accuracy: 0.9500\n",
      "Epoch 142/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0253 - accuracy: 0.9975 - val_loss: 0.1849 - val_accuracy: 0.9500\n",
      "Epoch 143/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0249 - accuracy: 0.9975 - val_loss: 0.1851 - val_accuracy: 0.9500\n",
      "Epoch 144/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0246 - accuracy: 0.9975 - val_loss: 0.1849 - val_accuracy: 0.9500\n",
      "Epoch 145/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0241 - accuracy: 0.9975 - val_loss: 0.1854 - val_accuracy: 0.9500\n",
      "Epoch 146/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9500\n",
      "Epoch 147/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9500\n",
      "Epoch 148/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9500\n",
      "Epoch 149/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9500\n",
      "Epoch 150/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9500\n",
      "Epoch 151/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.45939710082583457\n",
      "F1 Micro: 0.9393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 646us/step - loss: 1.8834 - accuracy: 0.4000 - val_loss: 1.3668 - val_accuracy: 0.8600\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.9807 - accuracy: 0.8550 - val_loss: 0.4711 - val_accuracy: 0.8800\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5912 - accuracy: 0.8225 - val_loss: 0.4102 - val_accuracy: 0.8900\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4873 - accuracy: 0.8525 - val_loss: 0.3497 - val_accuracy: 0.9300\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4439 - accuracy: 0.8875 - val_loss: 0.3153 - val_accuracy: 0.9300\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4077 - accuracy: 0.8875 - val_loss: 0.2993 - val_accuracy: 0.9300\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3807 - accuracy: 0.8950 - val_loss: 0.2893 - val_accuracy: 0.9300\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 208us/step - loss: 0.3606 - accuracy: 0.9025 - val_loss: 0.2770 - val_accuracy: 0.9300\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3405 - accuracy: 0.9050 - val_loss: 0.2641 - val_accuracy: 0.9300\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3262 - accuracy: 0.9075 - val_loss: 0.2593 - val_accuracy: 0.9300\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3101 - accuracy: 0.9150 - val_loss: 0.2508 - val_accuracy: 0.9300\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.3002 - accuracy: 0.9225 - val_loss: 0.2433 - val_accuracy: 0.9400\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2863 - accuracy: 0.9250 - val_loss: 0.2378 - val_accuracy: 0.9400\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2773 - accuracy: 0.9250 - val_loss: 0.2320 - val_accuracy: 0.9500\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2662 - accuracy: 0.9275 - val_loss: 0.2309 - val_accuracy: 0.9400\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2564 - accuracy: 0.9275 - val_loss: 0.2200 - val_accuracy: 0.9500\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2457 - accuracy: 0.9325 - val_loss: 0.2180 - val_accuracy: 0.9500\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2392 - accuracy: 0.9300 - val_loss: 0.2133 - val_accuracy: 0.9500\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2294 - accuracy: 0.9325 - val_loss: 0.2081 - val_accuracy: 0.9500\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 171us/step - loss: 0.2233 - accuracy: 0.9375 - val_loss: 0.2044 - val_accuracy: 0.9500\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 176us/step - loss: 0.2164 - accuracy: 0.9450 - val_loss: 0.2000 - val_accuracy: 0.9500\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2095 - accuracy: 0.9450 - val_loss: 0.1970 - val_accuracy: 0.9500\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2047 - accuracy: 0.9475 - val_loss: 0.1938 - val_accuracy: 0.9500\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1971 - accuracy: 0.9475 - val_loss: 0.1919 - val_accuracy: 0.9500\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1924 - accuracy: 0.9475 - val_loss: 0.1869 - val_accuracy: 0.9500\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1876 - accuracy: 0.9575 - val_loss: 0.1819 - val_accuracy: 0.9500\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1809 - accuracy: 0.9550 - val_loss: 0.1835 - val_accuracy: 0.9500\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1777 - accuracy: 0.9475 - val_loss: 0.1771 - val_accuracy: 0.9500\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1747 - accuracy: 0.9575 - val_loss: 0.1787 - val_accuracy: 0.9500\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1664 - accuracy: 0.9575 - val_loss: 0.1739 - val_accuracy: 0.9500\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1627 - accuracy: 0.9625 - val_loss: 0.1684 - val_accuracy: 0.9500\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1578 - accuracy: 0.9625 - val_loss: 0.1722 - val_accuracy: 0.9500\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1592 - accuracy: 0.9575 - val_loss: 0.1637 - val_accuracy: 0.9500\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 176us/step - loss: 0.1521 - accuracy: 0.9700 - val_loss: 0.1648 - val_accuracy: 0.9500\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1519 - accuracy: 0.9550 - val_loss: 0.1627 - val_accuracy: 0.9500\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1453 - accuracy: 0.9700 - val_loss: 0.1576 - val_accuracy: 0.9500\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1396 - accuracy: 0.9700 - val_loss: 0.1588 - val_accuracy: 0.9500\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1401 - accuracy: 0.9725 - val_loss: 0.1580 - val_accuracy: 0.9500\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1375 - accuracy: 0.9650 - val_loss: 0.1521 - val_accuracy: 0.9500\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1357 - accuracy: 0.9725 - val_loss: 0.1548 - val_accuracy: 0.9500\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1269 - accuracy: 0.9700 - val_loss: 0.1496 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1252 - accuracy: 0.9700 - val_loss: 0.1469 - val_accuracy: 0.9600\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1215 - accuracy: 0.9725 - val_loss: 0.1473 - val_accuracy: 0.9600\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1171 - accuracy: 0.9775 - val_loss: 0.1470 - val_accuracy: 0.9500\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1152 - accuracy: 0.9725 - val_loss: 0.1441 - val_accuracy: 0.9600\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 178us/step - loss: 0.1118 - accuracy: 0.9750 - val_loss: 0.1449 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1099 - accuracy: 0.9750 - val_loss: 0.1422 - val_accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 206us/step - loss: 0.1078 - accuracy: 0.9775 - val_loss: 0.1433 - val_accuracy: 0.9600\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.1055 - accuracy: 0.9750 - val_loss: 0.1441 - val_accuracy: 0.9600\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1060 - accuracy: 0.9725 - val_loss: 0.1397 - val_accuracy: 0.9500\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1061 - accuracy: 0.9800 - val_loss: 0.1412 - val_accuracy: 0.9600\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 196us/step - loss: 0.1081 - accuracy: 0.9675 - val_loss: 0.1406 - val_accuracy: 0.9600\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0996 - accuracy: 0.9850 - val_loss: 0.1328 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0973 - accuracy: 0.9825 - val_loss: 0.1446 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0931 - accuracy: 0.9825 - val_loss: 0.1320 - val_accuracy: 0.9600\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 242us/step - loss: 0.0909 - accuracy: 0.9850 - val_loss: 0.1355 - val_accuracy: 0.9600\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 193us/step - loss: 0.0887 - accuracy: 0.9800 - val_loss: 0.1366 - val_accuracy: 0.9600\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 196us/step - loss: 0.0863 - accuracy: 0.9850 - val_loss: 0.1301 - val_accuracy: 0.9600\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.0845 - accuracy: 0.9850 - val_loss: 0.1307 - val_accuracy: 0.9600\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 159us/step - loss: 0.0826 - accuracy: 0.9875 - val_loss: 0.1318 - val_accuracy: 0.9600\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0824 - accuracy: 0.9825 - val_loss: 0.1291 - val_accuracy: 0.9600\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0794 - accuracy: 0.9875 - val_loss: 0.1290 - val_accuracy: 0.9600\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0772 - accuracy: 0.9875 - val_loss: 0.1339 - val_accuracy: 0.9600\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.0788 - accuracy: 0.9800 - val_loss: 0.1305 - val_accuracy: 0.9600\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0769 - accuracy: 0.9900 - val_loss: 0.1283 - val_accuracy: 0.9600\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0741 - accuracy: 0.9825 - val_loss: 0.1284 - val_accuracy: 0.9600\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0706 - accuracy: 0.9875 - val_loss: 0.1262 - val_accuracy: 0.9600\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0680 - accuracy: 0.9875 - val_loss: 0.1282 - val_accuracy: 0.9600\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.0672 - accuracy: 0.9825 - val_loss: 0.1273 - val_accuracy: 0.9600\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0650 - accuracy: 0.9925 - val_loss: 0.1242 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 175us/step - loss: 0.0646 - accuracy: 0.9925 - val_loss: 0.1278 - val_accuracy: 0.9600\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0642 - accuracy: 0.9850 - val_loss: 0.1192 - val_accuracy: 0.9600\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0635 - accuracy: 0.9875 - val_loss: 0.1347 - val_accuracy: 0.9600\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0619 - accuracy: 0.9900 - val_loss: 0.1190 - val_accuracy: 0.9600\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0580 - accuracy: 0.9925 - val_loss: 0.1271 - val_accuracy: 0.9600\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0567 - accuracy: 0.9925 - val_loss: 0.1273 - val_accuracy: 0.9600\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0570 - accuracy: 0.9900 - val_loss: 0.1118 - val_accuracy: 0.9600\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0538 - accuracy: 0.9950 - val_loss: 0.1335 - val_accuracy: 0.9600\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.0550 - accuracy: 0.9875 - val_loss: 0.1142 - val_accuracy: 0.9600\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.0525 - accuracy: 0.9925 - val_loss: 0.1264 - val_accuracy: 0.9600\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 238us/step - loss: 0.0508 - accuracy: 0.9925 - val_loss: 0.1128 - val_accuracy: 0.9600\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0487 - accuracy: 0.9950 - val_loss: 0.1229 - val_accuracy: 0.9600\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.0459 - accuracy: 0.9950 - val_loss: 0.1185 - val_accuracy: 0.9600\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 184us/step - loss: 0.0442 - accuracy: 0.9950 - val_loss: 0.1207 - val_accuracy: 0.9600\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0443 - accuracy: 0.9950 - val_loss: 0.1149 - val_accuracy: 0.9600\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0444 - accuracy: 0.9925 - val_loss: 0.1124 - val_accuracy: 0.9600\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0440 - accuracy: 0.9950 - val_loss: 0.1517 - val_accuracy: 0.9500\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0465 - accuracy: 0.9875 - val_loss: 0.1089 - val_accuracy: 0.9600\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0407 - accuracy: 0.9950 - val_loss: 0.1273 - val_accuracy: 0.9600\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0377 - accuracy: 0.9950 - val_loss: 0.1109 - val_accuracy: 0.9600\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0361 - accuracy: 0.9950 - val_loss: 0.1305 - val_accuracy: 0.9600\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0369 - accuracy: 0.9950 - val_loss: 0.1083 - val_accuracy: 0.9600\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0329 - accuracy: 0.9950 - val_loss: 0.1219 - val_accuracy: 0.9600\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0336 - accuracy: 0.9950 - val_loss: 0.1103 - val_accuracy: 0.9600\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0332 - accuracy: 0.9950 - val_loss: 0.1451 - val_accuracy: 0.9600\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0362 - accuracy: 0.9950 - val_loss: 0.1088 - val_accuracy: 0.9600\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 160us/step - loss: 0.0312 - accuracy: 0.9950 - val_loss: 0.1141 - val_accuracy: 0.9500\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0289 - accuracy: 0.9950 - val_loss: 0.1188 - val_accuracy: 0.9600\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0269 - accuracy: 0.9950 - val_loss: 0.1133 - val_accuracy: 0.9600\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0268 - accuracy: 0.9975 - val_loss: 0.1109 - val_accuracy: 0.9600\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0251 - accuracy: 0.9975 - val_loss: 0.1234 - val_accuracy: 0.9600\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0247 - accuracy: 0.9975 - val_loss: 0.1102 - val_accuracy: 0.9600\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0249 - accuracy: 0.9975 - val_loss: 0.1060 - val_accuracy: 0.9600\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9600\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9600\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9600\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9600\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9600\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.1187 - val_accuracy: 0.9600\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 160us/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9600\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9600\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9500\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9600\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9600\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9600\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9600\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9600\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 0.9600\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9600\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9600\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9600\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9600\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.4888817907371825\n",
      "F1 Micro: 0.9419\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.47641294670499906\n",
      "F1 Micro: 0.939\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.48191830201771946\n",
      "F1 Micro: 0.9395\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 3 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 233us/step - loss: 0.8639 - accuracy: 0.8445 - val_loss: 0.6594 - val_accuracy: 0.8480\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.6324 - accuracy: 0.8503 - val_loss: 0.6109 - val_accuracy: 0.8480\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.5056 - accuracy: 0.8695 - val_loss: 0.3892 - val_accuracy: 0.9020\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.3643 - accuracy: 0.9047 - val_loss: 0.3131 - val_accuracy: 0.9180\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.3252 - accuracy: 0.9162 - val_loss: 0.2845 - val_accuracy: 0.9220\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.2937 - accuracy: 0.9190 - val_loss: 0.2611 - val_accuracy: 0.9250\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.2642 - accuracy: 0.9252 - val_loss: 0.2342 - val_accuracy: 0.9290\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.2360 - accuracy: 0.9345 - val_loss: 0.2660 - val_accuracy: 0.9270\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.2205 - accuracy: 0.9380 - val_loss: 0.2178 - val_accuracy: 0.9400\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.2109 - accuracy: 0.9398 - val_loss: 0.2267 - val_accuracy: 0.9320\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.1971 - accuracy: 0.9433 - val_loss: 0.1996 - val_accuracy: 0.9430\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1851 - accuracy: 0.9465 - val_loss: 0.2187 - val_accuracy: 0.9420\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1726 - accuracy: 0.9498 - val_loss: 0.1946 - val_accuracy: 0.9470\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1695 - accuracy: 0.9490 - val_loss: 0.1941 - val_accuracy: 0.9460\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1696 - accuracy: 0.9513 - val_loss: 0.1757 - val_accuracy: 0.9470\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.1510 - accuracy: 0.9540 - val_loss: 0.1730 - val_accuracy: 0.9500\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.1444 - accuracy: 0.9580 - val_loss: 0.1651 - val_accuracy: 0.9500\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.1420 - accuracy: 0.9567 - val_loss: 0.1590 - val_accuracy: 0.9490\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1274 - accuracy: 0.9622 - val_loss: 0.1716 - val_accuracy: 0.9490\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1278 - accuracy: 0.9592 - val_loss: 0.1523 - val_accuracy: 0.9560\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1221 - accuracy: 0.9615 - val_loss: 0.1503 - val_accuracy: 0.9550\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.1140 - accuracy: 0.9632 - val_loss: 0.1482 - val_accuracy: 0.9560\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1083 - accuracy: 0.9630 - val_loss: 0.1622 - val_accuracy: 0.9520\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1013 - accuracy: 0.9670 - val_loss: 0.1562 - val_accuracy: 0.9510\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1038 - accuracy: 0.9653 - val_loss: 0.1596 - val_accuracy: 0.9560\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.0968 - accuracy: 0.9668 - val_loss: 0.1638 - val_accuracy: 0.9550\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0927 - accuracy: 0.9712 - val_loss: 0.1833 - val_accuracy: 0.9520\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0885 - accuracy: 0.9725 - val_loss: 0.1486 - val_accuracy: 0.9570\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0838 - accuracy: 0.9720 - val_loss: 0.1484 - val_accuracy: 0.9600\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0772 - accuracy: 0.9737 - val_loss: 0.1442 - val_accuracy: 0.9600\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0729 - accuracy: 0.9762 - val_loss: 0.1432 - val_accuracy: 0.9540\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0688 - accuracy: 0.9780 - val_loss: 0.1403 - val_accuracy: 0.9630\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0669 - accuracy: 0.9770 - val_loss: 0.1515 - val_accuracy: 0.9610\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0659 - accuracy: 0.9775 - val_loss: 0.1468 - val_accuracy: 0.9540\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.0650 - accuracy: 0.9772 - val_loss: 0.1464 - val_accuracy: 0.9610\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0606 - accuracy: 0.9785 - val_loss: 0.1391 - val_accuracy: 0.9610\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0580 - accuracy: 0.9808 - val_loss: 0.1503 - val_accuracy: 0.9610\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.0506 - accuracy: 0.9845 - val_loss: 0.1471 - val_accuracy: 0.9570\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0505 - accuracy: 0.9835 - val_loss: 0.1511 - val_accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.0446 - accuracy: 0.9868 - val_loss: 0.1562 - val_accuracy: 0.9580\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.1568 - val_accuracy: 0.9580\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0404 - accuracy: 0.9868 - val_loss: 0.1544 - val_accuracy: 0.9610\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.0351 - accuracy: 0.9902 - val_loss: 0.1588 - val_accuracy: 0.9600\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0326 - accuracy: 0.9908 - val_loss: 0.1558 - val_accuracy: 0.9580\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0315 - accuracy: 0.9908 - val_loss: 0.1954 - val_accuracy: 0.9580\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0281 - accuracy: 0.9918 - val_loss: 0.1817 - val_accuracy: 0.9570\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.1682 - val_accuracy: 0.9530\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0343 - accuracy: 0.9885 - val_loss: 0.1647 - val_accuracy: 0.9600\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.1566 - val_accuracy: 0.9550\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.1637 - val_accuracy: 0.9560\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0218 - accuracy: 0.9935 - val_loss: 0.1796 - val_accuracy: 0.9550\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0141 - accuracy: 0.9987 - val_loss: 0.1708 - val_accuracy: 0.9580\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.0135 - accuracy: 0.9980 - val_loss: 0.1714 - val_accuracy: 0.9600\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0307 - accuracy: 0.9918 - val_loss: 0.1745 - val_accuracy: 0.9590\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0167 - accuracy: 0.9973 - val_loss: 0.1681 - val_accuracy: 0.9560\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 0.1841 - val_accuracy: 0.9530\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5769413639913794\n",
      "F1 Micro: 0.9534\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6058172699101256\n",
      "F1 Micro: 0.956\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 90us/step - loss: 1.7333 - accuracy: 0.5065 - val_loss: 1.3810 - val_accuracy: 0.6840\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 1.0792 - accuracy: 0.7900 - val_loss: 0.8607 - val_accuracy: 0.8570\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.6562 - accuracy: 0.8905 - val_loss: 0.5121 - val_accuracy: 0.9220\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.4026 - accuracy: 0.9290 - val_loss: 0.3334 - val_accuracy: 0.9440\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.2775 - accuracy: 0.9457 - val_loss: 0.2552 - val_accuracy: 0.9480\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.2186 - accuracy: 0.9528 - val_loss: 0.2180 - val_accuracy: 0.9500\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1869 - accuracy: 0.9563 - val_loss: 0.1978 - val_accuracy: 0.9540\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1676 - accuracy: 0.9590 - val_loss: 0.1867 - val_accuracy: 0.9540\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1549 - accuracy: 0.9600 - val_loss: 0.1801 - val_accuracy: 0.9560\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1450 - accuracy: 0.9605 - val_loss: 0.1744 - val_accuracy: 0.9570\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1372 - accuracy: 0.9615 - val_loss: 0.1699 - val_accuracy: 0.9560\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1315 - accuracy: 0.9650 - val_loss: 0.1685 - val_accuracy: 0.9570\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.1260 - accuracy: 0.9653 - val_loss: 0.1655 - val_accuracy: 0.9560\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1212 - accuracy: 0.9657 - val_loss: 0.1632 - val_accuracy: 0.9560\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1165 - accuracy: 0.9675 - val_loss: 0.1610 - val_accuracy: 0.9550\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1130 - accuracy: 0.9672 - val_loss: 0.1593 - val_accuracy: 0.9550\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1099 - accuracy: 0.9688 - val_loss: 0.1570 - val_accuracy: 0.9560\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1069 - accuracy: 0.9703 - val_loss: 0.1563 - val_accuracy: 0.9560\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1037 - accuracy: 0.9705 - val_loss: 0.1566 - val_accuracy: 0.9560\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 64us/step - loss: 0.1008 - accuracy: 0.9718 - val_loss: 0.1554 - val_accuracy: 0.9560\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0980 - accuracy: 0.9725 - val_loss: 0.1548 - val_accuracy: 0.9560\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0957 - accuracy: 0.9732 - val_loss: 0.1539 - val_accuracy: 0.9570\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0930 - accuracy: 0.9735 - val_loss: 0.1553 - val_accuracy: 0.9560\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0914 - accuracy: 0.9743 - val_loss: 0.1529 - val_accuracy: 0.9570\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0898 - accuracy: 0.9747 - val_loss: 0.1518 - val_accuracy: 0.9570\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0880 - accuracy: 0.9762 - val_loss: 0.1509 - val_accuracy: 0.9570\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0855 - accuracy: 0.9778 - val_loss: 0.1514 - val_accuracy: 0.9570\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0839 - accuracy: 0.9768 - val_loss: 0.1497 - val_accuracy: 0.9580\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0825 - accuracy: 0.9787 - val_loss: 0.1484 - val_accuracy: 0.9570\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0807 - accuracy: 0.9793 - val_loss: 0.1494 - val_accuracy: 0.9570\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.0793 - accuracy: 0.9793 - val_loss: 0.1482 - val_accuracy: 0.9580\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0778 - accuracy: 0.9797 - val_loss: 0.1493 - val_accuracy: 0.9580\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0765 - accuracy: 0.9793 - val_loss: 0.1480 - val_accuracy: 0.9570\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0749 - accuracy: 0.9812 - val_loss: 0.1485 - val_accuracy: 0.9570\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0738 - accuracy: 0.9808 - val_loss: 0.1486 - val_accuracy: 0.9600\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0726 - accuracy: 0.9818 - val_loss: 0.1496 - val_accuracy: 0.9580\n",
      "Epoch 37/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0709 - accuracy: 0.9820 - val_loss: 0.1477 - val_accuracy: 0.9580\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0698 - accuracy: 0.9822 - val_loss: 0.1471 - val_accuracy: 0.9580\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0688 - accuracy: 0.9808 - val_loss: 0.1481 - val_accuracy: 0.9590\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0676 - accuracy: 0.9827 - val_loss: 0.1464 - val_accuracy: 0.9590\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0666 - accuracy: 0.9818 - val_loss: 0.1475 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0652 - accuracy: 0.9822 - val_loss: 0.1467 - val_accuracy: 0.9580\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.0641 - accuracy: 0.9820 - val_loss: 0.1483 - val_accuracy: 0.9620\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0631 - accuracy: 0.9840 - val_loss: 0.1486 - val_accuracy: 0.9590\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0617 - accuracy: 0.9830 - val_loss: 0.1485 - val_accuracy: 0.9580\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0613 - accuracy: 0.9850 - val_loss: 0.1475 - val_accuracy: 0.9590\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0599 - accuracy: 0.9850 - val_loss: 0.1472 - val_accuracy: 0.9600\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0590 - accuracy: 0.9858 - val_loss: 0.1484 - val_accuracy: 0.9580\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0580 - accuracy: 0.9860 - val_loss: 0.1492 - val_accuracy: 0.9610\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0574 - accuracy: 0.9862 - val_loss: 0.1507 - val_accuracy: 0.9600\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0560 - accuracy: 0.9860 - val_loss: 0.1471 - val_accuracy: 0.9570\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0554 - accuracy: 0.9868 - val_loss: 0.1482 - val_accuracy: 0.9620\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0541 - accuracy: 0.9865 - val_loss: 0.1503 - val_accuracy: 0.9620\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0539 - accuracy: 0.9875 - val_loss: 0.1488 - val_accuracy: 0.9620\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0530 - accuracy: 0.9870 - val_loss: 0.1486 - val_accuracy: 0.9600\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 0s 63us/step - loss: 0.0513 - accuracy: 0.9875 - val_loss: 0.1488 - val_accuracy: 0.9620\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0514 - accuracy: 0.9877 - val_loss: 0.1487 - val_accuracy: 0.9610\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0504 - accuracy: 0.9885 - val_loss: 0.1503 - val_accuracy: 0.9620\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 64us/step - loss: 0.0494 - accuracy: 0.9890 - val_loss: 0.1503 - val_accuracy: 0.9610\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0481 - accuracy: 0.9890 - val_loss: 0.1506 - val_accuracy: 0.9610\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6490970576531881\n",
      "F1 Micro: 0.957\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 231us/step - loss: 0.6083 - accuracy: 0.8413 - val_loss: 0.3196 - val_accuracy: 0.9130\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.2996 - accuracy: 0.9178 - val_loss: 0.2581 - val_accuracy: 0.9230\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.2497 - accuracy: 0.9335 - val_loss: 0.2247 - val_accuracy: 0.9350\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.2203 - accuracy: 0.9410 - val_loss: 0.2044 - val_accuracy: 0.9420\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.1971 - accuracy: 0.9460 - val_loss: 0.1895 - val_accuracy: 0.9430\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 177us/step - loss: 0.1813 - accuracy: 0.9498 - val_loss: 0.1793 - val_accuracy: 0.9470\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1699 - accuracy: 0.9540 - val_loss: 0.1717 - val_accuracy: 0.9540\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1620 - accuracy: 0.9535 - val_loss: 0.1731 - val_accuracy: 0.9560\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1508 - accuracy: 0.9555 - val_loss: 0.1600 - val_accuracy: 0.9530\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1431 - accuracy: 0.9588 - val_loss: 0.1598 - val_accuracy: 0.9530\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1373 - accuracy: 0.9597 - val_loss: 0.1605 - val_accuracy: 0.9540\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1332 - accuracy: 0.9590 - val_loss: 0.1544 - val_accuracy: 0.9560\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1259 - accuracy: 0.9615 - val_loss: 0.1543 - val_accuracy: 0.9550\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1216 - accuracy: 0.9617 - val_loss: 0.1543 - val_accuracy: 0.9580\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1152 - accuracy: 0.9635 - val_loss: 0.1502 - val_accuracy: 0.9590\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1131 - accuracy: 0.9645 - val_loss: 0.1546 - val_accuracy: 0.9550\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1086 - accuracy: 0.9647 - val_loss: 0.1442 - val_accuracy: 0.9610\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1051 - accuracy: 0.9655 - val_loss: 0.1468 - val_accuracy: 0.9580\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1018 - accuracy: 0.9690 - val_loss: 0.1538 - val_accuracy: 0.9570\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0974 - accuracy: 0.9693 - val_loss: 0.1439 - val_accuracy: 0.9590\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0935 - accuracy: 0.9710 - val_loss: 0.1445 - val_accuracy: 0.9580\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0915 - accuracy: 0.9725 - val_loss: 0.1470 - val_accuracy: 0.9550\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0880 - accuracy: 0.9735 - val_loss: 0.1421 - val_accuracy: 0.9590\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0880 - accuracy: 0.9740 - val_loss: 0.1432 - val_accuracy: 0.9570\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0803 - accuracy: 0.9765 - val_loss: 0.1420 - val_accuracy: 0.9600\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0784 - accuracy: 0.9778 - val_loss: 0.1444 - val_accuracy: 0.9570\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.0730 - accuracy: 0.9793 - val_loss: 0.1450 - val_accuracy: 0.9560\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0697 - accuracy: 0.9800 - val_loss: 0.1467 - val_accuracy: 0.9590\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0675 - accuracy: 0.9822 - val_loss: 0.1528 - val_accuracy: 0.9540\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0648 - accuracy: 0.9815 - val_loss: 0.1499 - val_accuracy: 0.9560\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0606 - accuracy: 0.9837 - val_loss: 0.1473 - val_accuracy: 0.9610\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0531 - accuracy: 0.9877 - val_loss: 0.1492 - val_accuracy: 0.9580\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0498 - accuracy: 0.9880 - val_loss: 0.1521 - val_accuracy: 0.9590\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0462 - accuracy: 0.9887 - val_loss: 0.1598 - val_accuracy: 0.9580\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0424 - accuracy: 0.9900 - val_loss: 0.1536 - val_accuracy: 0.9590\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0387 - accuracy: 0.9902 - val_loss: 0.1598 - val_accuracy: 0.9560\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0370 - accuracy: 0.9923 - val_loss: 0.1651 - val_accuracy: 0.9590\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0313 - accuracy: 0.9933 - val_loss: 0.1641 - val_accuracy: 0.9560\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0293 - accuracy: 0.9950 - val_loss: 0.1732 - val_accuracy: 0.9570\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0266 - accuracy: 0.9940 - val_loss: 0.1705 - val_accuracy: 0.9560\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0248 - accuracy: 0.9952 - val_loss: 0.1790 - val_accuracy: 0.9570\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0217 - accuracy: 0.9962 - val_loss: 0.1828 - val_accuracy: 0.9560\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0206 - accuracy: 0.9958 - val_loss: 0.1726 - val_accuracy: 0.9560\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0192 - accuracy: 0.9967 - val_loss: 0.1881 - val_accuracy: 0.9570\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0179 - accuracy: 0.9975 - val_loss: 0.2027 - val_accuracy: 0.9540\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.656649966593484\n",
      "F1 Micro: 0.9571\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6907725855304753\n",
      "F1 Micro: 0.9575\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7029428024874247\n",
      "F1 Micro: 0.9568\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 3 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.4319 - accuracy: 0.8946 - val_loss: 0.2303 - val_accuracy: 0.9338\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.1805 - accuracy: 0.9468 - val_loss: 0.1621 - val_accuracy: 0.9514\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1419 - accuracy: 0.9564 - val_loss: 0.1363 - val_accuracy: 0.9590\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1222 - accuracy: 0.9611 - val_loss: 0.1252 - val_accuracy: 0.9615\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.1112 - accuracy: 0.9653 - val_loss: 0.1279 - val_accuracy: 0.9562\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.1013 - accuracy: 0.9678 - val_loss: 0.1106 - val_accuracy: 0.9639\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0977 - accuracy: 0.9682 - val_loss: 0.1123 - val_accuracy: 0.9633\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0920 - accuracy: 0.9699 - val_loss: 0.1042 - val_accuracy: 0.9668\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0874 - accuracy: 0.9715 - val_loss: 0.0991 - val_accuracy: 0.9658\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0828 - accuracy: 0.9735 - val_loss: 0.0995 - val_accuracy: 0.9678\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0803 - accuracy: 0.9737 - val_loss: 0.0981 - val_accuracy: 0.9685\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0765 - accuracy: 0.9740 - val_loss: 0.1107 - val_accuracy: 0.9621\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0720 - accuracy: 0.9758 - val_loss: 0.0985 - val_accuracy: 0.9677oss: 0.0716 - \n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0689 - accuracy: 0.9766 - val_loss: 0.0989 - val_accuracy: 0.9678\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0648 - accuracy: 0.9781 - val_loss: 0.0982 - val_accuracy: 0.9660\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0610 - accuracy: 0.9797 - val_loss: 0.1146 - val_accuracy: 0.9674\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0568 - accuracy: 0.9808 - val_loss: 0.1081 - val_accuracy: 0.9683\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0536 - accuracy: 0.9822 - val_loss: 0.1036 - val_accuracy: 0.9656\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0515 - accuracy: 0.9825 - val_loss: 0.1125 - val_accuracy: 0.9648\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.0966 - val_accuracy: 0.9703\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0422 - accuracy: 0.9862 - val_loss: 0.0936 - val_accuracy: 0.9701\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0389 - accuracy: 0.9870 - val_loss: 0.1079 - val_accuracy: 0.9655\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0359 - accuracy: 0.9876 - val_loss: 0.1070 - val_accuracy: 0.9670\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0321 - accuracy: 0.9888 - val_loss: 0.1169 - val_accuracy: 0.9632\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0271 - accuracy: 0.9908 - val_loss: 0.1004 - val_accuracy: 0.9706\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.1165 - val_accuracy: 0.9696\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.1171 - val_accuracy: 0.9695\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.1249 - val_accuracy: 0.9692\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.1432 - val_accuracy: 0.9645\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.1194 - val_accuracy: 0.9687\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0127 - accuracy: 0.9955 - val_loss: 0.1373 - val_accuracy: 0.9695\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 0.1516 - val_accuracy: 0.9691\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.1358 - val_accuracy: 0.9696\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.1368 - val_accuracy: 0.9716\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.2385 - val_accuracy: 0.9616\n",
      "Epoch 36/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.1705 - val_accuracy: 0.9639\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.1653 - val_accuracy: 0.9683\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.1463 - val_accuracy: 0.9692\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.1901 - val_accuracy: 0.9631\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.1579 - val_accuracy: 0.9697\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.1780 - val_accuracy: 0.9684\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8320715291186738\n",
      "F1 Micro: 0.9702\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8063129948682687\n",
      "F1 Micro: 0.9665\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.4932 - accuracy: 0.8883 - val_loss: 0.1639 - val_accuracy: 0.9511\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.1438 - accuracy: 0.9584 - val_loss: 0.1377 - val_accuracy: 0.9564\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1259 - accuracy: 0.9613 - val_loss: 0.1286 - val_accuracy: 0.9602\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.1167 - accuracy: 0.9639 - val_loss: 0.1212 - val_accuracy: 0.9621\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.1106 - accuracy: 0.9650 - val_loss: 0.1194 - val_accuracy: 0.9635\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.1060 - accuracy: 0.9659 - val_loss: 0.1138 - val_accuracy: 0.9639\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.1021 - accuracy: 0.9675 - val_loss: 0.1121 - val_accuracy: 0.9660\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0990 - accuracy: 0.9680 - val_loss: 0.1113 - val_accuracy: 0.9658\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0968 - accuracy: 0.9692 - val_loss: 0.1094 - val_accuracy: 0.9666\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0939 - accuracy: 0.9696 - val_loss: 0.1067 - val_accuracy: 0.9675\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0919 - accuracy: 0.9699 - val_loss: 0.1066 - val_accuracy: 0.9676\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0900 - accuracy: 0.9715 - val_loss: 0.1051 - val_accuracy: 0.9694\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0886 - accuracy: 0.9708 - val_loss: 0.1050 - val_accuracy: 0.9685\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0870 - accuracy: 0.9720 - val_loss: 0.1054 - val_accuracy: 0.9668\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0856 - accuracy: 0.9723 - val_loss: 0.1044 - val_accuracy: 0.9692\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0844 - accuracy: 0.9725 - val_loss: 0.1027 - val_accuracy: 0.9692\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0829 - accuracy: 0.9729 - val_loss: 0.1044 - val_accuracy: 0.9689\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0815 - accuracy: 0.9738 - val_loss: 0.1005 - val_accuracy: 0.9699\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0801 - accuracy: 0.9743 - val_loss: 0.1011 - val_accuracy: 0.9692\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0792 - accuracy: 0.9748 - val_loss: 0.1014 - val_accuracy: 0.9696\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0781 - accuracy: 0.9745 - val_loss: 0.0998 - val_accuracy: 0.9692\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0767 - accuracy: 0.9751 - val_loss: 0.0998 - val_accuracy: 0.9698\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0762 - accuracy: 0.9754 - val_loss: 0.1005 - val_accuracy: 0.9683\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0751 - accuracy: 0.9761 - val_loss: 0.0984 - val_accuracy: 0.9704\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0742 - accuracy: 0.9764 - val_loss: 0.0998 - val_accuracy: 0.9697\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0730 - accuracy: 0.9770 - val_loss: 0.0994 - val_accuracy: 0.9695\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0723 - accuracy: 0.9771 - val_loss: 0.0984 - val_accuracy: 0.9694\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0712 - accuracy: 0.9775 - val_loss: 0.0984 - val_accuracy: 0.9688\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0701 - accuracy: 0.9781 - val_loss: 0.0985 - val_accuracy: 0.9695\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0694 - accuracy: 0.9780 - val_loss: 0.0982 - val_accuracy: 0.9692\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0686 - accuracy: 0.9783 - val_loss: 0.0997 - val_accuracy: 0.9692\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0679 - accuracy: 0.9788 - val_loss: 0.0974 - val_accuracy: 0.9700\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0669 - accuracy: 0.9789 - val_loss: 0.0980 - val_accuracy: 0.9695\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0661 - accuracy: 0.9793 - val_loss: 0.1002 - val_accuracy: 0.9687\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0655 - accuracy: 0.9790 - val_loss: 0.1005 - val_accuracy: 0.9694\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0648 - accuracy: 0.9793 - val_loss: 0.0981 - val_accuracy: 0.9693\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0640 - accuracy: 0.9798 - val_loss: 0.0972 - val_accuracy: 0.9698\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0633 - accuracy: 0.9801 - val_loss: 0.0977 - val_accuracy: 0.9698\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0621 - accuracy: 0.9802 - val_loss: 0.1008 - val_accuracy: 0.9689\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0617 - accuracy: 0.9807 - val_loss: 0.0966 - val_accuracy: 0.9694\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0609 - accuracy: 0.9810 - val_loss: 0.0970 - val_accuracy: 0.9697\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0604 - accuracy: 0.9813 - val_loss: 0.0991 - val_accuracy: 0.9695\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0597 - accuracy: 0.9816 - val_loss: 0.0984 - val_accuracy: 0.9685\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0591 - accuracy: 0.9821 - val_loss: 0.0982 - val_accuracy: 0.9693\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0582 - accuracy: 0.9825 - val_loss: 0.0986 - val_accuracy: 0.9692\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0577 - accuracy: 0.9820 - val_loss: 0.0998 - val_accuracy: 0.9690\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0569 - accuracy: 0.9827 - val_loss: 0.0979 - val_accuracy: 0.9695\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0565 - accuracy: 0.9827 - val_loss: 0.0982 - val_accuracy: 0.9698\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0560 - accuracy: 0.9829 - val_loss: 0.0989 - val_accuracy: 0.9693\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0552 - accuracy: 0.9830 - val_loss: 0.0980 - val_accuracy: 0.9684\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0547 - accuracy: 0.9832 - val_loss: 0.0979 - val_accuracy: 0.9698\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0539 - accuracy: 0.9839 - val_loss: 0.0990 - val_accuracy: 0.9692\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0534 - accuracy: 0.9839 - val_loss: 0.0991 - val_accuracy: 0.9692\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0523 - accuracy: 0.9839 - val_loss: 0.0989 - val_accuracy: 0.9691\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0519 - accuracy: 0.9840 - val_loss: 0.0990 - val_accuracy: 0.9693\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0515 - accuracy: 0.9844 - val_loss: 0.0997 - val_accuracy: 0.9688\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0509 - accuracy: 0.9845 - val_loss: 0.1001 - val_accuracy: 0.9690\n",
      "Epoch 58/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0504 - accuracy: 0.9844 - val_loss: 0.0998 - val_accuracy: 0.9692\n",
      "Epoch 59/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0498 - accuracy: 0.9853 - val_loss: 0.1004 - val_accuracy: 0.9695\n",
      "Epoch 60/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 0.1014 - val_accuracy: 0.9685\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8368098067130051\n",
      "F1 Micro: 0.972\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.2578 - accuracy: 0.9291 - val_loss: 0.1668 - val_accuracy: 0.9495\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.1429 - accuracy: 0.9571 - val_loss: 0.1353 - val_accuracy: 0.9563\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1199 - accuracy: 0.9627 - val_loss: 0.1206 - val_accuracy: 0.9603\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.1036 - accuracy: 0.9671 - val_loss: 0.1072 - val_accuracy: 0.9664\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0923 - accuracy: 0.9700 - val_loss: 0.1175 - val_accuracy: 0.9629\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0841 - accuracy: 0.9723 - val_loss: 0.0960 - val_accuracy: 0.9680\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0786 - accuracy: 0.9750 - val_loss: 0.0962 - val_accuracy: 0.9693\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0732 - accuracy: 0.9750 - val_loss: 0.0928 - val_accuracy: 0.9703\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0673 - accuracy: 0.9780 - val_loss: 0.0940 - val_accuracy: 0.9677\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0622 - accuracy: 0.9793 - val_loss: 0.0952 - val_accuracy: 0.9696\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0974 - val_accuracy: 0.9709\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0531 - accuracy: 0.9830 - val_loss: 0.0907 - val_accuracy: 0.9697\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0487 - accuracy: 0.9844 - val_loss: 0.1027 - val_accuracy: 0.9694\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0432 - accuracy: 0.9854 - val_loss: 0.0982 - val_accuracy: 0.9667\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0380 - accuracy: 0.9871 - val_loss: 0.0971 - val_accuracy: 0.9700\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0326 - accuracy: 0.9894 - val_loss: 0.1000 - val_accuracy: 0.9690\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0264 - accuracy: 0.9919 - val_loss: 0.1022 - val_accuracy: 0.9695\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.1061 - val_accuracy: 0.9706\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.1169 - val_accuracy: 0.9703\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.1143 - val_accuracy: 0.9686\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.1230 - val_accuracy: 0.9685\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.1327 - val_accuracy: 0.9655\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.1298 - val_accuracy: 0.9682\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1733 - val_accuracy: 0.9667\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.1667 - val_accuracy: 0.9675\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1450 - val_accuracy: 0.9676\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.1741 - val_accuracy: 0.9680\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.1430 - val_accuracy: 0.9689\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1537 - val_accuracy: 0.9659\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1463 - val_accuracy: 0.9694\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.1799 - val_accuracy: 0.9685\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.1535 - val_accuracy: 0.9703\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8252344740510054\n",
      "F1 Micro: 0.9704\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.817686417474842\n",
      "F1 Micro: 0.9681\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8308160698866126\n",
      "F1 Micro: 0.9729\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 3 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.2295 - accuracy: 0.9374 - val_loss: 0.1328 - val_accuracy: 0.9592\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.1155 - accuracy: 0.9631 - val_loss: 0.1004 - val_accuracy: 0.9687\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0987 - accuracy: 0.9680 - val_loss: 0.0938 - val_accuracy: 0.9699\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0887 - accuracy: 0.9707 - val_loss: 0.0976 - val_accuracy: 0.9689\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 180us/step - loss: 0.0814 - accuracy: 0.9731 - val_loss: 0.0844 - val_accuracy: 0.9723\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 23s 180us/step - loss: 0.0743 - accuracy: 0.9751 - val_loss: 0.0912 - val_accuracy: 0.9699\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 23s 180us/step - loss: 0.0678 - accuracy: 0.9767 - val_loss: 0.0746 - val_accuracy: 0.9748\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0627 - accuracy: 0.9787 - val_loss: 0.0713 - val_accuracy: 0.9763\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0584 - accuracy: 0.9799 - val_loss: 0.0731 - val_accuracy: 0.9760\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0537 - accuracy: 0.9813 - val_loss: 0.0698 - val_accuracy: 0.9769\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0506 - accuracy: 0.9823 - val_loss: 0.0683 - val_accuracy: 0.9763\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0473 - accuracy: 0.9832 - val_loss: 0.0751 - val_accuracy: 0.9763\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0434 - accuracy: 0.9843 - val_loss: 0.0783 - val_accuracy: 0.9770\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 23s 180us/step - loss: 0.0403 - accuracy: 0.9855 - val_loss: 0.0696 - val_accuracy: 0.9772\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0365 - accuracy: 0.9868 - val_loss: 0.0744 - val_accuracy: 0.9762\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0334 - accuracy: 0.9880 - val_loss: 0.0781 - val_accuracy: 0.9735\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0296 - accuracy: 0.9892 - val_loss: 0.0760 - val_accuracy: 0.9750\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0261 - accuracy: 0.9905 - val_loss: 0.0801 - val_accuracy: 0.9771\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0227 - accuracy: 0.9916 - val_loss: 0.0806 - val_accuracy: 0.9763\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0196 - accuracy: 0.9928 - val_loss: 0.0927 - val_accuracy: 0.9761\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0166 - accuracy: 0.9941 - val_loss: 0.0901 - val_accuracy: 0.9745\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0143 - accuracy: 0.9950 - val_loss: 0.0942 - val_accuracy: 0.9759\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.1006 - val_accuracy: 0.9769\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.1101 - val_accuracy: 0.9761\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0105 - accuracy: 0.9962 - val_loss: 0.1048 - val_accuracy: 0.9768\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.1138 - val_accuracy: 0.9732\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1172 - val_accuracy: 0.9770\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.1244 - val_accuracy: 0.9770\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.1216 - val_accuracy: 0.9763\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1183 - val_accuracy: 0.9762\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.1236 - val_accuracy: 0.9746\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8756351141052742\n",
      "F1 Micro: 0.9744\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8473315885097972\n",
      "F1 Micro: 0.9711\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.2512 - accuracy: 0.9355 - val_loss: 0.1233 - val_accuracy: 0.9625\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.1126 - accuracy: 0.9654 - val_loss: 0.1101 - val_accuracy: 0.9660\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.1025 - accuracy: 0.9678 - val_loss: 0.1037 - val_accuracy: 0.9682\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0967 - accuracy: 0.9694 - val_loss: 0.0996 - val_accuracy: 0.9693uracy: 0.96\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0929 - accuracy: 0.9707 - val_loss: 0.0964 - val_accuracy: 0.9705\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0896 - accuracy: 0.9716 - val_loss: 0.0948 - val_accuracy: 0.9707\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0871 - accuracy: 0.9721 - val_loss: 0.0930 - val_accuracy: 0.9705\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0851 - accuracy: 0.9730 - val_loss: 0.0913 - val_accuracy: 0.9714\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0834 - accuracy: 0.9734 - val_loss: 0.0908 - val_accuracy: 0.9712\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0817 - accuracy: 0.9738 - val_loss: 0.0919 - val_accuracy: 0.9710\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0803 - accuracy: 0.9742 - val_loss: 0.0891 - val_accuracy: 0.9717\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0788 - accuracy: 0.9745 - val_loss: 0.0894 - val_accuracy: 0.9717\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0776 - accuracy: 0.9751 - val_loss: 0.0874 - val_accuracy: 0.9721\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0767 - accuracy: 0.9753 - val_loss: 0.0882 - val_accuracy: 0.9722\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0756 - accuracy: 0.9754 - val_loss: 0.0871 - val_accuracy: 0.9722\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0745 - accuracy: 0.9760 - val_loss: 0.0875 - val_accuracy: 0.9721\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0737 - accuracy: 0.9762 - val_loss: 0.0860 - val_accuracy: 0.9728\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0727 - accuracy: 0.9766 - val_loss: 0.0857 - val_accuracy: 0.9726\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0720 - accuracy: 0.9765 - val_loss: 0.0879 - val_accuracy: 0.9720\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0710 - accuracy: 0.9770 - val_loss: 0.0862 - val_accuracy: 0.9719\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0702 - accuracy: 0.9772 - val_loss: 0.0847 - val_accuracy: 0.9730\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0694 - accuracy: 0.9775 - val_loss: 0.0858 - val_accuracy: 0.9722\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0686 - accuracy: 0.9781 - val_loss: 0.0845 - val_accuracy: 0.9732\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0681 - accuracy: 0.9782 - val_loss: 0.0854 - val_accuracy: 0.9729\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0672 - accuracy: 0.9783 - val_loss: 0.0860 - val_accuracy: 0.9727\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0666 - accuracy: 0.9783 - val_loss: 0.0840 - val_accuracy: 0.9731\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0657 - accuracy: 0.9788 - val_loss: 0.0848 - val_accuracy: 0.9734\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0653 - accuracy: 0.9786 - val_loss: 0.0837 - val_accuracy: 0.9731\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0645 - accuracy: 0.9790 - val_loss: 0.0861 - val_accuracy: 0.9728\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0640 - accuracy: 0.9793 - val_loss: 0.0839 - val_accuracy: 0.9738\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0633 - accuracy: 0.9793 - val_loss: 0.0849 - val_accuracy: 0.9732\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0625 - accuracy: 0.9799 - val_loss: 0.0839 - val_accuracy: 0.9740\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0621 - accuracy: 0.9798 - val_loss: 0.0834 - val_accuracy: 0.9737\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0613 - accuracy: 0.9802 - val_loss: 0.0851 - val_accuracy: 0.9734\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0607 - accuracy: 0.9800 - val_loss: 0.0866 - val_accuracy: 0.9718\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 0.0845 - val_accuracy: 0.9734\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0595 - accuracy: 0.9808 - val_loss: 0.0843 - val_accuracy: 0.9729\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0591 - accuracy: 0.9811 - val_loss: 0.0834 - val_accuracy: 0.9735\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0583 - accuracy: 0.9811 - val_loss: 0.0840 - val_accuracy: 0.9737\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0578 - accuracy: 0.9813 - val_loss: 0.0854 - val_accuracy: 0.9735\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0573 - accuracy: 0.9813 - val_loss: 0.0840 - val_accuracy: 0.9735\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0567 - accuracy: 0.9816 - val_loss: 0.0850 - val_accuracy: 0.9732\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0560 - accuracy: 0.9820 - val_loss: 0.0856 - val_accuracy: 0.9731\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0556 - accuracy: 0.9818 - val_loss: 0.0856 - val_accuracy: 0.9728\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0548 - accuracy: 0.9824 - val_loss: 0.0863 - val_accuracy: 0.9734\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0544 - accuracy: 0.9826 - val_loss: 0.0844 - val_accuracy: 0.9729\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0539 - accuracy: 0.9826 - val_loss: 0.0852 - val_accuracy: 0.9728\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0535 - accuracy: 0.9826 - val_loss: 0.0854 - val_accuracy: 0.9733\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0528 - accuracy: 0.9828 - val_loss: 0.0855 - val_accuracy: 0.9734\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0524 - accuracy: 0.9832 - val_loss: 0.0851 - val_accuracy: 0.9731\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0517 - accuracy: 0.9835 - val_loss: 0.0862 - val_accuracy: 0.9733ss: 0.0522 -  - ETA: 0s - loss: 0\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0511 - accuracy: 0.9835 - val_loss: 0.0873 - val_accuracy: 0.9721\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0508 - accuracy: 0.9835 - val_loss: 0.0870 - val_accuracy: 0.9725\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8562298463443065\n",
      "F1 Micro: 0.974\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.1717 - accuracy: 0.9500 - val_loss: 0.1214 - val_accuracy: 0.9627\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.1060 - accuracy: 0.9666 - val_loss: 0.1005 - val_accuracy: 0.9683\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0910 - accuracy: 0.9709 - val_loss: 0.0927 - val_accuracy: 0.9709\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0815 - accuracy: 0.9734 - val_loss: 0.0847 - val_accuracy: 0.9722\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0746 - accuracy: 0.9751 - val_loss: 0.0774 - val_accuracy: 0.9749\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0683 - accuracy: 0.9772 - val_loss: 0.0799 - val_accuracy: 0.9742\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0619 - accuracy: 0.9791 - val_loss: 0.0777 - val_accuracy: 0.9754\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0554 - accuracy: 0.9810 - val_loss: 0.0737 - val_accuracy: 0.9761\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0499 - accuracy: 0.9831 - val_loss: 0.0741 - val_accuracy: 0.9764\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0449 - accuracy: 0.9844 - val_loss: 0.0700 - val_accuracy: 0.9779\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 0.0724 - val_accuracy: 0.9757\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0327 - accuracy: 0.9888 - val_loss: 0.0745 - val_accuracy: 0.9766\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0264 - accuracy: 0.9912 - val_loss: 0.0822 - val_accuracy: 0.9760\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.0817 - val_accuracy: 0.9760\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.0905 - val_accuracy: 0.9764\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0946 - val_accuracy: 0.9753\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.1026 - val_accuracy: 0.9759\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1216 - val_accuracy: 0.9772\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1121 - val_accuracy: 0.9765\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.1277 - val_accuracy: 0.9760\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1256 - val_accuracy: 0.9759\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1546 - val_accuracy: 0.9681\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1429 - val_accuracy: 0.9706\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1286 - val_accuracy: 0.9752\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1369 - val_accuracy: 0.9760\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.1428 - val_accuracy: 0.9759\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1601 - val_accuracy: 0.9752\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1479 - val_accuracy: 0.9767\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1506 - val_accuracy: 0.9755\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1461 - val_accuracy: 0.9754\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8701771592264309\n",
      "F1 Micro: 0.9773000000000001\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8474239529883625\n",
      "F1 Micro: 0.9713\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8918639299038116\n",
      "F1 Micro: 0.9776\n",
      "\n",
      "\n",
      " 51.27370577255885 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 4 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 4 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 966us/step - loss: 1.9047 - accuracy: 0.7450 - val_loss: 1.4719 - val_accuracy: 0.8400\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 1.0468 - accuracy: 0.8650 - val_loss: 0.8938 - val_accuracy: 0.8400\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7567 - accuracy: 0.8650 - val_loss: 0.8473 - val_accuracy: 0.8400\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.7125 - accuracy: 0.8650 - val_loss: 0.7507 - val_accuracy: 0.8400\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6696 - accuracy: 0.8650 - val_loss: 0.7219 - val_accuracy: 0.8400\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6506 - accuracy: 0.8650 - val_loss: 0.7081 - val_accuracy: 0.8400\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6443 - accuracy: 0.8650 - val_loss: 0.6863 - val_accuracy: 0.8400\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6323 - accuracy: 0.8650 - val_loss: 0.6827 - val_accuracy: 0.8400\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6269 - accuracy: 0.8650 - val_loss: 0.6685 - val_accuracy: 0.8400\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.6218 - accuracy: 0.8650 - val_loss: 0.6652 - val_accuracy: 0.8400\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6190 - accuracy: 0.8650 - val_loss: 0.6568 - val_accuracy: 0.8400\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6188 - accuracy: 0.8650 - val_loss: 0.6557 - val_accuracy: 0.8400\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6088 - accuracy: 0.8650 - val_loss: 0.6450 - val_accuracy: 0.8400\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6022 - accuracy: 0.8650 - val_loss: 0.6380 - val_accuracy: 0.8400\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5932 - accuracy: 0.8650 - val_loss: 0.6318 - val_accuracy: 0.8400\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5838 - accuracy: 0.8650 - val_loss: 0.6127 - val_accuracy: 0.8400\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5699 - accuracy: 0.8650 - val_loss: 0.5999 - val_accuracy: 0.8400\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5616 - accuracy: 0.8650 - val_loss: 0.5807 - val_accuracy: 0.8400\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5380 - accuracy: 0.8650 - val_loss: 0.6036 - val_accuracy: 0.8400\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5285 - accuracy: 0.8650 - val_loss: 0.5447 - val_accuracy: 0.8400\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5180 - accuracy: 0.8650 - val_loss: 0.5514 - val_accuracy: 0.8400\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 208us/step - loss: 0.4982 - accuracy: 0.8725 - val_loss: 0.5102 - val_accuracy: 0.8600\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4652 - accuracy: 0.8775 - val_loss: 0.4874 - val_accuracy: 0.8600\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4425 - accuracy: 0.8750 - val_loss: 0.4589 - val_accuracy: 0.8600\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4115 - accuracy: 0.8825 - val_loss: 0.4313 - val_accuracy: 0.8600\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3939 - accuracy: 0.9000 - val_loss: 0.4021 - val_accuracy: 0.8900\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3739 - accuracy: 0.8900 - val_loss: 0.3856 - val_accuracy: 0.9000\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3576 - accuracy: 0.9150 - val_loss: 0.3680 - val_accuracy: 0.9100\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3650 - accuracy: 0.9150 - val_loss: 0.4045 - val_accuracy: 0.8800\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3361 - accuracy: 0.9200 - val_loss: 0.4721 - val_accuracy: 0.8700\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3533 - accuracy: 0.9125 - val_loss: 0.3766 - val_accuracy: 0.9000\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3114 - accuracy: 0.9250 - val_loss: 0.3632 - val_accuracy: 0.9000\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3289 - accuracy: 0.9175 - val_loss: 0.3384 - val_accuracy: 0.9300\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3307 - accuracy: 0.9200 - val_loss: 0.3352 - val_accuracy: 0.9400\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 179us/step - loss: 0.2899 - accuracy: 0.9325 - val_loss: 0.3405 - val_accuracy: 0.9200\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2886 - accuracy: 0.9350 - val_loss: 0.3684 - val_accuracy: 0.9000\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3091 - accuracy: 0.9275 - val_loss: 0.3317 - val_accuracy: 0.9300\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2854 - accuracy: 0.9350 - val_loss: 0.3274 - val_accuracy: 0.9300\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2714 - accuracy: 0.9300 - val_loss: 0.3221 - val_accuracy: 0.9500\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2738 - accuracy: 0.9400 - val_loss: 0.3230 - val_accuracy: 0.9400\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2600 - accuracy: 0.9425 - val_loss: 0.3212 - val_accuracy: 0.9300\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2558 - accuracy: 0.9375 - val_loss: 0.3764 - val_accuracy: 0.9400\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 195us/step - loss: 0.2883 - accuracy: 0.9300 - val_loss: 0.3439 - val_accuracy: 0.9200\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2403 - accuracy: 0.9475 - val_loss: 0.3783 - val_accuracy: 0.9200\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2608 - accuracy: 0.9425 - val_loss: 0.3198 - val_accuracy: 0.9400\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2558 - accuracy: 0.9350 - val_loss: 0.3282 - val_accuracy: 0.9300\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.93 - 0s 210us/step - loss: 0.2472 - accuracy: 0.9375 - val_loss: 0.3344 - val_accuracy: 0.9400\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 161us/step - loss: 0.2410 - accuracy: 0.9375 - val_loss: 0.3179 - val_accuracy: 0.9400\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2440 - accuracy: 0.9375 - val_loss: 0.3257 - val_accuracy: 0.9400\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2211 - accuracy: 0.9475 - val_loss: 0.4132 - val_accuracy: 0.9100\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2437 - accuracy: 0.9350 - val_loss: 0.3141 - val_accuracy: 0.9400\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2182 - accuracy: 0.9450 - val_loss: 0.3225 - val_accuracy: 0.9400\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2281 - accuracy: 0.9400 - val_loss: 0.3628 - val_accuracy: 0.9300\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2182 - accuracy: 0.9475 - val_loss: 0.3343 - val_accuracy: 0.9300\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2138 - accuracy: 0.9475 - val_loss: 0.3245 - val_accuracy: 0.9400\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2098 - accuracy: 0.9475 - val_loss: 0.3125 - val_accuracy: 0.9400\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2171 - accuracy: 0.9475 - val_loss: 0.3254 - val_accuracy: 0.9300\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2217 - accuracy: 0.9400 - val_loss: 0.3541 - val_accuracy: 0.9300\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2135 - accuracy: 0.9450 - val_loss: 0.3011 - val_accuracy: 0.9400\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 176us/step - loss: 0.2159 - accuracy: 0.9400 - val_loss: 0.3065 - val_accuracy: 0.9400\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2026 - accuracy: 0.9450 - val_loss: 0.3038 - val_accuracy: 0.9400\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1899 - accuracy: 0.9425 - val_loss: 0.3113 - val_accuracy: 0.9400\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1911 - accuracy: 0.9550 - val_loss: 0.3059 - val_accuracy: 0.9400\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1914 - accuracy: 0.9475 - val_loss: 0.3045 - val_accuracy: 0.9300\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1906 - accuracy: 0.9500 - val_loss: 0.3012 - val_accuracy: 0.9400\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1652 - accuracy: 0.9575 - val_loss: 0.3426 - val_accuracy: 0.9300\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1750 - accuracy: 0.9525 - val_loss: 0.3097 - val_accuracy: 0.9400\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1678 - accuracy: 0.9600 - val_loss: 0.3527 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2038 - accuracy: 0.9400 - val_loss: 0.3848 - val_accuracy: 0.9300\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1643 - accuracy: 0.9525 - val_loss: 0.3027 - val_accuracy: 0.9400\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1714 - accuracy: 0.9500 - val_loss: 0.3245 - val_accuracy: 0.9300\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1622 - accuracy: 0.9575 - val_loss: 0.3073 - val_accuracy: 0.9400\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.1886 - accuracy: 0.9475 - val_loss: 0.3024 - val_accuracy: 0.9400\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1653 - accuracy: 0.9500 - val_loss: 0.2969 - val_accuracy: 0.9400\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1522 - accuracy: 0.9625 - val_loss: 0.2987 - val_accuracy: 0.9500\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1450 - accuracy: 0.9575 - val_loss: 0.2907 - val_accuracy: 0.9400\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1443 - accuracy: 0.9625 - val_loss: 0.2913 - val_accuracy: 0.9500\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1437 - accuracy: 0.9600 - val_loss: 0.2905 - val_accuracy: 0.9400\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1466 - accuracy: 0.9625 - val_loss: 0.3614 - val_accuracy: 0.9300\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1341 - accuracy: 0.9575 - val_loss: 0.3360 - val_accuracy: 0.9400\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1339 - accuracy: 0.9600 - val_loss: 0.2907 - val_accuracy: 0.9400\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1229 - accuracy: 0.9650 - val_loss: 0.2963 - val_accuracy: 0.9500\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1154 - accuracy: 0.9675 - val_loss: 0.2965 - val_accuracy: 0.9400\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1122 - accuracy: 0.9675 - val_loss: 0.2957 - val_accuracy: 0.9500\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1219 - accuracy: 0.9650 - val_loss: 0.3064 - val_accuracy: 0.9500\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 160us/step - loss: 0.1167 - accuracy: 0.9675 - val_loss: 0.2930 - val_accuracy: 0.9400\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1174 - accuracy: 0.9700 - val_loss: 0.3033 - val_accuracy: 0.9400\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1113 - accuracy: 0.9625 - val_loss: 0.2991 - val_accuracy: 0.9500\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1064 - accuracy: 0.9725 - val_loss: 0.2939 - val_accuracy: 0.9400\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1244 - accuracy: 0.9575 - val_loss: 0.3409 - val_accuracy: 0.9400\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1156 - accuracy: 0.9700 - val_loss: 0.4179 - val_accuracy: 0.9400\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1021 - accuracy: 0.9750 - val_loss: 0.3058 - val_accuracy: 0.9400\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0931 - accuracy: 0.9750 - val_loss: 0.3136 - val_accuracy: 0.9500\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1003 - accuracy: 0.9750 - val_loss: 0.3479 - val_accuracy: 0.9400\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0969 - accuracy: 0.9725 - val_loss: 0.2999 - val_accuracy: 0.9400\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0879 - accuracy: 0.9775 - val_loss: 0.3079 - val_accuracy: 0.9400\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0839 - accuracy: 0.9800 - val_loss: 0.3009 - val_accuracy: 0.9500\n",
      "Epoch 98/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 216us/step - loss: 0.0826 - accuracy: 0.9775 - val_loss: 0.3014 - val_accuracy: 0.9400\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.39631208860485045\n",
      "F1 Micro: 0.9236\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.41870655429983117\n",
      "F1 Micro: 0.9316\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 272us/step - loss: 2.1942 - accuracy: 0.1150 - val_loss: 2.0507 - val_accuracy: 0.3200\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 43us/step - loss: 1.9842 - accuracy: 0.4200 - val_loss: 1.8874 - val_accuracy: 0.4900\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.8266 - accuracy: 0.5350 - val_loss: 1.7773 - val_accuracy: 0.5200\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.7182 - accuracy: 0.5775 - val_loss: 1.6958 - val_accuracy: 0.5500\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.6395 - accuracy: 0.5875 - val_loss: 1.6272 - val_accuracy: 0.5700\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.5697 - accuracy: 0.6175 - val_loss: 1.5629 - val_accuracy: 0.6200\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.5043 - accuracy: 0.6400 - val_loss: 1.5001 - val_accuracy: 0.6900\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 1.4391 - accuracy: 0.6600 - val_loss: 1.4369 - val_accuracy: 0.7000\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.3750 - accuracy: 0.6900 - val_loss: 1.3710 - val_accuracy: 0.7100\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.3094 - accuracy: 0.7150 - val_loss: 1.3069 - val_accuracy: 0.7200\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.2427 - accuracy: 0.7425 - val_loss: 1.2399 - val_accuracy: 0.7500\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1752 - accuracy: 0.7650 - val_loss: 1.1720 - val_accuracy: 0.7800\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1083 - accuracy: 0.7875 - val_loss: 1.1026 - val_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0397 - accuracy: 0.8225 - val_loss: 1.0359 - val_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.9744 - accuracy: 0.8425 - val_loss: 0.9700 - val_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.9090 - accuracy: 0.8700 - val_loss: 0.9076 - val_accuracy: 0.8200\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8463 - accuracy: 0.9025 - val_loss: 0.8453 - val_accuracy: 0.8300\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7866 - accuracy: 0.9075 - val_loss: 0.7871 - val_accuracy: 0.8500\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7294 - accuracy: 0.9150 - val_loss: 0.7337 - val_accuracy: 0.8600\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.6759 - accuracy: 0.9200 - val_loss: 0.6846 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.6264 - accuracy: 0.9225 - val_loss: 0.6401 - val_accuracy: 0.8900\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5814 - accuracy: 0.9275 - val_loss: 0.5984 - val_accuracy: 0.8900\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5394 - accuracy: 0.9350 - val_loss: 0.5601 - val_accuracy: 0.9000\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5025 - accuracy: 0.9350 - val_loss: 0.5282 - val_accuracy: 0.9100\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4691 - accuracy: 0.9400 - val_loss: 0.4966 - val_accuracy: 0.9100\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.5226 - accuracy: 0.90 - 0s 94us/step - loss: 0.4387 - accuracy: 0.9425 - val_loss: 0.4706 - val_accuracy: 0.9200\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.4121 - accuracy: 0.9450 - val_loss: 0.4480 - val_accuracy: 0.9200\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3871 - accuracy: 0.9475 - val_loss: 0.4245 - val_accuracy: 0.9300\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.3651 - accuracy: 0.9525 - val_loss: 0.4030 - val_accuracy: 0.9400\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3451 - accuracy: 0.9525 - val_loss: 0.3870 - val_accuracy: 0.9300\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.3268 - accuracy: 0.9550 - val_loss: 0.3734 - val_accuracy: 0.9300\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.3115 - accuracy: 0.9550 - val_loss: 0.3578 - val_accuracy: 0.9300\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2961 - accuracy: 0.9550 - val_loss: 0.3465 - val_accuracy: 0.9300\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2826 - accuracy: 0.9600 - val_loss: 0.3358 - val_accuracy: 0.9300\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2706 - accuracy: 0.9575 - val_loss: 0.3244 - val_accuracy: 0.9500\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.2593 - accuracy: 0.9550 - val_loss: 0.3152 - val_accuracy: 0.9500\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.2487 - accuracy: 0.9550 - val_loss: 0.3076 - val_accuracy: 0.9400\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.2393 - accuracy: 0.9550 - val_loss: 0.2999 - val_accuracy: 0.9400\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.2304 - accuracy: 0.9575 - val_loss: 0.2917 - val_accuracy: 0.9400\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.2223 - accuracy: 0.9600 - val_loss: 0.2849 - val_accuracy: 0.9400\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.2147 - accuracy: 0.9625 - val_loss: 0.2812 - val_accuracy: 0.9400\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.2079 - accuracy: 0.9675 - val_loss: 0.2753 - val_accuracy: 0.9400\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.2010 - accuracy: 0.9700 - val_loss: 0.2697 - val_accuracy: 0.9400\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.1949 - accuracy: 0.9675 - val_loss: 0.2650 - val_accuracy: 0.9400\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1892 - accuracy: 0.9700 - val_loss: 0.2625 - val_accuracy: 0.9400\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1836 - accuracy: 0.9750 - val_loss: 0.2590 - val_accuracy: 0.9400\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1788 - accuracy: 0.9750 - val_loss: 0.2564 - val_accuracy: 0.9400\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1743 - accuracy: 0.9750 - val_loss: 0.2511 - val_accuracy: 0.9400\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1693 - accuracy: 0.9750 - val_loss: 0.2492 - val_accuracy: 0.9400\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1651 - accuracy: 0.9750 - val_loss: 0.2478 - val_accuracy: 0.9400\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1612 - accuracy: 0.9750 - val_loss: 0.2450 - val_accuracy: 0.9400\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1571 - accuracy: 0.9750 - val_loss: 0.2424 - val_accuracy: 0.9400\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1536 - accuracy: 0.9750 - val_loss: 0.2408 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1500 - accuracy: 0.9750 - val_loss: 0.2382 - val_accuracy: 0.9400\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1470 - accuracy: 0.9750 - val_loss: 0.2364 - val_accuracy: 0.9400\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.1435 - accuracy: 0.9750 - val_loss: 0.2349 - val_accuracy: 0.9400\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1402 - accuracy: 0.9750 - val_loss: 0.2328 - val_accuracy: 0.9400\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 50us/step - loss: 0.1373 - accuracy: 0.9775 - val_loss: 0.2300 - val_accuracy: 0.9400\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1345 - accuracy: 0.9775 - val_loss: 0.2275 - val_accuracy: 0.9400\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1319 - accuracy: 0.9750 - val_loss: 0.2284 - val_accuracy: 0.9400\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1293 - accuracy: 0.9750 - val_loss: 0.2289 - val_accuracy: 0.9400\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1267 - accuracy: 0.9775 - val_loss: 0.2277 - val_accuracy: 0.9400\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1243 - accuracy: 0.9775 - val_loss: 0.2262 - val_accuracy: 0.9400\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1218 - accuracy: 0.9775 - val_loss: 0.2249 - val_accuracy: 0.9400\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1200 - accuracy: 0.9775 - val_loss: 0.2236 - val_accuracy: 0.9400\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1175 - accuracy: 0.9800 - val_loss: 0.2221 - val_accuracy: 0.9400\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1159 - accuracy: 0.9825 - val_loss: 0.2202 - val_accuracy: 0.9400\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1133 - accuracy: 0.9825 - val_loss: 0.2201 - val_accuracy: 0.9400\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 1.00 - 0s 78us/step - loss: 0.1117 - accuracy: 0.9825 - val_loss: 0.2203 - val_accuracy: 0.9400\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1095 - accuracy: 0.9850 - val_loss: 0.2196 - val_accuracy: 0.9400\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1087 - accuracy: 0.9850 - val_loss: 0.2194 - val_accuracy: 0.9400\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1063 - accuracy: 0.9825 - val_loss: 0.2184 - val_accuracy: 0.9400\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1042 - accuracy: 0.9850 - val_loss: 0.2169 - val_accuracy: 0.9400\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1033 - accuracy: 0.9875 - val_loss: 0.2187 - val_accuracy: 0.9400\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1009 - accuracy: 0.9875 - val_loss: 0.2165 - val_accuracy: 0.9400\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0993 - accuracy: 0.9875 - val_loss: 0.2168 - val_accuracy: 0.9400\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0981 - accuracy: 0.9875 - val_loss: 0.2162 - val_accuracy: 0.9400\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0965 - accuracy: 0.9875 - val_loss: 0.2156 - val_accuracy: 0.9400\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0950 - accuracy: 0.9875 - val_loss: 0.2144 - val_accuracy: 0.9400\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0934 - accuracy: 0.9875 - val_loss: 0.2130 - val_accuracy: 0.9400\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0920 - accuracy: 0.9875 - val_loss: 0.2125 - val_accuracy: 0.9400\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0906 - accuracy: 0.9875 - val_loss: 0.2137 - val_accuracy: 0.9400\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0890 - accuracy: 0.9875 - val_loss: 0.2126 - val_accuracy: 0.9400\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0880 - accuracy: 0.9875 - val_loss: 0.2120 - val_accuracy: 0.9400\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0867 - accuracy: 0.9875 - val_loss: 0.2107 - val_accuracy: 0.9400\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0858 - accuracy: 0.9875 - val_loss: 0.2123 - val_accuracy: 0.9400\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0840 - accuracy: 0.9875 - val_loss: 0.2122 - val_accuracy: 0.9400\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0832 - accuracy: 0.9875 - val_loss: 0.2117 - val_accuracy: 0.9400\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0816 - accuracy: 0.9875 - val_loss: 0.2111 - val_accuracy: 0.9400\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0807 - accuracy: 0.9875 - val_loss: 0.2089 - val_accuracy: 0.9400\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0795 - accuracy: 0.9875 - val_loss: 0.2098 - val_accuracy: 0.9400\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0782 - accuracy: 0.9875 - val_loss: 0.2103 - val_accuracy: 0.9400\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0772 - accuracy: 0.9900 - val_loss: 0.2095 - val_accuracy: 0.9400\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0763 - accuracy: 0.9900 - val_loss: 0.2094 - val_accuracy: 0.9400\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0752 - accuracy: 0.9900 - val_loss: 0.2099 - val_accuracy: 0.9400\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0745 - accuracy: 0.9900 - val_loss: 0.2096 - val_accuracy: 0.9400\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0731 - accuracy: 0.9900 - val_loss: 0.2098 - val_accuracy: 0.9400\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0723 - accuracy: 0.9900 - val_loss: 0.2089 - val_accuracy: 0.9400\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0716 - accuracy: 0.9900 - val_loss: 0.2093 - val_accuracy: 0.9400\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0703 - accuracy: 0.9900 - val_loss: 0.2085 - val_accuracy: 0.9400\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0694 - accuracy: 0.9900 - val_loss: 0.2078 - val_accuracy: 0.9400\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0686 - accuracy: 0.9900 - val_loss: 0.2096 - val_accuracy: 0.9400\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0675 - accuracy: 0.9900 - val_loss: 0.2094 - val_accuracy: 0.9400\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0668 - accuracy: 0.9900 - val_loss: 0.2078 - val_accuracy: 0.9300\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0659 - accuracy: 0.9900 - val_loss: 0.2091 - val_accuracy: 0.9400\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0650 - accuracy: 0.9900 - val_loss: 0.2097 - val_accuracy: 0.9400\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0642 - accuracy: 0.9900 - val_loss: 0.2082 - val_accuracy: 0.9300\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0632 - accuracy: 0.9900 - val_loss: 0.2077 - val_accuracy: 0.9300\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0624 - accuracy: 0.9900 - val_loss: 0.2082 - val_accuracy: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0616 - accuracy: 0.9900 - val_loss: 0.2080 - val_accuracy: 0.9300\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0609 - accuracy: 0.9900 - val_loss: 0.2070 - val_accuracy: 0.9300\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0601 - accuracy: 0.9900 - val_loss: 0.2074 - val_accuracy: 0.9400\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0594 - accuracy: 0.9900 - val_loss: 0.2092 - val_accuracy: 0.9200\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0586 - accuracy: 0.9900 - val_loss: 0.2086 - val_accuracy: 0.9200\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0577 - accuracy: 0.9900 - val_loss: 0.2077 - val_accuracy: 0.9300\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0570 - accuracy: 0.9900 - val_loss: 0.2079 - val_accuracy: 0.9200\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0567 - accuracy: 0.9900 - val_loss: 0.2087 - val_accuracy: 0.9200\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0557 - accuracy: 0.9900 - val_loss: 0.2089 - val_accuracy: 0.9200\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0550 - accuracy: 0.9900 - val_loss: 0.2094 - val_accuracy: 0.9200\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0544 - accuracy: 0.9900 - val_loss: 0.2104 - val_accuracy: 0.9200\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 42us/step - loss: 0.0537 - accuracy: 0.9900 - val_loss: 0.2097 - val_accuracy: 0.9200\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0531 - accuracy: 0.9900 - val_loss: 0.2096 - val_accuracy: 0.9200\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0523 - accuracy: 0.9900 - val_loss: 0.2097 - val_accuracy: 0.9200\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0516 - accuracy: 0.9900 - val_loss: 0.2089 - val_accuracy: 0.9200\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0507 - accuracy: 0.9925 - val_loss: 0.2090 - val_accuracy: 0.9200\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0502 - accuracy: 0.9925 - val_loss: 0.2087 - val_accuracy: 0.9200\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0496 - accuracy: 0.9925 - val_loss: 0.2111 - val_accuracy: 0.9100\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0490 - accuracy: 0.9925 - val_loss: 0.2120 - val_accuracy: 0.9100\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0484 - accuracy: 0.9925 - val_loss: 0.2112 - val_accuracy: 0.9100\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 1.00 - 0s 78us/step - loss: 0.0477 - accuracy: 0.9950 - val_loss: 0.2109 - val_accuracy: 0.9100\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0471 - accuracy: 0.9950 - val_loss: 0.2131 - val_accuracy: 0.9100\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5060135683510826\n",
      "F1 Micro: 0.9375\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 729us/step - loss: 1.8453 - accuracy: 0.5975 - val_loss: 1.3354 - val_accuracy: 0.8000\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.8003 - accuracy: 0.8700 - val_loss: 0.5910 - val_accuracy: 0.8400\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5367 - accuracy: 0.8650 - val_loss: 0.5886 - val_accuracy: 0.8400\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.4614 - accuracy: 0.8725 - val_loss: 0.4615 - val_accuracy: 0.8500\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4132 - accuracy: 0.8950 - val_loss: 0.4275 - val_accuracy: 0.8800\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.3798 - accuracy: 0.9000 - val_loss: 0.4025 - val_accuracy: 0.8800\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3567 - accuracy: 0.9025 - val_loss: 0.3725 - val_accuracy: 0.8900\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3384 - accuracy: 0.9150 - val_loss: 0.3590 - val_accuracy: 0.8900\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3207 - accuracy: 0.9175 - val_loss: 0.3427 - val_accuracy: 0.9000\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3051 - accuracy: 0.9250 - val_loss: 0.3294 - val_accuracy: 0.9100\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2935 - accuracy: 0.9250 - val_loss: 0.3233 - val_accuracy: 0.9300\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2809 - accuracy: 0.9350 - val_loss: 0.3138 - val_accuracy: 0.9300\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2700 - accuracy: 0.9425 - val_loss: 0.3062 - val_accuracy: 0.9400\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2601 - accuracy: 0.9450 - val_loss: 0.3011 - val_accuracy: 0.9400\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2519 - accuracy: 0.9475 - val_loss: 0.2933 - val_accuracy: 0.9400\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2424 - accuracy: 0.9475 - val_loss: 0.2890 - val_accuracy: 0.9400\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2349 - accuracy: 0.9475 - val_loss: 0.2794 - val_accuracy: 0.9400\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2284 - accuracy: 0.9450 - val_loss: 0.2761 - val_accuracy: 0.9400\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 177us/step - loss: 0.2214 - accuracy: 0.9500 - val_loss: 0.2724 - val_accuracy: 0.9400\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2149 - accuracy: 0.9500 - val_loss: 0.2684 - val_accuracy: 0.9400\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2080 - accuracy: 0.9500 - val_loss: 0.2662 - val_accuracy: 0.9400\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2101 - accuracy: 0.94 - 0s 234us/step - loss: 0.2034 - accuracy: 0.9475 - val_loss: 0.2626 - val_accuracy: 0.9400\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1982 - accuracy: 0.9500 - val_loss: 0.2574 - val_accuracy: 0.9400\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1928 - accuracy: 0.9500 - val_loss: 0.2564 - val_accuracy: 0.9400\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1929 - accuracy: 0.9550 - val_loss: 0.2526 - val_accuracy: 0.9400\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1848 - accuracy: 0.9525 - val_loss: 0.2514 - val_accuracy: 0.9400\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1790 - accuracy: 0.9600 - val_loss: 0.2472 - val_accuracy: 0.9400\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1760 - accuracy: 0.9600 - val_loss: 0.2447 - val_accuracy: 0.9400\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1700 - accuracy: 0.9600 - val_loss: 0.2441 - val_accuracy: 0.9400\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 182us/step - loss: 0.1691 - accuracy: 0.9575 - val_loss: 0.2414 - val_accuracy: 0.9400\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1638 - accuracy: 0.9650 - val_loss: 0.2407 - val_accuracy: 0.9400\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1613 - accuracy: 0.9625 - val_loss: 0.2390 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1586 - accuracy: 0.9600 - val_loss: 0.2399 - val_accuracy: 0.9400\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1526 - accuracy: 0.9675 - val_loss: 0.2354 - val_accuracy: 0.9400\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1506 - accuracy: 0.9600 - val_loss: 0.2369 - val_accuracy: 0.9400\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1463 - accuracy: 0.9700 - val_loss: 0.2346 - val_accuracy: 0.9400\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1439 - accuracy: 0.9700 - val_loss: 0.2324 - val_accuracy: 0.9400\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1402 - accuracy: 0.9675 - val_loss: 0.2327 - val_accuracy: 0.9400\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1370 - accuracy: 0.9700 - val_loss: 0.2326 - val_accuracy: 0.9400\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1329 - accuracy: 0.9700 - val_loss: 0.2293 - val_accuracy: 0.9400\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1318 - accuracy: 0.9675 - val_loss: 0.2270 - val_accuracy: 0.9400\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1336 - accuracy: 0.9725 - val_loss: 0.2304 - val_accuracy: 0.9400\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1266 - accuracy: 0.9675 - val_loss: 0.2268 - val_accuracy: 0.9300\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1226 - accuracy: 0.9725 - val_loss: 0.2251 - val_accuracy: 0.9400\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1205 - accuracy: 0.9675 - val_loss: 0.2247 - val_accuracy: 0.9400\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1204 - accuracy: 0.9750 - val_loss: 0.2239 - val_accuracy: 0.9300\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1200 - accuracy: 0.9675 - val_loss: 0.2283 - val_accuracy: 0.9200\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1140 - accuracy: 0.9775 - val_loss: 0.2277 - val_accuracy: 0.9200\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1111 - accuracy: 0.9775 - val_loss: 0.2273 - val_accuracy: 0.9300\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1087 - accuracy: 0.9775 - val_loss: 0.2303 - val_accuracy: 0.9200\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.97 - 0s 234us/step - loss: 0.1068 - accuracy: 0.9750 - val_loss: 0.2256 - val_accuracy: 0.9200\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1051 - accuracy: 0.9775 - val_loss: 0.2226 - val_accuracy: 0.9300\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1019 - accuracy: 0.9775 - val_loss: 0.2214 - val_accuracy: 0.9200\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 178us/step - loss: 0.0993 - accuracy: 0.9775 - val_loss: 0.2201 - val_accuracy: 0.9200\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0977 - accuracy: 0.9775 - val_loss: 0.2293 - val_accuracy: 0.9200\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0976 - accuracy: 0.9775 - val_loss: 0.2239 - val_accuracy: 0.9300\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0970 - accuracy: 0.9775 - val_loss: 0.2247 - val_accuracy: 0.9200\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0943 - accuracy: 0.9750 - val_loss: 0.2267 - val_accuracy: 0.9200\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0935 - accuracy: 0.9800 - val_loss: 0.2251 - val_accuracy: 0.9400\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0898 - accuracy: 0.9775 - val_loss: 0.2253 - val_accuracy: 0.9200\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0868 - accuracy: 0.9825 - val_loss: 0.2220 - val_accuracy: 0.9400\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0910 - accuracy: 0.9775 - val_loss: 0.2271 - val_accuracy: 0.9200\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0837 - accuracy: 0.9825 - val_loss: 0.2227 - val_accuracy: 0.9100\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0828 - accuracy: 0.9800 - val_loss: 0.2224 - val_accuracy: 0.9200\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0831 - accuracy: 0.9750 - val_loss: 0.2325 - val_accuracy: 0.9200\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.0779 - accuracy: 0.9850 - val_loss: 0.2225 - val_accuracy: 0.9200\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0785 - accuracy: 0.9800 - val_loss: 0.2213 - val_accuracy: 0.9200\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0738 - accuracy: 0.9875 - val_loss: 0.2186 - val_accuracy: 0.9200\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0745 - accuracy: 0.9800 - val_loss: 0.2250 - val_accuracy: 0.9300\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0752 - accuracy: 0.9800 - val_loss: 0.2243 - val_accuracy: 0.9300\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0707 - accuracy: 0.9850 - val_loss: 0.2227 - val_accuracy: 0.9300\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0700 - accuracy: 0.9875 - val_loss: 0.2181 - val_accuracy: 0.9300\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0658 - accuracy: 0.9900 - val_loss: 0.2200 - val_accuracy: 0.9100\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0647 - accuracy: 0.9875 - val_loss: 0.2212 - val_accuracy: 0.9300\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0637 - accuracy: 0.9900 - val_loss: 0.2198 - val_accuracy: 0.9200\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0626 - accuracy: 0.9900 - val_loss: 0.2254 - val_accuracy: 0.9300\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 240us/step - loss: 0.0612 - accuracy: 0.9875 - val_loss: 0.2237 - val_accuracy: 0.9200\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.0612 - accuracy: 0.9925 - val_loss: 0.2250 - val_accuracy: 0.9300\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0643 - accuracy: 0.9800 - val_loss: 0.2353 - val_accuracy: 0.9300\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0625 - accuracy: 0.9925 - val_loss: 0.2209 - val_accuracy: 0.9100\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0584 - accuracy: 0.9900 - val_loss: 0.2161 - val_accuracy: 0.9200\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0544 - accuracy: 0.9900 - val_loss: 0.2180 - val_accuracy: 0.9200\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0513 - accuracy: 0.9925 - val_loss: 0.2228 - val_accuracy: 0.9300\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0493 - accuracy: 0.9925 - val_loss: 0.2203 - val_accuracy: 0.9200\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0480 - accuracy: 0.9925 - val_loss: 0.2281 - val_accuracy: 0.9200\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0490 - accuracy: 0.9925 - val_loss: 0.2201 - val_accuracy: 0.9300\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0462 - accuracy: 0.9925 - val_loss: 0.2251 - val_accuracy: 0.9300\n",
      "Epoch 88/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 195us/step - loss: 0.0434 - accuracy: 0.9925 - val_loss: 0.2218 - val_accuracy: 0.9300\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0429 - accuracy: 0.9925 - val_loss: 0.2341 - val_accuracy: 0.9300\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0402 - accuracy: 0.9925 - val_loss: 0.2294 - val_accuracy: 0.9500\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0499 - accuracy: 0.9925 - val_loss: 0.2315 - val_accuracy: 0.9400\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0425 - accuracy: 0.9875 - val_loss: 0.2343 - val_accuracy: 0.9300\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0404 - accuracy: 0.9925 - val_loss: 0.2329 - val_accuracy: 0.9400\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0365 - accuracy: 0.9925 - val_loss: 0.2321 - val_accuracy: 0.9300\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0371 - accuracy: 0.9925 - val_loss: 0.2254 - val_accuracy: 0.9300\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0333 - accuracy: 0.9950 - val_loss: 0.2305 - val_accuracy: 0.9300\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0324 - accuracy: 0.9925 - val_loss: 0.2222 - val_accuracy: 0.9300\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0307 - accuracy: 0.9950 - val_loss: 0.2264 - val_accuracy: 0.9300\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0309 - accuracy: 0.9950 - val_loss: 0.2262 - val_accuracy: 0.9300\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0289 - accuracy: 0.9975 - val_loss: 0.2233 - val_accuracy: 0.9300\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0297 - accuracy: 0.9950 - val_loss: 0.2381 - val_accuracy: 0.9200\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.49054693108506153\n",
      "F1 Micro: 0.9323\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5214104648692989\n",
      "F1 Micro: 0.9326\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.540680080307682\n",
      "F1 Micro: 0.9425\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 4 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 231us/step - loss: 0.8528 - accuracy: 0.8545 - val_loss: 0.6701 - val_accuracy: 0.8520\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.6319 - accuracy: 0.8545 - val_loss: 0.6270 - val_accuracy: 0.8520\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.5755 - accuracy: 0.8545 - val_loss: 0.5873 - val_accuracy: 0.8520\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.4779 - accuracy: 0.8765 - val_loss: 0.4227 - val_accuracy: 0.8990\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 177us/step - loss: 0.3865 - accuracy: 0.8967 - val_loss: 0.3633 - val_accuracy: 0.9030\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 177us/step - loss: 0.3367 - accuracy: 0.9082 - val_loss: 0.3272 - val_accuracy: 0.9140\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.3176 - accuracy: 0.9107 - val_loss: 0.3256 - val_accuracy: 0.9090\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.2735 - accuracy: 0.9233 - val_loss: 0.2772 - val_accuracy: 0.9180\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.2434 - accuracy: 0.9290 - val_loss: 0.2494 - val_accuracy: 0.9240\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.2312 - accuracy: 0.9350 - val_loss: 0.2521 - val_accuracy: 0.9260\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.2189 - accuracy: 0.9355 - val_loss: 0.2409 - val_accuracy: 0.9240\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.2053 - accuracy: 0.9417 - val_loss: 0.2235 - val_accuracy: 0.9290\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.1839 - accuracy: 0.9480 - val_loss: 0.2158 - val_accuracy: 0.9370\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1837 - accuracy: 0.9457 - val_loss: 0.2133 - val_accuracy: 0.9350\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1659 - accuracy: 0.9498 - val_loss: 0.2204 - val_accuracy: 0.9360\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1588 - accuracy: 0.9572 - val_loss: 0.1890 - val_accuracy: 0.9350\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1540 - accuracy: 0.9555 - val_loss: 0.1937 - val_accuracy: 0.9380\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1491 - accuracy: 0.9563 - val_loss: 0.1862 - val_accuracy: 0.9390\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1416 - accuracy: 0.9595 - val_loss: 0.1795 - val_accuracy: 0.9420\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1354 - accuracy: 0.9600 - val_loss: 0.2013 - val_accuracy: 0.9380\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1323 - accuracy: 0.9628 - val_loss: 0.1781 - val_accuracy: 0.9420\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1267 - accuracy: 0.9625 - val_loss: 0.1930 - val_accuracy: 0.9400\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1274 - accuracy: 0.9620 - val_loss: 0.1764 - val_accuracy: 0.9440\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1212 - accuracy: 0.9657 - val_loss: 0.1642 - val_accuracy: 0.9420\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1133 - accuracy: 0.9663 - val_loss: 0.1664 - val_accuracy: 0.9490\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1107 - accuracy: 0.9690 - val_loss: 0.1738 - val_accuracy: 0.9430\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1089 - accuracy: 0.9672 - val_loss: 0.1610 - val_accuracy: 0.9440\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.0966 - accuracy: 0.9712 - val_loss: 0.1655 - val_accuracy: 0.9470\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0993 - accuracy: 0.9720 - val_loss: 0.1714 - val_accuracy: 0.9510\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1036 - accuracy: 0.9710 - val_loss: 0.1695 - val_accuracy: 0.9420\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0886 - accuracy: 0.9732 - val_loss: 0.1777 - val_accuracy: 0.9400\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0869 - accuracy: 0.9722 - val_loss: 0.1616 - val_accuracy: 0.9500\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0818 - accuracy: 0.9758 - val_loss: 0.1671 - val_accuracy: 0.9470\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0810 - accuracy: 0.9732 - val_loss: 0.1708 - val_accuracy: 0.9490\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0731 - accuracy: 0.9770 - val_loss: 0.1873 - val_accuracy: 0.9450\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0803 - accuracy: 0.9768 - val_loss: 0.1618 - val_accuracy: 0.9510\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0723 - accuracy: 0.9780 - val_loss: 0.1675 - val_accuracy: 0.9520\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0663 - accuracy: 0.9797 - val_loss: 0.1614 - val_accuracy: 0.9530\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0621 - accuracy: 0.9805 - val_loss: 0.1713 - val_accuracy: 0.9480\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0620 - accuracy: 0.9812 - val_loss: 0.1761 - val_accuracy: 0.9430\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0574 - accuracy: 0.9840 - val_loss: 0.1685 - val_accuracy: 0.9530\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0555 - accuracy: 0.9835 - val_loss: 0.1801 - val_accuracy: 0.9460\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0530 - accuracy: 0.9858 - val_loss: 0.1610 - val_accuracy: 0.9540\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0480 - accuracy: 0.9840 - val_loss: 0.1665 - val_accuracy: 0.9550\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0435 - accuracy: 0.9887 - val_loss: 0.1561 - val_accuracy: 0.9550\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0468 - accuracy: 0.9852 - val_loss: 0.1773 - val_accuracy: 0.9520\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.0464 - accuracy: 0.9868 - val_loss: 0.1725 - val_accuracy: 0.9550\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0339 - accuracy: 0.9915 - val_loss: 0.1693 - val_accuracy: 0.9510\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0341 - accuracy: 0.9918 - val_loss: 0.1763 - val_accuracy: 0.9570\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 0.1714 - val_accuracy: 0.9560\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0335 - accuracy: 0.9923 - val_loss: 0.2007 - val_accuracy: 0.9460\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0252 - accuracy: 0.9942 - val_loss: 0.1822 - val_accuracy: 0.9530\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0232 - accuracy: 0.9950 - val_loss: 0.1914 - val_accuracy: 0.9510\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0270 - accuracy: 0.9918 - val_loss: 0.1939 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 0.1854 - val_accuracy: 0.9490\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0177 - accuracy: 0.9960 - val_loss: 0.2047 - val_accuracy: 0.9510\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0151 - accuracy: 0.9965 - val_loss: 0.1780 - val_accuracy: 0.9550\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 0.1900 - val_accuracy: 0.9530\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0146 - accuracy: 0.9967 - val_loss: 0.2440 - val_accuracy: 0.9470\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0143 - accuracy: 0.9975 - val_loss: 0.1873 - val_accuracy: 0.9520\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0113 - accuracy: 0.9977 - val_loss: 0.2025 - val_accuracy: 0.9510\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0223 - accuracy: 0.9935 - val_loss: 0.1898 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0110 - accuracy: 0.9977 - val_loss: 0.2004 - val_accuracy: 0.9500\n",
      "Epoch 64/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.2227 - val_accuracy: 0.9500\n",
      "Epoch 65/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0076 - accuracy: 0.9995 - val_loss: 0.1974 - val_accuracy: 0.9530\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6599567699176239\n",
      "F1 Micro: 0.95923165424441\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6046317444593663\n",
      "F1 Micro: 0.9574\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 84us/step - loss: 1.7452 - accuracy: 0.5393 - val_loss: 1.4585 - val_accuracy: 0.6590\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 1.2094 - accuracy: 0.7362 - val_loss: 0.9620 - val_accuracy: 0.8190\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.7472 - accuracy: 0.8675 - val_loss: 0.5768 - val_accuracy: 0.8960\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.4490 - accuracy: 0.9193 - val_loss: 0.3645 - val_accuracy: 0.9250\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.2966 - accuracy: 0.9423 - val_loss: 0.2714 - val_accuracy: 0.9350\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.2264 - accuracy: 0.9488 - val_loss: 0.2303 - val_accuracy: 0.9360\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1912 - accuracy: 0.9532 - val_loss: 0.2087 - val_accuracy: 0.9380\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1713 - accuracy: 0.9553 - val_loss: 0.1962 - val_accuracy: 0.9390\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1581 - accuracy: 0.9600 - val_loss: 0.1879 - val_accuracy: 0.9380\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1489 - accuracy: 0.9585 - val_loss: 0.1815 - val_accuracy: 0.9410\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1409 - accuracy: 0.9613 - val_loss: 0.1769 - val_accuracy: 0.9450\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.1351 - accuracy: 0.9630 - val_loss: 0.1727 - val_accuracy: 0.9480\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1306 - accuracy: 0.9650 - val_loss: 0.1686 - val_accuracy: 0.9470\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1265 - accuracy: 0.9660 - val_loss: 0.1657 - val_accuracy: 0.9470\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1223 - accuracy: 0.9665 - val_loss: 0.1638 - val_accuracy: 0.9510\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1190 - accuracy: 0.9663 - val_loss: 0.1616 - val_accuracy: 0.9490\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1161 - accuracy: 0.9660 - val_loss: 0.1612 - val_accuracy: 0.9490\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1138 - accuracy: 0.9678 - val_loss: 0.1593 - val_accuracy: 0.9500\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1105 - accuracy: 0.9703 - val_loss: 0.1572 - val_accuracy: 0.9520\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1085 - accuracy: 0.9695 - val_loss: 0.1540 - val_accuracy: 0.9510\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1061 - accuracy: 0.9712 - val_loss: 0.1526 - val_accuracy: 0.9490\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1046 - accuracy: 0.9697 - val_loss: 0.1517 - val_accuracy: 0.9500\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1023 - accuracy: 0.9722 - val_loss: 0.1528 - val_accuracy: 0.9500\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1005 - accuracy: 0.9718 - val_loss: 0.1513 - val_accuracy: 0.9500\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0983 - accuracy: 0.9725 - val_loss: 0.1502 - val_accuracy: 0.9490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 64us/step - loss: 0.0969 - accuracy: 0.9728 - val_loss: 0.1497 - val_accuracy: 0.9500\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0951 - accuracy: 0.9732 - val_loss: 0.1498 - val_accuracy: 0.9490\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0940 - accuracy: 0.9728 - val_loss: 0.1475 - val_accuracy: 0.9490\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0921 - accuracy: 0.9743 - val_loss: 0.1466 - val_accuracy: 0.9500\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0905 - accuracy: 0.9743 - val_loss: 0.1461 - val_accuracy: 0.9510\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0891 - accuracy: 0.9737 - val_loss: 0.1454 - val_accuracy: 0.9510\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0880 - accuracy: 0.9747 - val_loss: 0.1454 - val_accuracy: 0.9510\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0860 - accuracy: 0.9758 - val_loss: 0.1477 - val_accuracy: 0.9500\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0852 - accuracy: 0.9760 - val_loss: 0.1469 - val_accuracy: 0.9510\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0841 - accuracy: 0.9778 - val_loss: 0.1445 - val_accuracy: 0.9490\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0825 - accuracy: 0.9762 - val_loss: 0.1446 - val_accuracy: 0.9510\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0809 - accuracy: 0.9772 - val_loss: 0.1450 - val_accuracy: 0.9490\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0803 - accuracy: 0.9775 - val_loss: 0.1437 - val_accuracy: 0.9510\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0792 - accuracy: 0.9780 - val_loss: 0.1431 - val_accuracy: 0.9520\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0777 - accuracy: 0.9790 - val_loss: 0.1445 - val_accuracy: 0.9510\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0770 - accuracy: 0.9795 - val_loss: 0.1427 - val_accuracy: 0.9520\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0756 - accuracy: 0.9795 - val_loss: 0.1416 - val_accuracy: 0.9510\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0750 - accuracy: 0.9805 - val_loss: 0.1432 - val_accuracy: 0.9520\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.0734 - accuracy: 0.9810 - val_loss: 0.1436 - val_accuracy: 0.9520\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0728 - accuracy: 0.9800 - val_loss: 0.1432 - val_accuracy: 0.9540\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0713 - accuracy: 0.9810 - val_loss: 0.1409 - val_accuracy: 0.9520\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0706 - accuracy: 0.9822 - val_loss: 0.1428 - val_accuracy: 0.9530\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0701 - accuracy: 0.9815 - val_loss: 0.1418 - val_accuracy: 0.9530\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0684 - accuracy: 0.9820 - val_loss: 0.1407 - val_accuracy: 0.9540\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0679 - accuracy: 0.9833 - val_loss: 0.1432 - val_accuracy: 0.9540\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0668 - accuracy: 0.9827 - val_loss: 0.1414 - val_accuracy: 0.9520\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0660 - accuracy: 0.9827 - val_loss: 0.1425 - val_accuracy: 0.9530\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0650 - accuracy: 0.9825 - val_loss: 0.1400 - val_accuracy: 0.9520\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0639 - accuracy: 0.9833 - val_loss: 0.1417 - val_accuracy: 0.9520\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0629 - accuracy: 0.9843 - val_loss: 0.1422 - val_accuracy: 0.9540\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0622 - accuracy: 0.9837 - val_loss: 0.1421 - val_accuracy: 0.9520\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0615 - accuracy: 0.9830 - val_loss: 0.1413 - val_accuracy: 0.9520\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0609 - accuracy: 0.9855 - val_loss: 0.1406 - val_accuracy: 0.9540\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0597 - accuracy: 0.9837 - val_loss: 0.1404 - val_accuracy: 0.9540\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0590 - accuracy: 0.9855 - val_loss: 0.1415 - val_accuracy: 0.9540\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0586 - accuracy: 0.9858 - val_loss: 0.1411 - val_accuracy: 0.9530\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0573 - accuracy: 0.9858 - val_loss: 0.1417 - val_accuracy: 0.9530\n",
      "Epoch 63/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0565 - accuracy: 0.9860 - val_loss: 0.1459 - val_accuracy: 0.9530\n",
      "Epoch 64/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0561 - accuracy: 0.9855 - val_loss: 0.1431 - val_accuracy: 0.9530\n",
      "Epoch 65/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0549 - accuracy: 0.9852 - val_loss: 0.1446 - val_accuracy: 0.9510\n",
      "Epoch 66/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0545 - accuracy: 0.9865 - val_loss: 0.1415 - val_accuracy: 0.9510\n",
      "Epoch 67/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0536 - accuracy: 0.9870 - val_loss: 0.1434 - val_accuracy: 0.9540\n",
      "Epoch 68/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0526 - accuracy: 0.9875 - val_loss: 0.1438 - val_accuracy: 0.9540\n",
      "Epoch 69/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0521 - accuracy: 0.9875 - val_loss: 0.1476 - val_accuracy: 0.9540\n",
      "Epoch 70/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0515 - accuracy: 0.9885 - val_loss: 0.1443 - val_accuracy: 0.9520\n",
      "Epoch 71/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0509 - accuracy: 0.9870 - val_loss: 0.1490 - val_accuracy: 0.9520\n",
      "Epoch 72/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0502 - accuracy: 0.9875 - val_loss: 0.1427 - val_accuracy: 0.9530\n",
      "Epoch 73/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0492 - accuracy: 0.9885 - val_loss: 0.1437 - val_accuracy: 0.9510\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7108022142553602\n",
      "F1 Micro: 0.9583312490620779\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 242us/step - loss: 0.7440 - accuracy: 0.7920 - val_loss: 0.3750 - val_accuracy: 0.8970\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.3191 - accuracy: 0.9147 - val_loss: 0.2961 - val_accuracy: 0.9200\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.2581 - accuracy: 0.9350 - val_loss: 0.2570 - val_accuracy: 0.9340\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.2247 - accuracy: 0.9440 - val_loss: 0.2324 - val_accuracy: 0.9380\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1989 - accuracy: 0.9475 - val_loss: 0.2195 - val_accuracy: 0.9370\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1829 - accuracy: 0.9505 - val_loss: 0.2062 - val_accuracy: 0.9360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1705 - accuracy: 0.9532 - val_loss: 0.1959 - val_accuracy: 0.9400\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1615 - accuracy: 0.9540 - val_loss: 0.1876 - val_accuracy: 0.9400\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1530 - accuracy: 0.9572 - val_loss: 0.1805 - val_accuracy: 0.9460\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1467 - accuracy: 0.9582 - val_loss: 0.1804 - val_accuracy: 0.9420\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1403 - accuracy: 0.9610 - val_loss: 0.1716 - val_accuracy: 0.9460\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1361 - accuracy: 0.9617 - val_loss: 0.1647 - val_accuracy: 0.9450\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1313 - accuracy: 0.9625 - val_loss: 0.1621 - val_accuracy: 0.9430\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1264 - accuracy: 0.9635 - val_loss: 0.1580 - val_accuracy: 0.9460\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1244 - accuracy: 0.9655 - val_loss: 0.1599 - val_accuracy: 0.9490\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1194 - accuracy: 0.9660 - val_loss: 0.1557 - val_accuracy: 0.9520\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1155 - accuracy: 0.9685 - val_loss: 0.1521 - val_accuracy: 0.9470\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1121 - accuracy: 0.9682 - val_loss: 0.1502 - val_accuracy: 0.9480\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1111 - accuracy: 0.9670 - val_loss: 0.1458 - val_accuracy: 0.9500\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1064 - accuracy: 0.9693 - val_loss: 0.1434 - val_accuracy: 0.9510\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1033 - accuracy: 0.9695 - val_loss: 0.1439 - val_accuracy: 0.9510\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1002 - accuracy: 0.9720 - val_loss: 0.1436 - val_accuracy: 0.9480\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0988 - accuracy: 0.9722 - val_loss: 0.1418 - val_accuracy: 0.9570\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0970 - accuracy: 0.9730 - val_loss: 0.1421 - val_accuracy: 0.9530\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0921 - accuracy: 0.9730 - val_loss: 0.1480 - val_accuracy: 0.9540\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0905 - accuracy: 0.9747 - val_loss: 0.1470 - val_accuracy: 0.9500\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0886 - accuracy: 0.9745 - val_loss: 0.1403 - val_accuracy: 0.9510\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0869 - accuracy: 0.9755 - val_loss: 0.1359 - val_accuracy: 0.9550\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0828 - accuracy: 0.9745 - val_loss: 0.1395 - val_accuracy: 0.9490\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0835 - accuracy: 0.9765 - val_loss: 0.1380 - val_accuracy: 0.9520\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0785 - accuracy: 0.9770 - val_loss: 0.1366 - val_accuracy: 0.9520\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0768 - accuracy: 0.9785 - val_loss: 0.1379 - val_accuracy: 0.9500\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0715 - accuracy: 0.9790 - val_loss: 0.1352 - val_accuracy: 0.9540\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0728 - accuracy: 0.9780 - val_loss: 0.1340 - val_accuracy: 0.9550\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0700 - accuracy: 0.9785 - val_loss: 0.1380 - val_accuracy: 0.9530\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0651 - accuracy: 0.9815 - val_loss: 0.1385 - val_accuracy: 0.9550\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0646 - accuracy: 0.9785 - val_loss: 0.1462 - val_accuracy: 0.9540\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0601 - accuracy: 0.9830 - val_loss: 0.1452 - val_accuracy: 0.9560\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0567 - accuracy: 0.9843 - val_loss: 0.1433 - val_accuracy: 0.9580\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0523 - accuracy: 0.9858 - val_loss: 0.1372 - val_accuracy: 0.9550\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0488 - accuracy: 0.9858 - val_loss: 0.1345 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0464 - accuracy: 0.9872 - val_loss: 0.1417 - val_accuracy: 0.9560\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0431 - accuracy: 0.9877 - val_loss: 0.1375 - val_accuracy: 0.9580\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0387 - accuracy: 0.9895 - val_loss: 0.1400 - val_accuracy: 0.9580\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0347 - accuracy: 0.9908 - val_loss: 0.1561 - val_accuracy: 0.9570\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0319 - accuracy: 0.9920 - val_loss: 0.1430 - val_accuracy: 0.9590\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0274 - accuracy: 0.9940 - val_loss: 0.1545 - val_accuracy: 0.9570\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.1673 - val_accuracy: 0.9560\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0234 - accuracy: 0.9950 - val_loss: 0.1597 - val_accuracy: 0.9560\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0212 - accuracy: 0.9950 - val_loss: 0.1528 - val_accuracy: 0.9580\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0197 - accuracy: 0.9967 - val_loss: 0.1680 - val_accuracy: 0.9580\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0190 - accuracy: 0.9962 - val_loss: 0.1918 - val_accuracy: 0.9550\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0163 - accuracy: 0.9977 - val_loss: 0.1645 - val_accuracy: 0.9570\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0147 - accuracy: 0.9983 - val_loss: 0.1578 - val_accuracy: 0.9600\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7281516517309127\n",
      "F1 Micro: 0.9623330498724426\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6796985806379284\n",
      "F1 Micro: 0.9596\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6455771951951927\n",
      "F1 Micro: 0.9618\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 4 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.4049 - accuracy: 0.9002 - val_loss: 0.1990 - val_accuracy: 0.9403\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.1780 - accuracy: 0.9472 - val_loss: 0.1596 - val_accuracy: 0.9539\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.1454 - accuracy: 0.9550 - val_loss: 0.1320 - val_accuracy: 0.9601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 0.1277 - accuracy: 0.9589 - val_loss: 0.1178 - val_accuracy: 0.9631\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 0.1163 - accuracy: 0.9629 - val_loss: 0.1381 - val_accuracy: 0.9584\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 0.1093 - accuracy: 0.9649 - val_loss: 0.1208 - val_accuracy: 0.9643\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 0.1012 - accuracy: 0.9674 - val_loss: 0.1066 - val_accuracy: 0.9658\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0969 - accuracy: 0.9694 - val_loss: 0.1057 - val_accuracy: 0.9633\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0897 - accuracy: 0.9709 - val_loss: 0.1060 - val_accuracy: 0.9666\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0883 - accuracy: 0.9708 - val_loss: 0.0991 - val_accuracy: 0.9696\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0829 - accuracy: 0.9725 - val_loss: 0.1007 - val_accuracy: 0.9671\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0793 - accuracy: 0.9736 - val_loss: 0.0929 - val_accuracy: 0.9707\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0747 - accuracy: 0.9745 - val_loss: 0.0887 - val_accuracy: 0.9718\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0707 - accuracy: 0.9762 - val_loss: 0.0896 - val_accuracy: 0.9704\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0689 - accuracy: 0.9768 - val_loss: 0.0873 - val_accuracy: 0.9710\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0640 - accuracy: 0.9791 - val_loss: 0.0910 - val_accuracy: 0.9705\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0593 - accuracy: 0.9801 - val_loss: 0.0904 - val_accuracy: 0.9691\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0553 - accuracy: 0.9811 - val_loss: 0.0863 - val_accuracy: 0.9706\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0509 - accuracy: 0.9821 - val_loss: 0.0844 - val_accuracy: 0.9749\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0472 - accuracy: 0.9833 - val_loss: 0.0872 - val_accuracy: 0.9714\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0437 - accuracy: 0.9852 - val_loss: 0.0847 - val_accuracy: 0.9741\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0386 - accuracy: 0.9869 - val_loss: 0.0859 - val_accuracy: 0.9751\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 0.1127 - val_accuracy: 0.9627\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0296 - accuracy: 0.9906 - val_loss: 0.0904 - val_accuracy: 0.9744\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.1002 - val_accuracy: 0.9725\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.1061 - val_accuracy: 0.9728\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.1087 - val_accuracy: 0.9723\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.1061 - val_accuracy: 0.9733\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.1073 - val_accuracy: 0.9713\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.1128 - val_accuracy: 0.9727\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.1147 - val_accuracy: 0.9700\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.1292 - val_accuracy: 0.9681\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.1169 - val_accuracy: 0.9732\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.1549 - val_accuracy: 0.9722\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.1332 - val_accuracy: 0.9713\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.1772 - val_accuracy: 0.9700\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.1402 - val_accuracy: 0.9714\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.1366 - val_accuracy: 0.9726\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1520 - val_accuracy: 0.9701\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7585929646054707\n",
      "F1 Micro: 0.9731\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7814891532869335\n",
      "F1 Micro: 0.9654\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.4860 - accuracy: 0.8927 - val_loss: 0.1578 - val_accuracy: 0.9542\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1457 - accuracy: 0.9576 - val_loss: 0.1280 - val_accuracy: 0.9607\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1275 - accuracy: 0.9620 - val_loss: 0.1178 - val_accuracy: 0.9635\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1184 - accuracy: 0.9635 - val_loss: 0.1126 - val_accuracy: 0.9645\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1122 - accuracy: 0.9660 - val_loss: 0.1086 - val_accuracy: 0.9654\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.1073 - accuracy: 0.9670 - val_loss: 0.1050 - val_accuracy: 0.9668\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1036 - accuracy: 0.9681 - val_loss: 0.1037 - val_accuracy: 0.9672\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1006 - accuracy: 0.9690 - val_loss: 0.1016 - val_accuracy: 0.9683\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0981 - accuracy: 0.9700 - val_loss: 0.1003 - val_accuracy: 0.9687\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0957 - accuracy: 0.9704 - val_loss: 0.0987 - val_accuracy: 0.9700\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0937 - accuracy: 0.9711 - val_loss: 0.0984 - val_accuracy: 0.9700\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0916 - accuracy: 0.9712 - val_loss: 0.0971 - val_accuracy: 0.9699\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0898 - accuracy: 0.9720 - val_loss: 0.0989 - val_accuracy: 0.9705\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0882 - accuracy: 0.9724 - val_loss: 0.0955 - val_accuracy: 0.9697\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0870 - accuracy: 0.9733 - val_loss: 0.0959 - val_accuracy: 0.9699\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0857 - accuracy: 0.9737 - val_loss: 0.0956 - val_accuracy: 0.9708\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0841 - accuracy: 0.9736 - val_loss: 0.0943 - val_accuracy: 0.9701\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0833 - accuracy: 0.9739 - val_loss: 0.0933 - val_accuracy: 0.9699\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0819 - accuracy: 0.9746 - val_loss: 0.0945 - val_accuracy: 0.9705\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0807 - accuracy: 0.9750 - val_loss: 0.0944 - val_accuracy: 0.9707\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0795 - accuracy: 0.9750 - val_loss: 0.0916 - val_accuracy: 0.9709\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0784 - accuracy: 0.9756 - val_loss: 0.0913 - val_accuracy: 0.9717\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0777 - accuracy: 0.9758 - val_loss: 0.0911 - val_accuracy: 0.9710\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0768 - accuracy: 0.9764 - val_loss: 0.0920 - val_accuracy: 0.9718\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0755 - accuracy: 0.9768 - val_loss: 0.0929 - val_accuracy: 0.9716\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0746 - accuracy: 0.9771 - val_loss: 0.0908 - val_accuracy: 0.9715\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0738 - accuracy: 0.9774 - val_loss: 0.0925 - val_accuracy: 0.9706\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0729 - accuracy: 0.9772 - val_loss: 0.0905 - val_accuracy: 0.9720\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0721 - accuracy: 0.9777 - val_loss: 0.0907 - val_accuracy: 0.9709\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0715 - accuracy: 0.9779 - val_loss: 0.0915 - val_accuracy: 0.9717\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0703 - accuracy: 0.9777 - val_loss: 0.0912 - val_accuracy: 0.9716\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0697 - accuracy: 0.9783 - val_loss: 0.0921 - val_accuracy: 0.9714\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0690 - accuracy: 0.9784 - val_loss: 0.0894 - val_accuracy: 0.9708\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0682 - accuracy: 0.9791 - val_loss: 0.0923 - val_accuracy: 0.9701\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0675 - accuracy: 0.9790 - val_loss: 0.0917 - val_accuracy: 0.9708\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0664 - accuracy: 0.9793 - val_loss: 0.0892 - val_accuracy: 0.9708\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0660 - accuracy: 0.9794 - val_loss: 0.0894 - val_accuracy: 0.9723\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0652 - accuracy: 0.9800 - val_loss: 0.0903 - val_accuracy: 0.9718\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0646 - accuracy: 0.9801 - val_loss: 0.0895 - val_accuracy: 0.9722\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0638 - accuracy: 0.9803 - val_loss: 0.0897 - val_accuracy: 0.9713\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0631 - accuracy: 0.9803 - val_loss: 0.0927 - val_accuracy: 0.9697\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0624 - accuracy: 0.9804 - val_loss: 0.0914 - val_accuracy: 0.9707\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0616 - accuracy: 0.9807 - val_loss: 0.0915 - val_accuracy: 0.9713\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0612 - accuracy: 0.9808 - val_loss: 0.0898 - val_accuracy: 0.9719\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0601 - accuracy: 0.9815 - val_loss: 0.0916 - val_accuracy: 0.9712\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0595 - accuracy: 0.9815 - val_loss: 0.0911 - val_accuracy: 0.9713\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0591 - accuracy: 0.9815 - val_loss: 0.0900 - val_accuracy: 0.9710\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0584 - accuracy: 0.9819 - val_loss: 0.0908 - val_accuracy: 0.9712\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0577 - accuracy: 0.9820 - val_loss: 0.0922 - val_accuracy: 0.97140\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0571 - accuracy: 0.9823 - val_loss: 0.0910 - val_accuracy: 0.9706\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0565 - accuracy: 0.9827 - val_loss: 0.0918 - val_accuracy: 0.9714\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0559 - accuracy: 0.9823 - val_loss: 0.0911 - val_accuracy: 0.9704\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0554 - accuracy: 0.9826 - val_loss: 0.0900 - val_accuracy: 0.9707\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0548 - accuracy: 0.9826 - val_loss: 0.0930 - val_accuracy: 0.9717\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0541 - accuracy: 0.9832 - val_loss: 0.0926 - val_accuracy: 0.9708\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0533 - accuracy: 0.9839 - val_loss: 0.0910 - val_accuracy: 0.9713\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8142660065490637\n",
      "F1 Micro: 0.9707\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.2432 - accuracy: 0.9329 - val_loss: 0.1453 - val_accuracy: 0.9545\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.1394 - accuracy: 0.9575 - val_loss: 0.1210 - val_accuracy: 0.9614\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.1207 - accuracy: 0.9628 - val_loss: 0.1094 - val_accuracy: 0.9651\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.1106 - accuracy: 0.9662 - val_loss: 0.1081 - val_accuracy: 0.9665\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.1050 - accuracy: 0.9679 - val_loss: 0.1001 - val_accuracy: 0.9669\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.1001 - accuracy: 0.9693 - val_loss: 0.0990 - val_accuracy: 0.9697\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0959 - accuracy: 0.9697 - val_loss: 0.0939 - val_accuracy: 0.9696\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0930 - accuracy: 0.9710 - val_loss: 0.0956 - val_accuracy: 0.9698\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0896 - accuracy: 0.9718 - val_loss: 0.0922 - val_accuracy: 0.9711\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0856 - accuracy: 0.9736 - val_loss: 0.1045 - val_accuracy: 0.9673\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0814 - accuracy: 0.9742 - val_loss: 0.0889 - val_accuracy: 0.9714\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0773 - accuracy: 0.9750 - val_loss: 0.0860 - val_accuracy: 0.9737\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0733 - accuracy: 0.9767 - val_loss: 0.0855 - val_accuracy: 0.9733\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0684 - accuracy: 0.9783 - val_loss: 0.0844 - val_accuracy: 0.9731\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0622 - accuracy: 0.9806 - val_loss: 0.0828 - val_accuracy: 0.9738\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0562 - accuracy: 0.9827 - val_loss: 0.0843 - val_accuracy: 0.9744\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0504 - accuracy: 0.9845 - val_loss: 0.0919 - val_accuracy: 0.9730\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.0935 - val_accuracy: 0.9712\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0370 - accuracy: 0.9890 - val_loss: 0.0981 - val_accuracy: 0.9720\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0298 - accuracy: 0.9909 - val_loss: 0.1109 - val_accuracy: 0.9728\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.1062 - val_accuracy: 0.9720\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0208 - accuracy: 0.9943 - val_loss: 0.1135 - val_accuracy: 0.9729\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.1120 - val_accuracy: 0.9743\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0149 - accuracy: 0.9965 - val_loss: 0.1255 - val_accuracy: 0.9728\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0117 - accuracy: 0.9973 - val_loss: 0.1259 - val_accuracy: 0.9723\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.1275 - val_accuracy: 0.9737\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.1363 - val_accuracy: 0.9737\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.1365 - val_accuracy: 0.9723\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.1392 - val_accuracy: 0.9720\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.1803 - val_accuracy: 0.9722\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.1842 - val_accuracy: 0.9696\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1473 - val_accuracy: 0.9723\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.1556 - val_accuracy: 0.9719\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.1518 - val_accuracy: 0.9745\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.1635 - val_accuracy: 0.9722\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.816659533059567\n",
      "F1 Micro: 0.9727\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.80402458904284\n",
      "F1 Micro: 0.9667\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8366265661778987\n",
      "F1 Micro: 0.9768\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 4 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.2426 - accuracy: 0.9345 - val_loss: 0.1403 - val_accuracy: 0.9566\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.1168 - accuracy: 0.9634 - val_loss: 0.1120 - val_accuracy: 0.9640\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0990 - accuracy: 0.9679 - val_loss: 0.0997 - val_accuracy: 0.9670\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0891 - accuracy: 0.9707 - val_loss: 0.0872 - val_accuracy: 0.9712\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0806 - accuracy: 0.9733 - val_loss: 0.0868 - val_accuracy: 0.9711\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0727 - accuracy: 0.9755 - val_loss: 0.0763 - val_accuracy: 0.9747\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0661 - accuracy: 0.9773 - val_loss: 0.0820 - val_accuracy: 0.9728\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0613 - accuracy: 0.9788 - val_loss: 0.0774 - val_accuracy: 0.9736\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0565 - accuracy: 0.9805 - val_loss: 0.0706 - val_accuracy: 0.9764\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0523 - accuracy: 0.9817 - val_loss: 0.0697 - val_accuracy: 0.9773\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0485 - accuracy: 0.9830 - val_loss: 0.0860 - val_accuracy: 0.9703\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0446 - accuracy: 0.9841 - val_loss: 0.0732 - val_accuracy: 0.9778\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0404 - accuracy: 0.9852 - val_loss: 0.0720 - val_accuracy: 0.9767\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0368 - accuracy: 0.9867 - val_loss: 0.0714 - val_accuracy: 0.9774\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0325 - accuracy: 0.9881 - val_loss: 0.0773 - val_accuracy: 0.9775\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0284 - accuracy: 0.9897 - val_loss: 0.0781 - val_accuracy: 0.9769\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 0.0789 - val_accuracy: 0.9766\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.0936 - val_accuracy: 0.9751\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0170 - accuracy: 0.9941 - val_loss: 0.0968 - val_accuracy: 0.9739\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.0966 - val_accuracy: 0.9767\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.0988 - val_accuracy: 0.9753\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.1037 - val_accuracy: 0.9747\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 181us/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.1116 - val_accuracy: 0.9770\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.1172 - val_accuracy: 0.9771\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.1221 - val_accuracy: 0.9770\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.1170 - val_accuracy: 0.9746\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.1318 - val_accuracy: 0.9731\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.1390 - val_accuracy: 0.9757\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.1336 - val_accuracy: 0.9756\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.1562 - val_accuracy: 0.9751\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8746248072676533\n",
      "F1 Micro: 0.9783\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8326392260571116\n",
      "F1 Micro: 0.9703\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.2479 - accuracy: 0.9372 - val_loss: 0.1254 - val_accuracy: 0.9618\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.1121 - accuracy: 0.9653 - val_loss: 0.1142 - val_accuracy: 0.9641\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.1024 - accuracy: 0.9681 - val_loss: 0.1078 - val_accuracy: 0.9665\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0970 - accuracy: 0.9696 - val_loss: 0.1047 - val_accuracy: 0.9673\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 65us/step - loss: 0.0932 - accuracy: 0.9705 - val_loss: 0.1007 - val_accuracy: 0.9683\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0903 - accuracy: 0.9711 - val_loss: 0.0986 - val_accuracy: 0.9687\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0877 - accuracy: 0.9717 - val_loss: 0.0968 - val_accuracy: 0.9698\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0856 - accuracy: 0.9728 - val_loss: 0.0966 - val_accuracy: 0.9695\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0840 - accuracy: 0.9734 - val_loss: 0.0934 - val_accuracy: 0.9706\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0822 - accuracy: 0.9737 - val_loss: 0.0927 - val_accuracy: 0.9705\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0810 - accuracy: 0.9741 - val_loss: 0.0922 - val_accuracy: 0.9712\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0796 - accuracy: 0.9743 - val_loss: 0.0906 - val_accuracy: 0.9715\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0781 - accuracy: 0.9751 - val_loss: 0.0903 - val_accuracy: 0.9718\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0771 - accuracy: 0.9750 - val_loss: 0.0893 - val_accuracy: 0.9722\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0761 - accuracy: 0.9755 - val_loss: 0.0901 - val_accuracy: 0.9720\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0751 - accuracy: 0.9759 - val_loss: 0.0897 - val_accuracy: 0.9716\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0741 - accuracy: 0.9761 - val_loss: 0.0892 - val_accuracy: 0.9717\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0731 - accuracy: 0.9763 - val_loss: 0.0895 - val_accuracy: 0.9725\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0723 - accuracy: 0.9765 - val_loss: 0.0878 - val_accuracy: 0.9725\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0714 - accuracy: 0.9769 - val_loss: 0.0886 - val_accuracy: 0.9720\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0705 - accuracy: 0.9771 - val_loss: 0.0873 - val_accuracy: 0.9726\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0698 - accuracy: 0.9772 - val_loss: 0.0861 - val_accuracy: 0.97220699 - accuracy\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0692 - accuracy: 0.9774 - val_loss: 0.0868 - val_accuracy: 0.9733\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0686 - accuracy: 0.9780 - val_loss: 0.0869 - val_accuracy: 0.9725\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0676 - accuracy: 0.9779 - val_loss: 0.0852 - val_accuracy: 0.9725\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0669 - accuracy: 0.9783 - val_loss: 0.0855 - val_accuracy: 0.9729\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0664 - accuracy: 0.9784 - val_loss: 0.0848 - val_accuracy: 0.9733\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0655 - accuracy: 0.9787 - val_loss: 0.0859 - val_accuracy: 0.9727\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0648 - accuracy: 0.9788 - val_loss: 0.0844 - val_accuracy: 0.9735s - loss: 0.0642 - accuracy\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0643 - accuracy: 0.9791 - val_loss: 0.0854 - val_accuracy: 0.9730\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0636 - accuracy: 0.9790 - val_loss: 0.0848 - val_accuracy: 0.9732\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0631 - accuracy: 0.9794 - val_loss: 0.0854 - val_accuracy: 0.9731\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0623 - accuracy: 0.9795 - val_loss: 0.0851 - val_accuracy: 0.9724\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0618 - accuracy: 0.9798 - val_loss: 0.0861 - val_accuracy: 0.9723\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0612 - accuracy: 0.9800 - val_loss: 0.0850 - val_accuracy: 0.9729\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0606 - accuracy: 0.9800 - val_loss: 0.0855 - val_accuracy: 0.9733\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0602 - accuracy: 0.9802 - val_loss: 0.0844 - val_accuracy: 0.9734\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0593 - accuracy: 0.9804 - val_loss: 0.0866 - val_accuracy: 0.9731059\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0587 - accuracy: 0.9808 - val_loss: 0.0851 - val_accuracy: 0.9727\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0585 - accuracy: 0.9806 - val_loss: 0.0851 - val_accuracy: 0.9731\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0576 - accuracy: 0.9810 - val_loss: 0.0866 - val_accuracy: 0.9730\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0572 - accuracy: 0.9814 - val_loss: 0.0851 - val_accuracy: 0.9734\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0565 - accuracy: 0.9814 - val_loss: 0.0847 - val_accuracy: 0.9744\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0560 - accuracy: 0.9817 - val_loss: 0.0866 - val_accuracy: 0.9739\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0555 - accuracy: 0.9816 - val_loss: 0.0849 - val_accuracy: 0.9735.055\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0549 - accuracy: 0.9819 - val_loss: 0.0858 - val_accuracy: 0.9731\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0543 - accuracy: 0.9823 - val_loss: 0.0866 - val_accuracy: 0.9734\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0538 - accuracy: 0.9822 - val_loss: 0.0870 - val_accuracy: 0.9733\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0534 - accuracy: 0.9827 - val_loss: 0.0854 - val_accuracy: 0.9737\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0527 - accuracy: 0.9826 - val_loss: 0.0867 - val_accuracy: 0.9733\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0522 - accuracy: 0.9825 - val_loss: 0.0861 - val_accuracy: 0.9731\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0517 - accuracy: 0.9830 - val_loss: 0.0867 - val_accuracy: 0.9728\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0512 - accuracy: 0.9833 - val_loss: 0.0877 - val_accuracy: 0.9726\n",
      "Epoch 54/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0506 - accuracy: 0.9834 - val_loss: 0.0865 - val_accuracy: 0.9734\n",
      "Epoch 55/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0502 - accuracy: 0.9836 - val_loss: 0.0877 - val_accuracy: 0.9733\n",
      "Epoch 56/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0498 - accuracy: 0.9839 - val_loss: 0.0870 - val_accuracy: 0.9734\n",
      "Epoch 57/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0491 - accuracy: 0.9840 - val_loss: 0.0874 - val_accuracy: 0.9732\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8786632345077507\n",
      "F1 Micro: 0.9764\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.1715 - accuracy: 0.9502 - val_loss: 0.1252 - val_accuracy: 0.9609\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.1074 - accuracy: 0.9660 - val_loss: 0.1050 - val_accuracy: 0.9672\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0951 - accuracy: 0.9696 - val_loss: 0.0953 - val_accuracy: 0.9689\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0852 - accuracy: 0.9726 - val_loss: 0.0863 - val_accuracy: 0.9719\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0777 - accuracy: 0.9746 - val_loss: 0.0823 - val_accuracy: 0.9730\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0720 - accuracy: 0.9761 - val_loss: 0.0780 - val_accuracy: 0.9745\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0667 - accuracy: 0.9777 - val_loss: 0.0795 - val_accuracy: 0.9734\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0612 - accuracy: 0.9796 - val_loss: 0.0737 - val_accuracy: 0.9750\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0550 - accuracy: 0.9814 - val_loss: 0.0722 - val_accuracy: 0.9762\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0494 - accuracy: 0.9831 - val_loss: 0.0754 - val_accuracy: 0.9752\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0437 - accuracy: 0.9850 - val_loss: 0.0709 - val_accuracy: 0.9768\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0381 - accuracy: 0.9869 - val_loss: 0.0748 - val_accuracy: 0.9769- l\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0321 - accuracy: 0.9888 - val_loss: 0.0784 - val_accuracy: 0.9749\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.0786 - val_accuracy: 0.9764\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0206 - accuracy: 0.9930 - val_loss: 0.0862 - val_accuracy: 0.9770\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0953 - val_accuracy: 0.9777\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0999 - val_accuracy: 0.9763\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.1105 - val_accuracy: 0.9766\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.1140 - val_accuracy: 0.9743\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1373 - val_accuracy: 0.9750\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.1456 - val_accuracy: 0.9743\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.1230 - val_accuracy: 0.9767\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1229 - val_accuracy: 0.9746\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1191 - val_accuracy: 0.9770\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1553 - val_accuracy: 0.9754\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1260 - val_accuracy: 0.9764\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1417 - val_accuracy: 0.9758\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.1382 - val_accuracy: 0.9759\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1407 - val_accuracy: 0.9766\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1380 - val_accuracy: 0.9756\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1512 - val_accuracy: 0.9761\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8871324538293303\n",
      "F1 Micro: 0.9789\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8221593354148993\n",
      "F1 Micro: 0.9697\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8964155223143003\n",
      "F1 Micro: 0.9806\n",
      "\n",
      "\n",
      " 52.17873209317525 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 5 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 5 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 2, 3, 4, 6, 7, 8]\n",
      "label_list [0, 2, 3, 4, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 1.9166 - accuracy: 0.7700 - val_loss: 1.3882 - val_accuracy: 0.8900\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 1.0558 - accuracy: 0.8425 - val_loss: 0.6405 - val_accuracy: 0.8900\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.8306 - accuracy: 0.8425 - val_loss: 0.5999 - val_accuracy: 0.8900\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.7614 - accuracy: 0.8425 - val_loss: 0.6036 - val_accuracy: 0.8900\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.7282 - accuracy: 0.8425 - val_loss: 0.5663 - val_accuracy: 0.8900\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7091 - accuracy: 0.8425 - val_loss: 0.5564 - val_accuracy: 0.8900\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6903 - accuracy: 0.8425 - val_loss: 0.5378 - val_accuracy: 0.8900\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6784 - accuracy: 0.8425 - val_loss: 0.5392 - val_accuracy: 0.8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6754 - accuracy: 0.8425 - val_loss: 0.5276 - val_accuracy: 0.8900\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.6706 - accuracy: 0.8425 - val_loss: 0.5143 - val_accuracy: 0.8900\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6615 - accuracy: 0.8425 - val_loss: 0.5366 - val_accuracy: 0.8900\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6620 - accuracy: 0.8425 - val_loss: 0.5143 - val_accuracy: 0.8900\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6538 - accuracy: 0.8425 - val_loss: 0.5129 - val_accuracy: 0.8900\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6528 - accuracy: 0.8425 - val_loss: 0.5053 - val_accuracy: 0.8900\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6458 - accuracy: 0.8425 - val_loss: 0.5059 - val_accuracy: 0.8900\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6450 - accuracy: 0.8425 - val_loss: 0.5013 - val_accuracy: 0.8900\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.6450 - accuracy: 0.8425 - val_loss: 0.4937 - val_accuracy: 0.8900\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 170us/step - loss: 0.6439 - accuracy: 0.8425 - val_loss: 0.5010 - val_accuracy: 0.8900\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6282 - accuracy: 0.8425 - val_loss: 0.4952 - val_accuracy: 0.8900\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6150 - accuracy: 0.8425 - val_loss: 0.4835 - val_accuracy: 0.8900\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6077 - accuracy: 0.8425 - val_loss: 0.4843 - val_accuracy: 0.8900\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6034 - accuracy: 0.8425 - val_loss: 0.4891 - val_accuracy: 0.8900\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5869 - accuracy: 0.8425 - val_loss: 0.4488 - val_accuracy: 0.8900\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5706 - accuracy: 0.8425 - val_loss: 0.4432 - val_accuracy: 0.8900\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5541 - accuracy: 0.8450 - val_loss: 0.4843 - val_accuracy: 0.9200\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5534 - accuracy: 0.8425 - val_loss: 0.4718 - val_accuracy: 0.9200\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5292 - accuracy: 0.8475 - val_loss: 0.4112 - val_accuracy: 0.9100\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5161 - accuracy: 0.8625 - val_loss: 0.3870 - val_accuracy: 0.8900\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 193us/step - loss: 0.5176 - accuracy: 0.8600 - val_loss: 0.3797 - val_accuracy: 0.9100\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4792 - accuracy: 0.8600 - val_loss: 0.3639 - val_accuracy: 0.9100\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4818 - accuracy: 0.8750 - val_loss: 0.3587 - val_accuracy: 0.9200\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4424 - accuracy: 0.8850 - val_loss: 0.3473 - val_accuracy: 0.9200\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4231 - accuracy: 0.8975 - val_loss: 0.3428 - val_accuracy: 0.9200\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4464 - accuracy: 0.8875 - val_loss: 0.3833 - val_accuracy: 0.9200\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4380 - accuracy: 0.8800 - val_loss: 0.3599 - val_accuracy: 0.9200\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4014 - accuracy: 0.9000 - val_loss: 0.3276 - val_accuracy: 0.9200\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3843 - accuracy: 0.8975 - val_loss: 0.3129 - val_accuracy: 0.9200\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3690 - accuracy: 0.9025 - val_loss: 0.2977 - val_accuracy: 0.9200\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3507 - accuracy: 0.9050 - val_loss: 0.2946 - val_accuracy: 0.9200\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3449 - accuracy: 0.8950 - val_loss: 0.2911 - val_accuracy: 0.9200\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.3376 - accuracy: 0.8975 - val_loss: 0.2872 - val_accuracy: 0.9200\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3598 - accuracy: 0.9025 - val_loss: 0.2982 - val_accuracy: 0.9400\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3190 - accuracy: 0.9150 - val_loss: 0.2696 - val_accuracy: 0.9200\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3147 - accuracy: 0.9075 - val_loss: 0.2900 - val_accuracy: 0.9200\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3574 - accuracy: 0.9000 - val_loss: 0.3850 - val_accuracy: 0.9200\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4142 - accuracy: 0.8900 - val_loss: 0.2778 - val_accuracy: 0.9200\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3223 - accuracy: 0.9100 - val_loss: 0.2777 - val_accuracy: 0.9300\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2931 - accuracy: 0.9150 - val_loss: 0.2904 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2974 - accuracy: 0.9125 - val_loss: 0.2757 - val_accuracy: 0.9500\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2975 - accuracy: 0.9175 - val_loss: 0.2943 - val_accuracy: 0.9500\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2802 - accuracy: 0.9275 - val_loss: 0.2525 - val_accuracy: 0.9500\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2550 - accuracy: 0.9300 - val_loss: 0.2430 - val_accuracy: 0.9500\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.2475 - accuracy: 0.9325 - val_loss: 0.2516 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 158us/step - loss: 0.2357 - accuracy: 0.9275 - val_loss: 0.2314 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2414 - accuracy: 0.9325 - val_loss: 0.2361 - val_accuracy: 0.9600\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2235 - accuracy: 0.9275 - val_loss: 0.2318 - val_accuracy: 0.9600\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2188 - accuracy: 0.9300 - val_loss: 0.2340 - val_accuracy: 0.9500\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2149 - accuracy: 0.9375 - val_loss: 0.2444 - val_accuracy: 0.9500\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2300 - accuracy: 0.9275 - val_loss: 0.2446 - val_accuracy: 0.9500\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2192 - accuracy: 0.9425 - val_loss: 0.2320 - val_accuracy: 0.9500\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1983 - accuracy: 0.9350 - val_loss: 0.2261 - val_accuracy: 0.9500\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1891 - accuracy: 0.9350 - val_loss: 0.2286 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1884 - accuracy: 0.9450 - val_loss: 0.2411 - val_accuracy: 0.9500\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2008 - accuracy: 0.9375 - val_loss: 0.2390 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2187 - accuracy: 0.9350 - val_loss: 0.2274 - val_accuracy: 0.9600\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1754 - accuracy: 0.9450 - val_loss: 0.2307 - val_accuracy: 0.9500\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.1802 - accuracy: 0.9475 - val_loss: 0.2169 - val_accuracy: 0.9600\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2031 - accuracy: 0.9425 - val_loss: 0.2514 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1802 - accuracy: 0.9450 - val_loss: 0.2402 - val_accuracy: 0.9500\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1689 - accuracy: 0.9450 - val_loss: 0.2444 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1769 - accuracy: 0.9475 - val_loss: 0.2127 - val_accuracy: 0.9600\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1526 - accuracy: 0.9475 - val_loss: 0.2333 - val_accuracy: 0.9500\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1427 - accuracy: 0.9525 - val_loss: 0.2154 - val_accuracy: 0.9500\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1463 - accuracy: 0.9650 - val_loss: 0.2166 - val_accuracy: 0.9500\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1420 - accuracy: 0.9575 - val_loss: 0.2129 - val_accuracy: 0.9600\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1257 - accuracy: 0.9700 - val_loss: 0.2512 - val_accuracy: 0.9500\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1406 - accuracy: 0.9600 - val_loss: 0.2367 - val_accuracy: 0.9500\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1274 - accuracy: 0.9675 - val_loss: 0.2236 - val_accuracy: 0.9500\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1213 - accuracy: 0.9675 - val_loss: 0.2228 - val_accuracy: 0.9600\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 160us/step - loss: 0.1224 - accuracy: 0.9675 - val_loss: 0.2503 - val_accuracy: 0.9500\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1142 - accuracy: 0.9675 - val_loss: 0.2278 - val_accuracy: 0.9500\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1307 - accuracy: 0.9600 - val_loss: 0.3197 - val_accuracy: 0.9400\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2391 - accuracy: 0.9425 - val_loss: 0.2394 - val_accuracy: 0.9500\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1923 - accuracy: 0.9425 - val_loss: 0.2122 - val_accuracy: 0.9500\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1244 - accuracy: 0.9625 - val_loss: 0.2301 - val_accuracy: 0.9500\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1221 - accuracy: 0.9650 - val_loss: 0.2233 - val_accuracy: 0.9600\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1261 - accuracy: 0.9675 - val_loss: 0.2244 - val_accuracy: 0.9500\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1047 - accuracy: 0.9725 - val_loss: 0.2188 - val_accuracy: 0.9600\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0957 - accuracy: 0.9750 - val_loss: 0.2212 - val_accuracy: 0.9500\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0916 - accuracy: 0.9775 - val_loss: 0.2270 - val_accuracy: 0.9500\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0969 - accuracy: 0.9800 - val_loss: 0.2520 - val_accuracy: 0.9500\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1055 - accuracy: 0.9650 - val_loss: 0.2444 - val_accuracy: 0.9500\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0887 - accuracy: 0.9800 - val_loss: 0.2319 - val_accuracy: 0.9500\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0904 - accuracy: 0.9775 - val_loss: 0.2411 - val_accuracy: 0.9500\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0787 - accuracy: 0.9850 - val_loss: 0.2495 - val_accuracy: 0.9500\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0812 - accuracy: 0.9775 - val_loss: 0.2370 - val_accuracy: 0.9500\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0741 - accuracy: 0.9850 - val_loss: 0.2450 - val_accuracy: 0.9500\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0702 - accuracy: 0.9850 - val_loss: 0.2274 - val_accuracy: 0.9500\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0671 - accuracy: 0.9850 - val_loss: 0.2250 - val_accuracy: 0.9600\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0694 - accuracy: 0.9875 - val_loss: 0.2435 - val_accuracy: 0.9500\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0621 - accuracy: 0.9900 - val_loss: 0.2324 - val_accuracy: 0.9600\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0597 - accuracy: 0.9850 - val_loss: 0.2338 - val_accuracy: 0.9500\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0583 - accuracy: 0.9875 - val_loss: 0.2325 - val_accuracy: 0.9600\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 179us/step - loss: 0.0561 - accuracy: 0.9900 - val_loss: 0.2381 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5352202740657294\n",
      "F1 Micro: 0.9319208755899187\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5587420457611552\n",
      "F1 Micro: 0.9390501054322723\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 240us/step - loss: 2.1388 - accuracy: 0.1475 - val_loss: 2.0475 - val_accuracy: 0.2000\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.9021 - accuracy: 0.4325 - val_loss: 1.8540 - val_accuracy: 0.5000\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.7223 - accuracy: 0.5875 - val_loss: 1.7147 - val_accuracy: 0.5900\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.6002 - accuracy: 0.6200 - val_loss: 1.6177 - val_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.5162 - accuracy: 0.6525 - val_loss: 1.5387 - val_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.4465 - accuracy: 0.6775 - val_loss: 1.4722 - val_accuracy: 0.6200\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.3834 - accuracy: 0.6925 - val_loss: 1.4091 - val_accuracy: 0.6200\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.3204 - accuracy: 0.7125 - val_loss: 1.3492 - val_accuracy: 0.6400\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.2586 - accuracy: 0.7225 - val_loss: 1.2900 - val_accuracy: 0.6900\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1961 - accuracy: 0.7500 - val_loss: 1.2339 - val_accuracy: 0.7200\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1359 - accuracy: 0.7775 - val_loss: 1.1795 - val_accuracy: 0.7600\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0767 - accuracy: 0.8075 - val_loss: 1.1217 - val_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0182 - accuracy: 0.8350 - val_loss: 1.0686 - val_accuracy: 0.8200\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 78us/step - loss: 0.9616 - accuracy: 0.8425 - val_loss: 1.0200 - val_accuracy: 0.8400\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.9083 - accuracy: 0.8475 - val_loss: 0.9779 - val_accuracy: 0.8600\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8533 - accuracy: 0.8600 - val_loss: 0.9301 - val_accuracy: 0.8600\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8039 - accuracy: 0.8700 - val_loss: 0.8836 - val_accuracy: 0.8700\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7560 - accuracy: 0.8850 - val_loss: 0.8433 - val_accuracy: 0.8700\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7110 - accuracy: 0.8975 - val_loss: 0.8007 - val_accuracy: 0.8700\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.6666 - accuracy: 0.9025 - val_loss: 0.7649 - val_accuracy: 0.8700\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.6260 - accuracy: 0.9050 - val_loss: 0.7303 - val_accuracy: 0.8700\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5896 - accuracy: 0.9125 - val_loss: 0.6981 - val_accuracy: 0.8700\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5521 - accuracy: 0.9175 - val_loss: 0.6633 - val_accuracy: 0.8800\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5189 - accuracy: 0.9225 - val_loss: 0.6318 - val_accuracy: 0.8800\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4878 - accuracy: 0.9225 - val_loss: 0.6040 - val_accuracy: 0.8800\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 123us/step - loss: 0.4584 - accuracy: 0.9275 - val_loss: 0.5781 - val_accuracy: 0.8900\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4319 - accuracy: 0.9275 - val_loss: 0.5524 - val_accuracy: 0.8900\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4069 - accuracy: 0.9300 - val_loss: 0.5289 - val_accuracy: 0.9000\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3835 - accuracy: 0.9350 - val_loss: 0.5064 - val_accuracy: 0.9100\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3631 - accuracy: 0.9375 - val_loss: 0.4851 - val_accuracy: 0.9100\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3435 - accuracy: 0.9400 - val_loss: 0.4678 - val_accuracy: 0.9100\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3257 - accuracy: 0.9400 - val_loss: 0.4510 - val_accuracy: 0.9300\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3100 - accuracy: 0.9400 - val_loss: 0.4353 - val_accuracy: 0.9400\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2954 - accuracy: 0.9400 - val_loss: 0.4200 - val_accuracy: 0.9500\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2820 - accuracy: 0.9425 - val_loss: 0.4067 - val_accuracy: 0.9500\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2700 - accuracy: 0.9425 - val_loss: 0.3926 - val_accuracy: 0.9500\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.2585 - accuracy: 0.9425 - val_loss: 0.3808 - val_accuracy: 0.9500\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2489 - accuracy: 0.9450 - val_loss: 0.3704 - val_accuracy: 0.9500\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2390 - accuracy: 0.9450 - val_loss: 0.3611 - val_accuracy: 0.9500\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2308 - accuracy: 0.9475 - val_loss: 0.3529 - val_accuracy: 0.9500\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.2225 - accuracy: 0.9475 - val_loss: 0.3454 - val_accuracy: 0.9500\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2152 - accuracy: 0.9475 - val_loss: 0.3366 - val_accuracy: 0.9500\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2081 - accuracy: 0.9475 - val_loss: 0.3301 - val_accuracy: 0.9600\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2013 - accuracy: 0.9500 - val_loss: 0.3230 - val_accuracy: 0.9600\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1957 - accuracy: 0.9550 - val_loss: 0.3170 - val_accuracy: 0.9600\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1900 - accuracy: 0.9550 - val_loss: 0.3107 - val_accuracy: 0.9600\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.1843 - accuracy: 0.9550 - val_loss: 0.3064 - val_accuracy: 0.9600\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1795 - accuracy: 0.9550 - val_loss: 0.3020 - val_accuracy: 0.9600\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1751 - accuracy: 0.9550 - val_loss: 0.2972 - val_accuracy: 0.9600\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.1701 - accuracy: 0.9575 - val_loss: 0.2942 - val_accuracy: 0.9600\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1658 - accuracy: 0.9575 - val_loss: 0.2903 - val_accuracy: 0.9600\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1620 - accuracy: 0.9575 - val_loss: 0.2873 - val_accuracy: 0.9600\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1579 - accuracy: 0.9600 - val_loss: 0.2836 - val_accuracy: 0.9600\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1542 - accuracy: 0.9600 - val_loss: 0.2800 - val_accuracy: 0.9600\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1512 - accuracy: 0.9650 - val_loss: 0.2761 - val_accuracy: 0.9600\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1470 - accuracy: 0.9625 - val_loss: 0.2757 - val_accuracy: 0.9600\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1440 - accuracy: 0.9675 - val_loss: 0.2742 - val_accuracy: 0.9600\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1411 - accuracy: 0.9725 - val_loss: 0.2712 - val_accuracy: 0.9600\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1379 - accuracy: 0.9725 - val_loss: 0.2685 - val_accuracy: 0.9600\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1350 - accuracy: 0.9750 - val_loss: 0.2673 - val_accuracy: 0.9600\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1322 - accuracy: 0.9750 - val_loss: 0.2651 - val_accuracy: 0.9600\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1294 - accuracy: 0.9800 - val_loss: 0.2632 - val_accuracy: 0.9600\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.1272 - accuracy: 0.9800 - val_loss: 0.2612 - val_accuracy: 0.9600\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1243 - accuracy: 0.9800 - val_loss: 0.2609 - val_accuracy: 0.9600\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1223 - accuracy: 0.9775 - val_loss: 0.2605 - val_accuracy: 0.9600\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1194 - accuracy: 0.9800 - val_loss: 0.2579 - val_accuracy: 0.9600\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1173 - accuracy: 0.9800 - val_loss: 0.2555 - val_accuracy: 0.9600\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1151 - accuracy: 0.9800 - val_loss: 0.2552 - val_accuracy: 0.9600\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1127 - accuracy: 0.9825 - val_loss: 0.2544 - val_accuracy: 0.9600\n",
      "Epoch 70/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 78us/step - loss: 0.1109 - accuracy: 0.9825 - val_loss: 0.2538 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1087 - accuracy: 0.9825 - val_loss: 0.2527 - val_accuracy: 0.9600\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.1070 - accuracy: 0.9825 - val_loss: 0.2509 - val_accuracy: 0.9600\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1052 - accuracy: 0.9825 - val_loss: 0.2508 - val_accuracy: 0.9600\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1031 - accuracy: 0.9825 - val_loss: 0.2501 - val_accuracy: 0.9500\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1014 - accuracy: 0.9825 - val_loss: 0.2497 - val_accuracy: 0.9500\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0997 - accuracy: 0.9850 - val_loss: 0.2486 - val_accuracy: 0.9600\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.0979 - accuracy: 0.9850 - val_loss: 0.2490 - val_accuracy: 0.9500\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0964 - accuracy: 0.9875 - val_loss: 0.2489 - val_accuracy: 0.9500\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0947 - accuracy: 0.9875 - val_loss: 0.2474 - val_accuracy: 0.9500\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0931 - accuracy: 0.9875 - val_loss: 0.2477 - val_accuracy: 0.9500\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0916 - accuracy: 0.9875 - val_loss: 0.2471 - val_accuracy: 0.9500\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0902 - accuracy: 0.9875 - val_loss: 0.2475 - val_accuracy: 0.9500\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0886 - accuracy: 0.9875 - val_loss: 0.2466 - val_accuracy: 0.9500\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0876 - accuracy: 0.9875 - val_loss: 0.2460 - val_accuracy: 0.9500\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0863 - accuracy: 0.9900 - val_loss: 0.2427 - val_accuracy: 0.9500\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0844 - accuracy: 0.9900 - val_loss: 0.2454 - val_accuracy: 0.9500\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0833 - accuracy: 0.9900 - val_loss: 0.2459 - val_accuracy: 0.9500\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1416 - accuracy: 0.96 - 0s 78us/step - loss: 0.0819 - accuracy: 0.9900 - val_loss: 0.2451 - val_accuracy: 0.9500\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.0809 - accuracy: 0.9900 - val_loss: 0.2436 - val_accuracy: 0.9500\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0797 - accuracy: 0.9900 - val_loss: 0.2437 - val_accuracy: 0.9500\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0787 - accuracy: 0.9925 - val_loss: 0.2455 - val_accuracy: 0.9500\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0771 - accuracy: 0.9925 - val_loss: 0.2438 - val_accuracy: 0.9500\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0759 - accuracy: 0.9925 - val_loss: 0.2437 - val_accuracy: 0.9500\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0750 - accuracy: 0.9925 - val_loss: 0.2411 - val_accuracy: 0.9500\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0740 - accuracy: 0.9900 - val_loss: 0.2436 - val_accuracy: 0.9500\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0725 - accuracy: 0.9925 - val_loss: 0.2441 - val_accuracy: 0.9500\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0716 - accuracy: 0.9925 - val_loss: 0.2436 - val_accuracy: 0.9500\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0708 - accuracy: 0.9925 - val_loss: 0.2441 - val_accuracy: 0.9500\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 1.00 - 0s 39us/step - loss: 0.0695 - accuracy: 0.9925 - val_loss: 0.2448 - val_accuracy: 0.9500\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0685 - accuracy: 0.9925 - val_loss: 0.2433 - val_accuracy: 0.9500\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0677 - accuracy: 0.9925 - val_loss: 0.2442 - val_accuracy: 0.9500\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0666 - accuracy: 0.9925 - val_loss: 0.2443 - val_accuracy: 0.9500\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0659 - accuracy: 0.9925 - val_loss: 0.2442 - val_accuracy: 0.9500\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0649 - accuracy: 0.9925 - val_loss: 0.2453 - val_accuracy: 0.9500\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0638 - accuracy: 0.9925 - val_loss: 0.2444 - val_accuracy: 0.9500\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0633 - accuracy: 0.9925 - val_loss: 0.2438 - val_accuracy: 0.9500\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0622 - accuracy: 0.9925 - val_loss: 0.2442 - val_accuracy: 0.9500\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0616 - accuracy: 0.9925 - val_loss: 0.2456 - val_accuracy: 0.9500\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 113us/step - loss: 0.0606 - accuracy: 0.9925 - val_loss: 0.2446 - val_accuracy: 0.9500\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0599 - accuracy: 0.9925 - val_loss: 0.2430 - val_accuracy: 0.9500\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0590 - accuracy: 0.9925 - val_loss: 0.2442 - val_accuracy: 0.9500\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0583 - accuracy: 0.9925 - val_loss: 0.2468 - val_accuracy: 0.9500\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0574 - accuracy: 0.9925 - val_loss: 0.2470 - val_accuracy: 0.9500\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0572 - accuracy: 0.9925 - val_loss: 0.2453 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6158907384861069\n",
      "F1 Micro: 0.9449743950195804\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 761us/step - loss: 1.9488 - accuracy: 0.4850 - val_loss: 1.6144 - val_accuracy: 0.7100\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 1.1720 - accuracy: 0.7900 - val_loss: 0.5020 - val_accuracy: 0.9000\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5491 - accuracy: 0.8475 - val_loss: 0.3811 - val_accuracy: 0.8900\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 177us/step - loss: 0.5045 - accuracy: 0.8575 - val_loss: 0.3465 - val_accuracy: 0.9100\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4451 - accuracy: 0.8725 - val_loss: 0.3367 - val_accuracy: 0.9200\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4206 - accuracy: 0.8825 - val_loss: 0.3130 - val_accuracy: 0.9200\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3966 - accuracy: 0.8850 - val_loss: 0.2985 - val_accuracy: 0.9200\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3785 - accuracy: 0.8950 - val_loss: 0.2878 - val_accuracy: 0.9200\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3627 - accuracy: 0.8950 - val_loss: 0.2799 - val_accuracy: 0.9200\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 195us/step - loss: 0.3476 - accuracy: 0.9050 - val_loss: 0.2728 - val_accuracy: 0.9300\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3376 - accuracy: 0.9075 - val_loss: 0.2583 - val_accuracy: 0.9300\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3242 - accuracy: 0.9150 - val_loss: 0.2548 - val_accuracy: 0.9400\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3117 - accuracy: 0.9175 - val_loss: 0.2467 - val_accuracy: 0.9300\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3026 - accuracy: 0.9175 - val_loss: 0.2420 - val_accuracy: 0.9300\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.2917 - accuracy: 0.9250 - val_loss: 0.2359 - val_accuracy: 0.9400\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2829 - accuracy: 0.9275 - val_loss: 0.2323 - val_accuracy: 0.9400\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2756 - accuracy: 0.9300 - val_loss: 0.2255 - val_accuracy: 0.9500\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2727 - accuracy: 0.9250 - val_loss: 0.2212 - val_accuracy: 0.9500\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2605 - accuracy: 0.9300 - val_loss: 0.2172 - val_accuracy: 0.9500\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2538 - accuracy: 0.9325 - val_loss: 0.2173 - val_accuracy: 0.9500\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2476 - accuracy: 0.9375 - val_loss: 0.2102 - val_accuracy: 0.9500\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2426 - accuracy: 0.9325 - val_loss: 0.2122 - val_accuracy: 0.9500\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2357 - accuracy: 0.9375 - val_loss: 0.2048 - val_accuracy: 0.9500\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2279 - accuracy: 0.9400 - val_loss: 0.2001 - val_accuracy: 0.9500\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2256 - accuracy: 0.9375 - val_loss: 0.2015 - val_accuracy: 0.9600\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2258 - accuracy: 0.9400 - val_loss: 0.1972 - val_accuracy: 0.9600\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2141 - accuracy: 0.9400 - val_loss: 0.1956 - val_accuracy: 0.9600\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 176us/step - loss: 0.2077 - accuracy: 0.9425 - val_loss: 0.1977 - val_accuracy: 0.9600\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2030 - accuracy: 0.9425 - val_loss: 0.1933 - val_accuracy: 0.9600\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2000 - accuracy: 0.9450 - val_loss: 0.1910 - val_accuracy: 0.9600\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1932 - accuracy: 0.9450 - val_loss: 0.1914 - val_accuracy: 0.9600\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1891 - accuracy: 0.9475 - val_loss: 0.1862 - val_accuracy: 0.9600\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1882 - accuracy: 0.9425 - val_loss: 0.1817 - val_accuracy: 0.9600\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1804 - accuracy: 0.9500 - val_loss: 0.1862 - val_accuracy: 0.9600\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1774 - accuracy: 0.9475 - val_loss: 0.1808 - val_accuracy: 0.9600\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1727 - accuracy: 0.9475 - val_loss: 0.1823 - val_accuracy: 0.9600\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1683 - accuracy: 0.9475 - val_loss: 0.1794 - val_accuracy: 0.9600\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1662 - accuracy: 0.9525 - val_loss: 0.1776 - val_accuracy: 0.9600\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1649 - accuracy: 0.9500 - val_loss: 0.1789 - val_accuracy: 0.9600\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1578 - accuracy: 0.9550 - val_loss: 0.1762 - val_accuracy: 0.9600\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 176us/step - loss: 0.1577 - accuracy: 0.9550 - val_loss: 0.1773 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1514 - accuracy: 0.9600 - val_loss: 0.1738 - val_accuracy: 0.9600\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1472 - accuracy: 0.9600 - val_loss: 0.1740 - val_accuracy: 0.9600\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1448 - accuracy: 0.9625 - val_loss: 0.1758 - val_accuracy: 0.9600\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1417 - accuracy: 0.9625 - val_loss: 0.1715 - val_accuracy: 0.9600\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1432 - accuracy: 0.9675 - val_loss: 0.1716 - val_accuracy: 0.9600\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1359 - accuracy: 0.9700 - val_loss: 0.1734 - val_accuracy: 0.9600\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1335 - accuracy: 0.9675 - val_loss: 0.1723 - val_accuracy: 0.9600\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1281 - accuracy: 0.9700 - val_loss: 0.1712 - val_accuracy: 0.9600\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1271 - accuracy: 0.9700 - val_loss: 0.1724 - val_accuracy: 0.9600\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1283 - accuracy: 0.9650 - val_loss: 0.1714 - val_accuracy: 0.9600\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1268 - accuracy: 0.9700 - val_loss: 0.1702 - val_accuracy: 0.9600\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1179 - accuracy: 0.9675 - val_loss: 0.1692 - val_accuracy: 0.9600\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1175 - accuracy: 0.9775 - val_loss: 0.1660 - val_accuracy: 0.9600\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1179 - accuracy: 0.9700 - val_loss: 0.1690 - val_accuracy: 0.9600\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1105 - accuracy: 0.9825 - val_loss: 0.1659 - val_accuracy: 0.9600\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1084 - accuracy: 0.9675 - val_loss: 0.1668 - val_accuracy: 0.9600\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1082 - accuracy: 0.9825 - val_loss: 0.1653 - val_accuracy: 0.9600\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1090 - accuracy: 0.9725 - val_loss: 0.1694 - val_accuracy: 0.9600\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0996 - accuracy: 0.9775 - val_loss: 0.1685 - val_accuracy: 0.9600\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0961 - accuracy: 0.9750 - val_loss: 0.1776 - val_accuracy: 0.9600\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1057 - accuracy: 0.9750 - val_loss: 0.1670 - val_accuracy: 0.9600\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0923 - accuracy: 0.9825 - val_loss: 0.1710 - val_accuracy: 0.9600\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0926 - accuracy: 0.9800 - val_loss: 0.1657 - val_accuracy: 0.9500\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0922 - accuracy: 0.9825 - val_loss: 0.1653 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 179us/step - loss: 0.0902 - accuracy: 0.9825 - val_loss: 0.1649 - val_accuracy: 0.9600\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0850 - accuracy: 0.9825 - val_loss: 0.1664 - val_accuracy: 0.9600\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0851 - accuracy: 0.9825 - val_loss: 0.1658 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0885 - accuracy: 0.9775 - val_loss: 0.1751 - val_accuracy: 0.9500\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0925 - accuracy: 0.9800 - val_loss: 0.1680 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0839 - accuracy: 0.9825 - val_loss: 0.1673 - val_accuracy: 0.9500\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0783 - accuracy: 0.9800 - val_loss: 0.1658 - val_accuracy: 0.9500\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0736 - accuracy: 0.9825 - val_loss: 0.1644 - val_accuracy: 0.9500\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0721 - accuracy: 0.9825 - val_loss: 0.1636 - val_accuracy: 0.9600\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0709 - accuracy: 0.9850 - val_loss: 0.1649 - val_accuracy: 0.9500\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0681 - accuracy: 0.9850 - val_loss: 0.1650 - val_accuracy: 0.9500\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0679 - accuracy: 0.9825 - val_loss: 0.1645 - val_accuracy: 0.9500\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0644 - accuracy: 0.9875 - val_loss: 0.1639 - val_accuracy: 0.9600\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 161us/step - loss: 0.0617 - accuracy: 0.9850 - val_loss: 0.1663 - val_accuracy: 0.9500\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0654 - accuracy: 0.9850 - val_loss: 0.1642 - val_accuracy: 0.9500\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0592 - accuracy: 0.9875 - val_loss: 0.1642 - val_accuracy: 0.9500\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0580 - accuracy: 0.9850 - val_loss: 0.1638 - val_accuracy: 0.9500\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0560 - accuracy: 0.9850 - val_loss: 0.1626 - val_accuracy: 0.9500\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0530 - accuracy: 0.9900 - val_loss: 0.1638 - val_accuracy: 0.9500\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0517 - accuracy: 0.9850 - val_loss: 0.1629 - val_accuracy: 0.9500\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0503 - accuracy: 0.9900 - val_loss: 0.1652 - val_accuracy: 0.9500\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0488 - accuracy: 0.9900 - val_loss: 0.1612 - val_accuracy: 0.9500\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0459 - accuracy: 0.9900 - val_loss: 0.1813 - val_accuracy: 0.9500\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0509 - accuracy: 0.9875 - val_loss: 0.1861 - val_accuracy: 0.9400\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0602 - accuracy: 0.9875 - val_loss: 0.1661 - val_accuracy: 0.9600\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0541 - accuracy: 0.9900 - val_loss: 0.1724 - val_accuracy: 0.9500\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 159us/step - loss: 0.0434 - accuracy: 0.9950 - val_loss: 0.1742 - val_accuracy: 0.9500\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0529 - accuracy: 0.9850 - val_loss: 0.1924 - val_accuracy: 0.9300\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0650 - accuracy: 0.9850 - val_loss: 0.1700 - val_accuracy: 0.9500\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0466 - accuracy: 0.9900 - val_loss: 0.1739 - val_accuracy: 0.9500\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0388 - accuracy: 0.9950 - val_loss: 0.1677 - val_accuracy: 0.9500\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0387 - accuracy: 0.9925 - val_loss: 0.1640 - val_accuracy: 0.9500\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0356 - accuracy: 0.9975 - val_loss: 0.1951 - val_accuracy: 0.9600\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0491 - accuracy: 0.9875 - val_loss: 0.1701 - val_accuracy: 0.9400\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0341 - accuracy: 0.9925 - val_loss: 0.1761 - val_accuracy: 0.9500\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0314 - accuracy: 0.9950 - val_loss: 0.1673 - val_accuracy: 0.9500\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0336 - accuracy: 0.9925 - val_loss: 0.1664 - val_accuracy: 0.9400\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0323 - accuracy: 0.9950 - val_loss: 0.1727 - val_accuracy: 0.9500\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.0301 - accuracy: 0.9975 - val_loss: 0.1860 - val_accuracy: 0.9500\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 160us/step - loss: 0.0300 - accuracy: 0.9975 - val_loss: 0.1725 - val_accuracy: 0.9400\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0314 - accuracy: 0.9975 - val_loss: 0.1786 - val_accuracy: 0.9500\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0310 - accuracy: 0.9975 - val_loss: 0.1938 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6559269440928158\n",
      "F1 Micro: 0.9450748067075008\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5777063188704338\n",
      "F1 Micro: 0.9413595742544433\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6422314082497641\n",
      "F1 Micro: 0.9445727482678984\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 5 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 231us/step - loss: 0.8453 - accuracy: 0.8520 - val_loss: 0.6305 - val_accuracy: 0.8590\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.6254 - accuracy: 0.8577 - val_loss: 0.5806 - val_accuracy: 0.8590\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.5509 - accuracy: 0.8622 - val_loss: 0.5163 - val_accuracy: 0.8590\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.4616 - accuracy: 0.8777 - val_loss: 0.4233 - val_accuracy: 0.9110\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.3736 - accuracy: 0.9040 - val_loss: 0.3431 - val_accuracy: 0.9100\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.3295 - accuracy: 0.9175 - val_loss: 0.3197 - val_accuracy: 0.9190\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.3087 - accuracy: 0.9202 - val_loss: 0.2990 - val_accuracy: 0.9250\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.2928 - accuracy: 0.9243 - val_loss: 0.2902 - val_accuracy: 0.9250\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.2762 - accuracy: 0.9258 - val_loss: 0.2650 - val_accuracy: 0.9300\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.2569 - accuracy: 0.9277 - val_loss: 0.2544 - val_accuracy: 0.9330\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.2441 - accuracy: 0.9333 - val_loss: 0.2438 - val_accuracy: 0.9350\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.2292 - accuracy: 0.9345 - val_loss: 0.2420 - val_accuracy: 0.9360\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.2068 - accuracy: 0.9402 - val_loss: 0.2001 - val_accuracy: 0.9470\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1919 - accuracy: 0.9467 - val_loss: 0.2040 - val_accuracy: 0.9490\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1795 - accuracy: 0.9485 - val_loss: 0.1861 - val_accuracy: 0.9510\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1727 - accuracy: 0.9530 - val_loss: 0.1824 - val_accuracy: 0.9490\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1507 - accuracy: 0.9540 - val_loss: 0.1717 - val_accuracy: 0.9480\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1503 - accuracy: 0.9570 - val_loss: 0.1676 - val_accuracy: 0.9490\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.1412 - accuracy: 0.9610 - val_loss: 0.1870 - val_accuracy: 0.9490\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1340 - accuracy: 0.9605 - val_loss: 0.1698 - val_accuracy: 0.9520\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1342 - accuracy: 0.9585 - val_loss: 0.1580 - val_accuracy: 0.9530\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1384 - accuracy: 0.9585 - val_loss: 0.1650 - val_accuracy: 0.9500\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1139 - accuracy: 0.9660 - val_loss: 0.1897 - val_accuracy: 0.9470\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1105 - accuracy: 0.9690 - val_loss: 0.1578 - val_accuracy: 0.9520\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1022 - accuracy: 0.9672 - val_loss: 0.1965 - val_accuracy: 0.9420\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1051 - accuracy: 0.9680 - val_loss: 0.1683 - val_accuracy: 0.9530\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0902 - accuracy: 0.9722 - val_loss: 0.1624 - val_accuracy: 0.9530\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0919 - accuracy: 0.9725 - val_loss: 0.1765 - val_accuracy: 0.9520\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0846 - accuracy: 0.9732 - val_loss: 0.1568 - val_accuracy: 0.9570\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0854 - accuracy: 0.9722 - val_loss: 0.1842 - val_accuracy: 0.9490\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0864 - accuracy: 0.9740 - val_loss: 0.1585 - val_accuracy: 0.9550\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0766 - accuracy: 0.9770 - val_loss: 0.2400 - val_accuracy: 0.9480\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0754 - accuracy: 0.9790 - val_loss: 0.1672 - val_accuracy: 0.9570\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0658 - accuracy: 0.9770 - val_loss: 0.1592 - val_accuracy: 0.9600\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0733 - accuracy: 0.9762 - val_loss: 0.1689 - val_accuracy: 0.9540\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0697 - accuracy: 0.9785 - val_loss: 0.1940 - val_accuracy: 0.9510\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0595 - accuracy: 0.9797 - val_loss: 0.1694 - val_accuracy: 0.9540\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0585 - accuracy: 0.9818 - val_loss: 0.1824 - val_accuracy: 0.9510\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0531 - accuracy: 0.9850 - val_loss: 0.1826 - val_accuracy: 0.9540\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0522 - accuracy: 0.9827 - val_loss: 0.1984 - val_accuracy: 0.9490\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0502 - accuracy: 0.9845 - val_loss: 0.1880 - val_accuracy: 0.9520\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0433 - accuracy: 0.9885 - val_loss: 0.1855 - val_accuracy: 0.9540\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0423 - accuracy: 0.9883 - val_loss: 0.1767 - val_accuracy: 0.9520\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 0.1872 - val_accuracy: 0.9560\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0443 - accuracy: 0.9862 - val_loss: 0.1839 - val_accuracy: 0.9490\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0361 - accuracy: 0.9898 - val_loss: 0.1927 - val_accuracy: 0.9470\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0445 - accuracy: 0.9872 - val_loss: 0.1854 - val_accuracy: 0.9520\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0353 - accuracy: 0.9905 - val_loss: 0.2317 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0289 - accuracy: 0.9940 - val_loss: 0.2153 - val_accuracy: 0.9530\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7094380904694497\n",
      "F1 Micro: 0.957\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7067963103827763\n",
      "F1 Micro: 0.9564\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 89us/step - loss: 1.7415 - accuracy: 0.5428 - val_loss: 1.4254 - val_accuracy: 0.6790\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 1.1726 - accuracy: 0.7495 - val_loss: 0.9049 - val_accuracy: 0.8410\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.6887 - accuracy: 0.8928 - val_loss: 0.5112 - val_accuracy: 0.9310\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.4049 - accuracy: 0.9290 - val_loss: 0.3295 - val_accuracy: 0.9420\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.2773 - accuracy: 0.9440 - val_loss: 0.2531 - val_accuracy: 0.9480\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.2171 - accuracy: 0.9520 - val_loss: 0.2181 - val_accuracy: 0.9530\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1862 - accuracy: 0.9538 - val_loss: 0.1986 - val_accuracy: 0.9530\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1680 - accuracy: 0.9567 - val_loss: 0.1871 - val_accuracy: 0.9540\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.1553 - accuracy: 0.9580 - val_loss: 0.1785 - val_accuracy: 0.9540\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.95 - 0s 74us/step - loss: 0.1457 - accuracy: 0.9600 - val_loss: 0.1730 - val_accuracy: 0.9550\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1388 - accuracy: 0.9622 - val_loss: 0.1696 - val_accuracy: 0.9570\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 63us/step - loss: 0.1322 - accuracy: 0.9610 - val_loss: 0.1646 - val_accuracy: 0.9560\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1269 - accuracy: 0.9645 - val_loss: 0.1618 - val_accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1220 - accuracy: 0.9660 - val_loss: 0.1591 - val_accuracy: 0.9580\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.1179 - accuracy: 0.9653 - val_loss: 0.1571 - val_accuracy: 0.9560\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1146 - accuracy: 0.9657 - val_loss: 0.1557 - val_accuracy: 0.9600\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1113 - accuracy: 0.9675 - val_loss: 0.1542 - val_accuracy: 0.9610\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.1082 - accuracy: 0.9693 - val_loss: 0.1536 - val_accuracy: 0.9590\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.1049 - accuracy: 0.9690 - val_loss: 0.1525 - val_accuracy: 0.9590\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1029 - accuracy: 0.9718 - val_loss: 0.1498 - val_accuracy: 0.9610\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0997 - accuracy: 0.9710 - val_loss: 0.1492 - val_accuracy: 0.9600\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0975 - accuracy: 0.9725 - val_loss: 0.1483 - val_accuracy: 0.9590\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0958 - accuracy: 0.9715 - val_loss: 0.1482 - val_accuracy: 0.9610\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0936 - accuracy: 0.9728 - val_loss: 0.1488 - val_accuracy: 0.9600\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0915 - accuracy: 0.9747 - val_loss: 0.1482 - val_accuracy: 0.9600\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0889 - accuracy: 0.9745 - val_loss: 0.1483 - val_accuracy: 0.9590\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.0879 - accuracy: 0.9755 - val_loss: 0.1462 - val_accuracy: 0.9610\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0853 - accuracy: 0.9753 - val_loss: 0.1450 - val_accuracy: 0.9620\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0845 - accuracy: 0.9762 - val_loss: 0.1453 - val_accuracy: 0.9610\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0827 - accuracy: 0.9765 - val_loss: 0.1458 - val_accuracy: 0.9610\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0808 - accuracy: 0.9768 - val_loss: 0.1457 - val_accuracy: 0.9600\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0798 - accuracy: 0.9780 - val_loss: 0.1453 - val_accuracy: 0.9600\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0783 - accuracy: 0.9795 - val_loss: 0.1437 - val_accuracy: 0.9630\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 63us/step - loss: 0.0765 - accuracy: 0.9783 - val_loss: 0.1437 - val_accuracy: 0.9610\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0761 - accuracy: 0.9790 - val_loss: 0.1441 - val_accuracy: 0.9610\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0738 - accuracy: 0.9800 - val_loss: 0.1442 - val_accuracy: 0.9610\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0726 - accuracy: 0.9785 - val_loss: 0.1444 - val_accuracy: 0.9620\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0714 - accuracy: 0.9805 - val_loss: 0.1440 - val_accuracy: 0.9570\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0698 - accuracy: 0.9805 - val_loss: 0.1476 - val_accuracy: 0.9610\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0699 - accuracy: 0.9800 - val_loss: 0.1430 - val_accuracy: 0.9610\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 59us/step - loss: 0.0679 - accuracy: 0.9810 - val_loss: 0.1427 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0668 - accuracy: 0.9812 - val_loss: 0.1434 - val_accuracy: 0.9610\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0656 - accuracy: 0.9822 - val_loss: 0.1429 - val_accuracy: 0.9590\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0644 - accuracy: 0.9830 - val_loss: 0.1466 - val_accuracy: 0.9630\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 63us/step - loss: 0.0638 - accuracy: 0.9830 - val_loss: 0.1423 - val_accuracy: 0.9600\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0625 - accuracy: 0.9845 - val_loss: 0.1424 - val_accuracy: 0.9600\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0613 - accuracy: 0.9833 - val_loss: 0.1452 - val_accuracy: 0.9600\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0606 - accuracy: 0.9837 - val_loss: 0.1447 - val_accuracy: 0.9610\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.0594 - accuracy: 0.9845 - val_loss: 0.1455 - val_accuracy: 0.9600\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.0589 - accuracy: 0.9850 - val_loss: 0.1464 - val_accuracy: 0.9610\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0578 - accuracy: 0.9850 - val_loss: 0.1439 - val_accuracy: 0.9610\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0568 - accuracy: 0.9840 - val_loss: 0.1444 - val_accuracy: 0.9570\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.0561 - accuracy: 0.9847 - val_loss: 0.1436 - val_accuracy: 0.9600\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0553 - accuracy: 0.9860 - val_loss: 0.1445 - val_accuracy: 0.9600\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0542 - accuracy: 0.9855 - val_loss: 0.1451 - val_accuracy: 0.9600\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 0s 60us/step - loss: 0.0532 - accuracy: 0.9870 - val_loss: 0.1449 - val_accuracy: 0.9610\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0525 - accuracy: 0.9862 - val_loss: 0.1477 - val_accuracy: 0.9590\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.0517 - accuracy: 0.9865 - val_loss: 0.1448 - val_accuracy: 0.9590\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0508 - accuracy: 0.9875 - val_loss: 0.1480 - val_accuracy: 0.9600\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0504 - accuracy: 0.9870 - val_loss: 0.1455 - val_accuracy: 0.9590\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0485 - accuracy: 0.9875 - val_loss: 0.1494 - val_accuracy: 0.9600\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0491 - accuracy: 0.9877 - val_loss: 0.1474 - val_accuracy: 0.9590\n",
      "Epoch 63/1000\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.0475 - accuracy: 0.9883 - val_loss: 0.1467 - val_accuracy: 0.9600\n",
      "Epoch 64/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0470 - accuracy: 0.9883 - val_loss: 0.1480 - val_accuracy: 0.9580\n",
      "Epoch 65/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.0463 - accuracy: 0.9890 - val_loss: 0.1470 - val_accuracy: 0.9580\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7377890783356315\n",
      "F1 Micro: 0.9613\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 239us/step - loss: 0.5917 - accuracy: 0.8440 - val_loss: 0.3242 - val_accuracy: 0.9110\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.2932 - accuracy: 0.9225 - val_loss: 0.2601 - val_accuracy: 0.9270\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.2408 - accuracy: 0.9360 - val_loss: 0.2274 - val_accuracy: 0.9370\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.2115 - accuracy: 0.9433 - val_loss: 0.2048 - val_accuracy: 0.9390\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1897 - accuracy: 0.9470 - val_loss: 0.1878 - val_accuracy: 0.9470\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1750 - accuracy: 0.9503 - val_loss: 0.1769 - val_accuracy: 0.9510\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1625 - accuracy: 0.9520 - val_loss: 0.1706 - val_accuracy: 0.9530\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1506 - accuracy: 0.9570 - val_loss: 0.1641 - val_accuracy: 0.9530\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.1435 - accuracy: 0.9560 - val_loss: 0.1562 - val_accuracy: 0.9550\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1369 - accuracy: 0.9607 - val_loss: 0.1552 - val_accuracy: 0.9550\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1315 - accuracy: 0.9628 - val_loss: 0.1535 - val_accuracy: 0.9570\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1230 - accuracy: 0.9638 - val_loss: 0.1486 - val_accuracy: 0.9560\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1213 - accuracy: 0.9665 - val_loss: 0.1492 - val_accuracy: 0.9590\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1151 - accuracy: 0.9672 - val_loss: 0.1589 - val_accuracy: 0.9540\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1134 - accuracy: 0.9647 - val_loss: 0.1443 - val_accuracy: 0.9590\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1083 - accuracy: 0.9693 - val_loss: 0.1424 - val_accuracy: 0.9620\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1049 - accuracy: 0.9690 - val_loss: 0.1416 - val_accuracy: 0.9580\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1000 - accuracy: 0.9712 - val_loss: 0.1452 - val_accuracy: 0.9580\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1006 - accuracy: 0.9700 - val_loss: 0.1382 - val_accuracy: 0.9610\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0951 - accuracy: 0.9725 - val_loss: 0.1349 - val_accuracy: 0.9640\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0924 - accuracy: 0.9732 - val_loss: 0.1368 - val_accuracy: 0.9610\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0883 - accuracy: 0.9753 - val_loss: 0.1405 - val_accuracy: 0.9530\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0881 - accuracy: 0.9775 - val_loss: 0.1424 - val_accuracy: 0.9620\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0823 - accuracy: 0.9768 - val_loss: 0.1360 - val_accuracy: 0.9610\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0796 - accuracy: 0.9775 - val_loss: 0.1350 - val_accuracy: 0.9610\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0793 - accuracy: 0.9775 - val_loss: 0.1390 - val_accuracy: 0.9550\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0782 - accuracy: 0.9760 - val_loss: 0.1345 - val_accuracy: 0.9630\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0762 - accuracy: 0.9787 - val_loss: 0.1601 - val_accuracy: 0.9570\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0706 - accuracy: 0.9815 - val_loss: 0.1372 - val_accuracy: 0.9640\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0653 - accuracy: 0.9822 - val_loss: 0.1357 - val_accuracy: 0.9640\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0602 - accuracy: 0.9827 - val_loss: 0.1383 - val_accuracy: 0.9570\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0557 - accuracy: 0.9840 - val_loss: 0.1465 - val_accuracy: 0.9650\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0524 - accuracy: 0.9868 - val_loss: 0.1464 - val_accuracy: 0.9620\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0465 - accuracy: 0.9875 - val_loss: 0.1383 - val_accuracy: 0.9600\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0417 - accuracy: 0.9893 - val_loss: 0.1392 - val_accuracy: 0.9600\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0372 - accuracy: 0.9905 - val_loss: 0.1662 - val_accuracy: 0.9580\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0333 - accuracy: 0.9915 - val_loss: 0.1404 - val_accuracy: 0.9590\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0292 - accuracy: 0.9937 - val_loss: 0.1657 - val_accuracy: 0.9620\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0260 - accuracy: 0.9948 - val_loss: 0.1407 - val_accuracy: 0.9590\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0236 - accuracy: 0.9952 - val_loss: 0.1589 - val_accuracy: 0.9610\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0228 - accuracy: 0.9967 - val_loss: 0.1512 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0195 - accuracy: 0.9973 - val_loss: 0.1469 - val_accuracy: 0.9580\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0189 - accuracy: 0.9960 - val_loss: 0.1609 - val_accuracy: 0.9610\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0166 - accuracy: 0.9980 - val_loss: 0.1476 - val_accuracy: 0.9590\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0142 - accuracy: 0.9983 - val_loss: 0.1548 - val_accuracy: 0.9590\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0132 - accuracy: 0.9992 - val_loss: 0.1646 - val_accuracy: 0.9580\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0116 - accuracy: 0.9995 - val_loss: 0.1780 - val_accuracy: 0.9580\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7213067650837232\n",
      "F1 Micro: 0.9594\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7080659204927435\n",
      "F1 Micro: 0.9546\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7580053796833469\n",
      "F1 Micro: 0.964\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 5 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.4248 - accuracy: 0.8973 - val_loss: 0.2029 - val_accuracy: 0.9445\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.1806 - accuracy: 0.9475 - val_loss: 0.1404 - val_accuracy: 0.9592\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.1415 - accuracy: 0.9565 - val_loss: 0.1270 - val_accuracy: 0.9595\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.1263 - accuracy: 0.9609 - val_loss: 0.1309 - val_accuracy: 0.9576\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.1140 - accuracy: 0.9635 - val_loss: 0.1119 - val_accuracy: 0.9641\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.1044 - accuracy: 0.9664 - val_loss: 0.0985 - val_accuracy: 0.9685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0983 - accuracy: 0.9680 - val_loss: 0.1072 - val_accuracy: 0.9681\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0922 - accuracy: 0.9696 - val_loss: 0.0940 - val_accuracy: 0.9704\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0872 - accuracy: 0.9708 - val_loss: 0.0966 - val_accuracy: 0.9681\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0832 - accuracy: 0.9731 - val_loss: 0.1033 - val_accuracy: 0.9651\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0784 - accuracy: 0.9736 - val_loss: 0.0903 - val_accuracy: 0.9714\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0742 - accuracy: 0.9756 - val_loss: 0.0902 - val_accuracy: 0.9698\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0707 - accuracy: 0.9757 - val_loss: 0.0913 - val_accuracy: 0.9699\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0664 - accuracy: 0.9776 - val_loss: 0.0867 - val_accuracy: 0.9707\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0643 - accuracy: 0.9781 - val_loss: 0.0860 - val_accuracy: 0.9722\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0583 - accuracy: 0.9802 - val_loss: 0.0813 - val_accuracy: 0.9726\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0568 - accuracy: 0.9804 - val_loss: 0.0839 - val_accuracy: 0.9727\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0494 - accuracy: 0.9829 - val_loss: 0.1013 - val_accuracy: 0.9694\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0488 - accuracy: 0.9837 - val_loss: 0.0875 - val_accuracy: 0.9705\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0426 - accuracy: 0.9855 - val_loss: 0.0927 - val_accuracy: 0.9707\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0390 - accuracy: 0.9866 - val_loss: 0.0905 - val_accuracy: 0.9689\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0336 - accuracy: 0.9882 - val_loss: 0.0915 - val_accuracy: 0.9718\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0311 - accuracy: 0.9893 - val_loss: 0.0891 - val_accuracy: 0.9724\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 0.0985 - val_accuracy: 0.9728\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.1100 - val_accuracy: 0.9729\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.0979 - val_accuracy: 0.9718\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.1006 - val_accuracy: 0.9726\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.1298 - val_accuracy: 0.9690\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1089 - val_accuracy: 0.9717\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.1176 - val_accuracy: 0.9697\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 0.1129 - val_accuracy: 0.9730\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.1198 - val_accuracy: 0.9669\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.1174 - val_accuracy: 0.9728\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.1231 - val_accuracy: 0.9709\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.1350 - val_accuracy: 0.9708\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.1396 - val_accuracy: 0.9693\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8545805455980617\n",
      "F1 Micro: 0.9748\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7995027553452019\n",
      "F1 Micro: 0.9662\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.5367 - accuracy: 0.8770 - val_loss: 0.1578 - val_accuracy: 0.9554\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.1434 - accuracy: 0.9575 - val_loss: 0.1311 - val_accuracy: 0.9604\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.1249 - accuracy: 0.9621 - val_loss: 0.1205 - val_accuracy: 0.9637\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1158 - accuracy: 0.9651 - val_loss: 0.1163 - val_accuracy: 0.9665\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1095 - accuracy: 0.9660 - val_loss: 0.1125 - val_accuracy: 0.9658\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1054 - accuracy: 0.9675 - val_loss: 0.1084 - val_accuracy: 0.9676\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1019 - accuracy: 0.9683 - val_loss: 0.1053 - val_accuracy: 0.9680\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0989 - accuracy: 0.9694 - val_loss: 0.1044 - val_accuracy: 0.9682\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0967 - accuracy: 0.9700 - val_loss: 0.1026 - val_accuracy: 0.9689\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0946 - accuracy: 0.9701 - val_loss: 0.1006 - val_accuracy: 0.9698\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0928 - accuracy: 0.9707 - val_loss: 0.0994 - val_accuracy: 0.9704\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0910 - accuracy: 0.9714 - val_loss: 0.0997 - val_accuracy: 0.9699\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0895 - accuracy: 0.9718 - val_loss: 0.0996 - val_accuracy: 0.9691\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0879 - accuracy: 0.9722 - val_loss: 0.0972 - val_accuracy: 0.9699\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0864 - accuracy: 0.9728 - val_loss: 0.0970 - val_accuracy: 0.9699\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0851 - accuracy: 0.9729 - val_loss: 0.0958 - val_accuracy: 0.9699\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0837 - accuracy: 0.9736 - val_loss: 0.0975 - val_accuracy: 0.9698\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0827 - accuracy: 0.9741 - val_loss: 0.0958 - val_accuracy: 0.9696\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0817 - accuracy: 0.9743 - val_loss: 0.0941 - val_accuracy: 0.9707\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0803 - accuracy: 0.9748 - val_loss: 0.0952 - val_accuracy: 0.9704\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0793 - accuracy: 0.9752 - val_loss: 0.0949 - val_accuracy: 0.9705\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0786 - accuracy: 0.9753 - val_loss: 0.0937 - val_accuracy: 0.9704\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0776 - accuracy: 0.9755 - val_loss: 0.0938 - val_accuracy: 0.9711\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0765 - accuracy: 0.9757 - val_loss: 0.0925 - val_accuracy: 0.9709\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0753 - accuracy: 0.9759 - val_loss: 0.0936 - val_accuracy: 0.9715\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0746 - accuracy: 0.9768 - val_loss: 0.0915 - val_accuracy: 0.9706\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0737 - accuracy: 0.9772 - val_loss: 0.0917 - val_accuracy: 0.9712\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0728 - accuracy: 0.9774 - val_loss: 0.0930 - val_accuracy: 0.9710\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0719 - accuracy: 0.9771 - val_loss: 0.0937 - val_accuracy: 0.9702\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0708 - accuracy: 0.9778 - val_loss: 0.0919 - val_accuracy: 0.9705\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0699 - accuracy: 0.9779 - val_loss: 0.0917 - val_accuracy: 0.9719\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0692 - accuracy: 0.9786 - val_loss: 0.0921 - val_accuracy: 0.9716\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0685 - accuracy: 0.9788 - val_loss: 0.0910 - val_accuracy: 0.9717\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0677 - accuracy: 0.9791 - val_loss: 0.0910 - val_accuracy: 0.9710\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0668 - accuracy: 0.9789 - val_loss: 0.0908 - val_accuracy: 0.9718\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0663 - accuracy: 0.9793 - val_loss: 0.0901 - val_accuracy: 0.9709\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0655 - accuracy: 0.9794 - val_loss: 0.0896 - val_accuracy: 0.9718\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0644 - accuracy: 0.9802 - val_loss: 0.0900 - val_accuracy: 0.9724\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0640 - accuracy: 0.9799 - val_loss: 0.0902 - val_accuracy: 0.9716\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0632 - accuracy: 0.9807 - val_loss: 0.0910 - val_accuracy: 0.9712\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0627 - accuracy: 0.9808 - val_loss: 0.0910 - val_accuracy: 0.9715\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0618 - accuracy: 0.9811 - val_loss: 0.0898 - val_accuracy: 0.9715\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0609 - accuracy: 0.9815 - val_loss: 0.0919 - val_accuracy: 0.9713\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0605 - accuracy: 0.9812 - val_loss: 0.0907 - val_accuracy: 0.9727\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0596 - accuracy: 0.9816 - val_loss: 0.0913 - val_accuracy: 0.9711\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0591 - accuracy: 0.9816 - val_loss: 0.0898 - val_accuracy: 0.9709\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0580 - accuracy: 0.9823 - val_loss: 0.0905 - val_accuracy: 0.9712\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0576 - accuracy: 0.9823 - val_loss: 0.0915 - val_accuracy: 0.9714\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0570 - accuracy: 0.9828 - val_loss: 0.0897 - val_accuracy: 0.9722\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0563 - accuracy: 0.9828 - val_loss: 0.0904 - val_accuracy: 0.9722\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0560 - accuracy: 0.9827 - val_loss: 0.0910 - val_accuracy: 0.9722\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0551 - accuracy: 0.9830 - val_loss: 0.0914 - val_accuracy: 0.9720\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0544 - accuracy: 0.9833 - val_loss: 0.0908 - val_accuracy: 0.9721\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0536 - accuracy: 0.9835 - val_loss: 0.0906 - val_accuracy: 0.9715\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0533 - accuracy: 0.9838 - val_loss: 0.0914 - val_accuracy: 0.9719\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0526 - accuracy: 0.9841 - val_loss: 0.0904 - val_accuracy: 0.9711\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0518 - accuracy: 0.9840 - val_loss: 0.0903 - val_accuracy: 0.9721\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8397202520873406\n",
      "F1 Micro: 0.9713\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.2512 - accuracy: 0.9318 - val_loss: 0.1568 - val_accuracy: 0.9535\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.1443 - accuracy: 0.9561 - val_loss: 0.1326 - val_accuracy: 0.9606\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1241 - accuracy: 0.9615 - val_loss: 0.1215 - val_accuracy: 0.9629\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.1130 - accuracy: 0.9655 - val_loss: 0.1103 - val_accuracy: 0.9665\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.1063 - accuracy: 0.9673 - val_loss: 0.1070 - val_accuracy: 0.9675\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.1006 - accuracy: 0.9693 - val_loss: 0.1016 - val_accuracy: 0.9668\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0960 - accuracy: 0.9698 - val_loss: 0.0991 - val_accuracy: 0.9686\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0923 - accuracy: 0.9717 - val_loss: 0.0986 - val_accuracy: 0.9692\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0872 - accuracy: 0.9724 - val_loss: 0.0986 - val_accuracy: 0.9695\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0820 - accuracy: 0.9741 - val_loss: 0.0896 - val_accuracy: 0.9707\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0776 - accuracy: 0.9755 - val_loss: 0.0894 - val_accuracy: 0.9720\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0715 - accuracy: 0.9770 - val_loss: 0.0856 - val_accuracy: 0.9721\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0648 - accuracy: 0.9794 - val_loss: 0.0855 - val_accuracy: 0.9726\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.0871 - val_accuracy: 0.9718\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0505 - accuracy: 0.9845 - val_loss: 0.0877 - val_accuracy: 0.9725\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0432 - accuracy: 0.9863 - val_loss: 0.0909 - val_accuracy: 0.9720\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0362 - accuracy: 0.9888 - val_loss: 0.1091 - val_accuracy: 0.9710\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.0949 - val_accuracy: 0.9731\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.1027 - val_accuracy: 0.9718\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.1127 - val_accuracy: 0.9684\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.1123 - val_accuracy: 0.9723\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.1267 - val_accuracy: 0.9717\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.1269 - val_accuracy: 0.9721\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.1247 - val_accuracy: 0.9714\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.1511 - val_accuracy: 0.9716\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.1274 - val_accuracy: 0.9708\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.1331 - val_accuracy: 0.9718\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1377 - val_accuracy: 0.9705\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.1379 - val_accuracy: 0.9696\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.1385 - val_accuracy: 0.9722\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.1476 - val_accuracy: 0.9708\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.1377 - val_accuracy: 0.9714\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.1401 - val_accuracy: 0.9714\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8348103411233548\n",
      "F1 Micro: 0.9715\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7988378972012917\n",
      "F1 Micro: 0.9652\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8793618903102419\n",
      "F1 Micro: 0.9771\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 5 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.2482 - accuracy: 0.9332 - val_loss: 0.1299 - val_accuracy: 0.9594\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.1198 - accuracy: 0.9623 - val_loss: 0.1058 - val_accuracy: 0.9670\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.1008 - accuracy: 0.9675 - val_loss: 0.0978 - val_accuracy: 0.9690\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0910 - accuracy: 0.9705 - val_loss: 0.0884 - val_accuracy: 0.9708\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0835 - accuracy: 0.9722 - val_loss: 0.0867 - val_accuracy: 0.9693\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0765 - accuracy: 0.9747 - val_loss: 0.0805 - val_accuracy: 0.9735\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0701 - accuracy: 0.9764 - val_loss: 0.0761 - val_accuracy: 0.9735\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0646 - accuracy: 0.9779 - val_loss: 0.0718 - val_accuracy: 0.9741\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0594 - accuracy: 0.9797 - val_loss: 0.0685 - val_accuracy: 0.9762\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 0.0813 - val_accuracy: 0.9733\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0500 - accuracy: 0.9821 - val_loss: 0.0665 - val_accuracy: 0.9764\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0461 - accuracy: 0.9838 - val_loss: 0.0725 - val_accuracy: 0.9750\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0422 - accuracy: 0.9851 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0380 - accuracy: 0.9864 - val_loss: 0.0765 - val_accuracy: 0.9763\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0336 - accuracy: 0.9880 - val_loss: 0.0714 - val_accuracy: 0.9766\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0295 - accuracy: 0.9896 - val_loss: 0.0740 - val_accuracy: 0.9775\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0250 - accuracy: 0.9909 - val_loss: 0.1055 - val_accuracy: 0.9746\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0216 - accuracy: 0.9924 - val_loss: 0.0927 - val_accuracy: 0.9759\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 0.0967 - val_accuracy: 0.9761\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0152 - accuracy: 0.9944 - val_loss: 0.0969 - val_accuracy: 0.9774\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.1004 - val_accuracy: 0.9764\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.1065 - val_accuracy: 0.9760\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.1187 - val_accuracy: 0.9754\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.1219 - val_accuracy: 0.9729\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.1214 - val_accuracy: 0.9766\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1229 - val_accuracy: 0.9736\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.1281 - val_accuracy: 0.9758\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1534 - val_accuracy: 0.9756\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.1265 - val_accuracy: 0.9750\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.1421 - val_accuracy: 0.9730\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.1818 - val_accuracy: 0.9653\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8970311100396402\n",
      "F1 Micro: 0.9797\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8174525178823128\n",
      "F1 Micro: 0.9688\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.2451 - accuracy: 0.9380 - val_loss: 0.1265 - val_accuracy: 0.9607\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.1132 - accuracy: 0.9650 - val_loss: 0.1114 - val_accuracy: 0.9647\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.1034 - accuracy: 0.9678 - val_loss: 0.1058 - val_accuracy: 0.9661\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0977 - accuracy: 0.9694 - val_loss: 0.1012 - val_accuracy: 0.9675\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0942 - accuracy: 0.9706 - val_loss: 0.0982 - val_accuracy: 0.9681\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0908 - accuracy: 0.9715 - val_loss: 0.0960 - val_accuracy: 0.9692\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0881 - accuracy: 0.9721 - val_loss: 0.0951 - val_accuracy: 0.9693\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0861 - accuracy: 0.9730 - val_loss: 0.0958 - val_accuracy: 0.9689\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0844 - accuracy: 0.9731 - val_loss: 0.0916 - val_accuracy: 0.9702\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0824 - accuracy: 0.9737 - val_loss: 0.0907 - val_accuracy: 0.970427 \n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0810 - accuracy: 0.9742 - val_loss: 0.0895 - val_accuracy: 0.9712\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0797 - accuracy: 0.9745 - val_loss: 0.0912 - val_accuracy: 0.9703\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0784 - accuracy: 0.9749 - val_loss: 0.0886 - val_accuracy: 0.9711\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0771 - accuracy: 0.9753 - val_loss: 0.0878 - val_accuracy: 0.9712\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0762 - accuracy: 0.9757 - val_loss: 0.0893 - val_accuracy: 0.9704\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0751 - accuracy: 0.9758 - val_loss: 0.0876 - val_accuracy: 0.9714\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0741 - accuracy: 0.9761 - val_loss: 0.0868 - val_accuracy: 0.9711\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0730 - accuracy: 0.9764 - val_loss: 0.0865 - val_accuracy: 0.9712\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0722 - accuracy: 0.9769 - val_loss: 0.0861 - val_accuracy: 0.9716\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0714 - accuracy: 0.9768 - val_loss: 0.0858 - val_accuracy: 0.9715\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0706 - accuracy: 0.9770 - val_loss: 0.0864 - val_accuracy: 0.9714\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0698 - accuracy: 0.9772 - val_loss: 0.0854 - val_accuracy: 0.9720\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0690 - accuracy: 0.9777 - val_loss: 0.0848 - val_accuracy: 0.9720\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0684 - accuracy: 0.9779 - val_loss: 0.0857 - val_accuracy: 0.9718\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0677 - accuracy: 0.9783 - val_loss: 0.0845 - val_accuracy: 0.9728\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0668 - accuracy: 0.9782 - val_loss: 0.0844 - val_accuracy: 0.9720\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0661 - accuracy: 0.9783 - val_loss: 0.0851 - val_accuracy: 0.9720\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0656 - accuracy: 0.9786 - val_loss: 0.0845 - val_accuracy: 0.9724\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0650 - accuracy: 0.9789 - val_loss: 0.0856 - val_accuracy: 0.9722\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0643 - accuracy: 0.9792 - val_loss: 0.0852 - val_accuracy: 0.9722\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0637 - accuracy: 0.9792 - val_loss: 0.0850 - val_accuracy: 0.9724\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0631 - accuracy: 0.9795 - val_loss: 0.0846 - val_accuracy: 0.9725\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0624 - accuracy: 0.9796 - val_loss: 0.0848 - val_accuracy: 0.9723\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0617 - accuracy: 0.9801 - val_loss: 0.0839 - val_accuracy: 0.9726\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0613 - accuracy: 0.9802 - val_loss: 0.0847 - val_accuracy: 0.9731\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0606 - accuracy: 0.9803 - val_loss: 0.0856 - val_accuracy: 0.9720\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0600 - accuracy: 0.9806 - val_loss: 0.0840 - val_accuracy: 0.9730\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0595 - accuracy: 0.9809 - val_loss: 0.0856 - val_accuracy: 0.9725\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0589 - accuracy: 0.9809 - val_loss: 0.0850 - val_accuracy: 0.9723\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0584 - accuracy: 0.9811 - val_loss: 0.0850 - val_accuracy: 0.9728\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0578 - accuracy: 0.9813 - val_loss: 0.0854 - val_accuracy: 0.9722\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0572 - accuracy: 0.9816 - val_loss: 0.0865 - val_accuracy: 0.9719\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0567 - accuracy: 0.9820 - val_loss: 0.0852 - val_accuracy: 0.9723\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0561 - accuracy: 0.9821 - val_loss: 0.0849 - val_accuracy: 0.9725\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0557 - accuracy: 0.9821 - val_loss: 0.0858 - val_accuracy: 0.9722\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0551 - accuracy: 0.9824 - val_loss: 0.0848 - val_accuracy: 0.9731\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0543 - accuracy: 0.9828 - val_loss: 0.0845 - val_accuracy: 0.9727\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0540 - accuracy: 0.9825 - val_loss: 0.0852 - val_accuracy: 0.9726\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0534 - accuracy: 0.9830 - val_loss: 0.0851 - val_accuracy: 0.9726\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0529 - accuracy: 0.9832 - val_loss: 0.0852 - val_accuracy: 0.9726\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0525 - accuracy: 0.9833 - val_loss: 0.0855 - val_accuracy: 0.9728\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0518 - accuracy: 0.9834 - val_loss: 0.0864 - val_accuracy: 0.9721\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0511 - accuracy: 0.9838 - val_loss: 0.0853 - val_accuracy: 0.9726\n",
      "Epoch 54/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0508 - accuracy: 0.9839 - val_loss: 0.0871 - val_accuracy: 0.9724\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8658347810001084\n",
      "F1 Micro: 0.9747\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.1652 - accuracy: 0.9508 - val_loss: 0.1088 - val_accuracy: 0.9651\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0951 - accuracy: 0.9696 - val_loss: 0.0927 - val_accuracy: 0.9697\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0831 - accuracy: 0.9731 - val_loss: 0.0852 - val_accuracy: 0.9725\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0749 - accuracy: 0.9754 - val_loss: 0.0829 - val_accuracy: 0.9726\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0688 - accuracy: 0.9774 - val_loss: 0.0761 - val_accuracy: 0.9748\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0638 - accuracy: 0.9786 - val_loss: 0.0738 - val_accuracy: 0.9759\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0576 - accuracy: 0.9806 - val_loss: 0.0705 - val_accuracy: 0.9756\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0526 - accuracy: 0.9821 - val_loss: 0.0691 - val_accuracy: 0.9771\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0467 - accuracy: 0.9839 - val_loss: 0.0700 - val_accuracy: 0.9769\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0395 - accuracy: 0.9864 - val_loss: 0.0793 - val_accuracy: 0.9735\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0330 - accuracy: 0.9886 - val_loss: 0.0720 - val_accuracy: 0.9765\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.0797 - val_accuracy: 0.9752\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.0905 - val_accuracy: 0.9751\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.0961 - val_accuracy: 0.9739\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.1031 - val_accuracy: 0.9751\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.1201 - val_accuracy: 0.9705\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.1258 - val_accuracy: 0.9759\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.1218 - val_accuracy: 0.9744\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1234 - val_accuracy: 0.9731\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.1274 - val_accuracy: 0.9742\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1293 - val_accuracy: 0.9756\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1435 - val_accuracy: 0.9756\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1439 - val_accuracy: 0.9750\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.1470 - val_accuracy: 0.9762\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1457 - val_accuracy: 0.9750\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1662 - val_accuracy: 0.9742\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.1554 - val_accuracy: 0.9758\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.1442 - val_accuracy: 0.9747\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8828218903415428\n",
      "F1 Micro: 0.977\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.82129064772669\n",
      "F1 Micro: 0.9687\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.9062342383621574\n",
      "F1 Micro: 0.9809\n",
      "\n",
      "\n",
      " 50.31865402460098 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 6 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 6 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 994us/step - loss: 1.7760 - accuracy: 0.8325 - val_loss: 1.0854 - val_accuracy: 0.8900\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.9398 - accuracy: 0.8325 - val_loss: 0.5985 - val_accuracy: 0.8900\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.8369 - accuracy: 0.8325 - val_loss: 0.5551 - val_accuracy: 0.8900\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7583 - accuracy: 0.8325 - val_loss: 0.5765 - val_accuracy: 0.8900\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7441 - accuracy: 0.8325 - val_loss: 0.5439 - val_accuracy: 0.8900\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7258 - accuracy: 0.8325 - val_loss: 0.5297 - val_accuracy: 0.8900\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.7130 - accuracy: 0.8325 - val_loss: 0.5377 - val_accuracy: 0.8900\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7029 - accuracy: 0.8325 - val_loss: 0.5256 - val_accuracy: 0.8900\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.6956 - accuracy: 0.8325 - val_loss: 0.5282 - val_accuracy: 0.8900\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6936 - accuracy: 0.8325 - val_loss: 0.5239 - val_accuracy: 0.8900\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6854 - accuracy: 0.8325 - val_loss: 0.5031 - val_accuracy: 0.8900\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 202us/step - loss: 0.6724 - accuracy: 0.8325 - val_loss: 0.5052 - val_accuracy: 0.8900\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.6621 - accuracy: 0.8325 - val_loss: 0.4915 - val_accuracy: 0.8900\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6473 - accuracy: 0.8325 - val_loss: 0.4786 - val_accuracy: 0.8900\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6284 - accuracy: 0.8325 - val_loss: 0.5368 - val_accuracy: 0.8900\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.6263 - accuracy: 0.8325 - val_loss: 0.4832 - val_accuracy: 0.8900\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5854 - accuracy: 0.8325 - val_loss: 0.4196 - val_accuracy: 0.8900\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5561 - accuracy: 0.8350 - val_loss: 0.3995 - val_accuracy: 0.8900\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5386 - accuracy: 0.8525 - val_loss: 0.4083 - val_accuracy: 0.9000\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5217 - accuracy: 0.8600 - val_loss: 0.3506 - val_accuracy: 0.8900\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4869 - accuracy: 0.8825 - val_loss: 0.3217 - val_accuracy: 0.9200\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4551 - accuracy: 0.8825 - val_loss: 0.3024 - val_accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4331 - accuracy: 0.8875 - val_loss: 0.2899 - val_accuracy: 0.9300\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.4135 - accuracy: 0.9000 - val_loss: 0.3127 - val_accuracy: 0.9500\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 159us/step - loss: 0.3937 - accuracy: 0.9050 - val_loss: 0.2676 - val_accuracy: 0.9200\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3750 - accuracy: 0.9075 - val_loss: 0.2624 - val_accuracy: 0.9400\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3729 - accuracy: 0.9075 - val_loss: 0.3159 - val_accuracy: 0.9500\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3617 - accuracy: 0.9100 - val_loss: 0.2855 - val_accuracy: 0.9500\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3427 - accuracy: 0.9200 - val_loss: 0.2438 - val_accuracy: 0.9600\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3691 - accuracy: 0.9050 - val_loss: 0.2648 - val_accuracy: 0.9100\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3435 - accuracy: 0.9175 - val_loss: 0.2389 - val_accuracy: 0.9300\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3544 - accuracy: 0.9075 - val_loss: 0.2302 - val_accuracy: 0.9500\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3455 - accuracy: 0.9100 - val_loss: 0.2350 - val_accuracy: 0.9600\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3079 - accuracy: 0.9250 - val_loss: 0.2747 - val_accuracy: 0.9500\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2975 - accuracy: 0.9250 - val_loss: 0.2258 - val_accuracy: 0.9600\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2928 - accuracy: 0.9275 - val_loss: 0.2251 - val_accuracy: 0.9600\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 175us/step - loss: 0.2778 - accuracy: 0.9275 - val_loss: 0.2004 - val_accuracy: 0.9600\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2850 - accuracy: 0.9275 - val_loss: 0.1970 - val_accuracy: 0.9600\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2845 - accuracy: 0.9225 - val_loss: 0.2122 - val_accuracy: 0.9600\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2693 - accuracy: 0.9275 - val_loss: 0.2454 - val_accuracy: 0.9600\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2664 - accuracy: 0.9225 - val_loss: 0.2396 - val_accuracy: 0.9500\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2571 - accuracy: 0.9300 - val_loss: 0.1905 - val_accuracy: 0.9600\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2626 - accuracy: 0.9275 - val_loss: 0.2278 - val_accuracy: 0.9600\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2738 - accuracy: 0.9175 - val_loss: 0.2376 - val_accuracy: 0.9600\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2407 - accuracy: 0.9325 - val_loss: 0.1838 - val_accuracy: 0.9600\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2582 - accuracy: 0.9200 - val_loss: 0.1852 - val_accuracy: 0.9600\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2532 - accuracy: 0.9125 - val_loss: 0.2848 - val_accuracy: 0.9400\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2476 - accuracy: 0.9275 - val_loss: 0.3050 - val_accuracy: 0.9400\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.2288 - accuracy: 0.9350 - val_loss: 0.2447 - val_accuracy: 0.9500\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 158us/step - loss: 0.2049 - accuracy: 0.9350 - val_loss: 0.2167 - val_accuracy: 0.9600\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2031 - accuracy: 0.9525 - val_loss: 0.1934 - val_accuracy: 0.9600\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1911 - accuracy: 0.9450 - val_loss: 0.1868 - val_accuracy: 0.9600\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1936 - accuracy: 0.9375 - val_loss: 0.1799 - val_accuracy: 0.9600\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1777 - accuracy: 0.9450 - val_loss: 0.1831 - val_accuracy: 0.9700\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1655 - accuracy: 0.9500 - val_loss: 0.1796 - val_accuracy: 0.9600\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1733 - accuracy: 0.9475 - val_loss: 0.1826 - val_accuracy: 0.9600\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1653 - accuracy: 0.9525 - val_loss: 0.1708 - val_accuracy: 0.9600\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1610 - accuracy: 0.9500 - val_loss: 0.1844 - val_accuracy: 0.9600\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1697 - accuracy: 0.9450 - val_loss: 0.1889 - val_accuracy: 0.9700\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1657 - accuracy: 0.9475 - val_loss: 0.1755 - val_accuracy: 0.9700\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1854 - accuracy: 0.9300 - val_loss: 0.1811 - val_accuracy: 0.9500\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.1444 - accuracy: 0.9500 - val_loss: 0.2181 - val_accuracy: 0.9600\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 160us/step - loss: 0.1364 - accuracy: 0.9625 - val_loss: 0.1688 - val_accuracy: 0.9600\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1582 - accuracy: 0.9450 - val_loss: 0.1892 - val_accuracy: 0.9600\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1287 - accuracy: 0.9675 - val_loss: 0.1771 - val_accuracy: 0.9500\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1782 - accuracy: 0.9425 - val_loss: 0.1724 - val_accuracy: 0.9500\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1745 - accuracy: 0.9475 - val_loss: 0.2429 - val_accuracy: 0.9400\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1390 - accuracy: 0.9575 - val_loss: 0.1808 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1186 - accuracy: 0.9650 - val_loss: 0.1650 - val_accuracy: 0.9700\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1169 - accuracy: 0.9650 - val_loss: 0.1794 - val_accuracy: 0.9500\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1202 - accuracy: 0.9650 - val_loss: 0.1763 - val_accuracy: 0.9600\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1176 - accuracy: 0.9575 - val_loss: 0.1687 - val_accuracy: 0.9600\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1585 - accuracy: 0.9525 - val_loss: 0.2092 - val_accuracy: 0.9600\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2050 - accuracy: 0.9325 - val_loss: 0.1749 - val_accuracy: 0.9700\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.1483 - accuracy: 0.9575 - val_loss: 0.2440 - val_accuracy: 0.9400\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1877 - accuracy: 0.9350 - val_loss: 0.1681 - val_accuracy: 0.9700\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1602 - accuracy: 0.9550 - val_loss: 0.1678 - val_accuracy: 0.9600\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1269 - accuracy: 0.9625 - val_loss: 0.1697 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1059 - accuracy: 0.9675 - val_loss: 0.1680 - val_accuracy: 0.9600\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0935 - accuracy: 0.9700 - val_loss: 0.1674 - val_accuracy: 0.9500\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0930 - accuracy: 0.9725 - val_loss: 0.1693 - val_accuracy: 0.9600\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0881 - accuracy: 0.9775 - val_loss: 0.1654 - val_accuracy: 0.9600\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0808 - accuracy: 0.9775 - val_loss: 0.1740 - val_accuracy: 0.9500\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0892 - accuracy: 0.9725 - val_loss: 0.1707 - val_accuracy: 0.9500\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0813 - accuracy: 0.9800 - val_loss: 0.1659 - val_accuracy: 0.9500\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0822 - accuracy: 0.9775 - val_loss: 0.1701 - val_accuracy: 0.9500\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1014 - accuracy: 0.9725 - val_loss: 0.1690 - val_accuracy: 0.9500\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 196us/step - loss: 0.0830 - accuracy: 0.9800 - val_loss: 0.1668 - val_accuracy: 0.9500\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0760 - accuracy: 0.9775 - val_loss: 0.1643 - val_accuracy: 0.9500\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0882 - accuracy: 0.9725 - val_loss: 0.2180 - val_accuracy: 0.9400\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0990 - accuracy: 0.9750 - val_loss: 0.2040 - val_accuracy: 0.9500\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0757 - accuracy: 0.9775 - val_loss: 0.1791 - val_accuracy: 0.9500\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0649 - accuracy: 0.9850 - val_loss: 0.1659 - val_accuracy: 0.9500\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0622 - accuracy: 0.9850 - val_loss: 0.1723 - val_accuracy: 0.9500\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0681 - accuracy: 0.9800 - val_loss: 0.1755 - val_accuracy: 0.9500\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0674 - accuracy: 0.9800 - val_loss: 0.2136 - val_accuracy: 0.9400\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0910 - accuracy: 0.9750 - val_loss: 0.2102 - val_accuracy: 0.9500\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0695 - accuracy: 0.9750 - val_loss: 0.1804 - val_accuracy: 0.9500\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0611 - accuracy: 0.9850 - val_loss: 0.2254 - val_accuracy: 0.9400\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0679 - accuracy: 0.9875 - val_loss: 0.1788 - val_accuracy: 0.9500\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.0676 - accuracy: 0.9800 - val_loss: 0.1878 - val_accuracy: 0.9500\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0641 - accuracy: 0.9825 - val_loss: 0.1870 - val_accuracy: 0.9500\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0500 - accuracy: 0.9875 - val_loss: 0.1754 - val_accuracy: 0.9500\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0518 - accuracy: 0.9875 - val_loss: 0.1734 - val_accuracy: 0.9500\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0483 - accuracy: 0.9875 - val_loss: 0.1649 - val_accuracy: 0.9500\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0413 - accuracy: 0.9975 - val_loss: 0.1829 - val_accuracy: 0.9500\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0421 - accuracy: 0.9875 - val_loss: 0.1695 - val_accuracy: 0.9500\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0388 - accuracy: 0.9925 - val_loss: 0.1718 - val_accuracy: 0.9500\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0408 - accuracy: 0.9925 - val_loss: 0.1779 - val_accuracy: 0.9600\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.38818207434439045\n",
      "F1 Micro: 0.9239157620929419\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.40704539789409455\n",
      "F1 Micro: 0.9273172927817517\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 273us/step - loss: 2.0802 - accuracy: 0.3525 - val_loss: 2.0293 - val_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.8929 - accuracy: 0.4800 - val_loss: 1.9110 - val_accuracy: 0.4500\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.7672 - accuracy: 0.5250 - val_loss: 1.8231 - val_accuracy: 0.5200\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.6730 - accuracy: 0.5850 - val_loss: 1.7431 - val_accuracy: 0.5800\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.5891 - accuracy: 0.6200 - val_loss: 1.6646 - val_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.5109 - accuracy: 0.6500 - val_loss: 1.5805 - val_accuracy: 0.6600\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.4327 - accuracy: 0.6725 - val_loss: 1.5003 - val_accuracy: 0.6700\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.3597 - accuracy: 0.6950 - val_loss: 1.4203 - val_accuracy: 0.6800\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.2866 - accuracy: 0.7225 - val_loss: 1.3430 - val_accuracy: 0.7200\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.2142 - accuracy: 0.7475 - val_loss: 1.2669 - val_accuracy: 0.7600\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1434 - accuracy: 0.7775 - val_loss: 1.1894 - val_accuracy: 0.7700\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0741 - accuracy: 0.7925 - val_loss: 1.1151 - val_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0076 - accuracy: 0.8075 - val_loss: 1.0431 - val_accuracy: 0.8200\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.9419 - accuracy: 0.8350 - val_loss: 0.9745 - val_accuracy: 0.8400\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8795 - accuracy: 0.8500 - val_loss: 0.9101 - val_accuracy: 0.8400\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8210 - accuracy: 0.8625 - val_loss: 0.8522 - val_accuracy: 0.8700\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7663 - accuracy: 0.8825 - val_loss: 0.7973 - val_accuracy: 0.9000\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7153 - accuracy: 0.9000 - val_loss: 0.7421 - val_accuracy: 0.9000\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.6694 - accuracy: 0.9050 - val_loss: 0.6983 - val_accuracy: 0.9000\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.6261 - accuracy: 0.9025 - val_loss: 0.6526 - val_accuracy: 0.9100\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5854 - accuracy: 0.9100 - val_loss: 0.6145 - val_accuracy: 0.9200\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5489 - accuracy: 0.9100 - val_loss: 0.5774 - val_accuracy: 0.9200\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 78us/step - loss: 0.5155 - accuracy: 0.9150 - val_loss: 0.5453 - val_accuracy: 0.9200\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4859 - accuracy: 0.9250 - val_loss: 0.5141 - val_accuracy: 0.9100\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4571 - accuracy: 0.9325 - val_loss: 0.4873 - val_accuracy: 0.9100\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4319 - accuracy: 0.9375 - val_loss: 0.4650 - val_accuracy: 0.9300\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4092 - accuracy: 0.9450 - val_loss: 0.4410 - val_accuracy: 0.9200\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3870 - accuracy: 0.9450 - val_loss: 0.4200 - val_accuracy: 0.9200\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3671 - accuracy: 0.9500 - val_loss: 0.4022 - val_accuracy: 0.9300\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3491 - accuracy: 0.9475 - val_loss: 0.3857 - val_accuracy: 0.9300\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3318 - accuracy: 0.9500 - val_loss: 0.3672 - val_accuracy: 0.9300\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3167 - accuracy: 0.9575 - val_loss: 0.3525 - val_accuracy: 0.9400\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3025 - accuracy: 0.9575 - val_loss: 0.3388 - val_accuracy: 0.9500\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 45us/step - loss: 0.2889 - accuracy: 0.9550 - val_loss: 0.3273 - val_accuracy: 0.9500\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2770 - accuracy: 0.9575 - val_loss: 0.3142 - val_accuracy: 0.9500\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2653 - accuracy: 0.9575 - val_loss: 0.3048 - val_accuracy: 0.9500\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2548 - accuracy: 0.9625 - val_loss: 0.2933 - val_accuracy: 0.9500\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2458 - accuracy: 0.9625 - val_loss: 0.2848 - val_accuracy: 0.9500\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2352 - accuracy: 0.9625 - val_loss: 0.2758 - val_accuracy: 0.9600\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2267 - accuracy: 0.9625 - val_loss: 0.2625 - val_accuracy: 0.9600\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2186 - accuracy: 0.9650 - val_loss: 0.2557 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2104 - accuracy: 0.9650 - val_loss: 0.2505 - val_accuracy: 0.9600\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2032 - accuracy: 0.9675 - val_loss: 0.2452 - val_accuracy: 0.9600\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1965 - accuracy: 0.9700 - val_loss: 0.2377 - val_accuracy: 0.9600\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1905 - accuracy: 0.9700 - val_loss: 0.2320 - val_accuracy: 0.9600\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1842 - accuracy: 0.9725 - val_loss: 0.2247 - val_accuracy: 0.9600\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1785 - accuracy: 0.9725 - val_loss: 0.2202 - val_accuracy: 0.9600\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1732 - accuracy: 0.9725 - val_loss: 0.2137 - val_accuracy: 0.9700\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1682 - accuracy: 0.9725 - val_loss: 0.2080 - val_accuracy: 0.9700\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1630 - accuracy: 0.9725 - val_loss: 0.2065 - val_accuracy: 0.9700\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1587 - accuracy: 0.9725 - val_loss: 0.2019 - val_accuracy: 0.9700\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1541 - accuracy: 0.9725 - val_loss: 0.1984 - val_accuracy: 0.9700\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1498 - accuracy: 0.9725 - val_loss: 0.1940 - val_accuracy: 0.9700\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1460 - accuracy: 0.9725 - val_loss: 0.1918 - val_accuracy: 0.9700\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1421 - accuracy: 0.9725 - val_loss: 0.1868 - val_accuracy: 0.9700\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1384 - accuracy: 0.9725 - val_loss: 0.1843 - val_accuracy: 0.9700\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1348 - accuracy: 0.9725 - val_loss: 0.1817 - val_accuracy: 0.9700\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1317 - accuracy: 0.9725 - val_loss: 0.1783 - val_accuracy: 0.9700\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1284 - accuracy: 0.9725 - val_loss: 0.1770 - val_accuracy: 0.9700\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1252 - accuracy: 0.9725 - val_loss: 0.1738 - val_accuracy: 0.9700\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1222 - accuracy: 0.9725 - val_loss: 0.1708 - val_accuracy: 0.9700\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1193 - accuracy: 0.9750 - val_loss: 0.1693 - val_accuracy: 0.9700\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1167 - accuracy: 0.9750 - val_loss: 0.1682 - val_accuracy: 0.9700\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 40us/step - loss: 0.1138 - accuracy: 0.9775 - val_loss: 0.1653 - val_accuracy: 0.9700\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1115 - accuracy: 0.9775 - val_loss: 0.1645 - val_accuracy: 0.9700\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1088 - accuracy: 0.9775 - val_loss: 0.1595 - val_accuracy: 0.9800\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1066 - accuracy: 0.9775 - val_loss: 0.1597 - val_accuracy: 0.9700\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1039 - accuracy: 0.9775 - val_loss: 0.1573 - val_accuracy: 0.9900\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1013 - accuracy: 0.9800 - val_loss: 0.1575 - val_accuracy: 0.9800\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0991 - accuracy: 0.9800 - val_loss: 0.1561 - val_accuracy: 0.9800\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0971 - accuracy: 0.9775 - val_loss: 0.1535 - val_accuracy: 0.9800\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0948 - accuracy: 0.9775 - val_loss: 0.1536 - val_accuracy: 0.9800\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0927 - accuracy: 0.9775 - val_loss: 0.1510 - val_accuracy: 0.9800\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0908 - accuracy: 0.9800 - val_loss: 0.1505 - val_accuracy: 0.9800\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0885 - accuracy: 0.9825 - val_loss: 0.1486 - val_accuracy: 0.9900\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0870 - accuracy: 0.9850 - val_loss: 0.1483 - val_accuracy: 0.9900\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0852 - accuracy: 0.9875 - val_loss: 0.1462 - val_accuracy: 0.9900\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0833 - accuracy: 0.9875 - val_loss: 0.1469 - val_accuracy: 0.9800\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 78us/step - loss: 0.0815 - accuracy: 0.9875 - val_loss: 0.1470 - val_accuracy: 0.9800\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0799 - accuracy: 0.9875 - val_loss: 0.1442 - val_accuracy: 0.9900\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0784 - accuracy: 0.9875 - val_loss: 0.1439 - val_accuracy: 0.9900\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0765 - accuracy: 0.9900 - val_loss: 0.1423 - val_accuracy: 0.9900\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0750 - accuracy: 0.9925 - val_loss: 0.1425 - val_accuracy: 0.9900\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0735 - accuracy: 0.9925 - val_loss: 0.1411 - val_accuracy: 0.9900\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0723 - accuracy: 0.9925 - val_loss: 0.1404 - val_accuracy: 0.9900\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0706 - accuracy: 0.9925 - val_loss: 0.1405 - val_accuracy: 0.9900\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0692 - accuracy: 0.9925 - val_loss: 0.1389 - val_accuracy: 0.9900\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0678 - accuracy: 0.9925 - val_loss: 0.1395 - val_accuracy: 0.9900\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0664 - accuracy: 0.9925 - val_loss: 0.1374 - val_accuracy: 0.9900\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0653 - accuracy: 0.9925 - val_loss: 0.1383 - val_accuracy: 0.9900\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0641 - accuracy: 0.9925 - val_loss: 0.1400 - val_accuracy: 0.9800\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0625 - accuracy: 0.9950 - val_loss: 0.1372 - val_accuracy: 0.9900\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0611 - accuracy: 0.9950 - val_loss: 0.1353 - val_accuracy: 0.9900\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 45us/step - loss: 0.0602 - accuracy: 0.9950 - val_loss: 0.1353 - val_accuracy: 0.9900\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0592 - accuracy: 0.9950 - val_loss: 0.1346 - val_accuracy: 0.9900\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0580 - accuracy: 0.9950 - val_loss: 0.1362 - val_accuracy: 0.9800\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0568 - accuracy: 0.9950 - val_loss: 0.1342 - val_accuracy: 0.9900\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0558 - accuracy: 0.9950 - val_loss: 0.1340 - val_accuracy: 0.9900\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0548 - accuracy: 0.9950 - val_loss: 0.1341 - val_accuracy: 0.9900\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0538 - accuracy: 0.9950 - val_loss: 0.1336 - val_accuracy: 0.9900\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0528 - accuracy: 0.9950 - val_loss: 0.1322 - val_accuracy: 0.9900\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0517 - accuracy: 0.9950 - val_loss: 0.1329 - val_accuracy: 0.9900\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0507 - accuracy: 0.9950 - val_loss: 0.1336 - val_accuracy: 0.9900\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0498 - accuracy: 0.9950 - val_loss: 0.1332 - val_accuracy: 0.9900\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0489 - accuracy: 0.9950 - val_loss: 0.1331 - val_accuracy: 0.9900\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0480 - accuracy: 0.9950 - val_loss: 0.1324 - val_accuracy: 0.9900\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0471 - accuracy: 0.9950 - val_loss: 0.1323 - val_accuracy: 0.9900\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0464 - accuracy: 0.9950 - val_loss: 0.1324 - val_accuracy: 0.9900\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0455 - accuracy: 0.9950 - val_loss: 0.1331 - val_accuracy: 0.9900\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0447 - accuracy: 0.9950 - val_loss: 0.1321 - val_accuracy: 0.9900\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0438 - accuracy: 0.9950 - val_loss: 0.1326 - val_accuracy: 0.9800\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0433 - accuracy: 0.9950 - val_loss: 0.1308 - val_accuracy: 0.9900\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0425 - accuracy: 0.9950 - val_loss: 0.1326 - val_accuracy: 0.9800\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0419 - accuracy: 0.9950 - val_loss: 0.1307 - val_accuracy: 0.9900\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0409 - accuracy: 0.9950 - val_loss: 0.1318 - val_accuracy: 0.9900\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0401 - accuracy: 0.9950 - val_loss: 0.1303 - val_accuracy: 0.9900\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0395 - accuracy: 0.9950 - val_loss: 0.1314 - val_accuracy: 0.9900\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0388 - accuracy: 0.9975 - val_loss: 0.1294 - val_accuracy: 0.9900\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0382 - accuracy: 0.9975 - val_loss: 0.1297 - val_accuracy: 0.9900\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0374 - accuracy: 0.9975 - val_loss: 0.1308 - val_accuracy: 0.9900\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0367 - accuracy: 0.9975 - val_loss: 0.1315 - val_accuracy: 0.9900\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0361 - accuracy: 0.9950 - val_loss: 0.1316 - val_accuracy: 0.9900\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0358 - accuracy: 0.9950 - val_loss: 0.1300 - val_accuracy: 0.9900\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 1.00 - 0s 78us/step - loss: 0.0349 - accuracy: 0.9975 - val_loss: 0.1308 - val_accuracy: 0.9900\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0345 - accuracy: 0.9950 - val_loss: 0.1323 - val_accuracy: 0.9800\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0340 - accuracy: 0.9950 - val_loss: 0.1305 - val_accuracy: 0.9900\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0332 - accuracy: 0.9975 - val_loss: 0.1310 - val_accuracy: 0.9900\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0328 - accuracy: 0.9975 - val_loss: 0.1323 - val_accuracy: 0.9800\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0323 - accuracy: 0.9975 - val_loss: 0.1301 - val_accuracy: 0.9900\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0317 - accuracy: 0.9975 - val_loss: 0.1311 - val_accuracy: 0.9800\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0311 - accuracy: 0.9975 - val_loss: 0.1311 - val_accuracy: 0.9800\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0305 - accuracy: 0.9975 - val_loss: 0.1308 - val_accuracy: 0.9900\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.9900\n",
      "Epoch 134/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0291 - accuracy: 0.9975 - val_loss: 0.1309 - val_accuracy: 0.9900\n",
      "Epoch 136/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9900\n",
      "Epoch 137/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9900\n",
      "Epoch 138/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9900\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5113629475780517\n",
      "F1 Micro: 0.9420239107598419\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 688us/step - loss: 1.9764 - accuracy: 0.4225 - val_loss: 1.5959 - val_accuracy: 0.7200\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 1.1727 - accuracy: 0.8075 - val_loss: 0.5234 - val_accuracy: 0.8900\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5807 - accuracy: 0.8575 - val_loss: 0.3601 - val_accuracy: 0.8900\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4935 - accuracy: 0.8750 - val_loss: 0.3249 - val_accuracy: 0.9100\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4405 - accuracy: 0.8950 - val_loss: 0.3117 - val_accuracy: 0.9100\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4104 - accuracy: 0.9025 - val_loss: 0.2737 - val_accuracy: 0.9200\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3895 - accuracy: 0.9025 - val_loss: 0.2706 - val_accuracy: 0.9100\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3727 - accuracy: 0.9075 - val_loss: 0.2602 - val_accuracy: 0.9600\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3578 - accuracy: 0.9075 - val_loss: 0.2400 - val_accuracy: 0.9500\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3441 - accuracy: 0.9150 - val_loss: 0.2394 - val_accuracy: 0.9600\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3290 - accuracy: 0.9125 - val_loss: 0.2271 - val_accuracy: 0.9700\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.3176 - accuracy: 0.9125 - val_loss: 0.2154 - val_accuracy: 0.9700\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3071 - accuracy: 0.9200 - val_loss: 0.2182 - val_accuracy: 0.9700\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2969 - accuracy: 0.9250 - val_loss: 0.2043 - val_accuracy: 0.9700\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2868 - accuracy: 0.9275 - val_loss: 0.2019 - val_accuracy: 0.9700\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2788 - accuracy: 0.9325 - val_loss: 0.1957 - val_accuracy: 0.9700\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2694 - accuracy: 0.9325 - val_loss: 0.1909 - val_accuracy: 0.9700\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2614 - accuracy: 0.9325 - val_loss: 0.1780 - val_accuracy: 0.9700\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2547 - accuracy: 0.9325 - val_loss: 0.1876 - val_accuracy: 0.9700\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2491 - accuracy: 0.9350 - val_loss: 0.1737 - val_accuracy: 0.9700\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2399 - accuracy: 0.9400 - val_loss: 0.1727 - val_accuracy: 0.9700\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2349 - accuracy: 0.9400 - val_loss: 0.1664 - val_accuracy: 0.9700\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2310 - accuracy: 0.9375 - val_loss: 0.1642 - val_accuracy: 0.9700\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2243 - accuracy: 0.9425 - val_loss: 0.1623 - val_accuracy: 0.9700\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 176us/step - loss: 0.2195 - accuracy: 0.9425 - val_loss: 0.1594 - val_accuracy: 0.9700\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2124 - accuracy: 0.9475 - val_loss: 0.1548 - val_accuracy: 0.9700\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2053 - accuracy: 0.9425 - val_loss: 0.1498 - val_accuracy: 0.9700\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2005 - accuracy: 0.9500 - val_loss: 0.1487 - val_accuracy: 0.9700\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1966 - accuracy: 0.9450 - val_loss: 0.1492 - val_accuracy: 0.9700\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1960 - accuracy: 0.9500 - val_loss: 0.1407 - val_accuracy: 0.9800\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1891 - accuracy: 0.9450 - val_loss: 0.1405 - val_accuracy: 0.9700\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1832 - accuracy: 0.9500 - val_loss: 0.1411 - val_accuracy: 0.9800\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1810 - accuracy: 0.9500 - val_loss: 0.1340 - val_accuracy: 0.9800\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1757 - accuracy: 0.9500 - val_loss: 0.1372 - val_accuracy: 0.9800\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1688 - accuracy: 0.9550 - val_loss: 0.1378 - val_accuracy: 0.9800\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.1674 - accuracy: 0.9525 - val_loss: 0.1327 - val_accuracy: 0.9800\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.1660 - accuracy: 0.9525 - val_loss: 0.1334 - val_accuracy: 0.9800\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 162us/step - loss: 0.1583 - accuracy: 0.9600 - val_loss: 0.1303 - val_accuracy: 0.9800\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1534 - accuracy: 0.9575 - val_loss: 0.1302 - val_accuracy: 0.9800\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1511 - accuracy: 0.9575 - val_loss: 0.1293 - val_accuracy: 0.9800\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1470 - accuracy: 0.9675 - val_loss: 0.1241 - val_accuracy: 0.9800\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1432 - accuracy: 0.9625 - val_loss: 0.1248 - val_accuracy: 0.9800\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1392 - accuracy: 0.9625 - val_loss: 0.1252 - val_accuracy: 0.9800\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1366 - accuracy: 0.9675 - val_loss: 0.1299 - val_accuracy: 0.9800\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1348 - accuracy: 0.9625 - val_loss: 0.1238 - val_accuracy: 0.9800\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1294 - accuracy: 0.9675 - val_loss: 0.1184 - val_accuracy: 0.9800\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1255 - accuracy: 0.9675 - val_loss: 0.1120 - val_accuracy: 0.9800\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1241 - accuracy: 0.9625 - val_loss: 0.1107 - val_accuracy: 0.9800\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1235 - accuracy: 0.9625 - val_loss: 0.1190 - val_accuracy: 0.9800\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.1185 - accuracy: 0.9625 - val_loss: 0.1216 - val_accuracy: 0.9800\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 195us/step - loss: 0.1146 - accuracy: 0.9700 - val_loss: 0.1140 - val_accuracy: 0.9800\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1143 - accuracy: 0.9675 - val_loss: 0.1289 - val_accuracy: 0.9800\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1109 - accuracy: 0.9700 - val_loss: 0.1075 - val_accuracy: 0.9800\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1091 - accuracy: 0.9650 - val_loss: 0.1248 - val_accuracy: 0.9800\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1031 - accuracy: 0.9700 - val_loss: 0.1078 - val_accuracy: 0.9800\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1014 - accuracy: 0.9700 - val_loss: 0.1042 - val_accuracy: 0.9800\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0974 - accuracy: 0.9675 - val_loss: 0.1128 - val_accuracy: 0.9800\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0969 - accuracy: 0.9700 - val_loss: 0.1028 - val_accuracy: 0.9800\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0928 - accuracy: 0.9750 - val_loss: 0.1095 - val_accuracy: 0.9800\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0898 - accuracy: 0.9775 - val_loss: 0.1089 - val_accuracy: 0.9800\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0901 - accuracy: 0.9675 - val_loss: 0.1084 - val_accuracy: 0.9800\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 159us/step - loss: 0.0851 - accuracy: 0.9775 - val_loss: 0.1032 - val_accuracy: 0.9800\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0862 - accuracy: 0.9750 - val_loss: 0.1094 - val_accuracy: 0.9900\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0832 - accuracy: 0.9775 - val_loss: 0.1044 - val_accuracy: 0.9800\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0794 - accuracy: 0.9825 - val_loss: 0.0975 - val_accuracy: 0.9800\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0883 - accuracy: 0.9750 - val_loss: 0.1205 - val_accuracy: 0.9900\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0752 - accuracy: 0.9750 - val_loss: 0.0998 - val_accuracy: 0.9800\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0717 - accuracy: 0.9800 - val_loss: 0.1117 - val_accuracy: 0.9900\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0695 - accuracy: 0.9850 - val_loss: 0.1003 - val_accuracy: 0.9800\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0689 - accuracy: 0.9750 - val_loss: 0.1062 - val_accuracy: 0.9900\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0651 - accuracy: 0.9825 - val_loss: 0.0998 - val_accuracy: 0.9900\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0645 - accuracy: 0.9825 - val_loss: 0.1034 - val_accuracy: 0.9900\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0628 - accuracy: 0.9900 - val_loss: 0.0974 - val_accuracy: 0.9900\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 180us/step - loss: 0.0608 - accuracy: 0.9875 - val_loss: 0.1057 - val_accuracy: 0.9900\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0634 - accuracy: 0.9875 - val_loss: 0.0951 - val_accuracy: 0.9800\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0613 - accuracy: 0.9900 - val_loss: 0.1047 - val_accuracy: 0.9900\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0558 - accuracy: 0.9875 - val_loss: 0.1057 - val_accuracy: 0.9900\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0560 - accuracy: 0.9875 - val_loss: 0.0963 - val_accuracy: 0.9900\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0509 - accuracy: 0.9900 - val_loss: 0.0973 - val_accuracy: 0.9900\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0497 - accuracy: 0.9900 - val_loss: 0.0939 - val_accuracy: 0.9900\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0517 - accuracy: 0.9850 - val_loss: 0.0959 - val_accuracy: 0.9900\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0487 - accuracy: 0.9900 - val_loss: 0.1077 - val_accuracy: 0.9900\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0444 - accuracy: 0.9925 - val_loss: 0.0986 - val_accuracy: 0.9900\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0428 - accuracy: 0.9925 - val_loss: 0.0977 - val_accuracy: 0.9900\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0422 - accuracy: 0.9925 - val_loss: 0.0953 - val_accuracy: 0.9900\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0458 - accuracy: 0.9925 - val_loss: 0.0986 - val_accuracy: 0.9900\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.0416 - accuracy: 0.9925 - val_loss: 0.1027 - val_accuracy: 0.9900\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0378 - accuracy: 0.9950 - val_loss: 0.1016 - val_accuracy: 0.9900\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9900\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9900\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0342 - accuracy: 0.9975 - val_loss: 0.1046 - val_accuracy: 0.9900\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9900\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0315 - accuracy: 0.9975 - val_loss: 0.1038 - val_accuracy: 0.9900\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0310 - accuracy: 0.9975 - val_loss: 0.0993 - val_accuracy: 0.9900\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9900\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0303 - accuracy: 0.9975 - val_loss: 0.0992 - val_accuracy: 0.9900\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9900\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9900\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9900\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9900\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.4897982126066558\n",
      "F1 Micro: 0.937822019908959\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.47326910294185975\n",
      "F1 Micro: 0.9319193637136712\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5167190767858008\n",
      "F1 Micro: 0.942123955780101\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 6 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 242us/step - loss: 0.8062 - accuracy: 0.8418 - val_loss: 0.5957 - val_accuracy: 0.8650\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.6135 - accuracy: 0.8543 - val_loss: 0.5179 - val_accuracy: 0.8650\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.4887 - accuracy: 0.8727 - val_loss: 0.3885 - val_accuracy: 0.8950\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.3683 - accuracy: 0.9062 - val_loss: 0.3140 - val_accuracy: 0.9280\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.2955 - accuracy: 0.9193 - val_loss: 0.2673 - val_accuracy: 0.9310\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.2548 - accuracy: 0.9280 - val_loss: 0.2369 - val_accuracy: 0.9330\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.2259 - accuracy: 0.9367 - val_loss: 0.2377 - val_accuracy: 0.9360\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.2135 - accuracy: 0.9390 - val_loss: 0.3615 - val_accuracy: 0.9170\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1973 - accuracy: 0.9417 - val_loss: 0.2302 - val_accuracy: 0.9330\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1825 - accuracy: 0.9467 - val_loss: 0.2087 - val_accuracy: 0.9460\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1746 - accuracy: 0.9457 - val_loss: 0.2087 - val_accuracy: 0.9440\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1524 - accuracy: 0.9525 - val_loss: 0.1824 - val_accuracy: 0.9440\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1495 - accuracy: 0.9570 - val_loss: 0.1670 - val_accuracy: 0.9500\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1438 - accuracy: 0.9545 - val_loss: 0.2198 - val_accuracy: 0.9400\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1399 - accuracy: 0.9572 - val_loss: 0.1547 - val_accuracy: 0.9530\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1397 - accuracy: 0.9580 - val_loss: 0.1534 - val_accuracy: 0.9520\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.1240 - accuracy: 0.9597 - val_loss: 0.1596 - val_accuracy: 0.9450\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1204 - accuracy: 0.9613 - val_loss: 0.1451 - val_accuracy: 0.9590\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1104 - accuracy: 0.9653 - val_loss: 0.1451 - val_accuracy: 0.9600\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1088 - accuracy: 0.9650 - val_loss: 0.1577 - val_accuracy: 0.9480\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0999 - accuracy: 0.9660 - val_loss: 0.1711 - val_accuracy: 0.9510\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0989 - accuracy: 0.9665 - val_loss: 0.2017 - val_accuracy: 0.9480\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0962 - accuracy: 0.9700 - val_loss: 0.1395 - val_accuracy: 0.9590\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0934 - accuracy: 0.9700 - val_loss: 0.2081 - val_accuracy: 0.9470\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0974 - accuracy: 0.9670 - val_loss: 0.1891 - val_accuracy: 0.9550\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0873 - accuracy: 0.9732 - val_loss: 0.1409 - val_accuracy: 0.9540\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1148 - accuracy: 0.9622 - val_loss: 0.1307 - val_accuracy: 0.9610\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0733 - accuracy: 0.9772 - val_loss: 0.1423 - val_accuracy: 0.9610\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0729 - accuracy: 0.9760 - val_loss: 0.1340 - val_accuracy: 0.9610\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0635 - accuracy: 0.9808 - val_loss: 0.1430 - val_accuracy: 0.9620\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0659 - accuracy: 0.9793 - val_loss: 0.1374 - val_accuracy: 0.9550\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0589 - accuracy: 0.9830 - val_loss: 0.1392 - val_accuracy: 0.9610\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0589 - accuracy: 0.9830 - val_loss: 0.1554 - val_accuracy: 0.9550\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0528 - accuracy: 0.9845 - val_loss: 0.1364 - val_accuracy: 0.9620\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0468 - accuracy: 0.9868 - val_loss: 0.1431 - val_accuracy: 0.9600\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0514 - accuracy: 0.9840 - val_loss: 0.1653 - val_accuracy: 0.9590\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0457 - accuracy: 0.9865 - val_loss: 0.1542 - val_accuracy: 0.9570\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0478 - accuracy: 0.9852 - val_loss: 0.1475 - val_accuracy: 0.9540\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0382 - accuracy: 0.9895 - val_loss: 0.1532 - val_accuracy: 0.9610\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0429 - accuracy: 0.9862 - val_loss: 0.1495 - val_accuracy: 0.9600\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0323 - accuracy: 0.9905 - val_loss: 0.1562 - val_accuracy: 0.9590\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0294 - accuracy: 0.9930 - val_loss: 0.1695 - val_accuracy: 0.9510\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0266 - accuracy: 0.9935 - val_loss: 0.1593 - val_accuracy: 0.9550\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0280 - accuracy: 0.9930 - val_loss: 0.1838 - val_accuracy: 0.9540\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0261 - accuracy: 0.9937 - val_loss: 0.1631 - val_accuracy: 0.9580\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0191 - accuracy: 0.9967 - val_loss: 0.1665 - val_accuracy: 0.9580\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0200 - accuracy: 0.9967 - val_loss: 0.1648 - val_accuracy: 0.9560\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5279193744717348\n",
      "F1 Micro: 0.9547\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6713535674198816\n",
      "F1 Micro: 0.9569\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 86us/step - loss: 1.7035 - accuracy: 0.5497 - val_loss: 1.2880 - val_accuracy: 0.7210\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 1.0886 - accuracy: 0.7905 - val_loss: 0.7930 - val_accuracy: 0.8690\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.6612 - accuracy: 0.8830 - val_loss: 0.4759 - val_accuracy: 0.9290\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.4110 - accuracy: 0.9255 - val_loss: 0.3144 - val_accuracy: 0.9470\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.2889 - accuracy: 0.9392 - val_loss: 0.2435 - val_accuracy: 0.9570\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.2318 - accuracy: 0.9475 - val_loss: 0.2113 - val_accuracy: 0.9550\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.2005 - accuracy: 0.9513 - val_loss: 0.1952 - val_accuracy: 0.9540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1829 - accuracy: 0.9525 - val_loss: 0.1837 - val_accuracy: 0.9580\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1704 - accuracy: 0.9545 - val_loss: 0.1762 - val_accuracy: 0.9600\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1603 - accuracy: 0.9563 - val_loss: 0.1692 - val_accuracy: 0.9590\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1530 - accuracy: 0.9557 - val_loss: 0.1660 - val_accuracy: 0.9590\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1462 - accuracy: 0.9580 - val_loss: 0.1618 - val_accuracy: 0.9590\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1408 - accuracy: 0.9605 - val_loss: 0.1604 - val_accuracy: 0.9600\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.1351 - accuracy: 0.9607 - val_loss: 0.1571 - val_accuracy: 0.9610\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1317 - accuracy: 0.9625 - val_loss: 0.1539 - val_accuracy: 0.9610\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1266 - accuracy: 0.9632 - val_loss: 0.1526 - val_accuracy: 0.9610\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.1237 - accuracy: 0.9657 - val_loss: 0.1506 - val_accuracy: 0.9610\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1196 - accuracy: 0.9660 - val_loss: 0.1506 - val_accuracy: 0.9600\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1164 - accuracy: 0.9665 - val_loss: 0.1489 - val_accuracy: 0.9600\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1136 - accuracy: 0.9672 - val_loss: 0.1477 - val_accuracy: 0.9610\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1107 - accuracy: 0.9685 - val_loss: 0.1489 - val_accuracy: 0.9570\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1084 - accuracy: 0.9680 - val_loss: 0.1460 - val_accuracy: 0.9600\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 61us/step - loss: 0.1058 - accuracy: 0.9707 - val_loss: 0.1448 - val_accuracy: 0.9620\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1038 - accuracy: 0.9695 - val_loss: 0.1455 - val_accuracy: 0.9590\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1022 - accuracy: 0.9690 - val_loss: 0.1437 - val_accuracy: 0.9600\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0994 - accuracy: 0.9707 - val_loss: 0.1451 - val_accuracy: 0.9600\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0976 - accuracy: 0.9722 - val_loss: 0.1416 - val_accuracy: 0.9600\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0959 - accuracy: 0.9720 - val_loss: 0.1423 - val_accuracy: 0.9600\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0941 - accuracy: 0.9730 - val_loss: 0.1400 - val_accuracy: 0.9600\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0921 - accuracy: 0.9737 - val_loss: 0.1418 - val_accuracy: 0.9590\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0908 - accuracy: 0.9725 - val_loss: 0.1412 - val_accuracy: 0.9600\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0889 - accuracy: 0.9750 - val_loss: 0.1402 - val_accuracy: 0.9600\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0876 - accuracy: 0.9758 - val_loss: 0.1381 - val_accuracy: 0.9600\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.0861 - accuracy: 0.9760 - val_loss: 0.1403 - val_accuracy: 0.9600\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0840 - accuracy: 0.9772 - val_loss: 0.1384 - val_accuracy: 0.9610\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0832 - accuracy: 0.9775 - val_loss: 0.1381 - val_accuracy: 0.9620\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0818 - accuracy: 0.9775 - val_loss: 0.1370 - val_accuracy: 0.9610\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0803 - accuracy: 0.9770 - val_loss: 0.1382 - val_accuracy: 0.9600\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0793 - accuracy: 0.9778 - val_loss: 0.1370 - val_accuracy: 0.9610\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0776 - accuracy: 0.9797 - val_loss: 0.1353 - val_accuracy: 0.9610\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0763 - accuracy: 0.9785 - val_loss: 0.1393 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0755 - accuracy: 0.9775 - val_loss: 0.1358 - val_accuracy: 0.9600\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0751 - accuracy: 0.9780 - val_loss: 0.1375 - val_accuracy: 0.9600\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0732 - accuracy: 0.9800 - val_loss: 0.1352 - val_accuracy: 0.9620\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0719 - accuracy: 0.9795 - val_loss: 0.1374 - val_accuracy: 0.9610\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0713 - accuracy: 0.9805 - val_loss: 0.1351 - val_accuracy: 0.9610\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0696 - accuracy: 0.9808 - val_loss: 0.1357 - val_accuracy: 0.9620\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0690 - accuracy: 0.9805 - val_loss: 0.1347 - val_accuracy: 0.9600\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0681 - accuracy: 0.9808 - val_loss: 0.1338 - val_accuracy: 0.9610\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0672 - accuracy: 0.9820 - val_loss: 0.1345 - val_accuracy: 0.9600\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0660 - accuracy: 0.9805 - val_loss: 0.1342 - val_accuracy: 0.9600\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0651 - accuracy: 0.9827 - val_loss: 0.1364 - val_accuracy: 0.9580\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0636 - accuracy: 0.9830 - val_loss: 0.1333 - val_accuracy: 0.9620\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0632 - accuracy: 0.9833 - val_loss: 0.1313 - val_accuracy: 0.9600\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0627 - accuracy: 0.9840 - val_loss: 0.1338 - val_accuracy: 0.9590\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0616 - accuracy: 0.9843 - val_loss: 0.1326 - val_accuracy: 0.9610\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0602 - accuracy: 0.9843 - val_loss: 0.1320 - val_accuracy: 0.9620\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0598 - accuracy: 0.9837 - val_loss: 0.1323 - val_accuracy: 0.9600\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0585 - accuracy: 0.9850 - val_loss: 0.1329 - val_accuracy: 0.9590\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0578 - accuracy: 0.9852 - val_loss: 0.1321 - val_accuracy: 0.9580\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0573 - accuracy: 0.9855 - val_loss: 0.1317 - val_accuracy: 0.9630\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0563 - accuracy: 0.9855 - val_loss: 0.1300 - val_accuracy: 0.9590\n",
      "Epoch 63/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0557 - accuracy: 0.9850 - val_loss: 0.1311 - val_accuracy: 0.9610\n",
      "Epoch 64/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0553 - accuracy: 0.9845 - val_loss: 0.1334 - val_accuracy: 0.9600\n",
      "Epoch 65/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0536 - accuracy: 0.9865 - val_loss: 0.1307 - val_accuracy: 0.9600\n",
      "Epoch 66/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0537 - accuracy: 0.9855 - val_loss: 0.1319 - val_accuracy: 0.9610\n",
      "Epoch 67/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0524 - accuracy: 0.9875 - val_loss: 0.1299 - val_accuracy: 0.9610\n",
      "Epoch 68/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0514 - accuracy: 0.9872 - val_loss: 0.1343 - val_accuracy: 0.9580\n",
      "Epoch 69/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0512 - accuracy: 0.9862 - val_loss: 0.1329 - val_accuracy: 0.9620\n",
      "Epoch 70/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0506 - accuracy: 0.9877 - val_loss: 0.1310 - val_accuracy: 0.9620\n",
      "Epoch 71/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0497 - accuracy: 0.9870 - val_loss: 0.1317 - val_accuracy: 0.9620\n",
      "Epoch 72/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0491 - accuracy: 0.9887 - val_loss: 0.1331 - val_accuracy: 0.9600\n",
      "Epoch 73/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0485 - accuracy: 0.9877 - val_loss: 0.1325 - val_accuracy: 0.9610\n",
      "Epoch 74/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0475 - accuracy: 0.9885 - val_loss: 0.1294 - val_accuracy: 0.9620\n",
      "Epoch 75/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0473 - accuracy: 0.9887 - val_loss: 0.1304 - val_accuracy: 0.9610\n",
      "Epoch 76/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0464 - accuracy: 0.9872 - val_loss: 0.1337 - val_accuracy: 0.9590\n",
      "Epoch 77/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0457 - accuracy: 0.9885 - val_loss: 0.1316 - val_accuracy: 0.9600\n",
      "Epoch 78/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0453 - accuracy: 0.9883 - val_loss: 0.1307 - val_accuracy: 0.9620\n",
      "Epoch 79/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0446 - accuracy: 0.9893 - val_loss: 0.1337 - val_accuracy: 0.9600\n",
      "Epoch 80/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0442 - accuracy: 0.9883 - val_loss: 0.1312 - val_accuracy: 0.9620\n",
      "Epoch 81/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0433 - accuracy: 0.9893 - val_loss: 0.1332 - val_accuracy: 0.9620\n",
      "Epoch 82/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0430 - accuracy: 0.9890 - val_loss: 0.1328 - val_accuracy: 0.9610\n",
      "Epoch 83/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0418 - accuracy: 0.9902 - val_loss: 0.1338 - val_accuracy: 0.9610\n",
      "Epoch 84/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0412 - accuracy: 0.9902 - val_loss: 0.1343 - val_accuracy: 0.9610\n",
      "Epoch 85/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0411 - accuracy: 0.9885 - val_loss: 0.1321 - val_accuracy: 0.9600\n",
      "Epoch 86/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0406 - accuracy: 0.9900 - val_loss: 0.1316 - val_accuracy: 0.9630\n",
      "Epoch 87/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0397 - accuracy: 0.9895 - val_loss: 0.1326 - val_accuracy: 0.9630\n",
      "Epoch 88/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0398 - accuracy: 0.9898 - val_loss: 0.1317 - val_accuracy: 0.9610\n",
      "Epoch 89/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0391 - accuracy: 0.9908 - val_loss: 0.1336 - val_accuracy: 0.9590\n",
      "Epoch 90/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0380 - accuracy: 0.9900 - val_loss: 0.1334 - val_accuracy: 0.9640\n",
      "Epoch 91/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0375 - accuracy: 0.9912 - val_loss: 0.1313 - val_accuracy: 0.9600\n",
      "Epoch 92/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0373 - accuracy: 0.9905 - val_loss: 0.1335 - val_accuracy: 0.9620\n",
      "Epoch 93/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0364 - accuracy: 0.9908 - val_loss: 0.1335 - val_accuracy: 0.9620\n",
      "Epoch 94/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0363 - accuracy: 0.9908 - val_loss: 0.1346 - val_accuracy: 0.9610\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6993164564620495\n",
      "F1 Micro: 0.9595\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 241us/step - loss: 0.6300 - accuracy: 0.8310 - val_loss: 0.3320 - val_accuracy: 0.9110\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.3091 - accuracy: 0.9147 - val_loss: 0.2794 - val_accuracy: 0.9250\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.2546 - accuracy: 0.9295 - val_loss: 0.2401 - val_accuracy: 0.9400\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.2253 - accuracy: 0.9365 - val_loss: 0.2121 - val_accuracy: 0.9420\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.2006 - accuracy: 0.9435 - val_loss: 0.1997 - val_accuracy: 0.9470\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1832 - accuracy: 0.9467 - val_loss: 0.1888 - val_accuracy: 0.9460\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1723 - accuracy: 0.9480 - val_loss: 0.1889 - val_accuracy: 0.9440\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1613 - accuracy: 0.9517 - val_loss: 0.1921 - val_accuracy: 0.9460\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1548 - accuracy: 0.9523 - val_loss: 0.1728 - val_accuracy: 0.9570\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.1453 - accuracy: 0.9572 - val_loss: 0.1649 - val_accuracy: 0.9540\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1365 - accuracy: 0.9590 - val_loss: 0.1608 - val_accuracy: 0.9560\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1319 - accuracy: 0.9588 - val_loss: 0.1667 - val_accuracy: 0.9490\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1278 - accuracy: 0.9628 - val_loss: 0.1584 - val_accuracy: 0.9540\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1254 - accuracy: 0.9620 - val_loss: 0.1527 - val_accuracy: 0.9580\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1193 - accuracy: 0.9645 - val_loss: 0.1625 - val_accuracy: 0.9540\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1119 - accuracy: 0.9650 - val_loss: 0.1507 - val_accuracy: 0.9590\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.1086 - accuracy: 0.9682 - val_loss: 0.1479 - val_accuracy: 0.9550\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1036 - accuracy: 0.9712 - val_loss: 0.1477 - val_accuracy: 0.9600\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0999 - accuracy: 0.9718 - val_loss: 0.1542 - val_accuracy: 0.9580\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0932 - accuracy: 0.9745 - val_loss: 0.1438 - val_accuracy: 0.9550\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0900 - accuracy: 0.9755 - val_loss: 0.1441 - val_accuracy: 0.9580\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0846 - accuracy: 0.9772 - val_loss: 0.1608 - val_accuracy: 0.9510\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0870 - accuracy: 0.9768 - val_loss: 0.1478 - val_accuracy: 0.9500\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0807 - accuracy: 0.9745 - val_loss: 0.1376 - val_accuracy: 0.9570\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0738 - accuracy: 0.9795 - val_loss: 0.1512 - val_accuracy: 0.9510\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0726 - accuracy: 0.9795 - val_loss: 0.1369 - val_accuracy: 0.9580\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0673 - accuracy: 0.9820 - val_loss: 0.1372 - val_accuracy: 0.9560\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0643 - accuracy: 0.9825 - val_loss: 0.1319 - val_accuracy: 0.9580\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0563 - accuracy: 0.9847 - val_loss: 0.1389 - val_accuracy: 0.9590\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.0542 - accuracy: 0.9855 - val_loss: 0.1338 - val_accuracy: 0.9590\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0505 - accuracy: 0.9860 - val_loss: 0.1397 - val_accuracy: 0.9610\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0454 - accuracy: 0.9885 - val_loss: 0.1369 - val_accuracy: 0.9560\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0418 - accuracy: 0.9895 - val_loss: 0.1407 - val_accuracy: 0.9590\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0383 - accuracy: 0.9910 - val_loss: 0.1567 - val_accuracy: 0.9550\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0395 - accuracy: 0.9895 - val_loss: 0.1393 - val_accuracy: 0.9580\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0330 - accuracy: 0.9933 - val_loss: 0.1486 - val_accuracy: 0.9560\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0291 - accuracy: 0.9948 - val_loss: 0.1317 - val_accuracy: 0.9630\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0261 - accuracy: 0.9948 - val_loss: 0.1532 - val_accuracy: 0.9510\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0231 - accuracy: 0.9973 - val_loss: 0.1374 - val_accuracy: 0.9620\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0214 - accuracy: 0.9970 - val_loss: 0.1353 - val_accuracy: 0.9630\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0171 - accuracy: 0.9975 - val_loss: 0.1443 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0157 - accuracy: 0.9985 - val_loss: 0.1396 - val_accuracy: 0.9620\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0142 - accuracy: 0.9990 - val_loss: 0.1495 - val_accuracy: 0.9600\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0132 - accuracy: 0.9987 - val_loss: 0.2120 - val_accuracy: 0.9580\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0133 - accuracy: 0.9983 - val_loss: 0.1464 - val_accuracy: 0.9610\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0113 - accuracy: 0.9987 - val_loss: 0.1521 - val_accuracy: 0.9560\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0089 - accuracy: 0.9995 - val_loss: 0.1494 - val_accuracy: 0.9590\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.1481 - val_accuracy: 0.9610\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 0.9620\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.1580 - val_accuracy: 0.9630\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1685 - val_accuracy: 0.9610\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9580\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9600\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9630\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9610\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9570\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9620\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7028125290535159\n",
      "F1 Micro: 0.9614\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6924980000271638\n",
      "F1 Micro: 0.9577000000000001\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7081541267326003\n",
      "F1 Micro: 0.9634\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 6 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.4083 - accuracy: 0.9012 - val_loss: 0.2528 - val_accuracy: 0.9336\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.1828 - accuracy: 0.9455 - val_loss: 0.1392 - val_accuracy: 0.9578\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1456 - accuracy: 0.9558 - val_loss: 0.1218 - val_accuracy: 0.9629\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1288 - accuracy: 0.9597 - val_loss: 0.1257 - val_accuracy: 0.9607\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.1181 - accuracy: 0.9633 - val_loss: 0.1258 - val_accuracy: 0.9605\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1096 - accuracy: 0.9658 - val_loss: 0.1045 - val_accuracy: 0.9678\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.1018 - accuracy: 0.9675 - val_loss: 0.1177 - val_accuracy: 0.9603\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0941 - accuracy: 0.9696 - val_loss: 0.1002 - val_accuracy: 0.9682\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0903 - accuracy: 0.9712 - val_loss: 0.0895 - val_accuracy: 0.9712\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0849 - accuracy: 0.9724 - val_loss: 0.0896 - val_accuracy: 0.9713\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0797 - accuracy: 0.9735 - val_loss: 0.0859 - val_accuracy: 0.9731\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0749 - accuracy: 0.9753 - val_loss: 0.0886 - val_accuracy: 0.9713\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0703 - accuracy: 0.9772 - val_loss: 0.0907 - val_accuracy: 0.9714\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0655 - accuracy: 0.9782 - val_loss: 0.0876 - val_accuracy: 0.9745\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0604 - accuracy: 0.9798 - val_loss: 0.0902 - val_accuracy: 0.9701\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0577 - accuracy: 0.9810 - val_loss: 0.1106 - val_accuracy: 0.9687\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0509 - accuracy: 0.9830 - val_loss: 0.1176 - val_accuracy: 0.9615\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0473 - accuracy: 0.9844 - val_loss: 0.0976 - val_accuracy: 0.9695\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0427 - accuracy: 0.9852 - val_loss: 0.0884 - val_accuracy: 0.9719\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0389 - accuracy: 0.9872 - val_loss: 0.0981 - val_accuracy: 0.9714\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0364 - accuracy: 0.9874 - val_loss: 0.0871 - val_accuracy: 0.9731\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0303 - accuracy: 0.9897 - val_loss: 0.0940 - val_accuracy: 0.9715\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 0.0964 - val_accuracy: 0.9712\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.0978 - val_accuracy: 0.9732\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.1211 - val_accuracy: 0.9650\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.1298 - val_accuracy: 0.9662\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 0.1133 - val_accuracy: 0.9734\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.1263 - val_accuracy: 0.9725\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.1197 - val_accuracy: 0.9707\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.1347 - val_accuracy: 0.9715\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.1263 - val_accuracy: 0.9727\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8225523820102342\n",
      "F1 Micro: 0.9705\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.794429962429242\n",
      "F1 Micro: 0.9647\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.5108 - accuracy: 0.8801 - val_loss: 0.1613 - val_accuracy: 0.9542\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1473 - accuracy: 0.9568 - val_loss: 0.1298 - val_accuracy: 0.9622\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1278 - accuracy: 0.9617 - val_loss: 0.1197 - val_accuracy: 0.9634\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1187 - accuracy: 0.9638 - val_loss: 0.1162 - val_accuracy: 0.9655\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.1123 - accuracy: 0.9657 - val_loss: 0.1110 - val_accuracy: 0.9649\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.1077 - accuracy: 0.9665 - val_loss: 0.1044 - val_accuracy: 0.9674\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1039 - accuracy: 0.9670 - val_loss: 0.1026 - val_accuracy: 0.9679\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1009 - accuracy: 0.9686 - val_loss: 0.1006 - val_accuracy: 0.9688\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0982 - accuracy: 0.9700 - val_loss: 0.0980 - val_accuracy: 0.9695\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0960 - accuracy: 0.9704 - val_loss: 0.0976 - val_accuracy: 0.9691\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0939 - accuracy: 0.9710 - val_loss: 0.0980 - val_accuracy: 0.9684\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0921 - accuracy: 0.9717 - val_loss: 0.0958 - val_accuracy: 0.9693\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0903 - accuracy: 0.9715 - val_loss: 0.0945 - val_accuracy: 0.9701\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0889 - accuracy: 0.9722 - val_loss: 0.0943 - val_accuracy: 0.9707\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0871 - accuracy: 0.9733 - val_loss: 0.0946 - val_accuracy: 0.9698\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0859 - accuracy: 0.9732 - val_loss: 0.0936 - val_accuracy: 0.9709\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0848 - accuracy: 0.9738 - val_loss: 0.0929 - val_accuracy: 0.9714 \n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0833 - accuracy: 0.9739 - val_loss: 0.0925 - val_accuracy: 0.9709\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0820 - accuracy: 0.9747 - val_loss: 0.0946 - val_accuracy: 0.9696\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0815 - accuracy: 0.9747 - val_loss: 0.0919 - val_accuracy: 0.9709\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0803 - accuracy: 0.9750 - val_loss: 0.0911 - val_accuracy: 0.9722\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0790 - accuracy: 0.9751 - val_loss: 0.0911 - val_accuracy: 0.9704\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0780 - accuracy: 0.9758 - val_loss: 0.0906 - val_accuracy: 0.9710\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0772 - accuracy: 0.9758 - val_loss: 0.0914 - val_accuracy: 0.9712\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0762 - accuracy: 0.9763 - val_loss: 0.0926 - val_accuracy: 0.9705\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0753 - accuracy: 0.9767 - val_loss: 0.0917 - val_accuracy: 0.9713\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0744 - accuracy: 0.9768 - val_loss: 0.0915 - val_accuracy: 0.9710 0s - loss: 0.0739 - ac\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0734 - accuracy: 0.9772 - val_loss: 0.0916 - val_accuracy: 0.9708\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0727 - accuracy: 0.9775 - val_loss: 0.0920 - val_accuracy: 0.9706\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0716 - accuracy: 0.9775 - val_loss: 0.0908 - val_accuracy: 0.9709\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0712 - accuracy: 0.9778 - val_loss: 0.0894 - val_accuracy: 0.9723\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0699 - accuracy: 0.9782 - val_loss: 0.0895 - val_accuracy: 0.9722\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0692 - accuracy: 0.9787 - val_loss: 0.0902 - val_accuracy: 0.9719\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0682 - accuracy: 0.9787 - val_loss: 0.0913 - val_accuracy: 0.9717\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0678 - accuracy: 0.9793 - val_loss: 0.0898 - val_accuracy: 0.9720\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0668 - accuracy: 0.9795 - val_loss: 0.0910 - val_accuracy: 0.9718\n",
      "Epoch 37/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0662 - accuracy: 0.9793 - val_loss: 0.0929 - val_accuracy: 0.9707 0s - loss: 0.0633 - accu - ETA: 0s - loss: 0.0654 - ac\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0652 - accuracy: 0.9802 - val_loss: 0.0907 - val_accuracy: 0.9723\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0646 - accuracy: 0.9798 - val_loss: 0.0896 - val_accuracy: 0.9720\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0636 - accuracy: 0.9806 - val_loss: 0.0912 - val_accuracy: 0.9722\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0631 - accuracy: 0.9807 - val_loss: 0.0899 - val_accuracy: 0.9716\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0624 - accuracy: 0.9806 - val_loss: 0.0923 - val_accuracy: 0.9716\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0616 - accuracy: 0.9812 - val_loss: 0.0914 - val_accuracy: 0.9708\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0610 - accuracy: 0.9814 - val_loss: 0.0908 - val_accuracy: 0.9713\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0603 - accuracy: 0.9820 - val_loss: 0.0913 - val_accuracy: 0.9717\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0597 - accuracy: 0.9820 - val_loss: 0.0901 - val_accuracy: 0.9721\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0591 - accuracy: 0.9819 - val_loss: 0.0921 - val_accuracy: 0.9711\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0584 - accuracy: 0.9823 - val_loss: 0.0925 - val_accuracy: 0.9713\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0578 - accuracy: 0.9823 - val_loss: 0.0926 - val_accuracy: 0.9708\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0574 - accuracy: 0.9826 - val_loss: 0.0930 - val_accuracy: 0.9717\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0562 - accuracy: 0.9825 - val_loss: 0.0916 - val_accuracy: 0.9722\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8612914910270261\n",
      "F1 Micro: 0.9718\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.2562 - accuracy: 0.9303 - val_loss: 0.1512 - val_accuracy: 0.9553\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.1458 - accuracy: 0.9557 - val_loss: 0.1241 - val_accuracy: 0.9596\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1257 - accuracy: 0.9602 - val_loss: 0.1173 - val_accuracy: 0.9644\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.1144 - accuracy: 0.9643 - val_loss: 0.1039 - val_accuracy: 0.9661\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1060 - accuracy: 0.9663 - val_loss: 0.0982 - val_accuracy: 0.9690\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0980 - accuracy: 0.9693 - val_loss: 0.0982 - val_accuracy: 0.9681\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0910 - accuracy: 0.9711 - val_loss: 0.0868 - val_accuracy: 0.9730\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0848 - accuracy: 0.9731 - val_loss: 0.0826 - val_accuracy: 0.9741\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0789 - accuracy: 0.9748 - val_loss: 0.0825 - val_accuracy: 0.9733\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0749 - accuracy: 0.9762 - val_loss: 0.0920 - val_accuracy: 0.9687\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0690 - accuracy: 0.9785 - val_loss: 0.0829 - val_accuracy: 0.9733\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0647 - accuracy: 0.9790 - val_loss: 0.0817 - val_accuracy: 0.9741\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0589 - accuracy: 0.9809 - val_loss: 0.0836 - val_accuracy: 0.9735\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0536 - accuracy: 0.9829 - val_loss: 0.0833 - val_accuracy: 0.9742\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0486 - accuracy: 0.9843 - val_loss: 0.0882 - val_accuracy: 0.9745\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0424 - accuracy: 0.9862 - val_loss: 0.0866 - val_accuracy: 0.9746\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0359 - accuracy: 0.9885 - val_loss: 0.0896 - val_accuracy: 0.9737\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.0959 - val_accuracy: 0.9720\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.1005 - val_accuracy: 0.9732\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.1127 - val_accuracy: 0.9703\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0158 - accuracy: 0.9955 - val_loss: 0.1074 - val_accuracy: 0.9735\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.1243 - val_accuracy: 0.9708\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.1307 - val_accuracy: 0.9732\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.1298 - val_accuracy: 0.9694\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.1362 - val_accuracy: 0.9727\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1332 - val_accuracy: 0.9698\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.1324 - val_accuracy: 0.9745\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1365 - val_accuracy: 0.9732\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.1355 - val_accuracy: 0.9733\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.1371 - val_accuracy: 0.9711\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.1391 - val_accuracy: 0.9716\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.1561 - val_accuracy: 0.9720\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8739105162593103\n",
      "F1 Micro: 0.9755\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7831024007469115\n",
      "F1 Micro: 0.9612\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8779450343779734\n",
      "F1 Micro: 0.9755\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 6 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.2342 - accuracy: 0.9366 - val_loss: 0.1325 - val_accuracy: 0.9587\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.1255 - accuracy: 0.9605 - val_loss: 0.1143 - val_accuracy: 0.9632\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.1054 - accuracy: 0.9666 - val_loss: 0.0983 - val_accuracy: 0.9681\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0935 - accuracy: 0.9697 - val_loss: 0.1054 - val_accuracy: 0.9672\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0841 - accuracy: 0.9722 - val_loss: 0.0888 - val_accuracy: 0.9709\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0755 - accuracy: 0.9745 - val_loss: 0.0862 - val_accuracy: 0.9711\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0687 - accuracy: 0.9768 - val_loss: 0.0745 - val_accuracy: 0.9752\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0625 - accuracy: 0.9782 - val_loss: 0.0714 - val_accuracy: 0.9749\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0562 - accuracy: 0.9805 - val_loss: 0.0682 - val_accuracy: 0.9769\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0521 - accuracy: 0.9815 - val_loss: 0.0900 - val_accuracy: 0.9726\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0468 - accuracy: 0.9834 - val_loss: 0.0810 - val_accuracy: 0.9737\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0423 - accuracy: 0.9852 - val_loss: 0.0766 - val_accuracy: 0.9739\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0372 - accuracy: 0.9867 - val_loss: 0.0770 - val_accuracy: 0.9750\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0327 - accuracy: 0.9883 - val_loss: 0.0757 - val_accuracy: 0.9768\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0279 - accuracy: 0.9899 - val_loss: 0.0857 - val_accuracy: 0.9723\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.0866 - val_accuracy: 0.9755\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.0897 - val_accuracy: 0.9749\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.0954 - val_accuracy: 0.9764\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.1014 - val_accuracy: 0.9754\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.1148 - val_accuracy: 0.9756\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.1237 - val_accuracy: 0.9763\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.1262 - val_accuracy: 0.9759\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.1385 - val_accuracy: 0.9750\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.1323 - val_accuracy: 0.9760\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.1496 - val_accuracy: 0.9711\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.1355 - val_accuracy: 0.9737\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1321 - val_accuracy: 0.9751\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.1313 - val_accuracy: 0.9753\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.1367 - val_accuracy: 0.9742\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8841727287633953\n",
      "F1 Micro: 0.9761\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8344296227415591\n",
      "F1 Micro: 0.9696\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.2504 - accuracy: 0.9362 - val_loss: 0.1233 - val_accuracy: 0.9619\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.1123 - accuracy: 0.9654 - val_loss: 0.1105 - val_accuracy: 0.9651\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.1028 - accuracy: 0.9680 - val_loss: 0.1039 - val_accuracy: 0.9670\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0976 - accuracy: 0.9694 - val_loss: 0.0995 - val_accuracy: 0.9687\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0938 - accuracy: 0.9708 - val_loss: 0.0981 - val_accuracy: 0.9683\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0911 - accuracy: 0.9713 - val_loss: 0.0952 - val_accuracy: 0.9693\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0889 - accuracy: 0.9723 - val_loss: 0.0939 - val_accuracy: 0.9692\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0869 - accuracy: 0.9725 - val_loss: 0.0933 - val_accuracy: 0.9693\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0850 - accuracy: 0.9730 - val_loss: 0.0909 - val_accuracy: 0.9701\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0834 - accuracy: 0.9732 - val_loss: 0.0908 - val_accuracy: 0.9707\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0819 - accuracy: 0.9739 - val_loss: 0.0898 - val_accuracy: 0.9704\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0806 - accuracy: 0.9742 - val_loss: 0.0875 - val_accuracy: 0.9705\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0796 - accuracy: 0.9746 - val_loss: 0.0884 - val_accuracy: 0.9709\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0781 - accuracy: 0.9748 - val_loss: 0.0874 - val_accuracy: 0.9711\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0770 - accuracy: 0.9754 - val_loss: 0.0873 - val_accuracy: 0.97150.0 - ETA: 0s - loss: 0.0\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0760 - accuracy: 0.9755 - val_loss: 0.0854 - val_accuracy: 0.9716\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0750 - accuracy: 0.9757 - val_loss: 0.0861 - val_accuracy: 0.9719\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0741 - accuracy: 0.9759 - val_loss: 0.0855 - val_accuracy: 0.9721\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0732 - accuracy: 0.9762 - val_loss: 0.0856 - val_accuracy: 0.9715\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0724 - accuracy: 0.9763 - val_loss: 0.0844 - val_accuracy: 0.9720\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0713 - accuracy: 0.9770 - val_loss: 0.0842 - val_accuracy: 0.9721\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0705 - accuracy: 0.9771 - val_loss: 0.0844 - val_accuracy: 0.9715\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0696 - accuracy: 0.9773 - val_loss: 0.0851 - val_accuracy: 0.9720\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0692 - accuracy: 0.9777 - val_loss: 0.0835 - val_accuracy: 0.9718\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0683 - accuracy: 0.9777 - val_loss: 0.0832 - val_accuracy: 0.9726\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0676 - accuracy: 0.9780 - val_loss: 0.0829 - val_accuracy: 0.9727\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0669 - accuracy: 0.9783 - val_loss: 0.0828 - val_accuracy: 0.9727\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0661 - accuracy: 0.9785 - val_loss: 0.0841 - val_accuracy: 0.9727\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0656 - accuracy: 0.9788 - val_loss: 0.0837 - val_accuracy: 0.9723\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0648 - accuracy: 0.9791 - val_loss: 0.0817 - val_accuracy: 0.9727\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0642 - accuracy: 0.9791 - val_loss: 0.0827 - val_accuracy: 0.9726\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0636 - accuracy: 0.9793 - val_loss: 0.0823 - val_accuracy: 0.9730\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0629 - accuracy: 0.9794 - val_loss: 0.0833 - val_accuracy: 0.9724\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0623 - accuracy: 0.9796 - val_loss: 0.0815 - val_accuracy: 0.9733\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0618 - accuracy: 0.9799 - val_loss: 0.0839 - val_accuracy: 0.9724\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0609 - accuracy: 0.9803 - val_loss: 0.0820 - val_accuracy: 0.9734\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0604 - accuracy: 0.9804 - val_loss: 0.0847 - val_accuracy: 0.9722\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0597 - accuracy: 0.9808 - val_loss: 0.0816 - val_accuracy: 0.9737\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0593 - accuracy: 0.9806 - val_loss: 0.0823 - val_accuracy: 0.9728\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0587 - accuracy: 0.9811 - val_loss: 0.0818 - val_accuracy: 0.9734\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0581 - accuracy: 0.9813 - val_loss: 0.0815 - val_accuracy: 0.9735\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0576 - accuracy: 0.9814 - val_loss: 0.0828 - val_accuracy: 0.9732\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0570 - accuracy: 0.9817 - val_loss: 0.0823 - val_accuracy: 0.9732\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.0811 - val_accuracy: 0.9732 0s - l\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0559 - accuracy: 0.9819 - val_loss: 0.0815 - val_accuracy: 0.9734\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0552 - accuracy: 0.9822 - val_loss: 0.0816 - val_accuracy: 0.9732\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0548 - accuracy: 0.9820 - val_loss: 0.0841 - val_accuracy: 0.9733\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0541 - accuracy: 0.9825 - val_loss: 0.0826 - val_accuracy: 0.9736\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0536 - accuracy: 0.9825 - val_loss: 0.0835 - val_accuracy: 0.9726\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0531 - accuracy: 0.9829 - val_loss: 0.0822 - val_accuracy: 0.9734\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0526 - accuracy: 0.9830 - val_loss: 0.0842 - val_accuracy: 0.9725\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0518 - accuracy: 0.9835 - val_loss: 0.0851 - val_accuracy: 0.9726\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0515 - accuracy: 0.9836 - val_loss: 0.0836 - val_accuracy: 0.9731\n",
      "Epoch 54/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0510 - accuracy: 0.9835 - val_loss: 0.0856 - val_accuracy: 0.9730\n",
      "Epoch 55/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0505 - accuracy: 0.9839 - val_loss: 0.0839 - val_accuracy: 0.9733\n",
      "Epoch 56/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0499 - accuracy: 0.9837 - val_loss: 0.0840 - val_accuracy: 0.9734\n",
      "Epoch 57/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0494 - accuracy: 0.9840 - val_loss: 0.0848 - val_accuracy: 0.9733\n",
      "Epoch 58/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0489 - accuracy: 0.9842 - val_loss: 0.0851 - val_accuracy: 0.9726\n",
      "Epoch 59/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0486 - accuracy: 0.9842 - val_loss: 0.0851 - val_accuracy: 0.9724\n",
      "Epoch 60/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0478 - accuracy: 0.9846 - val_loss: 0.0841 - val_accuracy: 0.9734\n",
      "Epoch 61/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0474 - accuracy: 0.9849 - val_loss: 0.0867 - val_accuracy: 0.9726\n",
      "Epoch 62/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0471 - accuracy: 0.9848 - val_loss: 0.0846 - val_accuracy: 0.9731\n",
      "Epoch 63/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0466 - accuracy: 0.9850 - val_loss: 0.0847 - val_accuracy: 0.9732\n",
      "Epoch 64/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.0863 - val_accuracy: 0.9728\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8746915420022241\n",
      "F1 Micro: 0.9749\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.1667 - accuracy: 0.9513 - val_loss: 0.1208 - val_accuracy: 0.9627\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.1062 - accuracy: 0.9661 - val_loss: 0.1028 - val_accuracy: 0.9668\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0942 - accuracy: 0.9701 - val_loss: 0.0934 - val_accuracy: 0.9693\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0839 - accuracy: 0.9726 - val_loss: 0.0870 - val_accuracy: 0.9716\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0766 - accuracy: 0.9749 - val_loss: 0.0835 - val_accuracy: 0.9722\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0703 - accuracy: 0.9767 - val_loss: 0.0790 - val_accuracy: 0.9734\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0645 - accuracy: 0.9783 - val_loss: 0.0770 - val_accuracy: 0.9748\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0588 - accuracy: 0.9804 - val_loss: 0.0733 - val_accuracy: 0.9750\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0530 - accuracy: 0.9819 - val_loss: 0.0744 - val_accuracy: 0.9757\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0459 - accuracy: 0.9846 - val_loss: 0.0741 - val_accuracy: 0.9754\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0397 - accuracy: 0.9865 - val_loss: 0.0723 - val_accuracy: 0.9759\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0332 - accuracy: 0.9888 - val_loss: 0.0798 - val_accuracy: 0.9754\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.0840 - val_accuracy: 0.9759\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.0883 - val_accuracy: 0.9768\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.1014 - val_accuracy: 0.9764\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.1163 - val_accuracy: 0.9753\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.1257 - val_accuracy: 0.9755\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.1356 - val_accuracy: 0.9758\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1267 - val_accuracy: 0.9750\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.1333 - val_accuracy: 0.9753\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1407 - val_accuracy: 0.9745\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1384 - val_accuracy: 0.9758\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 23s 178us/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1386 - val_accuracy: 0.9756\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 23s 179us/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1357 - val_accuracy: 0.9765\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 23s 179us/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1393 - val_accuracy: 0.9741\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1752 - val_accuracy: 0.9652\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1534 - val_accuracy: 0.9759\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.1531 - val_accuracy: 0.9753\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1442 - val_accuracy: 0.9756\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1581 - val_accuracy: 0.9754\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1540 - val_accuracy: 0.9746\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.881135158896948\n",
      "F1 Micro: 0.977\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8205365274900474\n",
      "F1 Micro: 0.9672\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8991395192568581\n",
      "F1 Micro: 0.9784\n",
      "\n",
      "\n",
      " 51.265493683020274 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 7 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 7 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 719us/step - loss: 1.9538 - accuracy: 0.7225 - val_loss: 1.5089 - val_accuracy: 0.8900\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 177us/step - loss: 1.0730 - accuracy: 0.8600 - val_loss: 0.6184 - val_accuracy: 0.8900\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.7560 - accuracy: 0.8600 - val_loss: 0.5941 - val_accuracy: 0.8900\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7139 - accuracy: 0.8600 - val_loss: 0.5709 - val_accuracy: 0.8900\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6747 - accuracy: 0.8600 - val_loss: 0.5694 - val_accuracy: 0.8900\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6559 - accuracy: 0.8600 - val_loss: 0.5470 - val_accuracy: 0.8900\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6530 - accuracy: 0.8600 - val_loss: 0.5477 - val_accuracy: 0.8900\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6367 - accuracy: 0.8600 - val_loss: 0.5417 - val_accuracy: 0.8900\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6365 - accuracy: 0.8600 - val_loss: 0.5337 - val_accuracy: 0.8900\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6310 - accuracy: 0.8600 - val_loss: 0.5311 - val_accuracy: 0.8900\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6264 - accuracy: 0.8600 - val_loss: 0.5249 - val_accuracy: 0.8900\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6221 - accuracy: 0.8600 - val_loss: 0.5251 - val_accuracy: 0.8900\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.6164 - accuracy: 0.8600 - val_loss: 0.5266 - val_accuracy: 0.8900\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.6092 - accuracy: 0.8600 - val_loss: 0.5099 - val_accuracy: 0.8900\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6041 - accuracy: 0.8600 - val_loss: 0.5099 - val_accuracy: 0.8900\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5966 - accuracy: 0.8600 - val_loss: 0.5148 - val_accuracy: 0.8900\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5834 - accuracy: 0.8600 - val_loss: 0.4997 - val_accuracy: 0.8900\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5737 - accuracy: 0.8600 - val_loss: 0.4946 - val_accuracy: 0.8900\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5567 - accuracy: 0.8600 - val_loss: 0.5130 - val_accuracy: 0.8900\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5447 - accuracy: 0.8600 - val_loss: 0.4829 - val_accuracy: 0.8900\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5402 - accuracy: 0.8600 - val_loss: 0.4756 - val_accuracy: 0.8900\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5247 - accuracy: 0.8625 - val_loss: 0.4719 - val_accuracy: 0.8900\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5188 - accuracy: 0.8600 - val_loss: 0.4700 - val_accuracy: 0.8900\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5022 - accuracy: 0.8650 - val_loss: 0.4665 - val_accuracy: 0.8800\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.5018 - accuracy: 0.8650 - val_loss: 0.4749 - val_accuracy: 0.8900\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.4979 - accuracy: 0.8675 - val_loss: 0.4398 - val_accuracy: 0.8800\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4783 - accuracy: 0.8675 - val_loss: 0.4343 - val_accuracy: 0.8800\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.4704 - accuracy: 0.8675 - val_loss: 0.4204 - val_accuracy: 0.8800\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4663 - accuracy: 0.8675 - val_loss: 0.4413 - val_accuracy: 0.8900\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4627 - accuracy: 0.8650 - val_loss: 0.4159 - val_accuracy: 0.8800\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 195us/step - loss: 0.4578 - accuracy: 0.8750 - val_loss: 0.4145 - val_accuracy: 0.8800\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4351 - accuracy: 0.8725 - val_loss: 0.3836 - val_accuracy: 0.8800\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4368 - accuracy: 0.8875 - val_loss: 0.3749 - val_accuracy: 0.8800\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4192 - accuracy: 0.8850 - val_loss: 0.3632 - val_accuracy: 0.8800\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4041 - accuracy: 0.8875 - val_loss: 0.3516 - val_accuracy: 0.9200\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3984 - accuracy: 0.9025 - val_loss: 0.3429 - val_accuracy: 0.9100\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.3757 - accuracy: 0.9075 - val_loss: 0.3393 - val_accuracy: 0.9000\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3883 - accuracy: 0.9050 - val_loss: 0.3904 - val_accuracy: 0.8900\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3825 - accuracy: 0.9025 - val_loss: 0.3218 - val_accuracy: 0.9100\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3626 - accuracy: 0.9125 - val_loss: 0.3116 - val_accuracy: 0.9300\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3551 - accuracy: 0.9125 - val_loss: 0.3023 - val_accuracy: 0.9400\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3403 - accuracy: 0.9175 - val_loss: 0.2995 - val_accuracy: 0.9400\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3402 - accuracy: 0.9200 - val_loss: 0.3077 - val_accuracy: 0.9300\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3326 - accuracy: 0.9250 - val_loss: 0.2954 - val_accuracy: 0.9400\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3354 - accuracy: 0.9100 - val_loss: 0.3283 - val_accuracy: 0.9200\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3417 - accuracy: 0.9200 - val_loss: 0.2824 - val_accuracy: 0.9400\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3142 - accuracy: 0.9225 - val_loss: 0.2963 - val_accuracy: 0.9400\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3249 - accuracy: 0.9100 - val_loss: 0.2757 - val_accuracy: 0.9400\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 182us/step - loss: 0.3413 - accuracy: 0.9250 - val_loss: 0.2817 - val_accuracy: 0.9400\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3560 - accuracy: 0.9075 - val_loss: 0.2804 - val_accuracy: 0.9400\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.3624 - accuracy: 0.9175 - val_loss: 0.2756 - val_accuracy: 0.9400\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3016 - accuracy: 0.9250 - val_loss: 0.2708 - val_accuracy: 0.9400\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2888 - accuracy: 0.9275 - val_loss: 0.2667 - val_accuracy: 0.9400\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2854 - accuracy: 0.9250 - val_loss: 0.2681 - val_accuracy: 0.9400\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2892 - accuracy: 0.9250 - val_loss: 0.3138 - val_accuracy: 0.9400\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3002 - accuracy: 0.9225 - val_loss: 0.2615 - val_accuracy: 0.9400\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3662 - accuracy: 0.9200 - val_loss: 0.2743 - val_accuracy: 0.9400\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3540 - accuracy: 0.9150 - val_loss: 0.2752 - val_accuracy: 0.9400\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2833 - accuracy: 0.9300 - val_loss: 0.3069 - val_accuracy: 0.9300\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2986 - accuracy: 0.9275 - val_loss: 0.2784 - val_accuracy: 0.9400\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.93 - 0s 211us/step - loss: 0.2991 - accuracy: 0.9250 - val_loss: 0.2565 - val_accuracy: 0.9400\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2953 - accuracy: 0.9300 - val_loss: 0.2850 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2757 - accuracy: 0.9225 - val_loss: 0.2622 - val_accuracy: 0.9400\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3113 - accuracy: 0.9250 - val_loss: 0.2608 - val_accuracy: 0.9400\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2639 - accuracy: 0.9300 - val_loss: 0.2542 - val_accuracy: 0.9400\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2625 - accuracy: 0.9275 - val_loss: 0.2561 - val_accuracy: 0.9400\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2703 - accuracy: 0.9300 - val_loss: 0.2568 - val_accuracy: 0.9400\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2614 - accuracy: 0.9225 - val_loss: 0.2739 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2532 - accuracy: 0.9375 - val_loss: 0.2553 - val_accuracy: 0.9400\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2469 - accuracy: 0.9300 - val_loss: 0.2540 - val_accuracy: 0.9400\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2526 - accuracy: 0.9325 - val_loss: 0.2515 - val_accuracy: 0.9400\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2850 - accuracy: 0.9200 - val_loss: 0.2857 - val_accuracy: 0.9400\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 235us/step - loss: 0.2505 - accuracy: 0.9300 - val_loss: 0.2586 - val_accuracy: 0.9400\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 159us/step - loss: 0.2418 - accuracy: 0.9325 - val_loss: 0.2746 - val_accuracy: 0.9500\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2516 - accuracy: 0.9275 - val_loss: 0.2456 - val_accuracy: 0.9400\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2144 - accuracy: 0.9350 - val_loss: 0.2594 - val_accuracy: 0.9400\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2198 - accuracy: 0.9375 - val_loss: 0.2429 - val_accuracy: 0.9400\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2120 - accuracy: 0.9475 - val_loss: 0.2460 - val_accuracy: 0.9400\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2091 - accuracy: 0.9400 - val_loss: 0.2420 - val_accuracy: 0.9400\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2020 - accuracy: 0.9425 - val_loss: 0.2433 - val_accuracy: 0.9400\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2015 - accuracy: 0.9450 - val_loss: 0.2435 - val_accuracy: 0.9500\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1974 - accuracy: 0.9400 - val_loss: 0.2484 - val_accuracy: 0.9500\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1926 - accuracy: 0.9475 - val_loss: 0.2455 - val_accuracy: 0.9400\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1849 - accuracy: 0.9475 - val_loss: 0.2537 - val_accuracy: 0.9400\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 238us/step - loss: 0.1869 - accuracy: 0.9450 - val_loss: 0.2487 - val_accuracy: 0.9400\n",
      "Epoch 86/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 199us/step - loss: 0.1835 - accuracy: 0.9475 - val_loss: 0.2401 - val_accuracy: 0.9500\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1901 - accuracy: 0.9475 - val_loss: 0.2498 - val_accuracy: 0.9400\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1956 - accuracy: 0.9450 - val_loss: 0.2469 - val_accuracy: 0.9400\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1831 - accuracy: 0.9500 - val_loss: 0.2512 - val_accuracy: 0.9500\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1623 - accuracy: 0.9575 - val_loss: 0.2710 - val_accuracy: 0.9500\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1863 - accuracy: 0.9450 - val_loss: 0.2817 - val_accuracy: 0.9500\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2345 - accuracy: 0.9300 - val_loss: 0.3116 - val_accuracy: 0.9500\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1993 - accuracy: 0.9475 - val_loss: 0.2528 - val_accuracy: 0.9400\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1986 - accuracy: 0.9375 - val_loss: 0.2499 - val_accuracy: 0.9500\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1806 - accuracy: 0.9500 - val_loss: 0.2965 - val_accuracy: 0.9500\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1858 - accuracy: 0.9525 - val_loss: 0.2415 - val_accuracy: 0.9600\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 203us/step - loss: 0.1537 - accuracy: 0.9525 - val_loss: 0.2628 - val_accuracy: 0.9500\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.1862 - accuracy: 0.9475 - val_loss: 0.2479 - val_accuracy: 0.9500\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1542 - accuracy: 0.9575 - val_loss: 0.2376 - val_accuracy: 0.9500\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1425 - accuracy: 0.9525 - val_loss: 0.2431 - val_accuracy: 0.9500\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1467 - accuracy: 0.9625 - val_loss: 0.2337 - val_accuracy: 0.9500\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1409 - accuracy: 0.9650 - val_loss: 0.2448 - val_accuracy: 0.9600\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1286 - accuracy: 0.9625 - val_loss: 0.2371 - val_accuracy: 0.9500\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1412 - accuracy: 0.9625 - val_loss: 0.2681 - val_accuracy: 0.9400\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1337 - accuracy: 0.9625 - val_loss: 0.2793 - val_accuracy: 0.9400\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1303 - accuracy: 0.9625 - val_loss: 0.2422 - val_accuracy: 0.9400\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1236 - accuracy: 0.9625 - val_loss: 0.2350 - val_accuracy: 0.9500\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1388 - accuracy: 0.9600 - val_loss: 0.2323 - val_accuracy: 0.9500\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1061 - accuracy: 0.9675 - val_loss: 0.2348 - val_accuracy: 0.9500\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 203us/step - loss: 0.1095 - accuracy: 0.9700 - val_loss: 0.2510 - val_accuracy: 0.9400\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1185 - accuracy: 0.9625 - val_loss: 0.2417 - val_accuracy: 0.9500\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1033 - accuracy: 0.9750 - val_loss: 0.2554 - val_accuracy: 0.9600\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1131 - accuracy: 0.9700 - val_loss: 0.2408 - val_accuracy: 0.9600\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0989 - accuracy: 0.9725 - val_loss: 0.2633 - val_accuracy: 0.9500\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1352 - accuracy: 0.9550 - val_loss: 0.2610 - val_accuracy: 0.9600\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1126 - accuracy: 0.9525 - val_loss: 0.2659 - val_accuracy: 0.9600\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1092 - accuracy: 0.9625 - val_loss: 0.2432 - val_accuracy: 0.9600\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0909 - accuracy: 0.9725 - val_loss: 0.2325 - val_accuracy: 0.9500\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0811 - accuracy: 0.9775 - val_loss: 0.2433 - val_accuracy: 0.9500\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0883 - accuracy: 0.9725 - val_loss: 0.2413 - val_accuracy: 0.9500\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0859 - accuracy: 0.9850 - val_loss: 0.2481 - val_accuracy: 0.9500\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0917 - accuracy: 0.9725 - val_loss: 0.2478 - val_accuracy: 0.9500\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.0779 - accuracy: 0.9750 - val_loss: 0.2803 - val_accuracy: 0.9300\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0909 - accuracy: 0.9700 - val_loss: 0.2707 - val_accuracy: 0.9400\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0806 - accuracy: 0.9725 - val_loss: 0.2486 - val_accuracy: 0.9500\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0795 - accuracy: 0.9750 - val_loss: 0.2421 - val_accuracy: 0.9500\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0889 - accuracy: 0.9725 - val_loss: 0.2488 - val_accuracy: 0.9600\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1334 - accuracy: 0.9650 - val_loss: 0.2446 - val_accuracy: 0.9600\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.44154499825954363\n",
      "F1 Micro: 0.921414636586464\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5082192859376035\n",
      "F1 Micro: 0.9388224701115502\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 273us/step - loss: 2.2483 - accuracy: 0.0925 - val_loss: 2.0245 - val_accuracy: 0.2400\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 2.0383 - accuracy: 0.3375 - val_loss: 1.7698 - val_accuracy: 0.5400\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.8820 - accuracy: 0.4925 - val_loss: 1.6032 - val_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.7741 - accuracy: 0.5325 - val_loss: 1.4951 - val_accuracy: 0.6300\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.7006 - accuracy: 0.5625 - val_loss: 1.4108 - val_accuracy: 0.6700\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.6367 - accuracy: 0.5750 - val_loss: 1.3491 - val_accuracy: 0.6800\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.5775 - accuracy: 0.5950 - val_loss: 1.2944 - val_accuracy: 0.7000\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.5214 - accuracy: 0.6100 - val_loss: 1.2394 - val_accuracy: 0.7300\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.4655 - accuracy: 0.6325 - val_loss: 1.1866 - val_accuracy: 0.7800\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.4089 - accuracy: 0.6725 - val_loss: 1.1366 - val_accuracy: 0.7900\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 88us/step - loss: 1.3512 - accuracy: 0.6925 - val_loss: 1.0835 - val_accuracy: 0.8100\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.2932 - accuracy: 0.7150 - val_loss: 1.0335 - val_accuracy: 0.8200\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.2358 - accuracy: 0.7225 - val_loss: 0.9839 - val_accuracy: 0.8300\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1768 - accuracy: 0.7500 - val_loss: 0.9281 - val_accuracy: 0.8300\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1184 - accuracy: 0.7725 - val_loss: 0.8746 - val_accuracy: 0.8800\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0594 - accuracy: 0.7850 - val_loss: 0.8248 - val_accuracy: 0.8800\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0021 - accuracy: 0.8200 - val_loss: 0.7780 - val_accuracy: 0.9100\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.9454 - accuracy: 0.8400 - val_loss: 0.7301 - val_accuracy: 0.9200\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8912 - accuracy: 0.8500 - val_loss: 0.6882 - val_accuracy: 0.9200\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8387 - accuracy: 0.8625 - val_loss: 0.6472 - val_accuracy: 0.9200\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7857 - accuracy: 0.8725 - val_loss: 0.6005 - val_accuracy: 0.9300\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7378 - accuracy: 0.8800 - val_loss: 0.5632 - val_accuracy: 0.9300\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.6920 - accuracy: 0.8925 - val_loss: 0.5309 - val_accuracy: 0.9200\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.6504 - accuracy: 0.9075 - val_loss: 0.5058 - val_accuracy: 0.9300\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.6102 - accuracy: 0.9175 - val_loss: 0.4716 - val_accuracy: 0.9300\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5726 - accuracy: 0.9175 - val_loss: 0.4415 - val_accuracy: 0.9300\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.5379 - accuracy: 0.9275 - val_loss: 0.4249 - val_accuracy: 0.9400\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5054 - accuracy: 0.9350 - val_loss: 0.4017 - val_accuracy: 0.9400\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4749 - accuracy: 0.9375 - val_loss: 0.3778 - val_accuracy: 0.9400\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4479 - accuracy: 0.9400 - val_loss: 0.3606 - val_accuracy: 0.9400\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4208 - accuracy: 0.9500 - val_loss: 0.3425 - val_accuracy: 0.9400\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3968 - accuracy: 0.9500 - val_loss: 0.3269 - val_accuracy: 0.9500\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3756 - accuracy: 0.9525 - val_loss: 0.3129 - val_accuracy: 0.9500\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3554 - accuracy: 0.9550 - val_loss: 0.2993 - val_accuracy: 0.9500\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3358 - accuracy: 0.9600 - val_loss: 0.2895 - val_accuracy: 0.9500\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3198 - accuracy: 0.9625 - val_loss: 0.2806 - val_accuracy: 0.9500\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3037 - accuracy: 0.9625 - val_loss: 0.2675 - val_accuracy: 0.9500\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2890 - accuracy: 0.9625 - val_loss: 0.2576 - val_accuracy: 0.9500\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2760 - accuracy: 0.9625 - val_loss: 0.2499 - val_accuracy: 0.9500\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2640 - accuracy: 0.9650 - val_loss: 0.2445 - val_accuracy: 0.9500\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 49us/step - loss: 0.2535 - accuracy: 0.9650 - val_loss: 0.2331 - val_accuracy: 0.9500\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2430 - accuracy: 0.9675 - val_loss: 0.2288 - val_accuracy: 0.9500\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2326 - accuracy: 0.9675 - val_loss: 0.2224 - val_accuracy: 0.9500\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2248 - accuracy: 0.9675 - val_loss: 0.2179 - val_accuracy: 0.9500\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2172 - accuracy: 0.9675 - val_loss: 0.2096 - val_accuracy: 0.9500\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2086 - accuracy: 0.9700 - val_loss: 0.2076 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2021 - accuracy: 0.9700 - val_loss: 0.2028 - val_accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1958 - accuracy: 0.9725 - val_loss: 0.1996 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1897 - accuracy: 0.9725 - val_loss: 0.1945 - val_accuracy: 0.9500\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1841 - accuracy: 0.9725 - val_loss: 0.1912 - val_accuracy: 0.9500\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1790 - accuracy: 0.9725 - val_loss: 0.1887 - val_accuracy: 0.9500\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1738 - accuracy: 0.9725 - val_loss: 0.1850 - val_accuracy: 0.9500\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1691 - accuracy: 0.9725 - val_loss: 0.1823 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1649 - accuracy: 0.9725 - val_loss: 0.1787 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1609 - accuracy: 0.9725 - val_loss: 0.1759 - val_accuracy: 0.9500\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1569 - accuracy: 0.9725 - val_loss: 0.1753 - val_accuracy: 0.9500\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1532 - accuracy: 0.9725 - val_loss: 0.1738 - val_accuracy: 0.9500\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1500 - accuracy: 0.9725 - val_loss: 0.1713 - val_accuracy: 0.9500\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1464 - accuracy: 0.9725 - val_loss: 0.1691 - val_accuracy: 0.9500\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1439 - accuracy: 0.9750 - val_loss: 0.1698 - val_accuracy: 0.9500\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1401 - accuracy: 0.9775 - val_loss: 0.1664 - val_accuracy: 0.9500\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1377 - accuracy: 0.9750 - val_loss: 0.1640 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1345 - accuracy: 0.9775 - val_loss: 0.1648 - val_accuracy: 0.9500\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1316 - accuracy: 0.9775 - val_loss: 0.1642 - val_accuracy: 0.9500\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1294 - accuracy: 0.9775 - val_loss: 0.1617 - val_accuracy: 0.9500\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1270 - accuracy: 0.9775 - val_loss: 0.1612 - val_accuracy: 0.9500\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 78us/step - loss: 0.1245 - accuracy: 0.9775 - val_loss: 0.1579 - val_accuracy: 0.9500\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1221 - accuracy: 0.9775 - val_loss: 0.1596 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1196 - accuracy: 0.9800 - val_loss: 0.1589 - val_accuracy: 0.9500\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1180 - accuracy: 0.9800 - val_loss: 0.1565 - val_accuracy: 0.9500\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1152 - accuracy: 0.9800 - val_loss: 0.1580 - val_accuracy: 0.9500\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.1133 - accuracy: 0.9800 - val_loss: 0.1582 - val_accuracy: 0.9500\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1114 - accuracy: 0.9800 - val_loss: 0.1569 - val_accuracy: 0.9500\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1096 - accuracy: 0.9800 - val_loss: 0.1566 - val_accuracy: 0.9500\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1076 - accuracy: 0.9825 - val_loss: 0.1534 - val_accuracy: 0.9500\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1059 - accuracy: 0.9825 - val_loss: 0.1545 - val_accuracy: 0.9500\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1039 - accuracy: 0.9825 - val_loss: 0.1528 - val_accuracy: 0.9500\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1021 - accuracy: 0.9825 - val_loss: 0.1536 - val_accuracy: 0.9500\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1006 - accuracy: 0.9825 - val_loss: 0.1524 - val_accuracy: 0.9500\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0992 - accuracy: 0.9825 - val_loss: 0.1567 - val_accuracy: 0.9500\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0969 - accuracy: 0.9850 - val_loss: 0.1535 - val_accuracy: 0.9500\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0952 - accuracy: 0.9825 - val_loss: 0.1530 - val_accuracy: 0.9500\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0939 - accuracy: 0.9825 - val_loss: 0.1532 - val_accuracy: 0.9500\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0923 - accuracy: 0.9825 - val_loss: 0.1515 - val_accuracy: 0.9500\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0911 - accuracy: 0.9850 - val_loss: 0.1556 - val_accuracy: 0.9500\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0894 - accuracy: 0.9850 - val_loss: 0.1556 - val_accuracy: 0.9500\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0882 - accuracy: 0.9825 - val_loss: 0.1523 - val_accuracy: 0.9500\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0866 - accuracy: 0.9850 - val_loss: 0.1541 - val_accuracy: 0.9500\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.0850 - accuracy: 0.9850 - val_loss: 0.1539 - val_accuracy: 0.9500\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0839 - accuracy: 0.9875 - val_loss: 0.1539 - val_accuracy: 0.9500\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0826 - accuracy: 0.9875 - val_loss: 0.1533 - val_accuracy: 0.9500\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0813 - accuracy: 0.9875 - val_loss: 0.1545 - val_accuracy: 0.9500\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0802 - accuracy: 0.9875 - val_loss: 0.1538 - val_accuracy: 0.9500\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0787 - accuracy: 0.9875 - val_loss: 0.1547 - val_accuracy: 0.9500\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0776 - accuracy: 0.9875 - val_loss: 0.1540 - val_accuracy: 0.9500\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0764 - accuracy: 0.9875 - val_loss: 0.1548 - val_accuracy: 0.9500\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0751 - accuracy: 0.9875 - val_loss: 0.1548 - val_accuracy: 0.9500\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0742 - accuracy: 0.9875 - val_loss: 0.1568 - val_accuracy: 0.9500\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0731 - accuracy: 0.9875 - val_loss: 0.1615 - val_accuracy: 0.9500\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0718 - accuracy: 0.9900 - val_loss: 0.1589 - val_accuracy: 0.9500\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0706 - accuracy: 0.9900 - val_loss: 0.1577 - val_accuracy: 0.9500\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0696 - accuracy: 0.9900 - val_loss: 0.1566 - val_accuracy: 0.9500\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 1.00 - 0s 81us/step - loss: 0.0686 - accuracy: 0.9900 - val_loss: 0.1570 - val_accuracy: 0.9500\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0675 - accuracy: 0.9900 - val_loss: 0.1582 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5178263194890345\n",
      "F1 Micro: 0.9382221999899956\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 692us/step - loss: 1.8166 - accuracy: 0.5450 - val_loss: 1.1712 - val_accuracy: 0.8300\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.8046 - accuracy: 0.8600 - val_loss: 0.4123 - val_accuracy: 0.8900\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5043 - accuracy: 0.8650 - val_loss: 0.3917 - val_accuracy: 0.8900\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4395 - accuracy: 0.8800 - val_loss: 0.3277 - val_accuracy: 0.9200\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3959 - accuracy: 0.9025 - val_loss: 0.3098 - val_accuracy: 0.9300\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 177us/step - loss: 0.3698 - accuracy: 0.9100 - val_loss: 0.2907 - val_accuracy: 0.9400\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3501 - accuracy: 0.9100 - val_loss: 0.2768 - val_accuracy: 0.9400\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3345 - accuracy: 0.9100 - val_loss: 0.2625 - val_accuracy: 0.9500\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3207 - accuracy: 0.9150 - val_loss: 0.2537 - val_accuracy: 0.9400\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3090 - accuracy: 0.9175 - val_loss: 0.2448 - val_accuracy: 0.9400\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2993 - accuracy: 0.9300 - val_loss: 0.2356 - val_accuracy: 0.9400\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2853 - accuracy: 0.9300 - val_loss: 0.2319 - val_accuracy: 0.9400\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2788 - accuracy: 0.9225 - val_loss: 0.2228 - val_accuracy: 0.9400\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2688 - accuracy: 0.9350 - val_loss: 0.2198 - val_accuracy: 0.9400\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2607 - accuracy: 0.9375 - val_loss: 0.2143 - val_accuracy: 0.9400\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2545 - accuracy: 0.9425 - val_loss: 0.2079 - val_accuracy: 0.9400\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 227us/step - loss: 0.2472 - accuracy: 0.9450 - val_loss: 0.2046 - val_accuracy: 0.9400\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2394 - accuracy: 0.9450 - val_loss: 0.1992 - val_accuracy: 0.9400\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2338 - accuracy: 0.9450 - val_loss: 0.1936 - val_accuracy: 0.9400\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2281 - accuracy: 0.9450 - val_loss: 0.1899 - val_accuracy: 0.9400\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2228 - accuracy: 0.9450 - val_loss: 0.1876 - val_accuracy: 0.9400\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2171 - accuracy: 0.9475 - val_loss: 0.1857 - val_accuracy: 0.9400\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2111 - accuracy: 0.9475 - val_loss: 0.1815 - val_accuracy: 0.9500\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2070 - accuracy: 0.9475 - val_loss: 0.1764 - val_accuracy: 0.9400\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2020 - accuracy: 0.9500 - val_loss: 0.1734 - val_accuracy: 0.9400\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1991 - accuracy: 0.9525 - val_loss: 0.1743 - val_accuracy: 0.9500\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1922 - accuracy: 0.9500 - val_loss: 0.1696 - val_accuracy: 0.9500\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1929 - accuracy: 0.9525 - val_loss: 0.1672 - val_accuracy: 0.9500\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 181us/step - loss: 0.1979 - accuracy: 0.9500 - val_loss: 0.1637 - val_accuracy: 0.9400\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1886 - accuracy: 0.9600 - val_loss: 0.1635 - val_accuracy: 0.9600\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1916 - accuracy: 0.9500 - val_loss: 0.1628 - val_accuracy: 0.9500\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1760 - accuracy: 0.9550 - val_loss: 0.1599 - val_accuracy: 0.9500\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1683 - accuracy: 0.9525 - val_loss: 0.1553 - val_accuracy: 0.9500\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1649 - accuracy: 0.9550 - val_loss: 0.1534 - val_accuracy: 0.9600\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1605 - accuracy: 0.9525 - val_loss: 0.1540 - val_accuracy: 0.9600\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1579 - accuracy: 0.9525 - val_loss: 0.1500 - val_accuracy: 0.9600\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1548 - accuracy: 0.9600 - val_loss: 0.1492 - val_accuracy: 0.9600\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1530 - accuracy: 0.9575 - val_loss: 0.1485 - val_accuracy: 0.9600\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1492 - accuracy: 0.9625 - val_loss: 0.1469 - val_accuracy: 0.9600\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.1457 - accuracy: 0.9550 - val_loss: 0.1442 - val_accuracy: 0.9600\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1411 - accuracy: 0.9575 - val_loss: 0.1410 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1394 - accuracy: 0.9650 - val_loss: 0.1441 - val_accuracy: 0.9600\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1361 - accuracy: 0.9575 - val_loss: 0.1431 - val_accuracy: 0.9600\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1329 - accuracy: 0.9650 - val_loss: 0.1387 - val_accuracy: 0.9600\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1292 - accuracy: 0.9675 - val_loss: 0.1399 - val_accuracy: 0.9600\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1291 - accuracy: 0.9625 - val_loss: 0.1370 - val_accuracy: 0.9600\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1261 - accuracy: 0.9750 - val_loss: 0.1406 - val_accuracy: 0.9600\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1271 - accuracy: 0.9575 - val_loss: 0.1364 - val_accuracy: 0.9600\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1180 - accuracy: 0.9675 - val_loss: 0.1357 - val_accuracy: 0.9600\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1211 - accuracy: 0.9625 - val_loss: 0.1331 - val_accuracy: 0.9700\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1197 - accuracy: 0.9750 - val_loss: 0.1427 - val_accuracy: 0.9600\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1150 - accuracy: 0.9625 - val_loss: 0.1327 - val_accuracy: 0.9700\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1078 - accuracy: 0.9725 - val_loss: 0.1335 - val_accuracy: 0.9600\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1084 - accuracy: 0.9650 - val_loss: 0.1311 - val_accuracy: 0.9700\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1074 - accuracy: 0.9750 - val_loss: 0.1329 - val_accuracy: 0.9600\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0997 - accuracy: 0.9700 - val_loss: 0.1294 - val_accuracy: 0.9700\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0996 - accuracy: 0.9850 - val_loss: 0.1380 - val_accuracy: 0.9600\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0990 - accuracy: 0.9700 - val_loss: 0.1307 - val_accuracy: 0.9700\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0946 - accuracy: 0.9750 - val_loss: 0.1302 - val_accuracy: 0.9700\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0902 - accuracy: 0.9800 - val_loss: 0.1274 - val_accuracy: 0.9700\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0891 - accuracy: 0.9775 - val_loss: 0.1276 - val_accuracy: 0.9700\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0852 - accuracy: 0.9850 - val_loss: 0.1292 - val_accuracy: 0.9700\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0855 - accuracy: 0.9850 - val_loss: 0.1395 - val_accuracy: 0.9600\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.0851 - accuracy: 0.9725 - val_loss: 0.1286 - val_accuracy: 0.9800\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0830 - accuracy: 0.9775 - val_loss: 0.1263 - val_accuracy: 0.9700\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0764 - accuracy: 0.9875 - val_loss: 0.1262 - val_accuracy: 0.9700\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0762 - accuracy: 0.9800 - val_loss: 0.1294 - val_accuracy: 0.9700\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0718 - accuracy: 0.9875 - val_loss: 0.1394 - val_accuracy: 0.9600\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0706 - accuracy: 0.9800 - val_loss: 0.1256 - val_accuracy: 0.9800\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0710 - accuracy: 0.9875 - val_loss: 0.1334 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0656 - accuracy: 0.9925 - val_loss: 0.1324 - val_accuracy: 0.9700\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0616 - accuracy: 0.9925 - val_loss: 0.1260 - val_accuracy: 0.9700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0608 - accuracy: 0.9925 - val_loss: 0.1264 - val_accuracy: 0.9700\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0570 - accuracy: 0.9925 - val_loss: 0.1274 - val_accuracy: 0.9700\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0563 - accuracy: 0.9925 - val_loss: 0.1217 - val_accuracy: 0.9800\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0661 - accuracy: 0.9825 - val_loss: 0.1477 - val_accuracy: 0.9600\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0499 - accuracy: 0.9925 - val_loss: 0.1240 - val_accuracy: 0.9800\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0496 - accuracy: 0.9900 - val_loss: 0.1514 - val_accuracy: 0.9600\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0491 - accuracy: 0.9950 - val_loss: 0.1261 - val_accuracy: 0.9700\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0463 - accuracy: 0.9950 - val_loss: 0.1265 - val_accuracy: 0.9700\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0417 - accuracy: 0.9975 - val_loss: 0.1443 - val_accuracy: 0.9600\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0407 - accuracy: 0.9975 - val_loss: 0.1233 - val_accuracy: 0.9800\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0380 - accuracy: 0.9975 - val_loss: 0.1381 - val_accuracy: 0.9700\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0406 - accuracy: 0.9950 - val_loss: 0.1501 - val_accuracy: 0.9600\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0382 - accuracy: 0.9975 - val_loss: 0.1384 - val_accuracy: 0.9600\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0340 - accuracy: 0.9950 - val_loss: 0.1309 - val_accuracy: 0.9700\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0308 - accuracy: 0.9975 - val_loss: 0.1293 - val_accuracy: 0.9700\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 196us/step - loss: 0.0312 - accuracy: 0.9975 - val_loss: 0.1414 - val_accuracy: 0.9600\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0297 - accuracy: 0.9975 - val_loss: 0.1456 - val_accuracy: 0.9600\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0273 - accuracy: 0.9975 - val_loss: 0.1311 - val_accuracy: 0.9700\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0243 - accuracy: 0.9975 - val_loss: 0.1439 - val_accuracy: 0.9600\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0242 - accuracy: 0.9975 - val_loss: 0.1516 - val_accuracy: 0.9600\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0234 - accuracy: 0.9975 - val_loss: 0.1377 - val_accuracy: 0.9700\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0211 - accuracy: 0.9975 - val_loss: 0.1286 - val_accuracy: 0.9700\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0195 - accuracy: 0.9975 - val_loss: 0.1238 - val_accuracy: 0.9800\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5468153799226537\n",
      "F1 Micro: 0.9423240458206192\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5324591594899133\n",
      "F1 Micro: 0.9431244059826922\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5385317762183817\n",
      "F1 Micro: 0.9409234155369917\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 7 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 234us/step - loss: 0.8521 - accuracy: 0.8512 - val_loss: 0.6605 - val_accuracy: 0.8540\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.6510 - accuracy: 0.8512 - val_loss: 0.6072 - val_accuracy: 0.8540\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.5733 - accuracy: 0.8515 - val_loss: 0.4651 - val_accuracy: 0.8610\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.4341 - accuracy: 0.8910 - val_loss: 0.3673 - val_accuracy: 0.9030\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.3606 - accuracy: 0.9050 - val_loss: 0.3059 - val_accuracy: 0.9140\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.3207 - accuracy: 0.9147 - val_loss: 0.2704 - val_accuracy: 0.9200\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.2840 - accuracy: 0.9202 - val_loss: 0.2489 - val_accuracy: 0.9200\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.2755 - accuracy: 0.9235 - val_loss: 0.2225 - val_accuracy: 0.9360\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.2445 - accuracy: 0.9285 - val_loss: 0.2251 - val_accuracy: 0.9270\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.2262 - accuracy: 0.9317 - val_loss: 0.2553 - val_accuracy: 0.9210\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.2082 - accuracy: 0.9425 - val_loss: 0.1968 - val_accuracy: 0.9440\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1922 - accuracy: 0.9433 - val_loss: 0.1694 - val_accuracy: 0.9510\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1880 - accuracy: 0.9470 - val_loss: 0.1717 - val_accuracy: 0.9470\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1677 - accuracy: 0.9513 - val_loss: 0.1639 - val_accuracy: 0.9500\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1643 - accuracy: 0.9517 - val_loss: 0.1530 - val_accuracy: 0.9520\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1557 - accuracy: 0.9553 - val_loss: 0.2028 - val_accuracy: 0.9430\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1492 - accuracy: 0.9555 - val_loss: 0.1458 - val_accuracy: 0.9560\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1402 - accuracy: 0.9575 - val_loss: 0.1551 - val_accuracy: 0.9530\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1385 - accuracy: 0.9555 - val_loss: 0.1572 - val_accuracy: 0.9520\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1280 - accuracy: 0.9603 - val_loss: 0.1393 - val_accuracy: 0.9610\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1247 - accuracy: 0.9597 - val_loss: 0.1464 - val_accuracy: 0.9530\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1201 - accuracy: 0.9610 - val_loss: 0.1562 - val_accuracy: 0.9510\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1138 - accuracy: 0.9630 - val_loss: 0.1741 - val_accuracy: 0.9560\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1093 - accuracy: 0.9657 - val_loss: 0.1299 - val_accuracy: 0.9630\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1132 - accuracy: 0.9653 - val_loss: 0.1457 - val_accuracy: 0.9580\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1007 - accuracy: 0.9668 - val_loss: 0.1466 - val_accuracy: 0.9510\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1030 - accuracy: 0.9672 - val_loss: 0.1273 - val_accuracy: 0.9600\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0943 - accuracy: 0.9685 - val_loss: 0.1379 - val_accuracy: 0.9540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0875 - accuracy: 0.9712 - val_loss: 0.1353 - val_accuracy: 0.9590\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0932 - accuracy: 0.9707 - val_loss: 0.1494 - val_accuracy: 0.9580\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0792 - accuracy: 0.9753 - val_loss: 0.1453 - val_accuracy: 0.9590\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.0842 - accuracy: 0.9730 - val_loss: 0.1506 - val_accuracy: 0.9530\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0729 - accuracy: 0.9755 - val_loss: 0.1358 - val_accuracy: 0.9590\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0751 - accuracy: 0.9778 - val_loss: 0.1385 - val_accuracy: 0.9590\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0730 - accuracy: 0.9755 - val_loss: 0.1585 - val_accuracy: 0.9570\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0688 - accuracy: 0.9753 - val_loss: 0.1406 - val_accuracy: 0.9570\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0602 - accuracy: 0.9822 - val_loss: 0.1315 - val_accuracy: 0.9600\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0656 - accuracy: 0.9772 - val_loss: 0.1352 - val_accuracy: 0.9600\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0556 - accuracy: 0.9830 - val_loss: 0.1514 - val_accuracy: 0.9530\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0567 - accuracy: 0.9815 - val_loss: 0.1694 - val_accuracy: 0.9570\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0474 - accuracy: 0.9855 - val_loss: 0.1564 - val_accuracy: 0.9570\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0494 - accuracy: 0.9862 - val_loss: 0.1553 - val_accuracy: 0.9590\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0500 - accuracy: 0.9840 - val_loss: 0.1521 - val_accuracy: 0.9580\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0395 - accuracy: 0.9890 - val_loss: 0.1500 - val_accuracy: 0.9570\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0386 - accuracy: 0.9887 - val_loss: 0.1520 - val_accuracy: 0.9570\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0352 - accuracy: 0.9905 - val_loss: 0.1980 - val_accuracy: 0.9560\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 0.1490 - val_accuracy: 0.9590\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6400986079411085\n",
      "F1 Micro: 0.9562\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7016968993129802\n",
      "F1 Micro: 0.9548\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 88us/step - loss: 1.6003 - accuracy: 0.5760 - val_loss: 1.2847 - val_accuracy: 0.7310\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.9938 - accuracy: 0.8075 - val_loss: 0.7424 - val_accuracy: 0.8830\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.5665 - accuracy: 0.9047 - val_loss: 0.4243 - val_accuracy: 0.9300\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.3523 - accuracy: 0.9375 - val_loss: 0.2893 - val_accuracy: 0.9430\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.2589 - accuracy: 0.9480 - val_loss: 0.2284 - val_accuracy: 0.9440\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.2137 - accuracy: 0.9532 - val_loss: 0.1953 - val_accuracy: 0.9450\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1879 - accuracy: 0.9548 - val_loss: 0.1774 - val_accuracy: 0.9500\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1720 - accuracy: 0.9570 - val_loss: 0.1656 - val_accuracy: 0.9510\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1597 - accuracy: 0.9590 - val_loss: 0.1578 - val_accuracy: 0.9540\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 80us/step - loss: 0.1504 - accuracy: 0.9610 - val_loss: 0.1538 - val_accuracy: 0.9530\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1438 - accuracy: 0.9640 - val_loss: 0.1482 - val_accuracy: 0.9510\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1376 - accuracy: 0.9632 - val_loss: 0.1444 - val_accuracy: 0.9510\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1324 - accuracy: 0.9660 - val_loss: 0.1424 - val_accuracy: 0.9510\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1282 - accuracy: 0.9680 - val_loss: 0.1422 - val_accuracy: 0.9530\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.1238 - accuracy: 0.9685 - val_loss: 0.1398 - val_accuracy: 0.9480\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1201 - accuracy: 0.9693 - val_loss: 0.1395 - val_accuracy: 0.9490\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1171 - accuracy: 0.9700 - val_loss: 0.1384 - val_accuracy: 0.9490\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1135 - accuracy: 0.9700 - val_loss: 0.1384 - val_accuracy: 0.9520\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1103 - accuracy: 0.9712 - val_loss: 0.1369 - val_accuracy: 0.9490\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1082 - accuracy: 0.9705 - val_loss: 0.1371 - val_accuracy: 0.9500\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1062 - accuracy: 0.9720 - val_loss: 0.1375 - val_accuracy: 0.9500\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1037 - accuracy: 0.9725 - val_loss: 0.1378 - val_accuracy: 0.9480\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.1019 - accuracy: 0.9737 - val_loss: 0.1376 - val_accuracy: 0.9490\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0991 - accuracy: 0.9743 - val_loss: 0.1376 - val_accuracy: 0.9490\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0976 - accuracy: 0.9737 - val_loss: 0.1384 - val_accuracy: 0.9490\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0962 - accuracy: 0.9747 - val_loss: 0.1380 - val_accuracy: 0.9490\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0944 - accuracy: 0.9750 - val_loss: 0.1390 - val_accuracy: 0.9500\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0925 - accuracy: 0.9753 - val_loss: 0.1387 - val_accuracy: 0.9500\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0907 - accuracy: 0.9755 - val_loss: 0.1394 - val_accuracy: 0.9480\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0891 - accuracy: 0.9775 - val_loss: 0.1401 - val_accuracy: 0.9470\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0876 - accuracy: 0.9778 - val_loss: 0.1400 - val_accuracy: 0.9480\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0866 - accuracy: 0.9770 - val_loss: 0.1397 - val_accuracy: 0.9470\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0846 - accuracy: 0.9772 - val_loss: 0.1402 - val_accuracy: 0.9480\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0835 - accuracy: 0.9790 - val_loss: 0.1399 - val_accuracy: 0.9480\n",
      "Epoch 35/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0820 - accuracy: 0.9778 - val_loss: 0.1404 - val_accuracy: 0.9480\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0808 - accuracy: 0.9785 - val_loss: 0.1418 - val_accuracy: 0.9490\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0800 - accuracy: 0.9785 - val_loss: 0.1404 - val_accuracy: 0.9480\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 63us/step - loss: 0.0785 - accuracy: 0.9783 - val_loss: 0.1402 - val_accuracy: 0.9490\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0769 - accuracy: 0.9805 - val_loss: 0.1419 - val_accuracy: 0.9480\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6314331359177333\n",
      "F1 Micro: 0.9563\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 232us/step - loss: 0.6077 - accuracy: 0.8447 - val_loss: 0.3383 - val_accuracy: 0.9100\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.3103 - accuracy: 0.9183 - val_loss: 0.2627 - val_accuracy: 0.9340\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.2495 - accuracy: 0.9327 - val_loss: 0.2215 - val_accuracy: 0.9400\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.2157 - accuracy: 0.9410 - val_loss: 0.2065 - val_accuracy: 0.9440\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1993 - accuracy: 0.9450 - val_loss: 0.1885 - val_accuracy: 0.9500\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1790 - accuracy: 0.9500 - val_loss: 0.1779 - val_accuracy: 0.9510\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1669 - accuracy: 0.9548 - val_loss: 0.1725 - val_accuracy: 0.9510\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1589 - accuracy: 0.9542 - val_loss: 0.1648 - val_accuracy: 0.9500\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1483 - accuracy: 0.9595 - val_loss: 0.1639 - val_accuracy: 0.9490\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1463 - accuracy: 0.9595 - val_loss: 0.1590 - val_accuracy: 0.9510\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1358 - accuracy: 0.9582 - val_loss: 0.1555 - val_accuracy: 0.9530\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1302 - accuracy: 0.9620 - val_loss: 0.1532 - val_accuracy: 0.9530\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.1273 - accuracy: 0.9632 - val_loss: 0.1580 - val_accuracy: 0.9520\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1217 - accuracy: 0.9635 - val_loss: 0.1554 - val_accuracy: 0.9520\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1198 - accuracy: 0.9660 - val_loss: 0.1516 - val_accuracy: 0.9530\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1140 - accuracy: 0.9668 - val_loss: 0.1521 - val_accuracy: 0.9530\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1103 - accuracy: 0.9685 - val_loss: 0.1469 - val_accuracy: 0.9540\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1082 - accuracy: 0.9680 - val_loss: 0.1458 - val_accuracy: 0.9540\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.1028 - accuracy: 0.9693 - val_loss: 0.1485 - val_accuracy: 0.9540\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1011 - accuracy: 0.9705 - val_loss: 0.1552 - val_accuracy: 0.9540\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0981 - accuracy: 0.9718 - val_loss: 0.1433 - val_accuracy: 0.9570\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0955 - accuracy: 0.9722 - val_loss: 0.1408 - val_accuracy: 0.9570\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0899 - accuracy: 0.9745 - val_loss: 0.1437 - val_accuracy: 0.9540\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0885 - accuracy: 0.9747 - val_loss: 0.1420 - val_accuracy: 0.9510\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0850 - accuracy: 0.9765 - val_loss: 0.1398 - val_accuracy: 0.9590\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0863 - accuracy: 0.9762 - val_loss: 0.1467 - val_accuracy: 0.9570\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0818 - accuracy: 0.9772 - val_loss: 0.1395 - val_accuracy: 0.9570\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0763 - accuracy: 0.9793 - val_loss: 0.1396 - val_accuracy: 0.9540\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0739 - accuracy: 0.9800 - val_loss: 0.1378 - val_accuracy: 0.9570\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0716 - accuracy: 0.9793 - val_loss: 0.1542 - val_accuracy: 0.9460\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0687 - accuracy: 0.9800 - val_loss: 0.1436 - val_accuracy: 0.9540\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0681 - accuracy: 0.9805 - val_loss: 0.1473 - val_accuracy: 0.9510\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.0611 - accuracy: 0.9825 - val_loss: 0.1455 - val_accuracy: 0.9520\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0576 - accuracy: 0.9847 - val_loss: 0.1426 - val_accuracy: 0.9530\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0574 - accuracy: 0.9843 - val_loss: 0.1389 - val_accuracy: 0.9600\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0539 - accuracy: 0.9872 - val_loss: 0.1425 - val_accuracy: 0.9520\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0473 - accuracy: 0.9880 - val_loss: 0.1544 - val_accuracy: 0.9560\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0453 - accuracy: 0.9893 - val_loss: 0.1472 - val_accuracy: 0.9540\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0407 - accuracy: 0.9908 - val_loss: 0.1446 - val_accuracy: 0.9580\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0377 - accuracy: 0.9920 - val_loss: 0.1438 - val_accuracy: 0.9540\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0365 - accuracy: 0.9910 - val_loss: 0.1458 - val_accuracy: 0.9560\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0311 - accuracy: 0.9935 - val_loss: 0.1553 - val_accuracy: 0.9430\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0313 - accuracy: 0.9933 - val_loss: 0.1469 - val_accuracy: 0.9550\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0262 - accuracy: 0.9942 - val_loss: 0.1552 - val_accuracy: 0.9530\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0269 - accuracy: 0.9942 - val_loss: 0.1558 - val_accuracy: 0.9550\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0230 - accuracy: 0.9960 - val_loss: 0.1544 - val_accuracy: 0.9550\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0197 - accuracy: 0.9967 - val_loss: 0.1562 - val_accuracy: 0.9520\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0196 - accuracy: 0.9960 - val_loss: 0.1644 - val_accuracy: 0.9550\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0175 - accuracy: 0.9973 - val_loss: 0.1564 - val_accuracy: 0.9530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7060172007225376\n",
      "F1 Micro: 0.9596\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7079206872922666\n",
      "F1 Micro: 0.9542\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6923351634618976\n",
      "F1 Micro: 0.9607\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 7 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.3624 - accuracy: 0.9098 - val_loss: 0.2262 - val_accuracy: 0.9362\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.1683 - accuracy: 0.9503 - val_loss: 0.1461 - val_accuracy: 0.9570\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.1374 - accuracy: 0.9570 - val_loss: 0.1736 - val_accuracy: 0.9489\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.1228 - accuracy: 0.9607 - val_loss: 0.1265 - val_accuracy: 0.9603\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.1144 - accuracy: 0.9636 - val_loss: 0.1240 - val_accuracy: 0.9608\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.1043 - accuracy: 0.9666 - val_loss: 0.1196 - val_accuracy: 0.9650\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0974 - accuracy: 0.9688 - val_loss: 0.1050 - val_accuracy: 0.9679\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0920 - accuracy: 0.9697 - val_loss: 0.1062 - val_accuracy: 0.9665\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0864 - accuracy: 0.9714 - val_loss: 0.1087 - val_accuracy: 0.9658\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0798 - accuracy: 0.9740 - val_loss: 0.0973 - val_accuracy: 0.9681\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0743 - accuracy: 0.9746 - val_loss: 0.0917 - val_accuracy: 0.9722\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0681 - accuracy: 0.9772 - val_loss: 0.0978 - val_accuracy: 0.9681\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0634 - accuracy: 0.9784 - val_loss: 0.0986 - val_accuracy: 0.9700\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0569 - accuracy: 0.9810 - val_loss: 0.1065 - val_accuracy: 0.9678\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0519 - accuracy: 0.9825 - val_loss: 0.1084 - val_accuracy: 0.9648\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0474 - accuracy: 0.9837 - val_loss: 0.1136 - val_accuracy: 0.9615\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0416 - accuracy: 0.9854 - val_loss: 0.1081 - val_accuracy: 0.9684\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0350 - accuracy: 0.9883 - val_loss: 0.1034 - val_accuracy: 0.9697\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0303 - accuracy: 0.9896 - val_loss: 0.1014 - val_accuracy: 0.9699\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 0.1267 - val_accuracy: 0.9698\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 0.1035 - val_accuracy: 0.9709\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.1115 - val_accuracy: 0.9704\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.1328 - val_accuracy: 0.9720\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.1239 - val_accuracy: 0.9731\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.1473 - val_accuracy: 0.9671\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.1934 - val_accuracy: 0.9673\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.1695 - val_accuracy: 0.9664\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1446 - val_accuracy: 0.9719\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.1377 - val_accuracy: 0.9688\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.1807 - val_accuracy: 0.9665\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.1374 - val_accuracy: 0.9702\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7730439886821769\n",
      "F1 Micro: 0.9697\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7971820150259421\n",
      "F1 Micro: 0.9651\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.4899 - accuracy: 0.8909 - val_loss: 0.1667 - val_accuracy: 0.9537\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.1396 - accuracy: 0.9592 - val_loss: 0.1376 - val_accuracy: 0.9595\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1221 - accuracy: 0.9633 - val_loss: 0.1268 - val_accuracy: 0.9610\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1130 - accuracy: 0.9656 - val_loss: 0.1213 - val_accuracy: 0.9624\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1069 - accuracy: 0.9669 - val_loss: 0.1156 - val_accuracy: 0.9640\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1027 - accuracy: 0.9689 - val_loss: 0.1111 - val_accuracy: 0.9647\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0996 - accuracy: 0.9694 - val_loss: 0.1118 - val_accuracy: 0.9645\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0965 - accuracy: 0.9706 - val_loss: 0.1068 - val_accuracy: 0.9665\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0943 - accuracy: 0.9703 - val_loss: 0.1063 - val_accuracy: 0.9667\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0920 - accuracy: 0.9712 - val_loss: 0.1042 - val_accuracy: 0.9679\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0906 - accuracy: 0.9717 - val_loss: 0.1042 - val_accuracy: 0.9673\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0887 - accuracy: 0.9718 - val_loss: 0.1025 - val_accuracy: 0.9677\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0868 - accuracy: 0.9725 - val_loss: 0.1007 - val_accuracy: 0.9683\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0856 - accuracy: 0.9732 - val_loss: 0.1006 - val_accuracy: 0.9679\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0841 - accuracy: 0.9734 - val_loss: 0.1002 - val_accuracy: 0.9677\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0829 - accuracy: 0.9743 - val_loss: 0.0983 - val_accuracy: 0.9686\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0814 - accuracy: 0.9747 - val_loss: 0.0977 - val_accuracy: 0.9690\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0805 - accuracy: 0.9749 - val_loss: 0.0978 - val_accuracy: 0.9692\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0792 - accuracy: 0.9754 - val_loss: 0.0968 - val_accuracy: 0.9690\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0785 - accuracy: 0.9754 - val_loss: 0.0959 - val_accuracy: 0.9696\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0773 - accuracy: 0.9754 - val_loss: 0.0959 - val_accuracy: 0.9693\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0763 - accuracy: 0.9763 - val_loss: 0.0960 - val_accuracy: 0.9684\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0754 - accuracy: 0.9761 - val_loss: 0.0958 - val_accuracy: 0.9689\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0744 - accuracy: 0.9765 - val_loss: 0.0948 - val_accuracy: 0.9690\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0736 - accuracy: 0.9770 - val_loss: 0.0962 - val_accuracy: 0.9693\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0725 - accuracy: 0.9771 - val_loss: 0.0969 - val_accuracy: 0.9686\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0718 - accuracy: 0.9775 - val_loss: 0.0939 - val_accuracy: 0.9698\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0710 - accuracy: 0.9777 - val_loss: 0.0947 - val_accuracy: 0.9696\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0699 - accuracy: 0.9780 - val_loss: 0.0940 - val_accuracy: 0.9706\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0692 - accuracy: 0.9779 - val_loss: 0.0961 - val_accuracy: 0.9685\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0687 - accuracy: 0.9782 - val_loss: 0.0940 - val_accuracy: 0.9705\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0679 - accuracy: 0.9783 - val_loss: 0.0932 - val_accuracy: 0.9696\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0669 - accuracy: 0.9793 - val_loss: 0.0925 - val_accuracy: 0.9707\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0660 - accuracy: 0.9792 - val_loss: 0.0930 - val_accuracy: 0.9693\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0655 - accuracy: 0.9790 - val_loss: 0.0924 - val_accuracy: 0.9699\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0647 - accuracy: 0.9794 - val_loss: 0.0939 - val_accuracy: 0.9695\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0640 - accuracy: 0.9794 - val_loss: 0.0938 - val_accuracy: 0.9692\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0633 - accuracy: 0.9796 - val_loss: 0.0935 - val_accuracy: 0.9700\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0627 - accuracy: 0.9799 - val_loss: 0.0941 - val_accuracy: 0.9698\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0618 - accuracy: 0.9800 - val_loss: 0.0932 - val_accuracy: 0.9693\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0611 - accuracy: 0.9804 - val_loss: 0.0943 - val_accuracy: 0.9702\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0606 - accuracy: 0.9807 - val_loss: 0.0930 - val_accuracy: 0.9704\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0600 - accuracy: 0.9808 - val_loss: 0.0926 - val_accuracy: 0.9716\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0591 - accuracy: 0.9811 - val_loss: 0.0920 - val_accuracy: 0.9710\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0583 - accuracy: 0.9811 - val_loss: 0.0930 - val_accuracy: 0.9706\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0576 - accuracy: 0.9816 - val_loss: 0.0949 - val_accuracy: 0.9704uracy: 0.98\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0571 - accuracy: 0.9816 - val_loss: 0.0982 - val_accuracy: 0.9676\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0567 - accuracy: 0.9822 - val_loss: 0.0941 - val_accuracy: 0.9704\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0560 - accuracy: 0.9819 - val_loss: 0.0933 - val_accuracy: 0.9706\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0552 - accuracy: 0.9824 - val_loss: 0.0942 - val_accuracy: 0.9701\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0548 - accuracy: 0.9825 - val_loss: 0.0936 - val_accuracy: 0.9709\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0538 - accuracy: 0.9826 - val_loss: 0.0941 - val_accuracy: 0.9702\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0535 - accuracy: 0.9828 - val_loss: 0.0942 - val_accuracy: 0.9703\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0529 - accuracy: 0.9828 - val_loss: 0.0936 - val_accuracy: 0.9700\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0517 - accuracy: 0.9831 - val_loss: 0.0966 - val_accuracy: 0.9693\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0517 - accuracy: 0.9833 - val_loss: 0.0937 - val_accuracy: 0.9699\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0508 - accuracy: 0.9837 - val_loss: 0.0956 - val_accuracy: 0.9695\n",
      "Epoch 58/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0503 - accuracy: 0.9843 - val_loss: 0.0946 - val_accuracy: 0.9698\n",
      "Epoch 59/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0497 - accuracy: 0.9840 - val_loss: 0.0964 - val_accuracy: 0.9701\n",
      "Epoch 60/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0489 - accuracy: 0.9843 - val_loss: 0.0964 - val_accuracy: 0.9700\n",
      "Epoch 61/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0485 - accuracy: 0.9849 - val_loss: 0.0976 - val_accuracy: 0.9693\n",
      "Epoch 62/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0480 - accuracy: 0.9846 - val_loss: 0.0957 - val_accuracy: 0.9698\n",
      "Epoch 63/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0473 - accuracy: 0.9847 - val_loss: 0.0965 - val_accuracy: 0.9693\n",
      "Epoch 64/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0465 - accuracy: 0.9855 - val_loss: 0.0985 - val_accuracy: 0.9691\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.840462668220197\n",
      "F1 Micro: 0.9706\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.2525 - accuracy: 0.9297 - val_loss: 0.1620 - val_accuracy: 0.9541\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.1380 - accuracy: 0.9588 - val_loss: 0.1307 - val_accuracy: 0.9598\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.1193 - accuracy: 0.9635 - val_loss: 0.1188 - val_accuracy: 0.9629\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.1087 - accuracy: 0.9661 - val_loss: 0.1260 - val_accuracy: 0.9602\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1014 - accuracy: 0.9678 - val_loss: 0.1039 - val_accuracy: 0.9665\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0943 - accuracy: 0.9700 - val_loss: 0.0980 - val_accuracy: 0.9682\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0870 - accuracy: 0.9725 - val_loss: 0.1077 - val_accuracy: 0.9651\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0816 - accuracy: 0.9733 - val_loss: 0.0897 - val_accuracy: 0.9710\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0763 - accuracy: 0.9749 - val_loss: 0.0879 - val_accuracy: 0.9709\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0717 - accuracy: 0.9767 - val_loss: 0.0874 - val_accuracy: 0.9721\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0668 - accuracy: 0.9775 - val_loss: 0.0847 - val_accuracy: 0.9726\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0627 - accuracy: 0.9787 - val_loss: 0.0832 - val_accuracy: 0.9716\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0575 - accuracy: 0.9805 - val_loss: 0.0798 - val_accuracy: 0.9742\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0520 - accuracy: 0.9826 - val_loss: 0.0817 - val_accuracy: 0.9737\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0466 - accuracy: 0.9849 - val_loss: 0.0836 - val_accuracy: 0.9743\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0417 - accuracy: 0.9861 - val_loss: 0.0949 - val_accuracy: 0.9732\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0356 - accuracy: 0.9887 - val_loss: 0.0916 - val_accuracy: 0.9726\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0309 - accuracy: 0.9904 - val_loss: 0.0899 - val_accuracy: 0.9748\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.0963 - val_accuracy: 0.9741\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.1438 - val_accuracy: 0.9705\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.1022 - val_accuracy: 0.9717\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.1162 - val_accuracy: 0.9748\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.1088 - val_accuracy: 0.9742\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.1182 - val_accuracy: 0.9755\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.1241 - val_accuracy: 0.9733\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.1291 - val_accuracy: 0.9716\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.1224 - val_accuracy: 0.9749\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.1303 - val_accuracy: 0.9730\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.1329 - val_accuracy: 0.9747\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1295 - val_accuracy: 0.9740\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.1843 - val_accuracy: 0.9625\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.1500 - val_accuracy: 0.9724\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1597 - val_accuracy: 0.9728\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8348323801090954\n",
      "F1 Micro: 0.972\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8035886199752158\n",
      "F1 Micro: 0.9635\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.85900171708875\n",
      "F1 Micro: 0.9756\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 7 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.2311 - accuracy: 0.9378 - val_loss: 0.1390 - val_accuracy: 0.9561\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.1153 - accuracy: 0.9636 - val_loss: 0.1124 - val_accuracy: 0.9642\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0997 - accuracy: 0.9676 - val_loss: 0.1044 - val_accuracy: 0.9677\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0906 - accuracy: 0.9704 - val_loss: 0.0895 - val_accuracy: 0.9699\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0818 - accuracy: 0.9729 - val_loss: 0.0813 - val_accuracy: 0.9731\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0745 - accuracy: 0.9751 - val_loss: 0.0993 - val_accuracy: 0.9692\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0689 - accuracy: 0.9767 - val_loss: 0.0718 - val_accuracy: 0.9765\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0625 - accuracy: 0.9787 - val_loss: 0.0825 - val_accuracy: 0.9741\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0586 - accuracy: 0.9796 - val_loss: 0.0659 - val_accuracy: 0.9774\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0543 - accuracy: 0.9807 - val_loss: 0.0645 - val_accuracy: 0.9776\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0505 - accuracy: 0.9820 - val_loss: 0.0720 - val_accuracy: 0.9743\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0468 - accuracy: 0.9831 - val_loss: 0.0652 - val_accuracy: 0.9776\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0436 - accuracy: 0.9845 - val_loss: 0.0757 - val_accuracy: 0.9728\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0391 - accuracy: 0.9857 - val_loss: 0.0712 - val_accuracy: 0.9782\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0365 - accuracy: 0.9864 - val_loss: 0.0702 - val_accuracy: 0.9776\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0324 - accuracy: 0.9883 - val_loss: 0.0740 - val_accuracy: 0.9751\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0284 - accuracy: 0.9899 - val_loss: 0.0731 - val_accuracy: 0.9787\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0253 - accuracy: 0.9906 - val_loss: 0.0760 - val_accuracy: 0.9782\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 0.0805 - val_accuracy: 0.9777\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.0897 - val_accuracy: 0.9784\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.0891 - val_accuracy: 0.9777\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.1001 - val_accuracy: 0.9786\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.1023 - val_accuracy: 0.9757\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.1017 - val_accuracy: 0.9784\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.1083 - val_accuracy: 0.9732\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.1053 - val_accuracy: 0.9788\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.1182 - val_accuracy: 0.9754\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 182us/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.1140 - val_accuracy: 0.9761\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1242 - val_accuracy: 0.9774\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1480 - val_accuracy: 0.9768\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8656475698230258\n",
      "F1 Micro: 0.9779\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8298954981731046\n",
      "F1 Micro: 0.969\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.2491 - accuracy: 0.9367 - val_loss: 0.1216 - val_accuracy: 0.9633\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.1134 - accuracy: 0.9648 - val_loss: 0.1079 - val_accuracy: 0.9663\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.1034 - accuracy: 0.9677 - val_loss: 0.1024 - val_accuracy: 0.9685\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0978 - accuracy: 0.9693 - val_loss: 0.0987 - val_accuracy: 0.9691\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0939 - accuracy: 0.9701 - val_loss: 0.0970 - val_accuracy: 0.9693\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0908 - accuracy: 0.9713 - val_loss: 0.0936 - val_accuracy: 0.9705\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0885 - accuracy: 0.9720 - val_loss: 0.0927 - val_accuracy: 0.9707\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0864 - accuracy: 0.9727 - val_loss: 0.0905 - val_accuracy: 0.9713\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0846 - accuracy: 0.9731 - val_loss: 0.0899 - val_accuracy: 0.9720 0s -\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0828 - accuracy: 0.9737 - val_loss: 0.0929 - val_accuracy: 0.9712\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0814 - accuracy: 0.9738 - val_loss: 0.0880 - val_accuracy: 0.9720\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0800 - accuracy: 0.9745 - val_loss: 0.0870 - val_accuracy: 0.9725\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0787 - accuracy: 0.9746 - val_loss: 0.0868 - val_accuracy: 0.9727\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0774 - accuracy: 0.9748 - val_loss: 0.0862 - val_accuracy: 0.9729\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0764 - accuracy: 0.9749 - val_loss: 0.0864 - val_accuracy: 0.9730\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0753 - accuracy: 0.9757 - val_loss: 0.0857 - val_accuracy: 0.9734\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0743 - accuracy: 0.9758 - val_loss: 0.0860 - val_accuracy: 0.9734\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0734 - accuracy: 0.9761 - val_loss: 0.0842 - val_accuracy: 0.9735\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0724 - accuracy: 0.9766 - val_loss: 0.0841 - val_accuracy: 0.9734\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0715 - accuracy: 0.9767 - val_loss: 0.0827 - val_accuracy: 0.97350.0716 - accuracy\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0707 - accuracy: 0.9768 - val_loss: 0.0846 - val_accuracy: 0.9728\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0700 - accuracy: 0.9772 - val_loss: 0.0831 - val_accuracy: 0.9735\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0692 - accuracy: 0.9775 - val_loss: 0.0820 - val_accuracy: 0.9738\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0684 - accuracy: 0.9774 - val_loss: 0.0827 - val_accuracy: 0.9740\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0676 - accuracy: 0.9777 - val_loss: 0.0835 - val_accuracy: 0.9732\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0669 - accuracy: 0.9781 - val_loss: 0.0817 - val_accuracy: 0.9741\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0661 - accuracy: 0.9784 - val_loss: 0.0834 - val_accuracy: 0.9737\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0656 - accuracy: 0.9786 - val_loss: 0.0818 - val_accuracy: 0.9741\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0648 - accuracy: 0.9785 - val_loss: 0.0831 - val_accuracy: 0.9735\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0641 - accuracy: 0.9791 - val_loss: 0.0819 - val_accuracy: 0.9738\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0635 - accuracy: 0.9792 - val_loss: 0.0823 - val_accuracy: 0.9737\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0629 - accuracy: 0.9793 - val_loss: 0.0827 - val_accuracy: 0.9736\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0622 - accuracy: 0.9797 - val_loss: 0.0818 - val_accuracy: 0.9738\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0616 - accuracy: 0.9796 - val_loss: 0.0830 - val_accuracy: 0.9735\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0610 - accuracy: 0.9798 - val_loss: 0.0820 - val_accuracy: 0.9740\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0605 - accuracy: 0.9801 - val_loss: 0.0831 - val_accuracy: 0.9735\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0599 - accuracy: 0.9804 - val_loss: 0.0823 - val_accuracy: 0.9741\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0594 - accuracy: 0.9804 - val_loss: 0.0819 - val_accuracy: 0.9740\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0586 - accuracy: 0.9807 - val_loss: 0.0816 - val_accuracy: 0.9743\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0582 - accuracy: 0.9807 - val_loss: 0.0819 - val_accuracy: 0.9743\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0577 - accuracy: 0.9810 - val_loss: 0.0827 - val_accuracy: 0.9735\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0571 - accuracy: 0.9816 - val_loss: 0.0824 - val_accuracy: 0.9736\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0565 - accuracy: 0.9814 - val_loss: 0.0821 - val_accuracy: 0.9741\n",
      "Epoch 44/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0560 - accuracy: 0.9814 - val_loss: 0.0836 - val_accuracy: 0.9735.0559 - accuracy: 0.\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0556 - accuracy: 0.9818 - val_loss: 0.0832 - val_accuracy: 0.9732loss: 0.0549  - ETA: 0s - loss: 0.0557 - accuracy\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0550 - accuracy: 0.9823 - val_loss: 0.0839 - val_accuracy: 0.9732\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0546 - accuracy: 0.9819 - val_loss: 0.0845 - val_accuracy: 0.9734\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0539 - accuracy: 0.9824 - val_loss: 0.0834 - val_accuracy: 0.9733\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0534 - accuracy: 0.9826 - val_loss: 0.0842 - val_accuracy: 0.9732\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0530 - accuracy: 0.9828 - val_loss: 0.0834 - val_accuracy: 0.9732\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0524 - accuracy: 0.9827 - val_loss: 0.0843 - val_accuracy: 0.9734\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0519 - accuracy: 0.9829 - val_loss: 0.0832 - val_accuracy: 0.973421 - accuracy\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0515 - accuracy: 0.9833 - val_loss: 0.0841 - val_accuracy: 0.9732\n",
      "Epoch 54/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0509 - accuracy: 0.9836 - val_loss: 0.0851 - val_accuracy: 0.9729\n",
      "Epoch 55/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0503 - accuracy: 0.9838 - val_loss: 0.0839 - val_accuracy: 0.9739\n",
      "Epoch 56/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0499 - accuracy: 0.9836 - val_loss: 0.0836 - val_accuracy: 0.9743\n",
      "Epoch 57/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0493 - accuracy: 0.9838 - val_loss: 0.0850 - val_accuracy: 0.9735\n",
      "Epoch 58/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0490 - accuracy: 0.9843 - val_loss: 0.0854 - val_accuracy: 0.9733\n",
      "Epoch 59/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0484 - accuracy: 0.9844 - val_loss: 0.0853 - val_accuracy: 0.9730\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8638510131316077\n",
      "F1 Micro: 0.9728\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.1765 - accuracy: 0.9488 - val_loss: 0.1202 - val_accuracy: 0.9636\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 25s 191us/step - loss: 0.1076 - accuracy: 0.9662 - val_loss: 0.1033 - val_accuracy: 0.9682\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0969 - accuracy: 0.9693 - val_loss: 0.0938 - val_accuracy: 0.9706\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0882 - accuracy: 0.9716 - val_loss: 0.0871 - val_accuracy: 0.9717\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0802 - accuracy: 0.9738 - val_loss: 0.0868 - val_accuracy: 0.9716\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0743 - accuracy: 0.9754 - val_loss: 0.0792 - val_accuracy: 0.9742\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0685 - accuracy: 0.9772 - val_loss: 0.0803 - val_accuracy: 0.9739\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0630 - accuracy: 0.9789 - val_loss: 0.0775 - val_accuracy: 0.9747\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0572 - accuracy: 0.9807 - val_loss: 0.0797 - val_accuracy: 0.9752\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0513 - accuracy: 0.9827 - val_loss: 0.0774 - val_accuracy: 0.9741\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 0.0775 - val_accuracy: 0.9755\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0385 - accuracy: 0.9870 - val_loss: 0.0791 - val_accuracy: 0.9750\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0310 - accuracy: 0.9895 - val_loss: 0.0948 - val_accuracy: 0.9750\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 0.0883 - val_accuracy: 0.9753\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.0956 - val_accuracy: 0.9748\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.1207 - val_accuracy: 0.9751\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.1101 - val_accuracy: 0.9737\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.1269 - val_accuracy: 0.9753\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.1250 - val_accuracy: 0.9754\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.1341 - val_accuracy: 0.9758\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1396 - val_accuracy: 0.9764\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 25s 191us/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1382 - val_accuracy: 0.9750\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1326 - val_accuracy: 0.9743\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1443 - val_accuracy: 0.9745\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1405 - val_accuracy: 0.9745\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 25s 191us/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1665 - val_accuracy: 0.9749\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.1510 - val_accuracy: 0.9752\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.1646 - val_accuracy: 0.9760\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1536 - val_accuracy: 0.9760\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1435 - val_accuracy: 0.9751\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.882328706656277\n",
      "F1 Micro: 0.974\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8228697922165918\n",
      "F1 Micro: 0.9674000000000001\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.909253721161314\n",
      "F1 Micro: 0.9797\n",
      "\n",
      "\n",
      " 51.40051401058833 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 8 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 8 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 703us/step - loss: 1.9359 - accuracy: 0.7825 - val_loss: 1.4737 - val_accuracy: 0.8800\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 208us/step - loss: 1.0805 - accuracy: 0.8575 - val_loss: 0.6780 - val_accuracy: 0.8800\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7712 - accuracy: 0.8575 - val_loss: 0.6138 - val_accuracy: 0.8800\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6695 - accuracy: 0.8575 - val_loss: 0.5928 - val_accuracy: 0.8800\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6553 - accuracy: 0.8575 - val_loss: 0.5732 - val_accuracy: 0.8800\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6298 - accuracy: 0.8575 - val_loss: 0.5641 - val_accuracy: 0.8800\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6232 - accuracy: 0.8575 - val_loss: 0.5620 - val_accuracy: 0.8800\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6136 - accuracy: 0.8575 - val_loss: 0.5637 - val_accuracy: 0.8800\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6095 - accuracy: 0.8575 - val_loss: 0.5586 - val_accuracy: 0.8800\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 156us/step - loss: 0.5991 - accuracy: 0.8575 - val_loss: 0.5498 - val_accuracy: 0.8800\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5900 - accuracy: 0.8575 - val_loss: 0.5462 - val_accuracy: 0.8800\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5864 - accuracy: 0.8575 - val_loss: 0.5395 - val_accuracy: 0.8800\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5820 - accuracy: 0.8575 - val_loss: 0.5399 - val_accuracy: 0.8800\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5778 - accuracy: 0.8575 - val_loss: 0.5295 - val_accuracy: 0.8800\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.5669 - accuracy: 0.8575 - val_loss: 0.5265 - val_accuracy: 0.8800\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5619 - accuracy: 0.8575 - val_loss: 0.5188 - val_accuracy: 0.8800\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5613 - accuracy: 0.8575 - val_loss: 0.5217 - val_accuracy: 0.8800\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5387 - accuracy: 0.8575 - val_loss: 0.5114 - val_accuracy: 0.8800\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5324 - accuracy: 0.8575 - val_loss: 0.4979 - val_accuracy: 0.8800\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5263 - accuracy: 0.8575 - val_loss: 0.4872 - val_accuracy: 0.8800\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5078 - accuracy: 0.8575 - val_loss: 0.4906 - val_accuracy: 0.8800\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4878 - accuracy: 0.8575 - val_loss: 0.4507 - val_accuracy: 0.8800\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4763 - accuracy: 0.8575 - val_loss: 0.4651 - val_accuracy: 0.8800\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4709 - accuracy: 0.8650 - val_loss: 0.4373 - val_accuracy: 0.8800\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4425 - accuracy: 0.8675 - val_loss: 0.4321 - val_accuracy: 0.8900\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4248 - accuracy: 0.8825 - val_loss: 0.4127 - val_accuracy: 0.8800\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.4095 - accuracy: 0.8825 - val_loss: 0.4043 - val_accuracy: 0.9200\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4064 - accuracy: 0.9050 - val_loss: 0.3858 - val_accuracy: 0.9200\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3903 - accuracy: 0.8975 - val_loss: 0.3934 - val_accuracy: 0.9100\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4060 - accuracy: 0.8925 - val_loss: 0.3737 - val_accuracy: 0.9200\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3698 - accuracy: 0.9000 - val_loss: 0.3768 - val_accuracy: 0.9200\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3467 - accuracy: 0.9075 - val_loss: 0.3751 - val_accuracy: 0.9200\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3406 - accuracy: 0.9100 - val_loss: 0.3695 - val_accuracy: 0.9200\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3228 - accuracy: 0.9175 - val_loss: 0.3753 - val_accuracy: 0.9200\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3207 - accuracy: 0.9175 - val_loss: 0.3565 - val_accuracy: 0.9200\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.3237 - accuracy: 0.91 - 0s 234us/step - loss: 0.3163 - accuracy: 0.9175 - val_loss: 0.3633 - val_accuracy: 0.9200\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3021 - accuracy: 0.9200 - val_loss: 0.3640 - val_accuracy: 0.9200\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2905 - accuracy: 0.9250 - val_loss: 0.3490 - val_accuracy: 0.9200\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.2703 - accuracy: 0.9275 - val_loss: 0.3273 - val_accuracy: 0.9200\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2623 - accuracy: 0.9275 - val_loss: 0.3306 - val_accuracy: 0.9200\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2521 - accuracy: 0.9325 - val_loss: 0.3458 - val_accuracy: 0.9200\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2393 - accuracy: 0.9350 - val_loss: 0.3764 - val_accuracy: 0.9200\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2416 - accuracy: 0.9325 - val_loss: 0.3192 - val_accuracy: 0.9200\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2273 - accuracy: 0.9350 - val_loss: 0.3215 - val_accuracy: 0.9200\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2251 - accuracy: 0.9400 - val_loss: 0.3335 - val_accuracy: 0.9200\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2358 - accuracy: 0.9350 - val_loss: 0.3459 - val_accuracy: 0.9200\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2093 - accuracy: 0.9400 - val_loss: 0.3003 - val_accuracy: 0.9200\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2036 - accuracy: 0.9400 - val_loss: 0.3168 - val_accuracy: 0.9200\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2393 - accuracy: 0.9250 - val_loss: 0.3585 - val_accuracy: 0.9200\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2134 - accuracy: 0.9375 - val_loss: 0.3241 - val_accuracy: 0.9200\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 176us/step - loss: 0.1781 - accuracy: 0.9400 - val_loss: 0.3100 - val_accuracy: 0.9200\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1797 - accuracy: 0.9450 - val_loss: 0.3141 - val_accuracy: 0.9200\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2159 - accuracy: 0.9225 - val_loss: 0.3193 - val_accuracy: 0.9200\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1706 - accuracy: 0.9525 - val_loss: 0.3383 - val_accuracy: 0.9200\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1891 - accuracy: 0.9400 - val_loss: 0.3734 - val_accuracy: 0.9200\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1742 - accuracy: 0.9425 - val_loss: 0.3683 - val_accuracy: 0.9200\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 195us/step - loss: 0.1461 - accuracy: 0.9600 - val_loss: 0.3555 - val_accuracy: 0.9200\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1561 - accuracy: 0.9475 - val_loss: 0.3153 - val_accuracy: 0.9200\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1454 - accuracy: 0.9500 - val_loss: 0.2960 - val_accuracy: 0.9200\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1354 - accuracy: 0.9500 - val_loss: 0.3169 - val_accuracy: 0.9300\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1360 - accuracy: 0.9475 - val_loss: 0.3101 - val_accuracy: 0.9200\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1298 - accuracy: 0.9525 - val_loss: 0.3298 - val_accuracy: 0.9200\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1448 - accuracy: 0.9525 - val_loss: 0.3076 - val_accuracy: 0.9200\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 208us/step - loss: 0.1268 - accuracy: 0.9525 - val_loss: 0.3260 - val_accuracy: 0.8800\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.1360 - accuracy: 0.9700 - val_loss: 0.3269 - val_accuracy: 0.9200\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1127 - accuracy: 0.9575 - val_loss: 0.3387 - val_accuracy: 0.9200\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1084 - accuracy: 0.9625 - val_loss: 0.3129 - val_accuracy: 0.9100\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1178 - accuracy: 0.9625 - val_loss: 0.3593 - val_accuracy: 0.8800\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1306 - accuracy: 0.9550 - val_loss: 0.3103 - val_accuracy: 0.9200\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1197 - accuracy: 0.9575 - val_loss: 0.3472 - val_accuracy: 0.8900\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1228 - accuracy: 0.9675 - val_loss: 0.3196 - val_accuracy: 0.9100\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0966 - accuracy: 0.9725 - val_loss: 0.3028 - val_accuracy: 0.9100\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0915 - accuracy: 0.9750 - val_loss: 0.3225 - val_accuracy: 0.9200\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0854 - accuracy: 0.9750 - val_loss: 0.3633 - val_accuracy: 0.9200\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0912 - accuracy: 0.9725 - val_loss: 0.3898 - val_accuracy: 0.9200\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0917 - accuracy: 0.9650 - val_loss: 0.3647 - val_accuracy: 0.9200\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0853 - accuracy: 0.9750 - val_loss: 0.3551 - val_accuracy: 0.9200\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0745 - accuracy: 0.9850 - val_loss: 0.3359 - val_accuracy: 0.9100\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0769 - accuracy: 0.9775 - val_loss: 0.3658 - val_accuracy: 0.9200\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.40671734051278097\n",
      "F1 Micro: 0.9271988359841452\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5489894013851107\n",
      "F1 Micro: 0.9373338016155737\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 271us/step - loss: 2.1293 - accuracy: 0.1225 - val_loss: 2.0394 - val_accuracy: 0.3100\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.9211 - accuracy: 0.4250 - val_loss: 1.8534 - val_accuracy: 0.5200\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.7795 - accuracy: 0.5450 - val_loss: 1.7241 - val_accuracy: 0.5500\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.6742 - accuracy: 0.5875 - val_loss: 1.6362 - val_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.5935 - accuracy: 0.6150 - val_loss: 1.5618 - val_accuracy: 0.6500\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.5245 - accuracy: 0.6425 - val_loss: 1.4951 - val_accuracy: 0.6700\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.4553 - accuracy: 0.6650 - val_loss: 1.4324 - val_accuracy: 0.6800\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.3886 - accuracy: 0.6925 - val_loss: 1.3715 - val_accuracy: 0.6800\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.3229 - accuracy: 0.7150 - val_loss: 1.3091 - val_accuracy: 0.7200\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.2583 - accuracy: 0.7500 - val_loss: 1.2483 - val_accuracy: 0.7400\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1935 - accuracy: 0.7675 - val_loss: 1.1886 - val_accuracy: 0.7600\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1280 - accuracy: 0.7925 - val_loss: 1.1275 - val_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 1.1971 - accuracy: 0.81 - 0s 78us/step - loss: 1.0661 - accuracy: 0.8075 - val_loss: 1.0693 - val_accuracy: 0.8100\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0039 - accuracy: 0.8275 - val_loss: 1.0140 - val_accuracy: 0.8200\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.9444 - accuracy: 0.8425 - val_loss: 0.9610 - val_accuracy: 0.8400\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8872 - accuracy: 0.8675 - val_loss: 0.9107 - val_accuracy: 0.8400\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8310 - accuracy: 0.8800 - val_loss: 0.8649 - val_accuracy: 0.8300\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7818 - accuracy: 0.8950 - val_loss: 0.8203 - val_accuracy: 0.8300\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.7330 - accuracy: 0.9000 - val_loss: 0.7777 - val_accuracy: 0.8300\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.6876 - accuracy: 0.9025 - val_loss: 0.7396 - val_accuracy: 0.8400\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.6470 - accuracy: 0.9025 - val_loss: 0.7021 - val_accuracy: 0.8400\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 116us/step - loss: 0.6057 - accuracy: 0.9150 - val_loss: 0.6700 - val_accuracy: 0.8400\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 40us/step - loss: 0.5696 - accuracy: 0.9175 - val_loss: 0.6377 - val_accuracy: 0.8600\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5358 - accuracy: 0.9200 - val_loss: 0.6092 - val_accuracy: 0.8700\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5050 - accuracy: 0.9225 - val_loss: 0.5825 - val_accuracy: 0.8800\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4761 - accuracy: 0.9325 - val_loss: 0.5574 - val_accuracy: 0.9000\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4487 - accuracy: 0.9425 - val_loss: 0.5346 - val_accuracy: 0.9000\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4257 - accuracy: 0.9425 - val_loss: 0.5150 - val_accuracy: 0.9000\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4016 - accuracy: 0.9425 - val_loss: 0.4950 - val_accuracy: 0.9000\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3807 - accuracy: 0.9500 - val_loss: 0.4759 - val_accuracy: 0.9000\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 39us/step - loss: 0.3605 - accuracy: 0.9525 - val_loss: 0.4606 - val_accuracy: 0.9000\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.3427 - accuracy: 0.9525 - val_loss: 0.4460 - val_accuracy: 0.9000\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.3259 - accuracy: 0.9525 - val_loss: 0.4320 - val_accuracy: 0.9000\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.3104 - accuracy: 0.9525 - val_loss: 0.4183 - val_accuracy: 0.9000\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2958 - accuracy: 0.9550 - val_loss: 0.4068 - val_accuracy: 0.9000\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2816 - accuracy: 0.9550 - val_loss: 0.3964 - val_accuracy: 0.9000\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2693 - accuracy: 0.9575 - val_loss: 0.3860 - val_accuracy: 0.9000\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2571 - accuracy: 0.9650 - val_loss: 0.3748 - val_accuracy: 0.9000\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2456 - accuracy: 0.9650 - val_loss: 0.3663 - val_accuracy: 0.9000\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2354 - accuracy: 0.9700 - val_loss: 0.3575 - val_accuracy: 0.9000\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2253 - accuracy: 0.9700 - val_loss: 0.3505 - val_accuracy: 0.9000\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2165 - accuracy: 0.9725 - val_loss: 0.3429 - val_accuracy: 0.9100\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2069 - accuracy: 0.9725 - val_loss: 0.3367 - val_accuracy: 0.9100\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1988 - accuracy: 0.9725 - val_loss: 0.3313 - val_accuracy: 0.9100\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.1904 - accuracy: 0.9750 - val_loss: 0.3244 - val_accuracy: 0.9200\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.1830 - accuracy: 0.9750 - val_loss: 0.3195 - val_accuracy: 0.9200\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.1757 - accuracy: 0.9750 - val_loss: 0.3146 - val_accuracy: 0.9200\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.1694 - accuracy: 0.9750 - val_loss: 0.3082 - val_accuracy: 0.9200\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.1629 - accuracy: 0.9775 - val_loss: 0.3051 - val_accuracy: 0.9200\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1570 - accuracy: 0.9775 - val_loss: 0.3003 - val_accuracy: 0.9300\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1510 - accuracy: 0.9775 - val_loss: 0.2955 - val_accuracy: 0.9200\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1459 - accuracy: 0.9775 - val_loss: 0.2927 - val_accuracy: 0.9200\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1404 - accuracy: 0.9775 - val_loss: 0.2883 - val_accuracy: 0.9300\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1352 - accuracy: 0.9775 - val_loss: 0.2848 - val_accuracy: 0.9300\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 95us/step - loss: 0.1310 - accuracy: 0.9775 - val_loss: 0.2814 - val_accuracy: 0.9300\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.1267 - accuracy: 0.9775 - val_loss: 0.2785 - val_accuracy: 0.9400\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.1221 - accuracy: 0.9800 - val_loss: 0.2759 - val_accuracy: 0.9300\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.1181 - accuracy: 0.9825 - val_loss: 0.2729 - val_accuracy: 0.9300\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1143 - accuracy: 0.9825 - val_loss: 0.2702 - val_accuracy: 0.9400\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1104 - accuracy: 0.9825 - val_loss: 0.2686 - val_accuracy: 0.9400\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1068 - accuracy: 0.9825 - val_loss: 0.2661 - val_accuracy: 0.9400\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1036 - accuracy: 0.9850 - val_loss: 0.2650 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1001 - accuracy: 0.9850 - val_loss: 0.2630 - val_accuracy: 0.9500\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0976 - accuracy: 0.9850 - val_loss: 0.2598 - val_accuracy: 0.9300\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0943 - accuracy: 0.9850 - val_loss: 0.2603 - val_accuracy: 0.9500\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0910 - accuracy: 0.9850 - val_loss: 0.2585 - val_accuracy: 0.9500\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0883 - accuracy: 0.9850 - val_loss: 0.2560 - val_accuracy: 0.9400\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0850 - accuracy: 0.9850 - val_loss: 0.2563 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0833 - accuracy: 0.9850 - val_loss: 0.2581 - val_accuracy: 0.9500\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0804 - accuracy: 0.9875 - val_loss: 0.2554 - val_accuracy: 0.9500\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0779 - accuracy: 0.9900 - val_loss: 0.2534 - val_accuracy: 0.9400\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0757 - accuracy: 0.9900 - val_loss: 0.2537 - val_accuracy: 0.9500\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0739 - accuracy: 0.9900 - val_loss: 0.2519 - val_accuracy: 0.9400\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0716 - accuracy: 0.9900 - val_loss: 0.2525 - val_accuracy: 0.9400\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0698 - accuracy: 0.9900 - val_loss: 0.2515 - val_accuracy: 0.9400\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0680 - accuracy: 0.9900 - val_loss: 0.2495 - val_accuracy: 0.9400\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0660 - accuracy: 0.9900 - val_loss: 0.2508 - val_accuracy: 0.9400\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0642 - accuracy: 0.9925 - val_loss: 0.2495 - val_accuracy: 0.9400\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0626 - accuracy: 0.9925 - val_loss: 0.2485 - val_accuracy: 0.9400\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0609 - accuracy: 0.9925 - val_loss: 0.2481 - val_accuracy: 0.9300\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0594 - accuracy: 0.9950 - val_loss: 0.2467 - val_accuracy: 0.9400\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0579 - accuracy: 0.9950 - val_loss: 0.2476 - val_accuracy: 0.9300\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0564 - accuracy: 0.9975 - val_loss: 0.2468 - val_accuracy: 0.9300\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0550 - accuracy: 0.9975 - val_loss: 0.2478 - val_accuracy: 0.9300\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0537 - accuracy: 0.9975 - val_loss: 0.2471 - val_accuracy: 0.9300\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0524 - accuracy: 0.9975 - val_loss: 0.2461 - val_accuracy: 0.9300\n",
      "Epoch 87/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 39us/step - loss: 0.0511 - accuracy: 0.9975 - val_loss: 0.2465 - val_accuracy: 0.9300\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 51us/step - loss: 0.0500 - accuracy: 0.9975 - val_loss: 0.2460 - val_accuracy: 0.9300\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0488 - accuracy: 0.9975 - val_loss: 0.2465 - val_accuracy: 0.9300\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0477 - accuracy: 0.9975 - val_loss: 0.2458 - val_accuracy: 0.9300\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0467 - accuracy: 0.9975 - val_loss: 0.2472 - val_accuracy: 0.9300\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0455 - accuracy: 0.9975 - val_loss: 0.2470 - val_accuracy: 0.9300\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0445 - accuracy: 0.9975 - val_loss: 0.2454 - val_accuracy: 0.9300\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0434 - accuracy: 0.9975 - val_loss: 0.2458 - val_accuracy: 0.9300\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0425 - accuracy: 0.9975 - val_loss: 0.2467 - val_accuracy: 0.9300\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0417 - accuracy: 0.9975 - val_loss: 0.2454 - val_accuracy: 0.9300\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0405 - accuracy: 0.9975 - val_loss: 0.2471 - val_accuracy: 0.9300\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0398 - accuracy: 0.9975 - val_loss: 0.2468 - val_accuracy: 0.9300\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0388 - accuracy: 0.9975 - val_loss: 0.2473 - val_accuracy: 0.9300\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0380 - accuracy: 0.9975 - val_loss: 0.2459 - val_accuracy: 0.9300\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0373 - accuracy: 0.9975 - val_loss: 0.2468 - val_accuracy: 0.9300\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0363 - accuracy: 0.9975 - val_loss: 0.2465 - val_accuracy: 0.9300\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0357 - accuracy: 0.9975 - val_loss: 0.2466 - val_accuracy: 0.9300\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0350 - accuracy: 0.9975 - val_loss: 0.2453 - val_accuracy: 0.9300\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0342 - accuracy: 0.9975 - val_loss: 0.2468 - val_accuracy: 0.9300\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0336 - accuracy: 0.9975 - val_loss: 0.2480 - val_accuracy: 0.9300\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0329 - accuracy: 0.9975 - val_loss: 0.2478 - val_accuracy: 0.9300\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0322 - accuracy: 0.9975 - val_loss: 0.2472 - val_accuracy: 0.9300\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9300\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9300\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9300\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9300\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9300\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9300\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9300\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9300\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9300\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9300\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9300\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9300\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 63us/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9300\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9300\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9300\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9300\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6331467507491605\n",
      "F1 Micro: 0.9471677286638903\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 680us/step - loss: 2.0817 - accuracy: 0.3125 - val_loss: 1.5611 - val_accuracy: 0.8200\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 1.0789 - accuracy: 0.8550 - val_loss: 0.4675 - val_accuracy: 0.8900\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5222 - accuracy: 0.8575 - val_loss: 0.3972 - val_accuracy: 0.8900\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.4601 - accuracy: 0.8675 - val_loss: 0.3509 - val_accuracy: 0.9000\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4070 - accuracy: 0.8925 - val_loss: 0.3340 - val_accuracy: 0.9200\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3763 - accuracy: 0.9075 - val_loss: 0.3103 - val_accuracy: 0.9100\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3545 - accuracy: 0.9125 - val_loss: 0.2966 - val_accuracy: 0.9300\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3355 - accuracy: 0.9175 - val_loss: 0.2829 - val_accuracy: 0.9300\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3205 - accuracy: 0.9175 - val_loss: 0.2752 - val_accuracy: 0.9200\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3062 - accuracy: 0.9200 - val_loss: 0.2653 - val_accuracy: 0.9300\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2909 - accuracy: 0.9250 - val_loss: 0.2605 - val_accuracy: 0.9300\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2791 - accuracy: 0.9325 - val_loss: 0.2552 - val_accuracy: 0.9300\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2685 - accuracy: 0.9350 - val_loss: 0.2488 - val_accuracy: 0.9400\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2608 - accuracy: 0.9350 - val_loss: 0.2477 - val_accuracy: 0.9400\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2499 - accuracy: 0.9375 - val_loss: 0.2431 - val_accuracy: 0.9400\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 182us/step - loss: 0.2438 - accuracy: 0.9425 - val_loss: 0.2385 - val_accuracy: 0.9400\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 234us/step - loss: 0.2344 - accuracy: 0.9425 - val_loss: 0.2350 - val_accuracy: 0.9300\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2259 - accuracy: 0.9500 - val_loss: 0.2338 - val_accuracy: 0.9400\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2210 - accuracy: 0.9450 - val_loss: 0.2317 - val_accuracy: 0.9400\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2136 - accuracy: 0.9475 - val_loss: 0.2325 - val_accuracy: 0.9400\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2098 - accuracy: 0.9450 - val_loss: 0.2235 - val_accuracy: 0.9400\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1991 - accuracy: 0.9525 - val_loss: 0.2280 - val_accuracy: 0.9300\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1923 - accuracy: 0.9550 - val_loss: 0.2194 - val_accuracy: 0.9300\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1881 - accuracy: 0.9500 - val_loss: 0.2170 - val_accuracy: 0.9300\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1830 - accuracy: 0.9550 - val_loss: 0.2158 - val_accuracy: 0.9400\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1784 - accuracy: 0.9475 - val_loss: 0.2168 - val_accuracy: 0.9300\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1727 - accuracy: 0.9575 - val_loss: 0.2132 - val_accuracy: 0.9300\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1702 - accuracy: 0.9575 - val_loss: 0.2144 - val_accuracy: 0.9300\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1651 - accuracy: 0.9525 - val_loss: 0.2156 - val_accuracy: 0.9200\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1607 - accuracy: 0.9600 - val_loss: 0.2090 - val_accuracy: 0.9300\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1561 - accuracy: 0.9575 - val_loss: 0.2085 - val_accuracy: 0.9200\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1513 - accuracy: 0.9625 - val_loss: 0.2076 - val_accuracy: 0.9200\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1492 - accuracy: 0.9625 - val_loss: 0.2072 - val_accuracy: 0.9400\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1466 - accuracy: 0.96 - 0s 234us/step - loss: 0.1437 - accuracy: 0.9650 - val_loss: 0.2055 - val_accuracy: 0.9300\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1395 - accuracy: 0.9675 - val_loss: 0.2016 - val_accuracy: 0.9400\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1388 - accuracy: 0.9650 - val_loss: 0.2071 - val_accuracy: 0.9300\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1328 - accuracy: 0.9700 - val_loss: 0.2040 - val_accuracy: 0.9300\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1308 - accuracy: 0.9675 - val_loss: 0.2012 - val_accuracy: 0.9300\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 175us/step - loss: 0.1272 - accuracy: 0.9700 - val_loss: 0.2037 - val_accuracy: 0.9300\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1276 - accuracy: 0.9625 - val_loss: 0.2036 - val_accuracy: 0.9300\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1253 - accuracy: 0.9750 - val_loss: 0.2035 - val_accuracy: 0.9300\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1258 - accuracy: 0.9600 - val_loss: 0.1987 - val_accuracy: 0.9300\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1181 - accuracy: 0.9750 - val_loss: 0.2008 - val_accuracy: 0.9300\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1128 - accuracy: 0.9725 - val_loss: 0.1997 - val_accuracy: 0.9300\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1099 - accuracy: 0.9750 - val_loss: 0.2012 - val_accuracy: 0.9300\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1074 - accuracy: 0.9750 - val_loss: 0.2034 - val_accuracy: 0.9300\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1052 - accuracy: 0.9725 - val_loss: 0.2006 - val_accuracy: 0.9300\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1027 - accuracy: 0.9750 - val_loss: 0.1991 - val_accuracy: 0.9300\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1017 - accuracy: 0.9775 - val_loss: 0.2049 - val_accuracy: 0.9300\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1005 - accuracy: 0.9700 - val_loss: 0.1988 - val_accuracy: 0.9400\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0980 - accuracy: 0.9825 - val_loss: 0.2018 - val_accuracy: 0.9400\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0945 - accuracy: 0.9750 - val_loss: 0.2007 - val_accuracy: 0.9400\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0928 - accuracy: 0.9800 - val_loss: 0.1989 - val_accuracy: 0.9400\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0908 - accuracy: 0.9775 - val_loss: 0.2020 - val_accuracy: 0.9400\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0862 - accuracy: 0.9800 - val_loss: 0.2016 - val_accuracy: 0.9400\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0841 - accuracy: 0.9800 - val_loss: 0.2043 - val_accuracy: 0.9400\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0815 - accuracy: 0.9800 - val_loss: 0.1987 - val_accuracy: 0.9400\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0792 - accuracy: 0.9800 - val_loss: 0.2031 - val_accuracy: 0.9400\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0783 - accuracy: 0.9800 - val_loss: 0.2021 - val_accuracy: 0.9400\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0767 - accuracy: 0.9800 - val_loss: 0.2016 - val_accuracy: 0.9400\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0758 - accuracy: 0.9825 - val_loss: 0.2008 - val_accuracy: 0.9400\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0730 - accuracy: 0.9850 - val_loss: 0.2041 - val_accuracy: 0.9400\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 182us/step - loss: 0.0698 - accuracy: 0.9825 - val_loss: 0.2057 - val_accuracy: 0.9400\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0683 - accuracy: 0.9850 - val_loss: 0.2002 - val_accuracy: 0.9400\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0671 - accuracy: 0.9800 - val_loss: 0.2032 - val_accuracy: 0.9200\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0664 - accuracy: 0.9875 - val_loss: 0.2037 - val_accuracy: 0.9400\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0644 - accuracy: 0.9850 - val_loss: 0.2022 - val_accuracy: 0.9400\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0643 - accuracy: 0.9900 - val_loss: 0.2033 - val_accuracy: 0.9400\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0578 - accuracy: 0.9925 - val_loss: 0.2029 - val_accuracy: 0.9300\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0596 - accuracy: 0.9925 - val_loss: 0.2051 - val_accuracy: 0.9400\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0572 - accuracy: 0.9900 - val_loss: 0.2034 - val_accuracy: 0.9200\n",
      "Epoch 72/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 234us/step - loss: 0.0554 - accuracy: 0.9900 - val_loss: 0.2001 - val_accuracy: 0.9400\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0522 - accuracy: 0.9925 - val_loss: 0.2098 - val_accuracy: 0.9300\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0544 - accuracy: 0.9900 - val_loss: 0.2043 - val_accuracy: 0.9400\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0511 - accuracy: 0.9950 - val_loss: 0.2026 - val_accuracy: 0.9400\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0517 - accuracy: 0.9875 - val_loss: 0.2016 - val_accuracy: 0.9400\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0515 - accuracy: 0.9925 - val_loss: 0.2041 - val_accuracy: 0.9400\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5711808369387359\n",
      "F1 Micro: 0.9404445336410617\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5943566819955219\n",
      "F1 Micro: 0.9391400331142441\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6383408562622741\n",
      "F1 Micro: 0.9489739601625609\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 8 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 237us/step - loss: 0.8637 - accuracy: 0.8545 - val_loss: 0.6885 - val_accuracy: 0.8380\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.6081 - accuracy: 0.8633 - val_loss: 0.6570 - val_accuracy: 0.8380\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.5586 - accuracy: 0.8633 - val_loss: 0.5723 - val_accuracy: 0.8380\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.4485 - accuracy: 0.8798 - val_loss: 0.3928 - val_accuracy: 0.8960\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.3447 - accuracy: 0.9112 - val_loss: 0.4411 - val_accuracy: 0.8800\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.2985 - accuracy: 0.9197 - val_loss: 0.3378 - val_accuracy: 0.9110\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.2598 - accuracy: 0.9273 - val_loss: 0.2864 - val_accuracy: 0.9310\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.2345 - accuracy: 0.9355 - val_loss: 0.2773 - val_accuracy: 0.9360\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.2149 - accuracy: 0.9390 - val_loss: 0.2641 - val_accuracy: 0.9290\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.2004 - accuracy: 0.9435 - val_loss: 0.2637 - val_accuracy: 0.9230\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1948 - accuracy: 0.9442 - val_loss: 0.2240 - val_accuracy: 0.9440\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1792 - accuracy: 0.9477 - val_loss: 0.2536 - val_accuracy: 0.9310\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1657 - accuracy: 0.9510 - val_loss: 0.2268 - val_accuracy: 0.9420\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1589 - accuracy: 0.9530 - val_loss: 0.2295 - val_accuracy: 0.9370\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.1561 - accuracy: 0.9532 - val_loss: 0.1926 - val_accuracy: 0.9450\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1435 - accuracy: 0.9610 - val_loss: 0.1895 - val_accuracy: 0.9440\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1482 - accuracy: 0.9565 - val_loss: 0.2112 - val_accuracy: 0.9380\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1358 - accuracy: 0.9588 - val_loss: 0.1757 - val_accuracy: 0.9480\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1321 - accuracy: 0.9592 - val_loss: 0.1996 - val_accuracy: 0.9430\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.1266 - accuracy: 0.9622 - val_loss: 0.1901 - val_accuracy: 0.9430\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1204 - accuracy: 0.9650 - val_loss: 0.1915 - val_accuracy: 0.9450\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1199 - accuracy: 0.9640 - val_loss: 0.1783 - val_accuracy: 0.9470\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1119 - accuracy: 0.9675 - val_loss: 0.1795 - val_accuracy: 0.9470\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.1076 - accuracy: 0.9685 - val_loss: 0.1872 - val_accuracy: 0.9480\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.1057 - accuracy: 0.9693 - val_loss: 0.1740 - val_accuracy: 0.9510\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1052 - accuracy: 0.9688 - val_loss: 0.1982 - val_accuracy: 0.9460\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0965 - accuracy: 0.9732 - val_loss: 0.1776 - val_accuracy: 0.9500\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.0977 - accuracy: 0.9720 - val_loss: 0.1794 - val_accuracy: 0.9480\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0877 - accuracy: 0.9735 - val_loss: 0.1738 - val_accuracy: 0.9490\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.0892 - accuracy: 0.9735 - val_loss: 0.1975 - val_accuracy: 0.9450\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0849 - accuracy: 0.9762 - val_loss: 0.2619 - val_accuracy: 0.9350\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0800 - accuracy: 0.9787 - val_loss: 0.1668 - val_accuracy: 0.9520\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0785 - accuracy: 0.9770 - val_loss: 0.1694 - val_accuracy: 0.9470\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0728 - accuracy: 0.9772 - val_loss: 0.1775 - val_accuracy: 0.9460\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.0746 - accuracy: 0.9768 - val_loss: 0.1723 - val_accuracy: 0.9520\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.0682 - accuracy: 0.9790 - val_loss: 0.1646 - val_accuracy: 0.9510\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0749 - accuracy: 0.9768 - val_loss: 0.1670 - val_accuracy: 0.9560\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0609 - accuracy: 0.9825 - val_loss: 0.1749 - val_accuracy: 0.9520\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0615 - accuracy: 0.9812 - val_loss: 0.1779 - val_accuracy: 0.9510\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0561 - accuracy: 0.9835 - val_loss: 0.1924 - val_accuracy: 0.9480\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0563 - accuracy: 0.9825 - val_loss: 0.2689 - val_accuracy: 0.9410\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0575 - accuracy: 0.9837 - val_loss: 0.1701 - val_accuracy: 0.9560\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0487 - accuracy: 0.9847 - val_loss: 0.1984 - val_accuracy: 0.9430\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.0422 - accuracy: 0.9865 - val_loss: 0.1834 - val_accuracy: 0.9510\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0407 - accuracy: 0.9885 - val_loss: 0.1818 - val_accuracy: 0.9520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.0364 - accuracy: 0.9908 - val_loss: 0.1983 - val_accuracy: 0.9510\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.0405 - accuracy: 0.9877 - val_loss: 0.1961 - val_accuracy: 0.9560\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0340 - accuracy: 0.9893 - val_loss: 0.2256 - val_accuracy: 0.9460\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0346 - accuracy: 0.9905 - val_loss: 0.1779 - val_accuracy: 0.9530\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0327 - accuracy: 0.9902 - val_loss: 0.1796 - val_accuracy: 0.9560\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0268 - accuracy: 0.9940 - val_loss: 0.1875 - val_accuracy: 0.9540\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0234 - accuracy: 0.9942 - val_loss: 0.1889 - val_accuracy: 0.9470\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0221 - accuracy: 0.9955 - val_loss: 0.2058 - val_accuracy: 0.9460\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0280 - accuracy: 0.9898 - val_loss: 0.2129 - val_accuracy: 0.9530\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0177 - accuracy: 0.9973 - val_loss: 0.2008 - val_accuracy: 0.9530\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0144 - accuracy: 0.9977 - val_loss: 0.1991 - val_accuracy: 0.9540\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6108718078748908\n",
      "F1 Micro: 0.9585\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7050143923965406\n",
      "F1 Micro: 0.9567\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 84us/step - loss: 1.7094 - accuracy: 0.5595 - val_loss: 1.3682 - val_accuracy: 0.6800\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 1.1061 - accuracy: 0.7665 - val_loss: 0.8284 - val_accuracy: 0.8590\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.6265 - accuracy: 0.8992 - val_loss: 0.4744 - val_accuracy: 0.9220\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.3670 - accuracy: 0.9377 - val_loss: 0.3184 - val_accuracy: 0.9420\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.2526 - accuracy: 0.9532 - val_loss: 0.2496 - val_accuracy: 0.9490\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1999 - accuracy: 0.9580 - val_loss: 0.2130 - val_accuracy: 0.9550\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1718 - accuracy: 0.9617 - val_loss: 0.1922 - val_accuracy: 0.9570\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.1545 - accuracy: 0.9640 - val_loss: 0.1786 - val_accuracy: 0.9560\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.1431 - accuracy: 0.9657 - val_loss: 0.1700 - val_accuracy: 0.9580\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1343 - accuracy: 0.9668 - val_loss: 0.1624 - val_accuracy: 0.9600\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1269 - accuracy: 0.9675 - val_loss: 0.1569 - val_accuracy: 0.9600\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1213 - accuracy: 0.9675 - val_loss: 0.1532 - val_accuracy: 0.9600\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1164 - accuracy: 0.9685 - val_loss: 0.1488 - val_accuracy: 0.9580\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1127 - accuracy: 0.9690 - val_loss: 0.1478 - val_accuracy: 0.9610\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1085 - accuracy: 0.9700 - val_loss: 0.1455 - val_accuracy: 0.9600\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1059 - accuracy: 0.9712 - val_loss: 0.1431 - val_accuracy: 0.9600\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1025 - accuracy: 0.9703 - val_loss: 0.1423 - val_accuracy: 0.9610\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0991 - accuracy: 0.9715 - val_loss: 0.1410 - val_accuracy: 0.9600\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0971 - accuracy: 0.9730 - val_loss: 0.1390 - val_accuracy: 0.9610\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0944 - accuracy: 0.9740 - val_loss: 0.1393 - val_accuracy: 0.9610\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0919 - accuracy: 0.9760 - val_loss: 0.1391 - val_accuracy: 0.9620\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0901 - accuracy: 0.9747 - val_loss: 0.1366 - val_accuracy: 0.9610\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0877 - accuracy: 0.9755 - val_loss: 0.1368 - val_accuracy: 0.9610\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.0853 - accuracy: 0.9768 - val_loss: 0.1397 - val_accuracy: 0.9620\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0843 - accuracy: 0.9753 - val_loss: 0.1368 - val_accuracy: 0.9610\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0820 - accuracy: 0.9775 - val_loss: 0.1343 - val_accuracy: 0.9610\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0811 - accuracy: 0.9775 - val_loss: 0.1379 - val_accuracy: 0.9610\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0793 - accuracy: 0.9795 - val_loss: 0.1356 - val_accuracy: 0.9590\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0777 - accuracy: 0.9800 - val_loss: 0.1375 - val_accuracy: 0.9610\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0763 - accuracy: 0.9795 - val_loss: 0.1368 - val_accuracy: 0.9610\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0751 - accuracy: 0.9787 - val_loss: 0.1342 - val_accuracy: 0.9600\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0733 - accuracy: 0.9810 - val_loss: 0.1340 - val_accuracy: 0.9600\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0719 - accuracy: 0.9815 - val_loss: 0.1366 - val_accuracy: 0.9610\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0709 - accuracy: 0.9805 - val_loss: 0.1354 - val_accuracy: 0.9610\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0698 - accuracy: 0.9815 - val_loss: 0.1355 - val_accuracy: 0.9600\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0689 - accuracy: 0.9820 - val_loss: 0.1347 - val_accuracy: 0.9580\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0673 - accuracy: 0.9812 - val_loss: 0.1359 - val_accuracy: 0.9590\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0664 - accuracy: 0.9830 - val_loss: 0.1350 - val_accuracy: 0.9590\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0651 - accuracy: 0.9827 - val_loss: 0.1375 - val_accuracy: 0.9590\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0646 - accuracy: 0.9847 - val_loss: 0.1368 - val_accuracy: 0.9590\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0629 - accuracy: 0.9833 - val_loss: 0.1352 - val_accuracy: 0.9570\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0628 - accuracy: 0.9847 - val_loss: 0.1363 - val_accuracy: 0.9570\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0611 - accuracy: 0.9850 - val_loss: 0.1383 - val_accuracy: 0.9590\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0603 - accuracy: 0.9855 - val_loss: 0.1351 - val_accuracy: 0.9580\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0598 - accuracy: 0.9862 - val_loss: 0.1382 - val_accuracy: 0.9570\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0588 - accuracy: 0.9845 - val_loss: 0.1389 - val_accuracy: 0.9590\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0581 - accuracy: 0.9852 - val_loss: 0.1374 - val_accuracy: 0.9590\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0573 - accuracy: 0.9865 - val_loss: 0.1368 - val_accuracy: 0.9580\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0563 - accuracy: 0.9865 - val_loss: 0.1375 - val_accuracy: 0.9580\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0554 - accuracy: 0.9862 - val_loss: 0.1376 - val_accuracy: 0.9570\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0546 - accuracy: 0.9870 - val_loss: 0.1369 - val_accuracy: 0.9580\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0537 - accuracy: 0.9875 - val_loss: 0.1419 - val_accuracy: 0.9600\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.649912525614445\n",
      "F1 Micro: 0.9578\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 245us/step - loss: 0.6874 - accuracy: 0.8085 - val_loss: 0.3499 - val_accuracy: 0.9160\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.2841 - accuracy: 0.9230 - val_loss: 0.2886 - val_accuracy: 0.9240\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.2387 - accuracy: 0.9377 - val_loss: 0.2518 - val_accuracy: 0.9340\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.2099 - accuracy: 0.9410 - val_loss: 0.2253 - val_accuracy: 0.9360\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.1892 - accuracy: 0.9455 - val_loss: 0.2134 - val_accuracy: 0.9350\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1734 - accuracy: 0.9498 - val_loss: 0.1974 - val_accuracy: 0.9370\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1603 - accuracy: 0.9525 - val_loss: 0.1881 - val_accuracy: 0.9440\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1506 - accuracy: 0.9550 - val_loss: 0.1881 - val_accuracy: 0.9430\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1421 - accuracy: 0.9590 - val_loss: 0.1786 - val_accuracy: 0.9470\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1358 - accuracy: 0.9613 - val_loss: 0.1800 - val_accuracy: 0.9450\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1288 - accuracy: 0.9605 - val_loss: 0.1665 - val_accuracy: 0.9520\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1224 - accuracy: 0.9645 - val_loss: 0.1756 - val_accuracy: 0.9460\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1220 - accuracy: 0.9638 - val_loss: 0.1664 - val_accuracy: 0.9520\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.1194 - accuracy: 0.9643 - val_loss: 0.1598 - val_accuracy: 0.9530\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1140 - accuracy: 0.9653 - val_loss: 0.1591 - val_accuracy: 0.9510\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1051 - accuracy: 0.9682 - val_loss: 0.1550 - val_accuracy: 0.9530\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1036 - accuracy: 0.9693 - val_loss: 0.1504 - val_accuracy: 0.9530\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0996 - accuracy: 0.9688 - val_loss: 0.1551 - val_accuracy: 0.9490\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0971 - accuracy: 0.9678 - val_loss: 0.1535 - val_accuracy: 0.9500\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0930 - accuracy: 0.9703 - val_loss: 0.1454 - val_accuracy: 0.9520\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0907 - accuracy: 0.9720 - val_loss: 0.1458 - val_accuracy: 0.9500\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0874 - accuracy: 0.9722 - val_loss: 0.1472 - val_accuracy: 0.9540\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0863 - accuracy: 0.9728 - val_loss: 0.1454 - val_accuracy: 0.9520\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0816 - accuracy: 0.9743 - val_loss: 0.1605 - val_accuracy: 0.9500\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.0783 - accuracy: 0.9762 - val_loss: 0.1429 - val_accuracy: 0.9550\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0786 - accuracy: 0.9768 - val_loss: 0.1387 - val_accuracy: 0.9550\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0723 - accuracy: 0.9793 - val_loss: 0.1420 - val_accuracy: 0.9500\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0732 - accuracy: 0.9780 - val_loss: 0.1434 - val_accuracy: 0.9520\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0698 - accuracy: 0.9785 - val_loss: 0.1370 - val_accuracy: 0.9560\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0666 - accuracy: 0.9797 - val_loss: 0.1416 - val_accuracy: 0.9560\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0643 - accuracy: 0.9805 - val_loss: 0.1361 - val_accuracy: 0.9560\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0609 - accuracy: 0.9825 - val_loss: 0.1380 - val_accuracy: 0.9570\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0589 - accuracy: 0.9835 - val_loss: 0.1397 - val_accuracy: 0.9550\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0539 - accuracy: 0.9847 - val_loss: 0.1454 - val_accuracy: 0.9540\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0521 - accuracy: 0.9860 - val_loss: 0.1553 - val_accuracy: 0.9530\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0521 - accuracy: 0.9850 - val_loss: 0.1464 - val_accuracy: 0.9550\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0474 - accuracy: 0.9860 - val_loss: 0.1477 - val_accuracy: 0.9570\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0434 - accuracy: 0.9872 - val_loss: 0.1337 - val_accuracy: 0.9570\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0382 - accuracy: 0.9900 - val_loss: 0.1369 - val_accuracy: 0.9570\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0350 - accuracy: 0.9905 - val_loss: 0.1440 - val_accuracy: 0.9540\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0388 - accuracy: 0.9885 - val_loss: 0.1342 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0302 - accuracy: 0.9910 - val_loss: 0.1395 - val_accuracy: 0.9530\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0249 - accuracy: 0.9945 - val_loss: 0.1456 - val_accuracy: 0.9550\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0239 - accuracy: 0.9942 - val_loss: 0.1622 - val_accuracy: 0.9540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0204 - accuracy: 0.9965 - val_loss: 0.1749 - val_accuracy: 0.9510\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0218 - accuracy: 0.9962 - val_loss: 0.1501 - val_accuracy: 0.9610\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0166 - accuracy: 0.9975 - val_loss: 0.1665 - val_accuracy: 0.9560\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0152 - accuracy: 0.9985 - val_loss: 0.1466 - val_accuracy: 0.9540\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0146 - accuracy: 0.9985 - val_loss: 0.1523 - val_accuracy: 0.9610\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0125 - accuracy: 0.9987 - val_loss: 0.1676 - val_accuracy: 0.9530\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0120 - accuracy: 0.9995 - val_loss: 0.1611 - val_accuracy: 0.9560\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0106 - accuracy: 0.9995 - val_loss: 0.1707 - val_accuracy: 0.9580\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0099 - accuracy: 0.9992 - val_loss: 0.1790 - val_accuracy: 0.9530\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 0.9580\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 0.1836 - val_accuracy: 0.9530\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0075 - accuracy: 0.9998 - val_loss: 0.1557 - val_accuracy: 0.9560\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0073 - accuracy: 0.9998 - val_loss: 0.1628 - val_accuracy: 0.9540\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9570\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7515939976388404\n",
      "F1 Micro: 0.9606\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7304197757145685\n",
      "F1 Micro: 0.9576\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7023064431583124\n",
      "F1 Micro: 0.9636\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 8 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.3938 - accuracy: 0.9036 - val_loss: 0.2118 - val_accuracy: 0.9410\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.1773 - accuracy: 0.9479 - val_loss: 0.1532 - val_accuracy: 0.9524\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.1409 - accuracy: 0.9566 - val_loss: 0.1352 - val_accuracy: 0.9590\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.1256 - accuracy: 0.9613 - val_loss: 0.1232 - val_accuracy: 0.9614\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.1134 - accuracy: 0.9643 - val_loss: 0.1133 - val_accuracy: 0.9642\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.1040 - accuracy: 0.9668 - val_loss: 0.1073 - val_accuracy: 0.9663\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0980 - accuracy: 0.9686 - val_loss: 0.1080 - val_accuracy: 0.9663\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0912 - accuracy: 0.9702 - val_loss: 0.1018 - val_accuracy: 0.9669\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0863 - accuracy: 0.9715 - val_loss: 0.1019 - val_accuracy: 0.9685\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0804 - accuracy: 0.9732 - val_loss: 0.1088 - val_accuracy: 0.9659\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0735 - accuracy: 0.9759 - val_loss: 0.1055 - val_accuracy: 0.9682\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0708 - accuracy: 0.9765 - val_loss: 0.0962 - val_accuracy: 0.9691\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0655 - accuracy: 0.9778 - val_loss: 0.0973 - val_accuracy: 0.9700\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0628 - accuracy: 0.9796 - val_loss: 0.0883 - val_accuracy: 0.9718\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0570 - accuracy: 0.9809 - val_loss: 0.1001 - val_accuracy: 0.9672\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0514 - accuracy: 0.9826 - val_loss: 0.0897 - val_accuracy: 0.9718\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0478 - accuracy: 0.9842 - val_loss: 0.0997 - val_accuracy: 0.9704\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0453 - accuracy: 0.9843 - val_loss: 0.1180 - val_accuracy: 0.9691\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0383 - accuracy: 0.9867 - val_loss: 0.0945 - val_accuracy: 0.9713\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 0.1021 - val_accuracy: 0.9724\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0286 - accuracy: 0.9903 - val_loss: 0.1219 - val_accuracy: 0.9703\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0260 - accuracy: 0.9907 - val_loss: 0.1173 - val_accuracy: 0.9724\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0223 - accuracy: 0.9919 - val_loss: 0.1111 - val_accuracy: 0.9704\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.1253 - val_accuracy: 0.9729\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.1125 - val_accuracy: 0.9713\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.1478 - val_accuracy: 0.9706\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.1417 - val_accuracy: 0.9723\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.1436 - val_accuracy: 0.9709\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.1640 - val_accuracy: 0.9695\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.1499 - val_accuracy: 0.9718\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.1584 - val_accuracy: 0.9688\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1972 - val_accuracy: 0.9684\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.1574 - val_accuracy: 0.9703\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.2068 - val_accuracy: 0.9684\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8180742736301869\n",
      "F1 Micro: 0.9689\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8085266857679503\n",
      "F1 Micro: 0.9672\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.5202 - accuracy: 0.8802 - val_loss: 0.1663 - val_accuracy: 0.9537\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.1435 - accuracy: 0.9581 - val_loss: 0.1393 - val_accuracy: 0.9579\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.1262 - accuracy: 0.9621 - val_loss: 0.1324 - val_accuracy: 0.9603\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.1173 - accuracy: 0.9646 - val_loss: 0.1257 - val_accuracy: 0.9624\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.1116 - accuracy: 0.9658 - val_loss: 0.1209 - val_accuracy: 0.9643\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.1070 - accuracy: 0.9671 - val_loss: 0.1180 - val_accuracy: 0.9652\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.1031 - accuracy: 0.9683 - val_loss: 0.1155 - val_accuracy: 0.9638\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.1003 - accuracy: 0.9694 - val_loss: 0.1149 - val_accuracy: 0.9661\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0980 - accuracy: 0.9690 - val_loss: 0.1116 - val_accuracy: 0.9647\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0954 - accuracy: 0.9705 - val_loss: 0.1107 - val_accuracy: 0.9654\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0932 - accuracy: 0.9715 - val_loss: 0.1099 - val_accuracy: 0.9660\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0916 - accuracy: 0.9719 - val_loss: 0.1098 - val_accuracy: 0.9665\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0897 - accuracy: 0.9723 - val_loss: 0.1082 - val_accuracy: 0.9656\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0881 - accuracy: 0.9730 - val_loss: 0.1104 - val_accuracy: 0.9660\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0867 - accuracy: 0.9729 - val_loss: 0.1083 - val_accuracy: 0.9660\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0854 - accuracy: 0.9733 - val_loss: 0.1055 - val_accuracy: 0.9671\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0839 - accuracy: 0.9736 - val_loss: 0.1069 - val_accuracy: 0.9666\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0827 - accuracy: 0.9739 - val_loss: 0.1049 - val_accuracy: 0.9672\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0812 - accuracy: 0.9745 - val_loss: 0.1052 - val_accuracy: 0.9673\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0800 - accuracy: 0.9752 - val_loss: 0.1049 - val_accuracy: 0.9673\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0792 - accuracy: 0.9755 - val_loss: 0.1039 - val_accuracy: 0.9681\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0781 - accuracy: 0.9759 - val_loss: 0.1041 - val_accuracy: 0.9679\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0769 - accuracy: 0.9763 - val_loss: 0.1046 - val_accuracy: 0.9673\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0761 - accuracy: 0.9763 - val_loss: 0.1035 - val_accuracy: 0.9685\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0751 - accuracy: 0.9768 - val_loss: 0.1033 - val_accuracy: 0.9681\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0740 - accuracy: 0.9772 - val_loss: 0.1038 - val_accuracy: 0.9683\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0731 - accuracy: 0.9772 - val_loss: 0.1017 - val_accuracy: 0.9692\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0719 - accuracy: 0.9777 - val_loss: 0.1016 - val_accuracy: 0.9694\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0713 - accuracy: 0.9775 - val_loss: 0.1019 - val_accuracy: 0.9690\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0702 - accuracy: 0.9783 - val_loss: 0.1010 - val_accuracy: 0.9685\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0696 - accuracy: 0.9787 - val_loss: 0.1007 - val_accuracy: 0.9697\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0686 - accuracy: 0.9785 - val_loss: 0.1005 - val_accuracy: 0.9697\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0680 - accuracy: 0.9790 - val_loss: 0.1010 - val_accuracy: 0.9692\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0671 - accuracy: 0.9793 - val_loss: 0.1025 - val_accuracy: 0.9697\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0660 - accuracy: 0.9795 - val_loss: 0.1019 - val_accuracy: 0.96930662 - \n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0654 - accuracy: 0.9799 - val_loss: 0.1031 - val_accuracy: 0.9682\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0646 - accuracy: 0.9797 - val_loss: 0.1000 - val_accuracy: 0.9695\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0640 - accuracy: 0.9798 - val_loss: 0.1007 - val_accuracy: 0.9697\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0633 - accuracy: 0.9801 - val_loss: 0.1023 - val_accuracy: 0.9689\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0624 - accuracy: 0.9804 - val_loss: 0.1014 - val_accuracy: 0.9700\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0616 - accuracy: 0.9807 - val_loss: 0.1019 - val_accuracy: 0.9696\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0612 - accuracy: 0.9815 - val_loss: 0.1004 - val_accuracy: 0.9698\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0602 - accuracy: 0.9808 - val_loss: 0.1019 - val_accuracy: 0.9694\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0595 - accuracy: 0.9820 - val_loss: 0.1023 - val_accuracy: 0.9684\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0588 - accuracy: 0.9815 - val_loss: 0.1013 - val_accuracy: 0.9702\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0582 - accuracy: 0.9820 - val_loss: 0.1031 - val_accuracy: 0.9689\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0573 - accuracy: 0.9820 - val_loss: 0.1025 - val_accuracy: 0.9686\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0567 - accuracy: 0.9822 - val_loss: 0.1020 - val_accuracy: 0.9695\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0562 - accuracy: 0.9833 - val_loss: 0.1026 - val_accuracy: 0.9691\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0553 - accuracy: 0.9825 - val_loss: 0.1035 - val_accuracy: 0.9686\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0548 - accuracy: 0.9830 - val_loss: 0.1021 - val_accuracy: 0.9704\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0545 - accuracy: 0.9835 - val_loss: 0.1021 - val_accuracy: 0.9704\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0535 - accuracy: 0.9836 - val_loss: 0.1015 - val_accuracy: 0.9699loss: 0.0\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.1025 - val_accuracy: 0.9691\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0522 - accuracy: 0.9838 - val_loss: 0.1024 - val_accuracy: 0.9701\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 65us/step - loss: 0.0516 - accuracy: 0.9840 - val_loss: 0.1034 - val_accuracy: 0.9693\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 64us/step - loss: 0.0508 - accuracy: 0.9847 - val_loss: 0.1043 - val_accuracy: 0.9692\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8463296280979724\n",
      "F1 Micro: 0.9705\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.2481 - accuracy: 0.9317 - val_loss: 0.1642 - val_accuracy: 0.9503\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.1406 - accuracy: 0.9580 - val_loss: 0.1372 - val_accuracy: 0.9607\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.1214 - accuracy: 0.9630 - val_loss: 0.1236 - val_accuracy: 0.9619\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.1122 - accuracy: 0.9654 - val_loss: 0.1178 - val_accuracy: 0.9620\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.1045 - accuracy: 0.9674 - val_loss: 0.1150 - val_accuracy: 0.9641\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0991 - accuracy: 0.9692 - val_loss: 0.1070 - val_accuracy: 0.9678\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0937 - accuracy: 0.9704 - val_loss: 0.1032 - val_accuracy: 0.9676\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0878 - accuracy: 0.9728 - val_loss: 0.0960 - val_accuracy: 0.9700\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0820 - accuracy: 0.9745 - val_loss: 0.0968 - val_accuracy: 0.9698\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0765 - accuracy: 0.9757 - val_loss: 0.0899 - val_accuracy: 0.9726\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0715 - accuracy: 0.9775 - val_loss: 0.0934 - val_accuracy: 0.9712\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0667 - accuracy: 0.9782 - val_loss: 0.0907 - val_accuracy: 0.9717\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0607 - accuracy: 0.9808 - val_loss: 0.0912 - val_accuracy: 0.9721\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0562 - accuracy: 0.9824 - val_loss: 0.0880 - val_accuracy: 0.9724\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0505 - accuracy: 0.9841 - val_loss: 0.0921 - val_accuracy: 0.9707\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0445 - accuracy: 0.9859 - val_loss: 0.0890 - val_accuracy: 0.9739\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0384 - accuracy: 0.9884 - val_loss: 0.1028 - val_accuracy: 0.9684\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0324 - accuracy: 0.9905 - val_loss: 0.1019 - val_accuracy: 0.9709\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0266 - accuracy: 0.9922 - val_loss: 0.1160 - val_accuracy: 0.9704\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.1099 - val_accuracy: 0.9696\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0184 - accuracy: 0.9950 - val_loss: 0.1133 - val_accuracy: 0.9702\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.1210 - val_accuracy: 0.9703\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.1284 - val_accuracy: 0.9690\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.1351 - val_accuracy: 0.9695\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.1359 - val_accuracy: 0.9718\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.1476 - val_accuracy: 0.9691\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1624 - val_accuracy: 0.9700\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1768 - val_accuracy: 0.9696\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1489 - val_accuracy: 0.9713\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1870 - val_accuracy: 0.9690\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.1695 - val_accuracy: 0.9711\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1645 - val_accuracy: 0.9705\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.1537 - val_accuracy: 0.9681\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.1610 - val_accuracy: 0.9718\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8214768040995437\n",
      "F1 Micro: 0.9723\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.815675341176796\n",
      "F1 Micro: 0.9669\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8644403417496869\n",
      "F1 Micro: 0.9736\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 8 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.2402 - accuracy: 0.9351 - val_loss: 0.1312 - val_accuracy: 0.9591\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.1178 - accuracy: 0.9630 - val_loss: 0.1107 - val_accuracy: 0.9639\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.1002 - accuracy: 0.9676 - val_loss: 0.0952 - val_accuracy: 0.9692\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 20s 150us/step - loss: 0.0900 - accuracy: 0.9702 - val_loss: 0.1004 - val_accuracy: 0.9664\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0820 - accuracy: 0.9727 - val_loss: 0.0838 - val_accuracy: 0.9710\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0750 - accuracy: 0.9748 - val_loss: 0.0863 - val_accuracy: 0.9709\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0685 - accuracy: 0.9763 - val_loss: 0.0818 - val_accuracy: 0.9711\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0637 - accuracy: 0.9779 - val_loss: 0.0790 - val_accuracy: 0.9729\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0589 - accuracy: 0.9799 - val_loss: 0.0781 - val_accuracy: 0.9719\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.0788 - val_accuracy: 0.9745\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0508 - accuracy: 0.9822 - val_loss: 0.0695 - val_accuracy: 0.9776\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0475 - accuracy: 0.9831 - val_loss: 0.0669 - val_accuracy: 0.9774\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0441 - accuracy: 0.9839 - val_loss: 0.0769 - val_accuracy: 0.9764\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0403 - accuracy: 0.9853 - val_loss: 0.0678 - val_accuracy: 0.9770\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0367 - accuracy: 0.9869 - val_loss: 0.0713 - val_accuracy: 0.9761\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0334 - accuracy: 0.9876 - val_loss: 0.0758 - val_accuracy: 0.9772\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0295 - accuracy: 0.9895 - val_loss: 0.0763 - val_accuracy: 0.9743\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.0791 - val_accuracy: 0.9777\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0227 - accuracy: 0.9918 - val_loss: 0.0850 - val_accuracy: 0.9734\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0198 - accuracy: 0.9929 - val_loss: 0.0879 - val_accuracy: 0.9776 accura - ETA: 0s - loss: 0.0 - ETA: 0s - loss: 0.0198 - accuracy: 0.\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0171 - accuracy: 0.9938 - val_loss: 0.0855 - val_accuracy: 0.9763\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.1074 - val_accuracy: 0.9751\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.1058 - val_accuracy: 0.9768\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.1283 - val_accuracy: 0.9750\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.1046 - val_accuracy: 0.9761\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.1085 - val_accuracy: 0.9761\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.1146 - val_accuracy: 0.9756\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.1139 - val_accuracy: 0.9753\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.1305 - val_accuracy: 0.9724\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.1191 - val_accuracy: 0.9768\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.1313 - val_accuracy: 0.9760\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.1521 - val_accuracy: 0.9755\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8733029235532126\n",
      "F1 Micro: 0.977\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8519584002534696\n",
      "F1 Micro: 0.972\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.2433 - accuracy: 0.9374 - val_loss: 0.1243 - val_accuracy: 0.9621\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.1134 - accuracy: 0.9651 - val_loss: 0.1104 - val_accuracy: 0.9661\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.1032 - accuracy: 0.9676 - val_loss: 0.1041 - val_accuracy: 0.9680\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0974 - accuracy: 0.9692 - val_loss: 0.1012 - val_accuracy: 0.9671\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0936 - accuracy: 0.9706 - val_loss: 0.0987 - val_accuracy: 0.9689\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0905 - accuracy: 0.9713 - val_loss: 0.0961 - val_accuracy: 0.9694\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0879 - accuracy: 0.9721 - val_loss: 0.0947 - val_accuracy: 0.9702\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0857 - accuracy: 0.9727 - val_loss: 0.0940 - val_accuracy: 0.9704\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0839 - accuracy: 0.9732 - val_loss: 0.0921 - val_accuracy: 0.9704\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0823 - accuracy: 0.9737 - val_loss: 0.0913 - val_accuracy: 0.9705\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0807 - accuracy: 0.9739 - val_loss: 0.0902 - val_accuracy: 0.9708\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0793 - accuracy: 0.9745 - val_loss: 0.0915 - val_accuracy: 0.9710\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0778 - accuracy: 0.9747 - val_loss: 0.0897 - val_accuracy: 0.9713\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0767 - accuracy: 0.9751 - val_loss: 0.0892 - val_accuracy: 0.9712\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0755 - accuracy: 0.9754 - val_loss: 0.0892 - val_accuracy: 0.9712\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0744 - accuracy: 0.9759 - val_loss: 0.0887 - val_accuracy: 0.9714\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0734 - accuracy: 0.9761 - val_loss: 0.0894 - val_accuracy: 0.9714\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0726 - accuracy: 0.9762 - val_loss: 0.0880 - val_accuracy: 0.9716\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0717 - accuracy: 0.9767 - val_loss: 0.0873 - val_accuracy: 0.9718\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0708 - accuracy: 0.9768 - val_loss: 0.0868 - val_accuracy: 0.9722\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0700 - accuracy: 0.9770 - val_loss: 0.0869 - val_accuracy: 0.9713\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0692 - accuracy: 0.9773 - val_loss: 0.0862 - val_accuracy: 0.9718\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0683 - accuracy: 0.9775 - val_loss: 0.0868 - val_accuracy: 0.9717\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0677 - accuracy: 0.9778 - val_loss: 0.0858 - val_accuracy: 0.9719\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0671 - accuracy: 0.9779 - val_loss: 0.0857 - val_accuracy: 0.9720\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0663 - accuracy: 0.9784 - val_loss: 0.0863 - val_accuracy: 0.9716\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0656 - accuracy: 0.9786 - val_loss: 0.0865 - val_accuracy: 0.9718\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0650 - accuracy: 0.9788 - val_loss: 0.0869 - val_accuracy: 0.9720\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0643 - accuracy: 0.9790 - val_loss: 0.0856 - val_accuracy: 0.9721\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0637 - accuracy: 0.9791 - val_loss: 0.0853 - val_accuracy: 0.9731\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0632 - accuracy: 0.9793 - val_loss: 0.0846 - val_accuracy: 0.9721ss: 0.0629 - \n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0622 - accuracy: 0.9797 - val_loss: 0.0860 - val_accuracy: 0.9723\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0617 - accuracy: 0.9798 - val_loss: 0.0854 - val_accuracy: 0.9724\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0610 - accuracy: 0.9800 - val_loss: 0.0859 - val_accuracy: 0.9719\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0604 - accuracy: 0.9804 - val_loss: 0.0851 - val_accuracy: 0.9722\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0598 - accuracy: 0.9805 - val_loss: 0.0857 - val_accuracy: 0.9720\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0594 - accuracy: 0.9807 - val_loss: 0.0846 - val_accuracy: 0.9721\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0586 - accuracy: 0.9807 - val_loss: 0.0867 - val_accuracy: 0.9721\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0582 - accuracy: 0.9811 - val_loss: 0.0853 - val_accuracy: 0.9720 \n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0577 - accuracy: 0.9813 - val_loss: 0.0871 - val_accuracy: 0.9728\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0570 - accuracy: 0.9815 - val_loss: 0.0871 - val_accuracy: 0.9726\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.0858 - val_accuracy: 0.9723\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0559 - accuracy: 0.9817 - val_loss: 0.0868 - val_accuracy: 0.9722\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0555 - accuracy: 0.9821 - val_loss: 0.0861 - val_accuracy: 0.9725\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.0869 - val_accuracy: 0.9720\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0544 - accuracy: 0.9822 - val_loss: 0.0861 - val_accuracy: 0.9722\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0539 - accuracy: 0.9825 - val_loss: 0.0866 - val_accuracy: 0.9724\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0534 - accuracy: 0.9828 - val_loss: 0.0862 - val_accuracy: 0.9726\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0528 - accuracy: 0.9829 - val_loss: 0.0877 - val_accuracy: 0.9725\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0524 - accuracy: 0.9831 - val_loss: 0.0856 - val_accuracy: 0.9727\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0519 - accuracy: 0.9832 - val_loss: 0.0876 - val_accuracy: 0.9722\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0512 - accuracy: 0.9834 - val_loss: 0.0875 - val_accuracy: 0.9716\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0508 - accuracy: 0.9836 - val_loss: 0.0877 - val_accuracy: 0.9724\n",
      "Epoch 54/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0501 - accuracy: 0.9839 - val_loss: 0.0875 - val_accuracy: 0.9722\n",
      "Epoch 55/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0498 - accuracy: 0.9840 - val_loss: 0.0882 - val_accuracy: 0.9718\n",
      "Epoch 56/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0492 - accuracy: 0.9842 - val_loss: 0.0875 - val_accuracy: 0.9720\n",
      "Epoch 57/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0487 - accuracy: 0.9842 - val_loss: 0.0886 - val_accuracy: 0.9717\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8610388850527547\n",
      "F1 Micro: 0.9747\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.1685 - accuracy: 0.9514 - val_loss: 0.1169 - val_accuracy: 0.9645\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.1046 - accuracy: 0.9673 - val_loss: 0.1060 - val_accuracy: 0.9666s\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0892 - accuracy: 0.9715 - val_loss: 0.0925 - val_accuracy: 0.9706\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0803 - accuracy: 0.9740 - val_loss: 0.0867 - val_accuracy: 0.9720\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0735 - accuracy: 0.9757 - val_loss: 0.0820 - val_accuracy: 0.9735\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0676 - accuracy: 0.9778 - val_loss: 0.0795 - val_accuracy: 0.9738\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0616 - accuracy: 0.9792 - val_loss: 0.0739 - val_accuracy: 0.9748\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0562 - accuracy: 0.9810 - val_loss: 0.0721 - val_accuracy: 0.9759\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0506 - accuracy: 0.9827 - val_loss: 0.0706 - val_accuracy: 0.9756\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0446 - accuracy: 0.9848 - val_loss: 0.0705 - val_accuracy: 0.9758\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0385 - accuracy: 0.9867 - val_loss: 0.0721 - val_accuracy: 0.9763\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0324 - accuracy: 0.9888 - val_loss: 0.0787 - val_accuracy: 0.9743\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0263 - accuracy: 0.9910 - val_loss: 0.0771 - val_accuracy: 0.9755\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.0896 - val_accuracy: 0.9760\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.1016 - val_accuracy: 0.9712\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0948 - val_accuracy: 0.9758\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.1040 - val_accuracy: 0.9745\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.1182 - val_accuracy: 0.9763\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.1175 - val_accuracy: 0.9754\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.1473 - val_accuracy: 0.9756\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1386 - val_accuracy: 0.9687\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1324 - val_accuracy: 0.9755\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1303 - val_accuracy: 0.9743\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1252 - val_accuracy: 0.9765\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1419 - val_accuracy: 0.9704\n",
      "Epoch 26/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.1613 - val_accuracy: 0.9753\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.1416 - val_accuracy: 0.9766\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1489 - val_accuracy: 0.9742\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.1469 - val_accuracy: 0.9758\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.1501 - val_accuracy: 0.9761\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8831987028394148\n",
      "F1 Micro: 0.9761\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8532664823613128\n",
      "F1 Micro: 0.9703\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8811042758682779\n",
      "F1 Micro: 0.9786\n",
      "\n",
      "\n",
      " 51.52506095170975 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 9 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 9 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 2, 3, 4, 5, 6, 8]\n",
      "label_list [0, 2, 3, 4, 5, 6, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 760us/step - loss: 1.9006 - accuracy: 0.7950 - val_loss: 1.4317 - val_accuracy: 0.8400\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 177us/step - loss: 1.0023 - accuracy: 0.8575 - val_loss: 0.8444 - val_accuracy: 0.8400\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.8060 - accuracy: 0.8575 - val_loss: 0.7894 - val_accuracy: 0.8400\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.7213 - accuracy: 0.8575 - val_loss: 0.7266 - val_accuracy: 0.8400\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.7043 - accuracy: 0.8575 - val_loss: 0.7081 - val_accuracy: 0.8400\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6813 - accuracy: 0.8575 - val_loss: 0.6962 - val_accuracy: 0.8400\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6720 - accuracy: 0.8575 - val_loss: 0.6848 - val_accuracy: 0.8400\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.6660 - accuracy: 0.8575 - val_loss: 0.6869 - val_accuracy: 0.8400\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6477 - accuracy: 0.8575 - val_loss: 0.6740 - val_accuracy: 0.8400\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6484 - accuracy: 0.8575 - val_loss: 0.6740 - val_accuracy: 0.8400\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.6368 - accuracy: 0.8575 - val_loss: 0.6706 - val_accuracy: 0.8400\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6323 - accuracy: 0.8575 - val_loss: 0.6655 - val_accuracy: 0.8400\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 179us/step - loss: 0.6260 - accuracy: 0.8575 - val_loss: 0.6639 - val_accuracy: 0.8400\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6194 - accuracy: 0.8575 - val_loss: 0.6612 - val_accuracy: 0.8400\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6149 - accuracy: 0.8575 - val_loss: 0.6630 - val_accuracy: 0.8400\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6103 - accuracy: 0.8575 - val_loss: 0.6586 - val_accuracy: 0.8400\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6051 - accuracy: 0.8575 - val_loss: 0.6513 - val_accuracy: 0.8400\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5848 - accuracy: 0.8575 - val_loss: 0.6795 - val_accuracy: 0.8400\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5965 - accuracy: 0.8575 - val_loss: 0.6386 - val_accuracy: 0.8400\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5660 - accuracy: 0.8575 - val_loss: 0.6460 - val_accuracy: 0.8400\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5553 - accuracy: 0.8575 - val_loss: 0.6329 - val_accuracy: 0.8400\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5401 - accuracy: 0.8575 - val_loss: 0.6280 - val_accuracy: 0.8400\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5382 - accuracy: 0.8575 - val_loss: 0.6227 - val_accuracy: 0.8400\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.5647 - accuracy: 0.8625 - val_loss: 0.6807 - val_accuracy: 0.8400\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.5521 - accuracy: 0.8550 - val_loss: 0.6303 - val_accuracy: 0.8400\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5102 - accuracy: 0.8575 - val_loss: 0.6246 - val_accuracy: 0.8400\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5028 - accuracy: 0.8575 - val_loss: 0.6048 - val_accuracy: 0.8200\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.4869 - accuracy: 0.8625 - val_loss: 0.6067 - val_accuracy: 0.8200\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4803 - accuracy: 0.8650 - val_loss: 0.6142 - val_accuracy: 0.8200\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4704 - accuracy: 0.8625 - val_loss: 0.5898 - val_accuracy: 0.8300\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.4616 - accuracy: 0.8675 - val_loss: 0.6096 - val_accuracy: 0.8200\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4597 - accuracy: 0.8675 - val_loss: 0.5990 - val_accuracy: 0.8300\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4462 - accuracy: 0.8675 - val_loss: 0.6647 - val_accuracy: 0.8300\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4940 - accuracy: 0.8750 - val_loss: 0.5586 - val_accuracy: 0.8400\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4905 - accuracy: 0.8650 - val_loss: 0.5837 - val_accuracy: 0.8400\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.4554 - accuracy: 0.8775 - val_loss: 0.5705 - val_accuracy: 0.8300\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.4207 - accuracy: 0.8800 - val_loss: 0.5526 - val_accuracy: 0.8400\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4106 - accuracy: 0.8875 - val_loss: 0.5404 - val_accuracy: 0.8400\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3970 - accuracy: 0.8900 - val_loss: 0.5435 - val_accuracy: 0.8400\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3901 - accuracy: 0.8900 - val_loss: 0.5149 - val_accuracy: 0.8400\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3844 - accuracy: 0.8950 - val_loss: 0.5069 - val_accuracy: 0.8500\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3865 - accuracy: 0.8975 - val_loss: 0.5291 - val_accuracy: 0.8400\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3672 - accuracy: 0.9000 - val_loss: 0.4804 - val_accuracy: 0.8600\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3648 - accuracy: 0.9000 - val_loss: 0.4807 - val_accuracy: 0.8600\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3562 - accuracy: 0.9050 - val_loss: 0.4673 - val_accuracy: 0.8600\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3471 - accuracy: 0.9125 - val_loss: 0.4513 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3358 - accuracy: 0.9100 - val_loss: 0.4464 - val_accuracy: 0.8600\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.3288 - accuracy: 0.9150 - val_loss: 0.4380 - val_accuracy: 0.8600\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3234 - accuracy: 0.9175 - val_loss: 0.4213 - val_accuracy: 0.8600\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3197 - accuracy: 0.9125 - val_loss: 0.4211 - val_accuracy: 0.8600\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3139 - accuracy: 0.9150 - val_loss: 0.4636 - val_accuracy: 0.8600\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3106 - accuracy: 0.9175 - val_loss: 0.4112 - val_accuracy: 0.8700\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3259 - accuracy: 0.9125 - val_loss: 0.4923 - val_accuracy: 0.8700\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3226 - accuracy: 0.9125 - val_loss: 0.4163 - val_accuracy: 0.8600\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3160 - accuracy: 0.9175 - val_loss: 0.4010 - val_accuracy: 0.8600\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3301 - accuracy: 0.9075 - val_loss: 0.3930 - val_accuracy: 0.8800\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3264 - accuracy: 0.9100 - val_loss: 0.4241 - val_accuracy: 0.8700\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2955 - accuracy: 0.9150 - val_loss: 0.4200 - val_accuracy: 0.8600\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2861 - accuracy: 0.9100 - val_loss: 0.4386 - val_accuracy: 0.8600\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2862 - accuracy: 0.9225 - val_loss: 0.3934 - val_accuracy: 0.8600\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.2891 - accuracy: 0.9125 - val_loss: 0.3783 - val_accuracy: 0.8800\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2757 - accuracy: 0.9175 - val_loss: 0.3783 - val_accuracy: 0.8700\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2803 - accuracy: 0.9200 - val_loss: 0.4256 - val_accuracy: 0.8700\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2791 - accuracy: 0.9225 - val_loss: 0.3812 - val_accuracy: 0.8600\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2595 - accuracy: 0.9275 - val_loss: 0.3803 - val_accuracy: 0.8600\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2657 - accuracy: 0.9200 - val_loss: 0.3602 - val_accuracy: 0.8700\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2490 - accuracy: 0.9225 - val_loss: 0.3593 - val_accuracy: 0.8800\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2473 - accuracy: 0.9275 - val_loss: 0.3787 - val_accuracy: 0.8900\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2566 - accuracy: 0.9225 - val_loss: 0.3643 - val_accuracy: 0.8800\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2336 - accuracy: 0.9300 - val_loss: 0.3463 - val_accuracy: 0.8800\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2366 - accuracy: 0.9275 - val_loss: 0.3454 - val_accuracy: 0.8800\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.2251 - accuracy: 0.9300 - val_loss: 0.3408 - val_accuracy: 0.8800\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2227 - accuracy: 0.9275 - val_loss: 0.3461 - val_accuracy: 0.8700\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2222 - accuracy: 0.9325 - val_loss: 0.3391 - val_accuracy: 0.8900\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2253 - accuracy: 0.9350 - val_loss: 0.3371 - val_accuracy: 0.8700\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2289 - accuracy: 0.9350 - val_loss: 0.3373 - val_accuracy: 0.8800\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2149 - accuracy: 0.9325 - val_loss: 0.3386 - val_accuracy: 0.8800\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2053 - accuracy: 0.9375 - val_loss: 0.3305 - val_accuracy: 0.8800\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2073 - accuracy: 0.9400 - val_loss: 0.3288 - val_accuracy: 0.8800\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2095 - accuracy: 0.9300 - val_loss: 0.3464 - val_accuracy: 0.8800\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1984 - accuracy: 0.9425 - val_loss: 0.3229 - val_accuracy: 0.8900\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1944 - accuracy: 0.9400 - val_loss: 0.3194 - val_accuracy: 0.8800\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2066 - accuracy: 0.9350 - val_loss: 0.4030 - val_accuracy: 0.9000\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.1957 - accuracy: 0.9400 - val_loss: 0.3345 - val_accuracy: 0.9000\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.1902 - accuracy: 0.9475 - val_loss: 0.3425 - val_accuracy: 0.8900\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1906 - accuracy: 0.9425 - val_loss: 0.3056 - val_accuracy: 0.8800\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1750 - accuracy: 0.9475 - val_loss: 0.3110 - val_accuracy: 0.9000\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1702 - accuracy: 0.9500 - val_loss: 0.3291 - val_accuracy: 0.8900\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1782 - accuracy: 0.9475 - val_loss: 0.3116 - val_accuracy: 0.9100\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1732 - accuracy: 0.9575 - val_loss: 0.3409 - val_accuracy: 0.9000\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2344 - accuracy: 0.9200 - val_loss: 0.4585 - val_accuracy: 0.9000\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1845 - accuracy: 0.9450 - val_loss: 0.3462 - val_accuracy: 0.8900\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1592 - accuracy: 0.9600 - val_loss: 0.3166 - val_accuracy: 0.9000\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1519 - accuracy: 0.9500 - val_loss: 0.3156 - val_accuracy: 0.8900\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1451 - accuracy: 0.9550 - val_loss: 0.3153 - val_accuracy: 0.9000\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1539 - accuracy: 0.9525 - val_loss: 0.3252 - val_accuracy: 0.8900\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.1466 - accuracy: 0.9525 - val_loss: 0.3092 - val_accuracy: 0.8900\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1376 - accuracy: 0.9575 - val_loss: 0.3029 - val_accuracy: 0.9100\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1345 - accuracy: 0.9625 - val_loss: 0.3058 - val_accuracy: 0.8900\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1257 - accuracy: 0.9575 - val_loss: 0.3480 - val_accuracy: 0.9000\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1436 - accuracy: 0.9600 - val_loss: 0.3206 - val_accuracy: 0.8900\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1192 - accuracy: 0.9675 - val_loss: 0.3205 - val_accuracy: 0.9100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1204 - accuracy: 0.9650 - val_loss: 0.3103 - val_accuracy: 0.9000\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1244 - accuracy: 0.9550 - val_loss: 0.3547 - val_accuracy: 0.9100\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1209 - accuracy: 0.9600 - val_loss: 0.3031 - val_accuracy: 0.9100\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1196 - accuracy: 0.9700 - val_loss: 0.3389 - val_accuracy: 0.9000\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1051 - accuracy: 0.9650 - val_loss: 0.3082 - val_accuracy: 0.9000\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1028 - accuracy: 0.9700 - val_loss: 0.3101 - val_accuracy: 0.9000\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 201us/step - loss: 0.1018 - accuracy: 0.9675 - val_loss: 0.3281 - val_accuracy: 0.9000\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1081 - accuracy: 0.9750 - val_loss: 0.3054 - val_accuracy: 0.9000\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0968 - accuracy: 0.9750 - val_loss: 0.3117 - val_accuracy: 0.9100\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0955 - accuracy: 0.9750 - val_loss: 0.3612 - val_accuracy: 0.9100\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1164 - accuracy: 0.9700 - val_loss: 0.3624 - val_accuracy: 0.9100\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1194 - accuracy: 0.9600 - val_loss: 0.2976 - val_accuracy: 0.9000\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0851 - accuracy: 0.9700 - val_loss: 0.3175 - val_accuracy: 0.8900\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0809 - accuracy: 0.9775 - val_loss: 0.3212 - val_accuracy: 0.9000\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0818 - accuracy: 0.9775 - val_loss: 0.3072 - val_accuracy: 0.9000\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0735 - accuracy: 0.9750 - val_loss: 0.3045 - val_accuracy: 0.9000\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0717 - accuracy: 0.9875 - val_loss: 0.3171 - val_accuracy: 0.8900\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0661 - accuracy: 0.9800 - val_loss: 0.3058 - val_accuracy: 0.9000\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0643 - accuracy: 0.9775 - val_loss: 0.3323 - val_accuracy: 0.8900\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.0672 - accuracy: 0.9850 - val_loss: 0.3442 - val_accuracy: 0.9000\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0659 - accuracy: 0.9875 - val_loss: 0.3100 - val_accuracy: 0.9000\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0634 - accuracy: 0.9850 - val_loss: 0.3274 - val_accuracy: 0.9000\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0528 - accuracy: 0.9900 - val_loss: 0.3147 - val_accuracy: 0.9000\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0499 - accuracy: 0.9900 - val_loss: 0.3263 - val_accuracy: 0.8900\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0516 - accuracy: 0.9875 - val_loss: 0.3159 - val_accuracy: 0.8900\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0482 - accuracy: 0.9900 - val_loss: 0.3438 - val_accuracy: 0.9000\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0538 - accuracy: 0.9850 - val_loss: 0.3342 - val_accuracy: 0.9000\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0533 - accuracy: 0.9850 - val_loss: 0.3436 - val_accuracy: 0.9000\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0837 - accuracy: 0.9825 - val_loss: 0.3333 - val_accuracy: 0.9000\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0972 - accuracy: 0.9725 - val_loss: 0.3216 - val_accuracy: 0.9000\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0494 - accuracy: 0.9900 - val_loss: 0.3150 - val_accuracy: 0.9100\n",
      "Epoch 134/1000\n",
      "400/400 [==============================] - 0s 206us/step - loss: 0.0501 - accuracy: 0.9875 - val_loss: 0.4253 - val_accuracy: 0.8900\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5231831137864064\n",
      "F1 Micro: 0.927701788666767\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.599842880845091\n",
      "F1 Micro: 0.9433338343604388\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 273us/step - loss: 2.2048 - accuracy: 0.2075 - val_loss: 2.1092 - val_accuracy: 0.3800\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.9991 - accuracy: 0.4700 - val_loss: 1.9398 - val_accuracy: 0.4400\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.8581 - accuracy: 0.5250 - val_loss: 1.8290 - val_accuracy: 0.4500\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.7657 - accuracy: 0.5425 - val_loss: 1.7475 - val_accuracy: 0.4900\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.6963 - accuracy: 0.5625 - val_loss: 1.6789 - val_accuracy: 0.5100\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.6356 - accuracy: 0.5875 - val_loss: 1.6168 - val_accuracy: 0.5700\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.5760 - accuracy: 0.6025 - val_loss: 1.5575 - val_accuracy: 0.5900\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 51us/step - loss: 1.5187 - accuracy: 0.6275 - val_loss: 1.5000 - val_accuracy: 0.6100\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.4635 - accuracy: 0.6475 - val_loss: 1.4411 - val_accuracy: 0.6300\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.4073 - accuracy: 0.6625 - val_loss: 1.3810 - val_accuracy: 0.6900\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.3491 - accuracy: 0.6800 - val_loss: 1.3229 - val_accuracy: 0.7200\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.2930 - accuracy: 0.7025 - val_loss: 1.2630 - val_accuracy: 0.7400\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.2335 - accuracy: 0.7300 - val_loss: 1.2041 - val_accuracy: 0.7600\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1766 - accuracy: 0.7475 - val_loss: 1.1475 - val_accuracy: 0.7600\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1196 - accuracy: 0.7625 - val_loss: 1.0920 - val_accuracy: 0.8200\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0637 - accuracy: 0.7900 - val_loss: 1.0363 - val_accuracy: 0.8200\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0083 - accuracy: 0.8075 - val_loss: 0.9826 - val_accuracy: 0.8500\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.9546 - accuracy: 0.8175 - val_loss: 0.9327 - val_accuracy: 0.8600\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.9025 - accuracy: 0.8325 - val_loss: 0.8834 - val_accuracy: 0.8700\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8536 - accuracy: 0.8500 - val_loss: 0.8382 - val_accuracy: 0.8700\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8054 - accuracy: 0.8650 - val_loss: 0.7938 - val_accuracy: 0.8700\n",
      "Epoch 22/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 78us/step - loss: 0.7596 - accuracy: 0.8700 - val_loss: 0.7523 - val_accuracy: 0.8700\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7162 - accuracy: 0.8750 - val_loss: 0.7118 - val_accuracy: 0.8700\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.6738 - accuracy: 0.8925 - val_loss: 0.6773 - val_accuracy: 0.8700\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.6357 - accuracy: 0.8975 - val_loss: 0.6434 - val_accuracy: 0.8700\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5983 - accuracy: 0.9025 - val_loss: 0.6100 - val_accuracy: 0.8700\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5626 - accuracy: 0.9025 - val_loss: 0.5825 - val_accuracy: 0.8800\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5323 - accuracy: 0.9175 - val_loss: 0.5558 - val_accuracy: 0.8800\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4996 - accuracy: 0.9250 - val_loss: 0.5269 - val_accuracy: 0.8800\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4705 - accuracy: 0.9250 - val_loss: 0.5037 - val_accuracy: 0.8800\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4432 - accuracy: 0.9350 - val_loss: 0.4822 - val_accuracy: 0.8800\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4194 - accuracy: 0.9375 - val_loss: 0.4645 - val_accuracy: 0.9000\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3944 - accuracy: 0.9425 - val_loss: 0.4449 - val_accuracy: 0.8900\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3733 - accuracy: 0.9425 - val_loss: 0.4275 - val_accuracy: 0.8900\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3536 - accuracy: 0.9475 - val_loss: 0.4124 - val_accuracy: 0.9000\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3347 - accuracy: 0.9525 - val_loss: 0.3982 - val_accuracy: 0.9100\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3181 - accuracy: 0.9550 - val_loss: 0.3855 - val_accuracy: 0.9200\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.3023 - accuracy: 0.9550 - val_loss: 0.3726 - val_accuracy: 0.9300\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 43us/step - loss: 0.2873 - accuracy: 0.9550 - val_loss: 0.3611 - val_accuracy: 0.9300\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.2744 - accuracy: 0.9550 - val_loss: 0.3512 - val_accuracy: 0.9300\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.2617 - accuracy: 0.9575 - val_loss: 0.3419 - val_accuracy: 0.9300\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2509 - accuracy: 0.9600 - val_loss: 0.3329 - val_accuracy: 0.9300\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2400 - accuracy: 0.9650 - val_loss: 0.3262 - val_accuracy: 0.9300\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2302 - accuracy: 0.9700 - val_loss: 0.3202 - val_accuracy: 0.9300\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2218 - accuracy: 0.9700 - val_loss: 0.3135 - val_accuracy: 0.9400\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2138 - accuracy: 0.9725 - val_loss: 0.3078 - val_accuracy: 0.9400\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2070 - accuracy: 0.9725 - val_loss: 0.3034 - val_accuracy: 0.9400\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1988 - accuracy: 0.9725 - val_loss: 0.2977 - val_accuracy: 0.9400\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1919 - accuracy: 0.9725 - val_loss: 0.2926 - val_accuracy: 0.9400\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1858 - accuracy: 0.9725 - val_loss: 0.2882 - val_accuracy: 0.9400\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1800 - accuracy: 0.9725 - val_loss: 0.2834 - val_accuracy: 0.9400\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1742 - accuracy: 0.9750 - val_loss: 0.2788 - val_accuracy: 0.9400\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1699 - accuracy: 0.9750 - val_loss: 0.2745 - val_accuracy: 0.9400\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1639 - accuracy: 0.9725 - val_loss: 0.2736 - val_accuracy: 0.9400\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1595 - accuracy: 0.9750 - val_loss: 0.2705 - val_accuracy: 0.9300\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1555 - accuracy: 0.9750 - val_loss: 0.2670 - val_accuracy: 0.9300\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1511 - accuracy: 0.9800 - val_loss: 0.2638 - val_accuracy: 0.9300\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1472 - accuracy: 0.9800 - val_loss: 0.2628 - val_accuracy: 0.9300\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1433 - accuracy: 0.9775 - val_loss: 0.2603 - val_accuracy: 0.9300\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1402 - accuracy: 0.9800 - val_loss: 0.2562 - val_accuracy: 0.9300\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1364 - accuracy: 0.9800 - val_loss: 0.2566 - val_accuracy: 0.9300\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1328 - accuracy: 0.9800 - val_loss: 0.2540 - val_accuracy: 0.9300\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.1293 - accuracy: 0.9800 - val_loss: 0.2486 - val_accuracy: 0.9300\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1263 - accuracy: 0.9800 - val_loss: 0.2470 - val_accuracy: 0.9300\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1234 - accuracy: 0.9800 - val_loss: 0.2457 - val_accuracy: 0.9300\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1206 - accuracy: 0.9800 - val_loss: 0.2432 - val_accuracy: 0.9300\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1180 - accuracy: 0.9800 - val_loss: 0.2425 - val_accuracy: 0.9300\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.1155 - accuracy: 0.9800 - val_loss: 0.2413 - val_accuracy: 0.9300\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 50us/step - loss: 0.1128 - accuracy: 0.9800 - val_loss: 0.2377 - val_accuracy: 0.9300\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1106 - accuracy: 0.9825 - val_loss: 0.2373 - val_accuracy: 0.9300\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1082 - accuracy: 0.9825 - val_loss: 0.2338 - val_accuracy: 0.9400\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1059 - accuracy: 0.9825 - val_loss: 0.2340 - val_accuracy: 0.9400\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1036 - accuracy: 0.9825 - val_loss: 0.2340 - val_accuracy: 0.9300\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1019 - accuracy: 0.9825 - val_loss: 0.2320 - val_accuracy: 0.9300\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0995 - accuracy: 0.9850 - val_loss: 0.2305 - val_accuracy: 0.9300\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0975 - accuracy: 0.9850 - val_loss: 0.2302 - val_accuracy: 0.9300\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0955 - accuracy: 0.9850 - val_loss: 0.2288 - val_accuracy: 0.9300\n",
      "Epoch 78/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 78us/step - loss: 0.0937 - accuracy: 0.9850 - val_loss: 0.2279 - val_accuracy: 0.9300\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0918 - accuracy: 0.9875 - val_loss: 0.2272 - val_accuracy: 0.9300\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0903 - accuracy: 0.9875 - val_loss: 0.2272 - val_accuracy: 0.9300\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0884 - accuracy: 0.9875 - val_loss: 0.2246 - val_accuracy: 0.9300\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0868 - accuracy: 0.9875 - val_loss: 0.2229 - val_accuracy: 0.9400\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0858 - accuracy: 0.9875 - val_loss: 0.2240 - val_accuracy: 0.9300\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0837 - accuracy: 0.9875 - val_loss: 0.2200 - val_accuracy: 0.9400\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0820 - accuracy: 0.9875 - val_loss: 0.2207 - val_accuracy: 0.9300\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0807 - accuracy: 0.9875 - val_loss: 0.2199 - val_accuracy: 0.9300\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0788 - accuracy: 0.9875 - val_loss: 0.2186 - val_accuracy: 0.9400\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.96 - 0s 78us/step - loss: 0.0779 - accuracy: 0.9875 - val_loss: 0.2183 - val_accuracy: 0.9400\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0761 - accuracy: 0.9875 - val_loss: 0.2176 - val_accuracy: 0.9400\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0747 - accuracy: 0.9875 - val_loss: 0.2185 - val_accuracy: 0.9300\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0735 - accuracy: 0.9875 - val_loss: 0.2174 - val_accuracy: 0.9300\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0720 - accuracy: 0.9875 - val_loss: 0.2168 - val_accuracy: 0.9400\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0710 - accuracy: 0.9875 - val_loss: 0.2149 - val_accuracy: 0.9400\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0697 - accuracy: 0.9900 - val_loss: 0.2157 - val_accuracy: 0.9400\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0682 - accuracy: 0.9875 - val_loss: 0.2151 - val_accuracy: 0.9400\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0674 - accuracy: 0.9875 - val_loss: 0.2165 - val_accuracy: 0.9400\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0660 - accuracy: 0.9900 - val_loss: 0.2146 - val_accuracy: 0.9400\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0648 - accuracy: 0.9900 - val_loss: 0.2147 - val_accuracy: 0.9300\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 64us/step - loss: 0.0636 - accuracy: 0.9900 - val_loss: 0.2143 - val_accuracy: 0.9400\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0624 - accuracy: 0.9925 - val_loss: 0.2117 - val_accuracy: 0.9500\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0614 - accuracy: 0.9925 - val_loss: 0.2123 - val_accuracy: 0.9400\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0604 - accuracy: 0.9925 - val_loss: 0.2120 - val_accuracy: 0.9400\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.0593 - accuracy: 0.9925 - val_loss: 0.2120 - val_accuracy: 0.9400\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0581 - accuracy: 0.9925 - val_loss: 0.2116 - val_accuracy: 0.9400\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0572 - accuracy: 0.9925 - val_loss: 0.2109 - val_accuracy: 0.9400\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0563 - accuracy: 0.9925 - val_loss: 0.2101 - val_accuracy: 0.9500\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0552 - accuracy: 0.9925 - val_loss: 0.2109 - val_accuracy: 0.9400\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0543 - accuracy: 0.9925 - val_loss: 0.2095 - val_accuracy: 0.9400\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0531 - accuracy: 0.9925 - val_loss: 0.2079 - val_accuracy: 0.9500\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0524 - accuracy: 0.9925 - val_loss: 0.2073 - val_accuracy: 0.9500\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0515 - accuracy: 0.9925 - val_loss: 0.2084 - val_accuracy: 0.9400\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0504 - accuracy: 0.9925 - val_loss: 0.2092 - val_accuracy: 0.9400\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0497 - accuracy: 0.9925 - val_loss: 0.2078 - val_accuracy: 0.9400\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0490 - accuracy: 0.9925 - val_loss: 0.2088 - val_accuracy: 0.9500\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0481 - accuracy: 0.9925 - val_loss: 0.2102 - val_accuracy: 0.9400\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.0472 - accuracy: 0.9925 - val_loss: 0.2095 - val_accuracy: 0.9400\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0465 - accuracy: 0.9925 - val_loss: 0.2074 - val_accuracy: 0.9500\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0456 - accuracy: 0.9925 - val_loss: 0.2083 - val_accuracy: 0.9400\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0451 - accuracy: 0.9950 - val_loss: 0.2085 - val_accuracy: 0.9400\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0443 - accuracy: 0.9950 - val_loss: 0.2092 - val_accuracy: 0.9400\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0434 - accuracy: 0.9925 - val_loss: 0.2080 - val_accuracy: 0.9400\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0427 - accuracy: 0.9950 - val_loss: 0.2082 - val_accuracy: 0.9400\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0420 - accuracy: 0.9950 - val_loss: 0.2081 - val_accuracy: 0.9400\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0413 - accuracy: 0.9950 - val_loss: 0.2100 - val_accuracy: 0.9400\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0407 - accuracy: 0.9950 - val_loss: 0.2105 - val_accuracy: 0.9400\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0399 - accuracy: 0.9950 - val_loss: 0.2093 - val_accuracy: 0.9400\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0392 - accuracy: 0.9950 - val_loss: 0.2091 - val_accuracy: 0.9400\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0386 - accuracy: 0.9950 - val_loss: 0.2077 - val_accuracy: 0.9400\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 56us/step - loss: 0.0379 - accuracy: 0.9950 - val_loss: 0.2084 - val_accuracy: 0.9400\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0375 - accuracy: 0.9950 - val_loss: 0.2089 - val_accuracy: 0.9400\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6257936218089896\n",
      "F1 Micro: 0.9449371210982515\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 706us/step - loss: 2.0254 - accuracy: 0.3925 - val_loss: 1.5179 - val_accuracy: 0.8100\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 195us/step - loss: 1.0199 - accuracy: 0.8475 - val_loss: 0.6056 - val_accuracy: 0.8400\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5673 - accuracy: 0.8625 - val_loss: 0.5807 - val_accuracy: 0.8400\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.4793 - accuracy: 0.87 - 0s 195us/step - loss: 0.4740 - accuracy: 0.8675 - val_loss: 0.5040 - val_accuracy: 0.8500\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 177us/step - loss: 0.4208 - accuracy: 0.8850 - val_loss: 0.4779 - val_accuracy: 0.8500\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3891 - accuracy: 0.8925 - val_loss: 0.4540 - val_accuracy: 0.8600\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3672 - accuracy: 0.8925 - val_loss: 0.4362 - val_accuracy: 0.8600\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3431 - accuracy: 0.9100 - val_loss: 0.4161 - val_accuracy: 0.8600\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3270 - accuracy: 0.9100 - val_loss: 0.3991 - val_accuracy: 0.8600\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3119 - accuracy: 0.9200 - val_loss: 0.3859 - val_accuracy: 0.8600\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3018 - accuracy: 0.9200 - val_loss: 0.3740 - val_accuracy: 0.8700\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2892 - accuracy: 0.9350 - val_loss: 0.3604 - val_accuracy: 0.8800\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2769 - accuracy: 0.9350 - val_loss: 0.3567 - val_accuracy: 0.8700\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2644 - accuracy: 0.93 - 0s 195us/step - loss: 0.2679 - accuracy: 0.9325 - val_loss: 0.3412 - val_accuracy: 0.8800\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2575 - accuracy: 0.9375 - val_loss: 0.3308 - val_accuracy: 0.8800\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.2512 - accuracy: 0.9400 - val_loss: 0.3231 - val_accuracy: 0.8800\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2431 - accuracy: 0.9350 - val_loss: 0.3170 - val_accuracy: 0.8800\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.94 - 0s 234us/step - loss: 0.2354 - accuracy: 0.9450 - val_loss: 0.3094 - val_accuracy: 0.8900\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2300 - accuracy: 0.9425 - val_loss: 0.3052 - val_accuracy: 0.8900\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2209 - accuracy: 0.9450 - val_loss: 0.2980 - val_accuracy: 0.8900\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2182 - accuracy: 0.9475 - val_loss: 0.2911 - val_accuracy: 0.8900\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2102 - accuracy: 0.9475 - val_loss: 0.2878 - val_accuracy: 0.8900\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2037 - accuracy: 0.9500 - val_loss: 0.2826 - val_accuracy: 0.8900\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2054 - accuracy: 0.9475 - val_loss: 0.2786 - val_accuracy: 0.8900\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1981 - accuracy: 0.9500 - val_loss: 0.2720 - val_accuracy: 0.8900\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1925 - accuracy: 0.9500 - val_loss: 0.2698 - val_accuracy: 0.9000\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1888 - accuracy: 0.9500 - val_loss: 0.2641 - val_accuracy: 0.8900\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.1825 - accuracy: 0.9500 - val_loss: 0.2603 - val_accuracy: 0.8900\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1809 - accuracy: 0.9525 - val_loss: 0.2566 - val_accuracy: 0.9100\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1752 - accuracy: 0.9500 - val_loss: 0.2544 - val_accuracy: 0.9100\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1699 - accuracy: 0.9525 - val_loss: 0.2507 - val_accuracy: 0.8900\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1678 - accuracy: 0.9500 - val_loss: 0.2448 - val_accuracy: 0.9100\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1650 - accuracy: 0.9500 - val_loss: 0.2458 - val_accuracy: 0.9100\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1627 - accuracy: 0.9525 - val_loss: 0.2431 - val_accuracy: 0.9100\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1576 - accuracy: 0.9500 - val_loss: 0.2403 - val_accuracy: 0.9100\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1545 - accuracy: 0.9550 - val_loss: 0.2376 - val_accuracy: 0.9100\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1543 - accuracy: 0.9575 - val_loss: 0.2360 - val_accuracy: 0.9100\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1493 - accuracy: 0.9550 - val_loss: 0.2317 - val_accuracy: 0.9100\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 181us/step - loss: 0.1461 - accuracy: 0.9550 - val_loss: 0.2285 - val_accuracy: 0.9100\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1513 - accuracy: 0.9650 - val_loss: 0.2288 - val_accuracy: 0.9100\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1434 - accuracy: 0.9550 - val_loss: 0.2278 - val_accuracy: 0.9000\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1416 - accuracy: 0.9575 - val_loss: 0.2310 - val_accuracy: 0.9100\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1474 - accuracy: 0.95 - 0s 195us/step - loss: 0.1381 - accuracy: 0.9550 - val_loss: 0.2265 - val_accuracy: 0.9100\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1341 - accuracy: 0.9600 - val_loss: 0.2206 - val_accuracy: 0.9100\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1342 - accuracy: 0.9575 - val_loss: 0.2224 - val_accuracy: 0.9200\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1291 - accuracy: 0.9650 - val_loss: 0.2167 - val_accuracy: 0.9100\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1262 - accuracy: 0.9675 - val_loss: 0.2110 - val_accuracy: 0.9100\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1278 - accuracy: 0.9600 - val_loss: 0.2158 - val_accuracy: 0.9100\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1197 - accuracy: 0.9675 - val_loss: 0.2118 - val_accuracy: 0.9100\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.1176 - accuracy: 0.9675 - val_loss: 0.2122 - val_accuracy: 0.9200\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.1145 - accuracy: 0.9700 - val_loss: 0.2081 - val_accuracy: 0.9100\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1142 - accuracy: 0.9700 - val_loss: 0.2061 - val_accuracy: 0.9100\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1108 - accuracy: 0.9700 - val_loss: 0.2055 - val_accuracy: 0.9200\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1089 - accuracy: 0.9675 - val_loss: 0.2061 - val_accuracy: 0.9200\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1058 - accuracy: 0.9750 - val_loss: 0.2032 - val_accuracy: 0.9300\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1040 - accuracy: 0.9675 - val_loss: 0.2021 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1021 - accuracy: 0.9725 - val_loss: 0.2001 - val_accuracy: 0.9100\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0994 - accuracy: 0.9700 - val_loss: 0.2031 - val_accuracy: 0.9400\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0991 - accuracy: 0.9675 - val_loss: 0.2033 - val_accuracy: 0.9400\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0960 - accuracy: 0.9850 - val_loss: 0.1989 - val_accuracy: 0.9200\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0952 - accuracy: 0.9675 - val_loss: 0.1920 - val_accuracy: 0.9100\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 173us/step - loss: 0.0976 - accuracy: 0.9775 - val_loss: 0.1949 - val_accuracy: 0.9300\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0907 - accuracy: 0.9725 - val_loss: 0.1933 - val_accuracy: 0.9400\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0877 - accuracy: 0.9825 - val_loss: 0.1944 - val_accuracy: 0.9200\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0846 - accuracy: 0.9725 - val_loss: 0.1968 - val_accuracy: 0.9500\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0862 - accuracy: 0.9875 - val_loss: 0.1926 - val_accuracy: 0.9300\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0831 - accuracy: 0.9750 - val_loss: 0.1877 - val_accuracy: 0.9500\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0796 - accuracy: 0.9850 - val_loss: 0.1901 - val_accuracy: 0.9600\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0773 - accuracy: 0.9825 - val_loss: 0.1844 - val_accuracy: 0.9400\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0766 - accuracy: 0.9750 - val_loss: 0.1894 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0764 - accuracy: 0.9875 - val_loss: 0.1882 - val_accuracy: 0.9200\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0742 - accuracy: 0.9775 - val_loss: 0.1910 - val_accuracy: 0.9600\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0711 - accuracy: 0.9850 - val_loss: 0.1880 - val_accuracy: 0.9500\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0682 - accuracy: 0.9850 - val_loss: 0.1896 - val_accuracy: 0.9500\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0665 - accuracy: 0.9850 - val_loss: 0.1837 - val_accuracy: 0.9600\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0648 - accuracy: 0.9875 - val_loss: 0.1890 - val_accuracy: 0.9600\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0629 - accuracy: 0.9875 - val_loss: 0.1869 - val_accuracy: 0.9600\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0597 - accuracy: 0.9875 - val_loss: 0.1848 - val_accuracy: 0.9600\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0585 - accuracy: 0.9875 - val_loss: 0.1841 - val_accuracy: 0.9600\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0571 - accuracy: 0.9875 - val_loss: 0.1872 - val_accuracy: 0.9600\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0552 - accuracy: 0.9875 - val_loss: 0.1801 - val_accuracy: 0.9600\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0534 - accuracy: 0.9925 - val_loss: 0.1866 - val_accuracy: 0.9400\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0526 - accuracy: 0.9850 - val_loss: 0.1824 - val_accuracy: 0.9600\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0541 - accuracy: 0.9900 - val_loss: 0.1820 - val_accuracy: 0.9600\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0494 - accuracy: 0.9925 - val_loss: 0.1786 - val_accuracy: 0.9400\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0470 - accuracy: 0.9925 - val_loss: 0.1837 - val_accuracy: 0.9500\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0495 - accuracy: 0.9925 - val_loss: 0.1848 - val_accuracy: 0.9600\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0453 - accuracy: 0.9925 - val_loss: 0.1834 - val_accuracy: 0.9500\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0419 - accuracy: 0.9925 - val_loss: 0.1837 - val_accuracy: 0.9600\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0408 - accuracy: 0.9950 - val_loss: 0.1911 - val_accuracy: 0.9400\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0449 - accuracy: 0.9950 - val_loss: 0.1844 - val_accuracy: 0.9600\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0400 - accuracy: 0.9925 - val_loss: 0.1849 - val_accuracy: 0.9500\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0419 - accuracy: 0.9950 - val_loss: 0.1903 - val_accuracy: 0.9500\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0359 - accuracy: 0.9925 - val_loss: 0.1799 - val_accuracy: 0.9600\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0346 - accuracy: 0.9950 - val_loss: 0.1903 - val_accuracy: 0.9400\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0332 - accuracy: 0.9975 - val_loss: 0.1854 - val_accuracy: 0.9600\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.99 - 0s 195us/step - loss: 0.0333 - accuracy: 0.9950 - val_loss: 0.1847 - val_accuracy: 0.9600\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 193us/step - loss: 0.0317 - accuracy: 0.9975 - val_loss: 0.1882 - val_accuracy: 0.9400\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0297 - accuracy: 0.9975 - val_loss: 0.1828 - val_accuracy: 0.9500\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0287 - accuracy: 0.9975 - val_loss: 0.1850 - val_accuracy: 0.9500\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9400\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9500\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9400\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9500\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.605210860806317\n",
      "F1 Micro: 0.9414299313592865\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6219397186106148\n",
      "F1 Micro: 0.9439350668871185\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6475346815363616\n",
      "F1 Micro: 0.9467408186782904\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 9 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 240us/step - loss: 0.9140 - accuracy: 0.8328 - val_loss: 0.6953 - val_accuracy: 0.8440\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.6587 - accuracy: 0.8465 - val_loss: 0.6560 - val_accuracy: 0.8440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.5825 - accuracy: 0.8472 - val_loss: 0.5390 - val_accuracy: 0.8470\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.4465 - accuracy: 0.8808 - val_loss: 0.4230 - val_accuracy: 0.8960\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.3578 - accuracy: 0.9068 - val_loss: 0.3890 - val_accuracy: 0.8980\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.3294 - accuracy: 0.9130 - val_loss: 0.4410 - val_accuracy: 0.8920\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.3077 - accuracy: 0.9187 - val_loss: 0.3207 - val_accuracy: 0.9140\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.2826 - accuracy: 0.9202 - val_loss: 0.3682 - val_accuracy: 0.9100\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.2597 - accuracy: 0.9273 - val_loss: 0.3235 - val_accuracy: 0.9150\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.2597 - accuracy: 0.9273 - val_loss: 0.3025 - val_accuracy: 0.9160\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.2334 - accuracy: 0.9352 - val_loss: 0.2457 - val_accuracy: 0.9290\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.2213 - accuracy: 0.9380 - val_loss: 0.2488 - val_accuracy: 0.9260\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.2160 - accuracy: 0.9375 - val_loss: 0.2252 - val_accuracy: 0.9350\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.1982 - accuracy: 0.9415 - val_loss: 0.2077 - val_accuracy: 0.9390\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.1896 - accuracy: 0.9442 - val_loss: 0.2207 - val_accuracy: 0.9450\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1791 - accuracy: 0.9460 - val_loss: 0.2148 - val_accuracy: 0.9320\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1700 - accuracy: 0.9507 - val_loss: 0.2105 - val_accuracy: 0.9360\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.1613 - accuracy: 0.9513 - val_loss: 0.1823 - val_accuracy: 0.9420\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1579 - accuracy: 0.9535 - val_loss: 0.1821 - val_accuracy: 0.9430\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1458 - accuracy: 0.9548 - val_loss: 0.1835 - val_accuracy: 0.9440\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1404 - accuracy: 0.9580 - val_loss: 0.1806 - val_accuracy: 0.9410\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1380 - accuracy: 0.9617 - val_loss: 0.1907 - val_accuracy: 0.9480\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1322 - accuracy: 0.9607 - val_loss: 0.1815 - val_accuracy: 0.9390\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.1276 - accuracy: 0.9600 - val_loss: 0.1761 - val_accuracy: 0.9490\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1260 - accuracy: 0.9628 - val_loss: 0.1654 - val_accuracy: 0.9470\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1184 - accuracy: 0.9622 - val_loss: 0.1635 - val_accuracy: 0.9510\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1166 - accuracy: 0.9625 - val_loss: 0.1808 - val_accuracy: 0.9390\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1187 - accuracy: 0.9630 - val_loss: 0.1718 - val_accuracy: 0.9450\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1063 - accuracy: 0.9670 - val_loss: 0.1706 - val_accuracy: 0.9550\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.1039 - accuracy: 0.9685 - val_loss: 0.1660 - val_accuracy: 0.9490\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0974 - accuracy: 0.9715 - val_loss: 0.1697 - val_accuracy: 0.9390\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0942 - accuracy: 0.9712 - val_loss: 0.1795 - val_accuracy: 0.9390\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0956 - accuracy: 0.9700 - val_loss: 0.1608 - val_accuracy: 0.9490\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0932 - accuracy: 0.9730 - val_loss: 0.1651 - val_accuracy: 0.9410\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0862 - accuracy: 0.9740 - val_loss: 0.1691 - val_accuracy: 0.9440\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0871 - accuracy: 0.9707 - val_loss: 0.1697 - val_accuracy: 0.9510\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0812 - accuracy: 0.9743 - val_loss: 0.1624 - val_accuracy: 0.9570\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0776 - accuracy: 0.9772 - val_loss: 0.1704 - val_accuracy: 0.9360\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0755 - accuracy: 0.9762 - val_loss: 0.1660 - val_accuracy: 0.9460\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0731 - accuracy: 0.9775 - val_loss: 0.1603 - val_accuracy: 0.9520\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0700 - accuracy: 0.9785 - val_loss: 0.1695 - val_accuracy: 0.9530\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.0676 - accuracy: 0.9803 - val_loss: 0.1616 - val_accuracy: 0.9550\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.0657 - accuracy: 0.9810 - val_loss: 0.1647 - val_accuracy: 0.9520\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0590 - accuracy: 0.9830 - val_loss: 0.1655 - val_accuracy: 0.9510\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0584 - accuracy: 0.9830 - val_loss: 0.1611 - val_accuracy: 0.9490\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0635 - accuracy: 0.9805 - val_loss: 0.1615 - val_accuracy: 0.9480\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0499 - accuracy: 0.9858 - val_loss: 0.1669 - val_accuracy: 0.9450\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0519 - accuracy: 0.9868 - val_loss: 0.1736 - val_accuracy: 0.9530\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.0692 - accuracy: 0.9812 - val_loss: 0.1675 - val_accuracy: 0.9500\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.0471 - accuracy: 0.9865 - val_loss: 0.1832 - val_accuracy: 0.9520\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0445 - accuracy: 0.9887 - val_loss: 0.1741 - val_accuracy: 0.9500\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0404 - accuracy: 0.9883 - val_loss: 0.1798 - val_accuracy: 0.9470\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0376 - accuracy: 0.9898 - val_loss: 0.1935 - val_accuracy: 0.9490\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0436 - accuracy: 0.9870 - val_loss: 0.1776 - val_accuracy: 0.9510\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0396 - accuracy: 0.9895 - val_loss: 0.2010 - val_accuracy: 0.9520\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0340 - accuracy: 0.9923 - val_loss: 0.1773 - val_accuracy: 0.9470\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0383 - accuracy: 0.9890 - val_loss: 0.2347 - val_accuracy: 0.9290\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0307 - accuracy: 0.9933 - val_loss: 0.1900 - val_accuracy: 0.9430\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.0289 - accuracy: 0.9930 - val_loss: 0.1983 - val_accuracy: 0.9390\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0296 - accuracy: 0.9925 - val_loss: 0.1941 - val_accuracy: 0.9510\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6062662410767098\n",
      "F1 Micro: 0.9565\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6888325450115559\n",
      "F1 Micro: 0.9556\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 86us/step - loss: 1.7555 - accuracy: 0.5310 - val_loss: 1.4273 - val_accuracy: 0.6680\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 1.1434 - accuracy: 0.7623 - val_loss: 0.9079 - val_accuracy: 0.8270\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.6801 - accuracy: 0.8817 - val_loss: 0.5492 - val_accuracy: 0.8910\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.4139 - accuracy: 0.9237 - val_loss: 0.3787 - val_accuracy: 0.9230\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.2906 - accuracy: 0.9380 - val_loss: 0.2949 - val_accuracy: 0.9280\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.2321 - accuracy: 0.9463 - val_loss: 0.2514 - val_accuracy: 0.9350\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.2003 - accuracy: 0.9535 - val_loss: 0.2252 - val_accuracy: 0.9410\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1811 - accuracy: 0.9565 - val_loss: 0.2099 - val_accuracy: 0.9440\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1676 - accuracy: 0.9575 - val_loss: 0.2009 - val_accuracy: 0.9440\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1591 - accuracy: 0.9597 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1511 - accuracy: 0.9610 - val_loss: 0.1843 - val_accuracy: 0.9450\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1456 - accuracy: 0.9613 - val_loss: 0.1798 - val_accuracy: 0.9460\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 63us/step - loss: 0.1398 - accuracy: 0.9643 - val_loss: 0.1751 - val_accuracy: 0.9470\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1361 - accuracy: 0.9657 - val_loss: 0.1707 - val_accuracy: 0.9470\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1314 - accuracy: 0.9655 - val_loss: 0.1671 - val_accuracy: 0.9490\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1271 - accuracy: 0.9678 - val_loss: 0.1635 - val_accuracy: 0.9490\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1241 - accuracy: 0.9672 - val_loss: 0.1613 - val_accuracy: 0.9480\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1215 - accuracy: 0.9682 - val_loss: 0.1598 - val_accuracy: 0.9480\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1182 - accuracy: 0.9675 - val_loss: 0.1571 - val_accuracy: 0.9490\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1152 - accuracy: 0.9693 - val_loss: 0.1572 - val_accuracy: 0.9490\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1134 - accuracy: 0.9695 - val_loss: 0.1547 - val_accuracy: 0.9510\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1102 - accuracy: 0.9700 - val_loss: 0.1520 - val_accuracy: 0.9510\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1079 - accuracy: 0.9710 - val_loss: 0.1499 - val_accuracy: 0.9510\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1059 - accuracy: 0.9718 - val_loss: 0.1490 - val_accuracy: 0.9510\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1041 - accuracy: 0.9715 - val_loss: 0.1462 - val_accuracy: 0.9490\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1017 - accuracy: 0.9728 - val_loss: 0.1455 - val_accuracy: 0.9520\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0996 - accuracy: 0.9740 - val_loss: 0.1454 - val_accuracy: 0.9520\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0982 - accuracy: 0.9735 - val_loss: 0.1433 - val_accuracy: 0.9530\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0968 - accuracy: 0.9728 - val_loss: 0.1420 - val_accuracy: 0.9550\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0942 - accuracy: 0.9753 - val_loss: 0.1438 - val_accuracy: 0.9530\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0929 - accuracy: 0.9753 - val_loss: 0.1413 - val_accuracy: 0.9530\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0917 - accuracy: 0.9753 - val_loss: 0.1397 - val_accuracy: 0.9520\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0895 - accuracy: 0.9762 - val_loss: 0.1393 - val_accuracy: 0.9510\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0882 - accuracy: 0.9768 - val_loss: 0.1370 - val_accuracy: 0.9550\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0865 - accuracy: 0.9780 - val_loss: 0.1365 - val_accuracy: 0.9540\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0854 - accuracy: 0.9778 - val_loss: 0.1376 - val_accuracy: 0.9520\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0844 - accuracy: 0.9762 - val_loss: 0.1364 - val_accuracy: 0.9570\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0825 - accuracy: 0.9795 - val_loss: 0.1343 - val_accuracy: 0.9580\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0815 - accuracy: 0.9783 - val_loss: 0.1356 - val_accuracy: 0.9560\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0802 - accuracy: 0.9790 - val_loss: 0.1349 - val_accuracy: 0.9570\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0785 - accuracy: 0.9805 - val_loss: 0.1352 - val_accuracy: 0.9550\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0782 - accuracy: 0.9787 - val_loss: 0.1329 - val_accuracy: 0.9580\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0765 - accuracy: 0.9797 - val_loss: 0.1326 - val_accuracy: 0.9560\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0753 - accuracy: 0.9808 - val_loss: 0.1322 - val_accuracy: 0.9570\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0736 - accuracy: 0.9808 - val_loss: 0.1327 - val_accuracy: 0.9560\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0735 - accuracy: 0.9808 - val_loss: 0.1328 - val_accuracy: 0.9570\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0723 - accuracy: 0.9808 - val_loss: 0.1333 - val_accuracy: 0.9530\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0715 - accuracy: 0.9805 - val_loss: 0.1335 - val_accuracy: 0.9550\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0699 - accuracy: 0.9815 - val_loss: 0.1314 - val_accuracy: 0.9570\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0693 - accuracy: 0.9818 - val_loss: 0.1299 - val_accuracy: 0.9580\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0681 - accuracy: 0.9820 - val_loss: 0.1308 - val_accuracy: 0.9580\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0671 - accuracy: 0.9805 - val_loss: 0.1312 - val_accuracy: 0.9570\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0661 - accuracy: 0.9815 - val_loss: 0.1297 - val_accuracy: 0.9600\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0655 - accuracy: 0.9833 - val_loss: 0.1294 - val_accuracy: 0.9570\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0641 - accuracy: 0.9843 - val_loss: 0.1287 - val_accuracy: 0.9590\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0630 - accuracy: 0.9833 - val_loss: 0.1331 - val_accuracy: 0.9590\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0627 - accuracy: 0.9833 - val_loss: 0.1301 - val_accuracy: 0.9560\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0620 - accuracy: 0.9835 - val_loss: 0.1284 - val_accuracy: 0.9570\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0606 - accuracy: 0.9830 - val_loss: 0.1280 - val_accuracy: 0.9600\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0592 - accuracy: 0.9843 - val_loss: 0.1288 - val_accuracy: 0.9600\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0593 - accuracy: 0.9845 - val_loss: 0.1280 - val_accuracy: 0.9600\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0579 - accuracy: 0.9845 - val_loss: 0.1298 - val_accuracy: 0.9600\n",
      "Epoch 63/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0578 - accuracy: 0.9847 - val_loss: 0.1289 - val_accuracy: 0.9600\n",
      "Epoch 64/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0565 - accuracy: 0.9858 - val_loss: 0.1306 - val_accuracy: 0.9580\n",
      "Epoch 65/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0550 - accuracy: 0.9868 - val_loss: 0.1307 - val_accuracy: 0.9590\n",
      "Epoch 66/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0553 - accuracy: 0.9845 - val_loss: 0.1283 - val_accuracy: 0.9620\n",
      "Epoch 67/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0545 - accuracy: 0.9855 - val_loss: 0.1288 - val_accuracy: 0.9610\n",
      "Epoch 68/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0530 - accuracy: 0.9868 - val_loss: 0.1278 - val_accuracy: 0.9590\n",
      "Epoch 69/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0522 - accuracy: 0.9862 - val_loss: 0.1281 - val_accuracy: 0.9620\n",
      "Epoch 70/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0523 - accuracy: 0.9858 - val_loss: 0.1278 - val_accuracy: 0.9630\n",
      "Epoch 71/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0510 - accuracy: 0.9858 - val_loss: 0.1302 - val_accuracy: 0.9590\n",
      "Epoch 72/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0500 - accuracy: 0.9865 - val_loss: 0.1280 - val_accuracy: 0.9620\n",
      "Epoch 73/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0494 - accuracy: 0.9870 - val_loss: 0.1321 - val_accuracy: 0.9590\n",
      "Epoch 74/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0490 - accuracy: 0.9877 - val_loss: 0.1321 - val_accuracy: 0.9580\n",
      "Epoch 75/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0481 - accuracy: 0.9877 - val_loss: 0.1283 - val_accuracy: 0.9590\n",
      "Epoch 76/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0478 - accuracy: 0.9872 - val_loss: 0.1299 - val_accuracy: 0.9550\n",
      "Epoch 77/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0467 - accuracy: 0.9877 - val_loss: 0.1290 - val_accuracy: 0.9630\n",
      "Epoch 78/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0468 - accuracy: 0.9883 - val_loss: 0.1291 - val_accuracy: 0.9600\n",
      "Epoch 79/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0454 - accuracy: 0.9900 - val_loss: 0.1276 - val_accuracy: 0.9600\n",
      "Epoch 80/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0448 - accuracy: 0.9893 - val_loss: 0.1282 - val_accuracy: 0.9600\n",
      "Epoch 81/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0441 - accuracy: 0.9908 - val_loss: 0.1298 - val_accuracy: 0.9590\n",
      "Epoch 82/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0438 - accuracy: 0.9887 - val_loss: 0.1289 - val_accuracy: 0.9610\n",
      "Epoch 83/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0431 - accuracy: 0.9900 - val_loss: 0.1291 - val_accuracy: 0.9560\n",
      "Epoch 84/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0421 - accuracy: 0.9890 - val_loss: 0.1296 - val_accuracy: 0.9620\n",
      "Epoch 85/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0416 - accuracy: 0.9887 - val_loss: 0.1286 - val_accuracy: 0.9630\n",
      "Epoch 86/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0411 - accuracy: 0.9908 - val_loss: 0.1285 - val_accuracy: 0.9610\n",
      "Epoch 87/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0407 - accuracy: 0.9898 - val_loss: 0.1290 - val_accuracy: 0.9590\n",
      "Epoch 88/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0401 - accuracy: 0.9910 - val_loss: 0.1282 - val_accuracy: 0.9610\n",
      "Epoch 89/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0392 - accuracy: 0.9910 - val_loss: 0.1295 - val_accuracy: 0.9580\n",
      "Epoch 90/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0384 - accuracy: 0.9923 - val_loss: 0.1304 - val_accuracy: 0.9610\n",
      "Epoch 91/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0380 - accuracy: 0.9920 - val_loss: 0.1313 - val_accuracy: 0.9570\n",
      "Epoch 92/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0370 - accuracy: 0.9923 - val_loss: 0.1311 - val_accuracy: 0.9580\n",
      "Epoch 93/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0372 - accuracy: 0.9925 - val_loss: 0.1320 - val_accuracy: 0.9580\n",
      "Epoch 94/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0362 - accuracy: 0.9935 - val_loss: 0.1317 - val_accuracy: 0.9610\n",
      "Epoch 95/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0353 - accuracy: 0.9935 - val_loss: 0.1319 - val_accuracy: 0.9600\n",
      "Epoch 96/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0352 - accuracy: 0.9935 - val_loss: 0.1316 - val_accuracy: 0.9580\n",
      "Epoch 97/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0345 - accuracy: 0.9925 - val_loss: 0.1334 - val_accuracy: 0.9590\n",
      "Epoch 98/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0341 - accuracy: 0.9940 - val_loss: 0.1317 - val_accuracy: 0.9600\n",
      "Epoch 99/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0330 - accuracy: 0.9930 - val_loss: 0.1309 - val_accuracy: 0.9610\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7150357631136277\n",
      "F1 Micro: 0.9564\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 239us/step - loss: 0.6577 - accuracy: 0.8310 - val_loss: 0.3831 - val_accuracy: 0.8970\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.3130 - accuracy: 0.9187 - val_loss: 0.3150 - val_accuracy: 0.9140\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.2601 - accuracy: 0.9285 - val_loss: 0.2729 - val_accuracy: 0.9220\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.2278 - accuracy: 0.9377 - val_loss: 0.2457 - val_accuracy: 0.9330\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.2049 - accuracy: 0.9430 - val_loss: 0.2287 - val_accuracy: 0.9300\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1859 - accuracy: 0.9498 - val_loss: 0.2110 - val_accuracy: 0.9410\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1715 - accuracy: 0.9520 - val_loss: 0.2209 - val_accuracy: 0.9390\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1694 - accuracy: 0.9520 - val_loss: 0.1951 - val_accuracy: 0.9440\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1571 - accuracy: 0.9557 - val_loss: 0.1845 - val_accuracy: 0.9450\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1470 - accuracy: 0.9582 - val_loss: 0.1799 - val_accuracy: 0.9480\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1421 - accuracy: 0.9595 - val_loss: 0.1745 - val_accuracy: 0.9430\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1396 - accuracy: 0.9595 - val_loss: 0.1675 - val_accuracy: 0.9450\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1347 - accuracy: 0.9610 - val_loss: 0.1648 - val_accuracy: 0.9450\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1284 - accuracy: 0.9632 - val_loss: 0.1620 - val_accuracy: 0.9490\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1247 - accuracy: 0.9653 - val_loss: 0.1551 - val_accuracy: 0.9480\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1214 - accuracy: 0.9665 - val_loss: 0.1581 - val_accuracy: 0.9470\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1159 - accuracy: 0.9682 - val_loss: 0.1532 - val_accuracy: 0.9450\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1138 - accuracy: 0.9682 - val_loss: 0.1501 - val_accuracy: 0.9470\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1134 - accuracy: 0.9665 - val_loss: 0.1533 - val_accuracy: 0.9450\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1061 - accuracy: 0.9715 - val_loss: 0.1558 - val_accuracy: 0.9490\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1030 - accuracy: 0.9730 - val_loss: 0.1449 - val_accuracy: 0.9480\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1018 - accuracy: 0.9725 - val_loss: 0.1451 - val_accuracy: 0.9440\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0967 - accuracy: 0.9737 - val_loss: 0.1462 - val_accuracy: 0.9480\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0951 - accuracy: 0.9753 - val_loss: 0.1657 - val_accuracy: 0.9470\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0938 - accuracy: 0.9753 - val_loss: 0.1590 - val_accuracy: 0.9480\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0895 - accuracy: 0.9755 - val_loss: 0.1522 - val_accuracy: 0.9470\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0818 - accuracy: 0.9785 - val_loss: 0.1420 - val_accuracy: 0.9500\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0809 - accuracy: 0.9787 - val_loss: 0.1417 - val_accuracy: 0.9480\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0777 - accuracy: 0.9778 - val_loss: 0.1440 - val_accuracy: 0.9460\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0736 - accuracy: 0.9820 - val_loss: 0.1495 - val_accuracy: 0.9490\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0680 - accuracy: 0.9808 - val_loss: 0.1424 - val_accuracy: 0.9510\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0693 - accuracy: 0.9812 - val_loss: 0.1466 - val_accuracy: 0.9480\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0623 - accuracy: 0.9843 - val_loss: 0.1440 - val_accuracy: 0.9510\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0560 - accuracy: 0.9865 - val_loss: 0.1511 - val_accuracy: 0.9500\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0510 - accuracy: 0.9885 - val_loss: 0.1517 - val_accuracy: 0.9500\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0460 - accuracy: 0.9877 - val_loss: 0.1562 - val_accuracy: 0.9500\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0442 - accuracy: 0.9902 - val_loss: 0.1540 - val_accuracy: 0.9510\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0368 - accuracy: 0.9925 - val_loss: 0.1569 - val_accuracy: 0.9500\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0341 - accuracy: 0.9937 - val_loss: 0.1854 - val_accuracy: 0.9460\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0330 - accuracy: 0.9935 - val_loss: 0.1672 - val_accuracy: 0.9480\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0286 - accuracy: 0.9945 - val_loss: 0.1845 - val_accuracy: 0.9480\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0264 - accuracy: 0.9942 - val_loss: 0.1681 - val_accuracy: 0.9500\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0238 - accuracy: 0.9952 - val_loss: 0.1758 - val_accuracy: 0.9480\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0218 - accuracy: 0.9960 - val_loss: 0.1762 - val_accuracy: 0.9440\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0209 - accuracy: 0.9965 - val_loss: 0.1938 - val_accuracy: 0.9500\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0192 - accuracy: 0.9955 - val_loss: 0.1826 - val_accuracy: 0.9470\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0168 - accuracy: 0.9967 - val_loss: 0.1856 - val_accuracy: 0.9510\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0161 - accuracy: 0.9973 - val_loss: 0.1956 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7039429778295747\n",
      "F1 Micro: 0.9572\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7221293854400618\n",
      "F1 Micro: 0.9575\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7263112615868149\n",
      "F1 Micro: 0.9593\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 9 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.3945 - accuracy: 0.9039 - val_loss: 0.1935 - val_accuracy: 0.9441\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.1716 - accuracy: 0.9491 - val_loss: 0.1468 - val_accuracy: 0.9553\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1390 - accuracy: 0.9578 - val_loss: 0.1442 - val_accuracy: 0.9537\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.1229 - accuracy: 0.9610 - val_loss: 0.1279 - val_accuracy: 0.9608\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1137 - accuracy: 0.9644 - val_loss: 0.1173 - val_accuracy: 0.9636\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.1047 - accuracy: 0.9669 - val_loss: 0.1168 - val_accuracy: 0.9646\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0985 - accuracy: 0.9681 - val_loss: 0.1265 - val_accuracy: 0.9616\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0916 - accuracy: 0.9711 - val_loss: 0.1176 - val_accuracy: 0.9638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0881 - accuracy: 0.9711 - val_loss: 0.1099 - val_accuracy: 0.9642\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0829 - accuracy: 0.9729 - val_loss: 0.1013 - val_accuracy: 0.9683\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0783 - accuracy: 0.9746 - val_loss: 0.0962 - val_accuracy: 0.9694\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0748 - accuracy: 0.9758 - val_loss: 0.0909 - val_accuracy: 0.9711\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0696 - accuracy: 0.9768 - val_loss: 0.0953 - val_accuracy: 0.9691\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0657 - accuracy: 0.9784 - val_loss: 0.0857 - val_accuracy: 0.9729\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 7s 181us/step - loss: 0.0601 - accuracy: 0.9793 - val_loss: 0.1040 - val_accuracy: 0.9682\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0556 - accuracy: 0.9812 - val_loss: 0.0878 - val_accuracy: 0.9724\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0522 - accuracy: 0.9823 - val_loss: 0.0871 - val_accuracy: 0.9741\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0463 - accuracy: 0.9841 - val_loss: 0.1011 - val_accuracy: 0.9682\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0429 - accuracy: 0.9854 - val_loss: 0.0911 - val_accuracy: 0.9720\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0374 - accuracy: 0.9875 - val_loss: 0.0970 - val_accuracy: 0.9735\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.0907 - val_accuracy: 0.9737\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0286 - accuracy: 0.9904 - val_loss: 0.1098 - val_accuracy: 0.9714\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.1031 - val_accuracy: 0.9732\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.1030 - val_accuracy: 0.9727\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.1144 - val_accuracy: 0.9687\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.1380 - val_accuracy: 0.9720\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.1144 - val_accuracy: 0.9707\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.1269 - val_accuracy: 0.9720\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.1146 - val_accuracy: 0.9730\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.1236 - val_accuracy: 0.9725\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1666 - val_accuracy: 0.9697\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.1324 - val_accuracy: 0.9716\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.1219 - val_accuracy: 0.9737\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.1306 - val_accuracy: 0.9752\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8180167348719833\n",
      "F1 Micro: 0.9721\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8028019610424064\n",
      "F1 Micro: 0.9668\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.5336 - accuracy: 0.8750 - val_loss: 0.1639 - val_accuracy: 0.9554\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1471 - accuracy: 0.9577 - val_loss: 0.1342 - val_accuracy: 0.9606\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.1275 - accuracy: 0.9617 - val_loss: 0.1270 - val_accuracy: 0.9609\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.1180 - accuracy: 0.9650 - val_loss: 0.1181 - val_accuracy: 0.9633\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.1110 - accuracy: 0.9662 - val_loss: 0.1151 - val_accuracy: 0.9650\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1062 - accuracy: 0.9677 - val_loss: 0.1117 - val_accuracy: 0.9660\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.1025 - accuracy: 0.9683 - val_loss: 0.1098 - val_accuracy: 0.9661\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0992 - accuracy: 0.9693 - val_loss: 0.1076 - val_accuracy: 0.9667\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0963 - accuracy: 0.9704 - val_loss: 0.1069 - val_accuracy: 0.9678\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0941 - accuracy: 0.9707 - val_loss: 0.1045 - val_accuracy: 0.9683\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0919 - accuracy: 0.9721 - val_loss: 0.1051 - val_accuracy: 0.9673\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0898 - accuracy: 0.9722 - val_loss: 0.1025 - val_accuracy: 0.9684\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0882 - accuracy: 0.9729 - val_loss: 0.1015 - val_accuracy: 0.9679\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0867 - accuracy: 0.9729 - val_loss: 0.1007 - val_accuracy: 0.9686\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0851 - accuracy: 0.9736 - val_loss: 0.0998 - val_accuracy: 0.9698\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0838 - accuracy: 0.9738 - val_loss: 0.0996 - val_accuracy: 0.9692\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0823 - accuracy: 0.9746 - val_loss: 0.0990 - val_accuracy: 0.9689\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0809 - accuracy: 0.9753 - val_loss: 0.0996 - val_accuracy: 0.9700\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0800 - accuracy: 0.9752 - val_loss: 0.0975 - val_accuracy: 0.9705\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0787 - accuracy: 0.9755 - val_loss: 0.0988 - val_accuracy: 0.9696\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0775 - accuracy: 0.9762 - val_loss: 0.0988 - val_accuracy: 0.9701\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0768 - accuracy: 0.9760 - val_loss: 0.0971 - val_accuracy: 0.9697\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0756 - accuracy: 0.9767 - val_loss: 0.0973 - val_accuracy: 0.9706\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0746 - accuracy: 0.9771 - val_loss: 0.0961 - val_accuracy: 0.9707\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0735 - accuracy: 0.9773 - val_loss: 0.0963 - val_accuracy: 0.9708\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0726 - accuracy: 0.9776 - val_loss: 0.0959 - val_accuracy: 0.9706\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0718 - accuracy: 0.9781 - val_loss: 0.0957 - val_accuracy: 0.9713\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0713 - accuracy: 0.9778 - val_loss: 0.0957 - val_accuracy: 0.9707\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0700 - accuracy: 0.9786 - val_loss: 0.0952 - val_accuracy: 0.9710\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0692 - accuracy: 0.9787 - val_loss: 0.0962 - val_accuracy: 0.9713\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0682 - accuracy: 0.9788 - val_loss: 0.0955 - val_accuracy: 0.9720\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0677 - accuracy: 0.9796 - val_loss: 0.0958 - val_accuracy: 0.9712\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0668 - accuracy: 0.9794 - val_loss: 0.0955 - val_accuracy: 0.9709\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0658 - accuracy: 0.9800 - val_loss: 0.0957 - val_accuracy: 0.9711\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0653 - accuracy: 0.9799 - val_loss: 0.0952 - val_accuracy: 0.9712\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0645 - accuracy: 0.9804 - val_loss: 0.0967 - val_accuracy: 0.9710\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0639 - accuracy: 0.9803 - val_loss: 0.0938 - val_accuracy: 0.9723\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0631 - accuracy: 0.9804 - val_loss: 0.0951 - val_accuracy: 0.9716\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0624 - accuracy: 0.9805 - val_loss: 0.0937 - val_accuracy: 0.9715\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0617 - accuracy: 0.9809 - val_loss: 0.0948 - val_accuracy: 0.9714\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0611 - accuracy: 0.9806 - val_loss: 0.0974 - val_accuracy: 0.9707\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0603 - accuracy: 0.9812 - val_loss: 0.0945 - val_accuracy: 0.9716\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0597 - accuracy: 0.9815 - val_loss: 0.0956 - val_accuracy: 0.9715\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0590 - accuracy: 0.9817 - val_loss: 0.0940 - val_accuracy: 0.9716\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0584 - accuracy: 0.9819 - val_loss: 0.0956 - val_accuracy: 0.9720\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0577 - accuracy: 0.9816 - val_loss: 0.0937 - val_accuracy: 0.9710\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0570 - accuracy: 0.9816 - val_loss: 0.0960 - val_accuracy: 0.9713\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0564 - accuracy: 0.9829 - val_loss: 0.0961 - val_accuracy: 0.9711\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0556 - accuracy: 0.9828 - val_loss: 0.0971 - val_accuracy: 0.9716\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 66us/step - loss: 0.0549 - accuracy: 0.9833 - val_loss: 0.0962 - val_accuracy: 0.9703\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0543 - accuracy: 0.9831 - val_loss: 0.0965 - val_accuracy: 0.97020.0554 - accuracy: 0.98\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0537 - accuracy: 0.9833 - val_loss: 0.0943 - val_accuracy: 0.9705\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0532 - accuracy: 0.9837 - val_loss: 0.0974 - val_accuracy: 0.9702\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.0959 - val_accuracy: 0.9713\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0522 - accuracy: 0.9840 - val_loss: 0.0971 - val_accuracy: 0.9704\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 0.0967 - val_accuracy: 0.9701\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0509 - accuracy: 0.9846 - val_loss: 0.0964 - val_accuracy: 0.9702\n",
      "Epoch 58/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0500 - accuracy: 0.9847 - val_loss: 0.0986 - val_accuracy: 0.9702\n",
      "Epoch 59/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0495 - accuracy: 0.9850 - val_loss: 0.0966 - val_accuracy: 0.9703\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8366139057285833\n",
      "F1 Micro: 0.9696\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.2550 - accuracy: 0.9300 - val_loss: 0.1600 - val_accuracy: 0.9583\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.1403 - accuracy: 0.9577 - val_loss: 0.1322 - val_accuracy: 0.9618\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.1209 - accuracy: 0.9627 - val_loss: 0.1156 - val_accuracy: 0.9647\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.1101 - accuracy: 0.9658 - val_loss: 0.1140 - val_accuracy: 0.9644\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.1031 - accuracy: 0.9678 - val_loss: 0.1068 - val_accuracy: 0.9680\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0981 - accuracy: 0.9689 - val_loss: 0.1079 - val_accuracy: 0.9669\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0934 - accuracy: 0.9703 - val_loss: 0.1046 - val_accuracy: 0.9671\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0887 - accuracy: 0.9721 - val_loss: 0.0970 - val_accuracy: 0.9701\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0843 - accuracy: 0.9733 - val_loss: 0.0958 - val_accuracy: 0.9711\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0800 - accuracy: 0.9743 - val_loss: 0.1027 - val_accuracy: 0.9688\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0755 - accuracy: 0.9760 - val_loss: 0.0910 - val_accuracy: 0.9715\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0709 - accuracy: 0.9772 - val_loss: 0.0946 - val_accuracy: 0.9718\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0650 - accuracy: 0.9793 - val_loss: 0.0896 - val_accuracy: 0.9717\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0605 - accuracy: 0.9809 - val_loss: 0.0957 - val_accuracy: 0.9708\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0545 - accuracy: 0.9822 - val_loss: 0.0891 - val_accuracy: 0.9740\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0473 - accuracy: 0.9848 - val_loss: 0.0941 - val_accuracy: 0.9705\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 0.0994 - val_accuracy: 0.9737\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0338 - accuracy: 0.9894 - val_loss: 0.0993 - val_accuracy: 0.9714\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0279 - accuracy: 0.9915 - val_loss: 0.1089 - val_accuracy: 0.9720\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 0.1094 - val_accuracy: 0.9729\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.1131 - val_accuracy: 0.9729\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.1262 - val_accuracy: 0.9727\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 0.1335 - val_accuracy: 0.9717\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.1338 - val_accuracy: 0.9711\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.1350 - val_accuracy: 0.9730\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.1548 - val_accuracy: 0.9685\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.1446 - val_accuracy: 0.9723\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.1603 - val_accuracy: 0.9711\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.1536 - val_accuracy: 0.9725\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.1470 - val_accuracy: 0.9728\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.1750 - val_accuracy: 0.9703\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.1836 - val_accuracy: 0.9695\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1683 - val_accuracy: 0.9712\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.1633 - val_accuracy: 0.9729\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.1664 - val_accuracy: 0.9724\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8285082218295609\n",
      "F1 Micro: 0.9715\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7908664193985893\n",
      "F1 Micro: 0.9655\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8607959069691771\n",
      "F1 Micro: 0.9754\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 9 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.2491 - accuracy: 0.9331 - val_loss: 0.1201 - val_accuracy: 0.9623\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.1154 - accuracy: 0.9637 - val_loss: 0.0974 - val_accuracy: 0.9694\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0987 - accuracy: 0.9678 - val_loss: 0.0936 - val_accuracy: 0.9693\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0880 - accuracy: 0.9708 - val_loss: 0.0845 - val_accuracy: 0.9718\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0791 - accuracy: 0.9737 - val_loss: 0.0942 - val_accuracy: 0.9699\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0723 - accuracy: 0.9759 - val_loss: 0.0746 - val_accuracy: 0.9750\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0668 - accuracy: 0.9771 - val_loss: 0.0659 - val_accuracy: 0.9778\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0616 - accuracy: 0.9788 - val_loss: 0.0711 - val_accuracy: 0.97570616 - \n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0583 - accuracy: 0.9798 - val_loss: 0.0633 - val_accuracy: 0.9779\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0545 - accuracy: 0.9808 - val_loss: 0.0639 - val_accuracy: 0.9783\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0508 - accuracy: 0.9821 - val_loss: 0.0630 - val_accuracy: 0.9790\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0470 - accuracy: 0.9832 - val_loss: 0.0698 - val_accuracy: 0.9782\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0440 - accuracy: 0.9840 - val_loss: 0.0695 - val_accuracy: 0.9776\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0409 - accuracy: 0.9853 - val_loss: 0.0715 - val_accuracy: 0.9766\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0375 - accuracy: 0.9863 - val_loss: 0.0632 - val_accuracy: 0.9788\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0344 - accuracy: 0.9876 - val_loss: 0.0703 - val_accuracy: 0.9785\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0305 - accuracy: 0.9889 - val_loss: 0.0670 - val_accuracy: 0.9782\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0270 - accuracy: 0.9903 - val_loss: 0.0787 - val_accuracy: 0.9764\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.0764 - val_accuracy: 0.9783\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.0777 - val_accuracy: 0.9783\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0179 - accuracy: 0.9935 - val_loss: 0.0807 - val_accuracy: 0.9783\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.0857 - val_accuracy: 0.9769\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.1017 - val_accuracy: 0.9734\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0976 - val_accuracy: 0.9779\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.1011 - val_accuracy: 0.9769\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.1082 - val_accuracy: 0.9747s\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1076 - val_accuracy: 0.9760\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.1169 - val_accuracy: 0.9727\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1066 - val_accuracy: 0.9777\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.1054 - val_accuracy: 0.9790\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 24s 183us/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.1297 - val_accuracy: 0.9735\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8650699274083835\n",
      "F1 Micro: 0.9784\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8371880675742529\n",
      "F1 Micro: 0.9711\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.2603 - accuracy: 0.9327 - val_loss: 0.1207 - val_accuracy: 0.9641\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.1136 - accuracy: 0.9647 - val_loss: 0.1067 - val_accuracy: 0.9676\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.1038 - accuracy: 0.9672 - val_loss: 0.1008 - val_accuracy: 0.9690\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0985 - accuracy: 0.9686 - val_loss: 0.0968 - val_accuracy: 0.9710\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0945 - accuracy: 0.9697 - val_loss: 0.0958 - val_accuracy: 0.9713\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0914 - accuracy: 0.9707 - val_loss: 0.0920 - val_accuracy: 0.9720\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0891 - accuracy: 0.9716 - val_loss: 0.0916 - val_accuracy: 0.9718\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0870 - accuracy: 0.9720 - val_loss: 0.0904 - val_accuracy: 0.9729\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0849 - accuracy: 0.9728 - val_loss: 0.0901 - val_accuracy: 0.9719\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0835 - accuracy: 0.9731 - val_loss: 0.0875 - val_accuracy: 0.9731\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0819 - accuracy: 0.9737 - val_loss: 0.0864 - val_accuracy: 0.9720\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0805 - accuracy: 0.9739 - val_loss: 0.0865 - val_accuracy: 0.9731\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0792 - accuracy: 0.9746 - val_loss: 0.0853 - val_accuracy: 0.9733\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0779 - accuracy: 0.9749 - val_loss: 0.0861 - val_accuracy: 0.9729\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0768 - accuracy: 0.9752 - val_loss: 0.0842 - val_accuracy: 0.9736\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0759 - accuracy: 0.9755 - val_loss: 0.0852 - val_accuracy: 0.9735\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0748 - accuracy: 0.9757 - val_loss: 0.0837 - val_accuracy: 0.9739\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0740 - accuracy: 0.9758 - val_loss: 0.0824 - val_accuracy: 0.9742\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0728 - accuracy: 0.9764 - val_loss: 0.0827 - val_accuracy: 0.9741\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0723 - accuracy: 0.9764 - val_loss: 0.0826 - val_accuracy: 0.9743\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0713 - accuracy: 0.9770 - val_loss: 0.0818 - val_accuracy: 0.9747\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0705 - accuracy: 0.9770 - val_loss: 0.0825 - val_accuracy: 0.9736\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0698 - accuracy: 0.9774 - val_loss: 0.0814 - val_accuracy: 0.9743\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0688 - accuracy: 0.9776 - val_loss: 0.0822 - val_accuracy: 0.9746\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0682 - accuracy: 0.9780 - val_loss: 0.0825 - val_accuracy: 0.9738\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0675 - accuracy: 0.9780 - val_loss: 0.0818 - val_accuracy: 0.9741\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0669 - accuracy: 0.9781 - val_loss: 0.0826 - val_accuracy: 0.9741\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0661 - accuracy: 0.9784 - val_loss: 0.0824 - val_accuracy: 0.9740\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0655 - accuracy: 0.9788 - val_loss: 0.0824 - val_accuracy: 0.9736\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0647 - accuracy: 0.9791 - val_loss: 0.0800 - val_accuracy: 0.9749\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0642 - accuracy: 0.9790 - val_loss: 0.0805 - val_accuracy: 0.9744\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0635 - accuracy: 0.9793 - val_loss: 0.0817 - val_accuracy: 0.9743\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0629 - accuracy: 0.9797 - val_loss: 0.0811 - val_accuracy: 0.9747\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0624 - accuracy: 0.9795 - val_loss: 0.0817 - val_accuracy: 0.9744\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0616 - accuracy: 0.9796 - val_loss: 0.0820 - val_accuracy: 0.9742\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0610 - accuracy: 0.9799 - val_loss: 0.0805 - val_accuracy: 0.9747\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0604 - accuracy: 0.9803 - val_loss: 0.0804 - val_accuracy: 0.9749\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0599 - accuracy: 0.9804 - val_loss: 0.0808 - val_accuracy: 0.9748\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0592 - accuracy: 0.9807 - val_loss: 0.0807 - val_accuracy: 0.9745\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0587 - accuracy: 0.9806 - val_loss: 0.0810 - val_accuracy: 0.9745\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0580 - accuracy: 0.9811 - val_loss: 0.0814 - val_accuracy: 0.9743\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0575 - accuracy: 0.9812 - val_loss: 0.0813 - val_accuracy: 0.9749\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0569 - accuracy: 0.9814 - val_loss: 0.0814 - val_accuracy: 0.9747\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0562 - accuracy: 0.9812 - val_loss: 0.0808 - val_accuracy: 0.9747\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0557 - accuracy: 0.9815 - val_loss: 0.0816 - val_accuracy: 0.9738\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0553 - accuracy: 0.9822 - val_loss: 0.0812 - val_accuracy: 0.9742\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0547 - accuracy: 0.9820 - val_loss: 0.0835 - val_accuracy: 0.9738\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0543 - accuracy: 0.9819 - val_loss: 0.0815 - val_accuracy: 0.9739\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0536 - accuracy: 0.9826 - val_loss: 0.0817 - val_accuracy: 0.9746\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0531 - accuracy: 0.9826 - val_loss: 0.0824 - val_accuracy: 0.9736\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8532202014714007\n",
      "F1 Micro: 0.9733\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.1702 - accuracy: 0.9502 - val_loss: 0.1136 - val_accuracy: 0.9652\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.1075 - accuracy: 0.9657 - val_loss: 0.0950 - val_accuracy: 0.9706\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0914 - accuracy: 0.9703 - val_loss: 0.0837 - val_accuracy: 0.9739\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0815 - accuracy: 0.9733 - val_loss: 0.0773 - val_accuracy: 0.9750\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0745 - accuracy: 0.9752 - val_loss: 0.0761 - val_accuracy: 0.9755\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0691 - accuracy: 0.9770 - val_loss: 0.0736 - val_accuracy: 0.9762\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0636 - accuracy: 0.9786 - val_loss: 0.0751 - val_accuracy: 0.9742\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0588 - accuracy: 0.9800 - val_loss: 0.0698 - val_accuracy: 0.9773\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0535 - accuracy: 0.9821 - val_loss: 0.0664 - val_accuracy: 0.9779\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0478 - accuracy: 0.9837 - val_loss: 0.0677 - val_accuracy: 0.9782\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0422 - accuracy: 0.9855 - val_loss: 0.0711 - val_accuracy: 0.9776\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0362 - accuracy: 0.9878 - val_loss: 0.0680 - val_accuracy: 0.9790\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0301 - accuracy: 0.9897 - val_loss: 0.0773 - val_accuracy: 0.9778\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0769 - val_accuracy: 0.9778\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.0841 - val_accuracy: 0.9769\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0987 - val_accuracy: 0.9770\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.0939 - val_accuracy: 0.9751\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.1065 - val_accuracy: 0.9754\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.1142 - val_accuracy: 0.9773\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.1076 - val_accuracy: 0.9767\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.1156 - val_accuracy: 0.9767\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1156 - val_accuracy: 0.9768\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1274 - val_accuracy: 0.9761\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1354 - val_accuracy: 0.9771\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1256 - val_accuracy: 0.9747\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.1277 - val_accuracy: 0.9777\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1317 - val_accuracy: 0.9721\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1318 - val_accuracy: 0.9770\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.1529 - val_accuracy: 0.9739\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8662631043515852\n",
      "F1 Micro: 0.977\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8265585102139547\n",
      "F1 Micro: 0.9693\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8911463266555875\n",
      "F1 Micro: 0.9796\n",
      "\n",
      "\n",
      " 50.729884906609854 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 10 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 10 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.8753 - accuracy: 0.7650 - val_loss: 1.3791 - val_accuracy: 0.8500\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.9084 - accuracy: 0.8675 - val_loss: 0.8181 - val_accuracy: 0.8500\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.7197 - accuracy: 0.8675 - val_loss: 0.7705 - val_accuracy: 0.8500\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.6509 - accuracy: 0.8675 - val_loss: 0.7090 - val_accuracy: 0.8500\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.6233 - accuracy: 0.8675 - val_loss: 0.6897 - val_accuracy: 0.8500\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.6091 - accuracy: 0.8675 - val_loss: 0.6753 - val_accuracy: 0.8500\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 177us/step - loss: 0.6021 - accuracy: 0.8675 - val_loss: 0.6616 - val_accuracy: 0.8500\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5906 - accuracy: 0.8675 - val_loss: 0.6562 - val_accuracy: 0.8500\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5897 - accuracy: 0.8675 - val_loss: 0.6472 - val_accuracy: 0.8500\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5845 - accuracy: 0.8675 - val_loss: 0.6371 - val_accuracy: 0.8500\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5951 - accuracy: 0.8675 - val_loss: 0.6403 - val_accuracy: 0.8500\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5822 - accuracy: 0.8675 - val_loss: 0.6316 - val_accuracy: 0.8500\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5648 - accuracy: 0.8675 - val_loss: 0.6266 - val_accuracy: 0.8500\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5616 - accuracy: 0.8675 - val_loss: 0.6173 - val_accuracy: 0.8500\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5536 - accuracy: 0.8675 - val_loss: 0.6137 - val_accuracy: 0.8500\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5487 - accuracy: 0.8675 - val_loss: 0.6036 - val_accuracy: 0.8500\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5441 - accuracy: 0.8675 - val_loss: 0.5981 - val_accuracy: 0.8500\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.5338 - accuracy: 0.8675 - val_loss: 0.6064 - val_accuracy: 0.8500\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.5198 - accuracy: 0.8675 - val_loss: 0.5873 - val_accuracy: 0.8500\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.5291 - accuracy: 0.8675 - val_loss: 0.5816 - val_accuracy: 0.8500\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5063 - accuracy: 0.8675 - val_loss: 0.6018 - val_accuracy: 0.8500\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4913 - accuracy: 0.8675 - val_loss: 0.5680 - val_accuracy: 0.8500\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4728 - accuracy: 0.8675 - val_loss: 0.5479 - val_accuracy: 0.8500\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4618 - accuracy: 0.8675 - val_loss: 0.5601 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4376 - accuracy: 0.8675 - val_loss: 0.5230 - val_accuracy: 0.8500\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4261 - accuracy: 0.8675 - val_loss: 0.5282 - val_accuracy: 0.8500\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.4093 - accuracy: 0.8700 - val_loss: 0.5048 - val_accuracy: 0.8500\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3865 - accuracy: 0.8675 - val_loss: 0.4848 - val_accuracy: 0.8700\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3698 - accuracy: 0.8800 - val_loss: 0.4813 - val_accuracy: 0.8700\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.3609 - accuracy: 0.8875 - val_loss: 0.4639 - val_accuracy: 0.8700\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3516 - accuracy: 0.8950 - val_loss: 0.4802 - val_accuracy: 0.8700\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3322 - accuracy: 0.9050 - val_loss: 0.4578 - val_accuracy: 0.8700\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3170 - accuracy: 0.9050 - val_loss: 0.4188 - val_accuracy: 0.8800\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2823 - accuracy: 0.9250 - val_loss: 0.4886 - val_accuracy: 0.8700\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2839 - accuracy: 0.9225 - val_loss: 0.4069 - val_accuracy: 0.8800\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2619 - accuracy: 0.9325 - val_loss: 0.4500 - val_accuracy: 0.8800\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2551 - accuracy: 0.9325 - val_loss: 0.4173 - val_accuracy: 0.8900\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2404 - accuracy: 0.9375 - val_loss: 0.3807 - val_accuracy: 0.9000\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2410 - accuracy: 0.9400 - val_loss: 0.4042 - val_accuracy: 0.8900\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2309 - accuracy: 0.9500 - val_loss: 0.3958 - val_accuracy: 0.8900\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2237 - accuracy: 0.9400 - val_loss: 0.4026 - val_accuracy: 0.8900\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2068 - accuracy: 0.9550 - val_loss: 0.3729 - val_accuracy: 0.9000\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 175us/step - loss: 0.2077 - accuracy: 0.9425 - val_loss: 0.3818 - val_accuracy: 0.9000\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2000 - accuracy: 0.9500 - val_loss: 0.3772 - val_accuracy: 0.8900\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2123 - accuracy: 0.9425 - val_loss: 0.4230 - val_accuracy: 0.8900\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1896 - accuracy: 0.9550 - val_loss: 0.3532 - val_accuracy: 0.9100\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1794 - accuracy: 0.9525 - val_loss: 0.4643 - val_accuracy: 0.8900\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1850 - accuracy: 0.9525 - val_loss: 0.4253 - val_accuracy: 0.8900\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1924 - accuracy: 0.9425 - val_loss: 0.4727 - val_accuracy: 0.8800\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2142 - accuracy: 0.9450 - val_loss: 0.4718 - val_accuracy: 0.8800\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2459 - accuracy: 0.9300 - val_loss: 0.3641 - val_accuracy: 0.9000\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1788 - accuracy: 0.9500 - val_loss: 0.3755 - val_accuracy: 0.9100\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1608 - accuracy: 0.9600 - val_loss: 0.4169 - val_accuracy: 0.8900\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1558 - accuracy: 0.9600 - val_loss: 0.3840 - val_accuracy: 0.9000\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1469 - accuracy: 0.9600 - val_loss: 0.3730 - val_accuracy: 0.9000\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.1569 - accuracy: 0.9550 - val_loss: 0.4642 - val_accuracy: 0.8900\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1455 - accuracy: 0.9600 - val_loss: 0.3792 - val_accuracy: 0.9100\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1451 - accuracy: 0.9550 - val_loss: 0.3458 - val_accuracy: 0.9100\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1335 - accuracy: 0.9550 - val_loss: 0.3746 - val_accuracy: 0.9100\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1236 - accuracy: 0.9600 - val_loss: 0.3744 - val_accuracy: 0.9100\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1207 - accuracy: 0.9625 - val_loss: 0.4037 - val_accuracy: 0.9000\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1413 - accuracy: 0.9550 - val_loss: 0.3814 - val_accuracy: 0.9100\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1271 - accuracy: 0.9575 - val_loss: 0.4201 - val_accuracy: 0.9100\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1190 - accuracy: 0.9675 - val_loss: 0.4262 - val_accuracy: 0.9000\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1147 - accuracy: 0.9600 - val_loss: 0.3573 - val_accuracy: 0.9100\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1027 - accuracy: 0.9650 - val_loss: 0.3739 - val_accuracy: 0.9000\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1019 - accuracy: 0.9650 - val_loss: 0.3488 - val_accuracy: 0.9100\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.1049 - accuracy: 0.9675 - val_loss: 0.3671 - val_accuracy: 0.9100\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1131 - accuracy: 0.9575 - val_loss: 0.3659 - val_accuracy: 0.9100\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0954 - accuracy: 0.9700 - val_loss: 0.3787 - val_accuracy: 0.9000\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0920 - accuracy: 0.9600 - val_loss: 0.3537 - val_accuracy: 0.9000\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0914 - accuracy: 0.9700 - val_loss: 0.3698 - val_accuracy: 0.9100\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0889 - accuracy: 0.9725 - val_loss: 0.4208 - val_accuracy: 0.9000\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0853 - accuracy: 0.9625 - val_loss: 0.3601 - val_accuracy: 0.9100\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0908 - accuracy: 0.9675 - val_loss: 0.3524 - val_accuracy: 0.9100\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0851 - accuracy: 0.9750 - val_loss: 0.3532 - val_accuracy: 0.9000\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0823 - accuracy: 0.9725 - val_loss: 0.3663 - val_accuracy: 0.9000\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0796 - accuracy: 0.9750 - val_loss: 0.3565 - val_accuracy: 0.9100\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.4404287889669373\n",
      "F1 Micro: 0.924890873513622\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5769220920357498\n",
      "F1 Micro: 0.9383372635592796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 276us/step - loss: 2.0918 - accuracy: 0.2075 - val_loss: 1.9068 - val_accuracy: 0.5100\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 43us/step - loss: 1.8861 - accuracy: 0.5175 - val_loss: 1.7140 - val_accuracy: 0.6200\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.7441 - accuracy: 0.5650 - val_loss: 1.5912 - val_accuracy: 0.6300\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.6499 - accuracy: 0.5925 - val_loss: 1.5166 - val_accuracy: 0.6500\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 1.5835 - accuracy: 0.6050 - val_loss: 1.4606 - val_accuracy: 0.6600\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 1.5268 - accuracy: 0.6350 - val_loss: 1.4130 - val_accuracy: 0.6800\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 1.4773 - accuracy: 0.6575 - val_loss: 1.3703 - val_accuracy: 0.7000\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.4290 - accuracy: 0.6725 - val_loss: 1.3285 - val_accuracy: 0.7000\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.3819 - accuracy: 0.6950 - val_loss: 1.2872 - val_accuracy: 0.7100\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.3328 - accuracy: 0.7125 - val_loss: 1.2444 - val_accuracy: 0.7300\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.2853 - accuracy: 0.7225 - val_loss: 1.2026 - val_accuracy: 0.7300\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.2361 - accuracy: 0.7475 - val_loss: 1.1576 - val_accuracy: 0.7600\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1865 - accuracy: 0.7625 - val_loss: 1.1115 - val_accuracy: 0.7800\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.1353 - accuracy: 0.7750 - val_loss: 1.0639 - val_accuracy: 0.7900\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0836 - accuracy: 0.7900 - val_loss: 1.0148 - val_accuracy: 0.7900\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0321 - accuracy: 0.8175 - val_loss: 0.9644 - val_accuracy: 0.8100\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.9778 - accuracy: 0.8325 - val_loss: 0.9147 - val_accuracy: 0.8400\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.9243 - accuracy: 0.8475 - val_loss: 0.8670 - val_accuracy: 0.8600\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8736 - accuracy: 0.8575 - val_loss: 0.8174 - val_accuracy: 0.8600\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.8223 - accuracy: 0.8750 - val_loss: 0.7707 - val_accuracy: 0.9000\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7711 - accuracy: 0.8850 - val_loss: 0.7262 - val_accuracy: 0.9000\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7228 - accuracy: 0.8900 - val_loss: 0.6814 - val_accuracy: 0.9000\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.6771 - accuracy: 0.8950 - val_loss: 0.6404 - val_accuracy: 0.9200\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.6333 - accuracy: 0.9050 - val_loss: 0.5992 - val_accuracy: 0.9200\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5915 - accuracy: 0.9150 - val_loss: 0.5636 - val_accuracy: 0.9300\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5543 - accuracy: 0.9275 - val_loss: 0.5316 - val_accuracy: 0.9400\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5161 - accuracy: 0.9300 - val_loss: 0.4987 - val_accuracy: 0.9300\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4823 - accuracy: 0.9350 - val_loss: 0.4697 - val_accuracy: 0.9300\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.96 - 0s 78us/step - loss: 0.4504 - accuracy: 0.9375 - val_loss: 0.4451 - val_accuracy: 0.9400\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 50us/step - loss: 0.4216 - accuracy: 0.9400 - val_loss: 0.4222 - val_accuracy: 0.9300\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3949 - accuracy: 0.9425 - val_loss: 0.4038 - val_accuracy: 0.9400\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3697 - accuracy: 0.9475 - val_loss: 0.3835 - val_accuracy: 0.9300\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3468 - accuracy: 0.9525 - val_loss: 0.3667 - val_accuracy: 0.9300\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3257 - accuracy: 0.9525 - val_loss: 0.3515 - val_accuracy: 0.9600\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3079 - accuracy: 0.9575 - val_loss: 0.3402 - val_accuracy: 0.9600\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2889 - accuracy: 0.9625 - val_loss: 0.3274 - val_accuracy: 0.9600\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2728 - accuracy: 0.9550 - val_loss: 0.3159 - val_accuracy: 0.9600\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2582 - accuracy: 0.9650 - val_loss: 0.3083 - val_accuracy: 0.9600\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2446 - accuracy: 0.9725 - val_loss: 0.2979 - val_accuracy: 0.9600\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2330 - accuracy: 0.9725 - val_loss: 0.2920 - val_accuracy: 0.9600\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2215 - accuracy: 0.9725 - val_loss: 0.2851 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2116 - accuracy: 0.9725 - val_loss: 0.2801 - val_accuracy: 0.9500\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2020 - accuracy: 0.9725 - val_loss: 0.2731 - val_accuracy: 0.9500\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1937 - accuracy: 0.9725 - val_loss: 0.2681 - val_accuracy: 0.9500\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1861 - accuracy: 0.9725 - val_loss: 0.2645 - val_accuracy: 0.9500\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1794 - accuracy: 0.9725 - val_loss: 0.2634 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1729 - accuracy: 0.9725 - val_loss: 0.2569 - val_accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 1.00 - 0s 78us/step - loss: 0.1662 - accuracy: 0.9700 - val_loss: 0.2547 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1602 - accuracy: 0.9700 - val_loss: 0.2513 - val_accuracy: 0.9500\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1553 - accuracy: 0.9700 - val_loss: 0.2476 - val_accuracy: 0.9500\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1507 - accuracy: 0.9700 - val_loss: 0.2453 - val_accuracy: 0.9500\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1458 - accuracy: 0.9725 - val_loss: 0.2418 - val_accuracy: 0.9500\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 1.00 - 0s 78us/step - loss: 0.1417 - accuracy: 0.9750 - val_loss: 0.2397 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1378 - accuracy: 0.9750 - val_loss: 0.2384 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1346 - accuracy: 0.9750 - val_loss: 0.2376 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1306 - accuracy: 0.9750 - val_loss: 0.2332 - val_accuracy: 0.9500\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1273 - accuracy: 0.9750 - val_loss: 0.2342 - val_accuracy: 0.9500\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1238 - accuracy: 0.9750 - val_loss: 0.2306 - val_accuracy: 0.9500\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1208 - accuracy: 0.9775 - val_loss: 0.2290 - val_accuracy: 0.9500\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1186 - accuracy: 0.9750 - val_loss: 0.2292 - val_accuracy: 0.9500\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1152 - accuracy: 0.9775 - val_loss: 0.2267 - val_accuracy: 0.9500\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1130 - accuracy: 0.9775 - val_loss: 0.2234 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1099 - accuracy: 0.9775 - val_loss: 0.2237 - val_accuracy: 0.9500\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1080 - accuracy: 0.9775 - val_loss: 0.2253 - val_accuracy: 0.9500\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1051 - accuracy: 0.9775 - val_loss: 0.2244 - val_accuracy: 0.9500\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1026 - accuracy: 0.9800 - val_loss: 0.2214 - val_accuracy: 0.9500\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1005 - accuracy: 0.9800 - val_loss: 0.2196 - val_accuracy: 0.9600\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0982 - accuracy: 0.9800 - val_loss: 0.2196 - val_accuracy: 0.9600\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0966 - accuracy: 0.9800 - val_loss: 0.2201 - val_accuracy: 0.9500\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0949 - accuracy: 0.9800 - val_loss: 0.2188 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0921 - accuracy: 0.9800 - val_loss: 0.2161 - val_accuracy: 0.9600\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0905 - accuracy: 0.9825 - val_loss: 0.2154 - val_accuracy: 0.9600\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0888 - accuracy: 0.9825 - val_loss: 0.2154 - val_accuracy: 0.9600\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0870 - accuracy: 0.9825 - val_loss: 0.2154 - val_accuracy: 0.9600\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0856 - accuracy: 0.9825 - val_loss: 0.2146 - val_accuracy: 0.9600\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0837 - accuracy: 0.9825 - val_loss: 0.2132 - val_accuracy: 0.9600\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0820 - accuracy: 0.9825 - val_loss: 0.2125 - val_accuracy: 0.9600\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0806 - accuracy: 0.9825 - val_loss: 0.2125 - val_accuracy: 0.9600\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0792 - accuracy: 0.9825 - val_loss: 0.2121 - val_accuracy: 0.9600\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0777 - accuracy: 0.9850 - val_loss: 0.2109 - val_accuracy: 0.9600\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0762 - accuracy: 0.9850 - val_loss: 0.2104 - val_accuracy: 0.9600\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0750 - accuracy: 0.9875 - val_loss: 0.2117 - val_accuracy: 0.9600\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0737 - accuracy: 0.9850 - val_loss: 0.2103 - val_accuracy: 0.9600\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0726 - accuracy: 0.9850 - val_loss: 0.2082 - val_accuracy: 0.9600\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0709 - accuracy: 0.9850 - val_loss: 0.2099 - val_accuracy: 0.9600\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0699 - accuracy: 0.9875 - val_loss: 0.2087 - val_accuracy: 0.9600\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0685 - accuracy: 0.9850 - val_loss: 0.2078 - val_accuracy: 0.9600\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0674 - accuracy: 0.9875 - val_loss: 0.2089 - val_accuracy: 0.9600\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0662 - accuracy: 0.9875 - val_loss: 0.2074 - val_accuracy: 0.9600\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0651 - accuracy: 0.9875 - val_loss: 0.2078 - val_accuracy: 0.9600\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0640 - accuracy: 0.9875 - val_loss: 0.2063 - val_accuracy: 0.9600\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 39us/step - loss: 0.0627 - accuracy: 0.9875 - val_loss: 0.2072 - val_accuracy: 0.9600\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0618 - accuracy: 0.9875 - val_loss: 0.2062 - val_accuracy: 0.9600\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 108us/step - loss: 0.0606 - accuracy: 0.9875 - val_loss: 0.2063 - val_accuracy: 0.9600\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 44us/step - loss: 0.0600 - accuracy: 0.9900 - val_loss: 0.2068 - val_accuracy: 0.9600\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0586 - accuracy: 0.9875 - val_loss: 0.2056 - val_accuracy: 0.9600\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0580 - accuracy: 0.9875 - val_loss: 0.2034 - val_accuracy: 0.9600\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0567 - accuracy: 0.9875 - val_loss: 0.2046 - val_accuracy: 0.9600\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0557 - accuracy: 0.9875 - val_loss: 0.2051 - val_accuracy: 0.9600\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0549 - accuracy: 0.9900 - val_loss: 0.2056 - val_accuracy: 0.9600\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0541 - accuracy: 0.9900 - val_loss: 0.2048 - val_accuracy: 0.9600\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.0532 - accuracy: 0.9900 - val_loss: 0.2044 - val_accuracy: 0.9600\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0522 - accuracy: 0.9900 - val_loss: 0.2055 - val_accuracy: 0.9600\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0513 - accuracy: 0.9900 - val_loss: 0.2043 - val_accuracy: 0.9600\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0504 - accuracy: 0.9900 - val_loss: 0.2046 - val_accuracy: 0.9600\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0499 - accuracy: 0.9900 - val_loss: 0.2037 - val_accuracy: 0.9600\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0487 - accuracy: 0.9900 - val_loss: 0.2042 - val_accuracy: 0.9600\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0481 - accuracy: 0.9900 - val_loss: 0.2033 - val_accuracy: 0.9600\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0475 - accuracy: 0.9900 - val_loss: 0.2023 - val_accuracy: 0.9600\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0467 - accuracy: 0.9900 - val_loss: 0.2038 - val_accuracy: 0.9600\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0460 - accuracy: 0.9900 - val_loss: 0.2030 - val_accuracy: 0.9600\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 78us/step - loss: 0.0452 - accuracy: 0.9900 - val_loss: 0.2027 - val_accuracy: 0.9600\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0444 - accuracy: 0.9900 - val_loss: 0.2021 - val_accuracy: 0.9600\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0438 - accuracy: 0.9900 - val_loss: 0.2006 - val_accuracy: 0.9600\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.0432 - accuracy: 0.9950 - val_loss: 0.2020 - val_accuracy: 0.9600\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0424 - accuracy: 0.9950 - val_loss: 0.2027 - val_accuracy: 0.9600\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0416 - accuracy: 0.9950 - val_loss: 0.2024 - val_accuracy: 0.9600\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0411 - accuracy: 0.9950 - val_loss: 0.2024 - val_accuracy: 0.9600\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0408 - accuracy: 0.9950 - val_loss: 0.2029 - val_accuracy: 0.9600\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0399 - accuracy: 0.9950 - val_loss: 0.2008 - val_accuracy: 0.9600\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0395 - accuracy: 0.9950 - val_loss: 0.2012 - val_accuracy: 0.9600\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.0387 - accuracy: 0.9950 - val_loss: 0.2019 - val_accuracy: 0.9600\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0381 - accuracy: 0.9950 - val_loss: 0.2013 - val_accuracy: 0.9600\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0375 - accuracy: 0.9950 - val_loss: 0.2012 - val_accuracy: 0.9600\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0371 - accuracy: 0.9950 - val_loss: 0.2012 - val_accuracy: 0.9600\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 117us/step - loss: 0.0365 - accuracy: 0.9950 - val_loss: 0.2012 - val_accuracy: 0.9600\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0359 - accuracy: 0.9950 - val_loss: 0.2024 - val_accuracy: 0.9600\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0354 - accuracy: 0.9950 - val_loss: 0.2016 - val_accuracy: 0.9600\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0352 - accuracy: 0.9950 - val_loss: 0.2035 - val_accuracy: 0.9600\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0344 - accuracy: 0.9950 - val_loss: 0.2012 - val_accuracy: 0.9600\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0339 - accuracy: 0.9950 - val_loss: 0.2007 - val_accuracy: 0.9600\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0333 - accuracy: 0.9950 - val_loss: 0.2010 - val_accuracy: 0.9600\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0328 - accuracy: 0.9950 - val_loss: 0.2007 - val_accuracy: 0.9600\n",
      "Epoch 134/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0324 - accuracy: 0.9950 - val_loss: 0.2022 - val_accuracy: 0.9600\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5265965505131592\n",
      "F1 Micro: 0.942250765139732\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 703us/step - loss: 1.7590 - accuracy: 0.6125 - val_loss: 1.1599 - val_accuracy: 0.8800\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 177us/step - loss: 0.7200 - accuracy: 0.8950 - val_loss: 0.4502 - val_accuracy: 0.8800\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.4639 - accuracy: 0.8725 - val_loss: 0.4367 - val_accuracy: 0.8800\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3907 - accuracy: 0.8875 - val_loss: 0.3688 - val_accuracy: 0.9000\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3648 - accuracy: 0.8975 - val_loss: 0.3487 - val_accuracy: 0.9100\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3402 - accuracy: 0.9050 - val_loss: 0.3317 - val_accuracy: 0.9100\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3233 - accuracy: 0.9025 - val_loss: 0.3150 - val_accuracy: 0.9100\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.3095 - accuracy: 0.9075 - val_loss: 0.3076 - val_accuracy: 0.9100\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2963 - accuracy: 0.9200 - val_loss: 0.2990 - val_accuracy: 0.9200\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2825 - accuracy: 0.9175 - val_loss: 0.2915 - val_accuracy: 0.9200\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2718 - accuracy: 0.9300 - val_loss: 0.2828 - val_accuracy: 0.9200\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2622 - accuracy: 0.9375 - val_loss: 0.2803 - val_accuracy: 0.9200\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 176us/step - loss: 0.2540 - accuracy: 0.9400 - val_loss: 0.2743 - val_accuracy: 0.9200\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2439 - accuracy: 0.9425 - val_loss: 0.2691 - val_accuracy: 0.9200\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2358 - accuracy: 0.9450 - val_loss: 0.2634 - val_accuracy: 0.9200\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2283 - accuracy: 0.9450 - val_loss: 0.2610 - val_accuracy: 0.9200\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.94 - 0s 195us/step - loss: 0.2220 - accuracy: 0.9450 - val_loss: 0.2555 - val_accuracy: 0.9300\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2142 - accuracy: 0.9450 - val_loss: 0.2540 - val_accuracy: 0.9200\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2081 - accuracy: 0.9600 - val_loss: 0.2504 - val_accuracy: 0.9300\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.2021 - accuracy: 0.9625 - val_loss: 0.2461 - val_accuracy: 0.9300\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1966 - accuracy: 0.9525 - val_loss: 0.2439 - val_accuracy: 0.9300\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1886 - accuracy: 0.9600 - val_loss: 0.2403 - val_accuracy: 0.9300\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1867 - accuracy: 0.9650 - val_loss: 0.2413 - val_accuracy: 0.9300\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1827 - accuracy: 0.9600 - val_loss: 0.2341 - val_accuracy: 0.9300\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 176us/step - loss: 0.1749 - accuracy: 0.9650 - val_loss: 0.2292 - val_accuracy: 0.9300\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1703 - accuracy: 0.9625 - val_loss: 0.2278 - val_accuracy: 0.9300\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1666 - accuracy: 0.9675 - val_loss: 0.2285 - val_accuracy: 0.9400\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1615 - accuracy: 0.9675 - val_loss: 0.2294 - val_accuracy: 0.9400\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1575 - accuracy: 0.9675 - val_loss: 0.2209 - val_accuracy: 0.9400\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1527 - accuracy: 0.9700 - val_loss: 0.2190 - val_accuracy: 0.9400\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1520 - accuracy: 0.9625 - val_loss: 0.2160 - val_accuracy: 0.9400\n",
      "Epoch 32/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 195us/step - loss: 0.1468 - accuracy: 0.9600 - val_loss: 0.2182 - val_accuracy: 0.9400\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1415 - accuracy: 0.9700 - val_loss: 0.2165 - val_accuracy: 0.9400\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1377 - accuracy: 0.9700 - val_loss: 0.2108 - val_accuracy: 0.9400\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1361 - accuracy: 0.9700 - val_loss: 0.2102 - val_accuracy: 0.9400\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1328 - accuracy: 0.9650 - val_loss: 0.2086 - val_accuracy: 0.9400\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 178us/step - loss: 0.1298 - accuracy: 0.9725 - val_loss: 0.2094 - val_accuracy: 0.9400\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1250 - accuracy: 0.9700 - val_loss: 0.2084 - val_accuracy: 0.9400\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1219 - accuracy: 0.9675 - val_loss: 0.2048 - val_accuracy: 0.9400\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1188 - accuracy: 0.9750 - val_loss: 0.2038 - val_accuracy: 0.9400\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1155 - accuracy: 0.9750 - val_loss: 0.1996 - val_accuracy: 0.9400\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1131 - accuracy: 0.9750 - val_loss: 0.1991 - val_accuracy: 0.9400\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1103 - accuracy: 0.9800 - val_loss: 0.1980 - val_accuracy: 0.9400\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1105 - accuracy: 0.9700 - val_loss: 0.1983 - val_accuracy: 0.9400\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1066 - accuracy: 0.9800 - val_loss: 0.2066 - val_accuracy: 0.9400\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1031 - accuracy: 0.9750 - val_loss: 0.1976 - val_accuracy: 0.9400\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1002 - accuracy: 0.9800 - val_loss: 0.1978 - val_accuracy: 0.9400\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0986 - accuracy: 0.9775 - val_loss: 0.1968 - val_accuracy: 0.9400\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.0978 - accuracy: 0.9825 - val_loss: 0.1955 - val_accuracy: 0.9400\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0943 - accuracy: 0.9775 - val_loss: 0.1948 - val_accuracy: 0.9400\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0896 - accuracy: 0.9800 - val_loss: 0.2002 - val_accuracy: 0.9400\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0872 - accuracy: 0.9800 - val_loss: 0.1908 - val_accuracy: 0.9400\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0882 - accuracy: 0.9825 - val_loss: 0.1964 - val_accuracy: 0.9400\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0841 - accuracy: 0.9825 - val_loss: 0.1988 - val_accuracy: 0.9400\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0885 - accuracy: 0.9800 - val_loss: 0.1856 - val_accuracy: 0.9400\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0823 - accuracy: 0.9800 - val_loss: 0.1953 - val_accuracy: 0.9400\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0769 - accuracy: 0.9800 - val_loss: 0.1889 - val_accuracy: 0.9300\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0839 - accuracy: 0.9775 - val_loss: 0.1997 - val_accuracy: 0.9400\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0790 - accuracy: 0.9850 - val_loss: 0.1984 - val_accuracy: 0.9400\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0713 - accuracy: 0.9825 - val_loss: 0.1873 - val_accuracy: 0.9300\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 188us/step - loss: 0.0697 - accuracy: 0.9850 - val_loss: 0.1991 - val_accuracy: 0.9400\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0726 - accuracy: 0.9800 - val_loss: 0.1882 - val_accuracy: 0.9300\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0739 - accuracy: 0.9875 - val_loss: 0.2012 - val_accuracy: 0.9400\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0659 - accuracy: 0.9875 - val_loss: 0.1938 - val_accuracy: 0.9400\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0616 - accuracy: 0.9850 - val_loss: 0.1958 - val_accuracy: 0.9400\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.0599 - accuracy: 0.9850 - val_loss: 0.1932 - val_accuracy: 0.9400\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0579 - accuracy: 0.9850 - val_loss: 0.1934 - val_accuracy: 0.9400\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0575 - accuracy: 0.9850 - val_loss: 0.1900 - val_accuracy: 0.9300\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0571 - accuracy: 0.9850 - val_loss: 0.1921 - val_accuracy: 0.9400\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0550 - accuracy: 0.9875 - val_loss: 0.2054 - val_accuracy: 0.9400\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0527 - accuracy: 0.9900 - val_loss: 0.1889 - val_accuracy: 0.9400\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0479 - accuracy: 0.9875 - val_loss: 0.1955 - val_accuracy: 0.9400\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0453 - accuracy: 0.9875 - val_loss: 0.1952 - val_accuracy: 0.9300\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.0463 - accuracy: 0.9850 - val_loss: 0.1892 - val_accuracy: 0.9300\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0441 - accuracy: 0.9900 - val_loss: 0.2002 - val_accuracy: 0.9400\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5912535635803564\n",
      "F1 Micro: 0.940845918418544\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5717294586683147\n",
      "F1 Micro: 0.9390396869198735\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5529201157560446\n",
      "F1 Micro: 0.9457628819427023\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 10 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 232us/step - loss: 0.8383 - accuracy: 0.8455 - val_loss: 0.6101 - val_accuracy: 0.8670\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.5925 - accuracy: 0.8597 - val_loss: 0.5484 - val_accuracy: 0.8670\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.4888 - accuracy: 0.8752 - val_loss: 0.4257 - val_accuracy: 0.9050\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.3563 - accuracy: 0.9060 - val_loss: 0.3439 - val_accuracy: 0.9070\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.3045 - accuracy: 0.9172 - val_loss: 0.2977 - val_accuracy: 0.9190\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.2585 - accuracy: 0.9270 - val_loss: 0.2927 - val_accuracy: 0.9240\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.2348 - accuracy: 0.9337 - val_loss: 0.2436 - val_accuracy: 0.9370\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.2176 - accuracy: 0.9400 - val_loss: 0.2403 - val_accuracy: 0.9350\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.2014 - accuracy: 0.9440 - val_loss: 0.2278 - val_accuracy: 0.9390\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1898 - accuracy: 0.9465 - val_loss: 0.2191 - val_accuracy: 0.9420\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1720 - accuracy: 0.9505 - val_loss: 0.2127 - val_accuracy: 0.9360\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1612 - accuracy: 0.9557 - val_loss: 0.1970 - val_accuracy: 0.9430\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1702 - accuracy: 0.9517 - val_loss: 0.2001 - val_accuracy: 0.9440\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1418 - accuracy: 0.9613 - val_loss: 0.1905 - val_accuracy: 0.9400\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1412 - accuracy: 0.9575 - val_loss: 0.1842 - val_accuracy: 0.9470\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1395 - accuracy: 0.9597 - val_loss: 0.1928 - val_accuracy: 0.9480\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1250 - accuracy: 0.9630 - val_loss: 0.1912 - val_accuracy: 0.9480\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.1156 - accuracy: 0.9670 - val_loss: 0.1755 - val_accuracy: 0.9490\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1103 - accuracy: 0.9660 - val_loss: 0.1717 - val_accuracy: 0.9470\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.1238 - accuracy: 0.9625 - val_loss: 0.1880 - val_accuracy: 0.9490\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1060 - accuracy: 0.9688 - val_loss: 0.1677 - val_accuracy: 0.9490\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0984 - accuracy: 0.9712 - val_loss: 0.1672 - val_accuracy: 0.9520\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0979 - accuracy: 0.9707 - val_loss: 0.1746 - val_accuracy: 0.9450\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0901 - accuracy: 0.9728 - val_loss: 0.1738 - val_accuracy: 0.9500\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0882 - accuracy: 0.9730 - val_loss: 0.1667 - val_accuracy: 0.9510\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9706 ETA: 0s - loss: 0.0724 -  - 1s 186us/step - loss: 0.0914 - accuracy: 0.9705 - val_loss: 0.1637 - val_accuracy: 0.9520\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0783 - accuracy: 0.9765 - val_loss: 0.1557 - val_accuracy: 0.9530\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0744 - accuracy: 0.9770 - val_loss: 0.1670 - val_accuracy: 0.9460\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.0760 - accuracy: 0.9770 - val_loss: 0.1940 - val_accuracy: 0.9520\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0738 - accuracy: 0.9787 - val_loss: 0.2193 - val_accuracy: 0.9470\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0737 - accuracy: 0.9778 - val_loss: 0.1669 - val_accuracy: 0.9480\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.0599 - accuracy: 0.9822 - val_loss: 0.1725 - val_accuracy: 0.9540\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0657 - accuracy: 0.9787 - val_loss: 0.1870 - val_accuracy: 0.9520\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.0588 - accuracy: 0.9803 - val_loss: 0.1736 - val_accuracy: 0.9520\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0553 - accuracy: 0.9812 - val_loss: 0.1634 - val_accuracy: 0.9540\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0528 - accuracy: 0.9843 - val_loss: 0.1658 - val_accuracy: 0.9550\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0477 - accuracy: 0.9872 - val_loss: 0.1986 - val_accuracy: 0.9520\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0424 - accuracy: 0.9885 - val_loss: 0.1664 - val_accuracy: 0.9540\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0411 - accuracy: 0.9875 - val_loss: 0.1777 - val_accuracy: 0.9540\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0345 - accuracy: 0.9885 - val_loss: 0.1738 - val_accuracy: 0.9570\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0479 - accuracy: 0.9855 - val_loss: 0.1789 - val_accuracy: 0.9450\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0457 - accuracy: 0.9850 - val_loss: 0.2106 - val_accuracy: 0.9510\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0282 - accuracy: 0.9918 - val_loss: 0.1949 - val_accuracy: 0.9550\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.0254 - accuracy: 0.9933 - val_loss: 0.1956 - val_accuracy: 0.9600\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.0267 - accuracy: 0.9935 - val_loss: 0.1861 - val_accuracy: 0.9560\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0260 - accuracy: 0.9948 - val_loss: 0.1869 - val_accuracy: 0.9550\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0197 - accuracy: 0.9952 - val_loss: 0.1830 - val_accuracy: 0.9540\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5714553150396939\n",
      "F1 Micro: 0.9536\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6733169106831504\n",
      "F1 Micro: 0.955\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 86us/step - loss: 1.7072 - accuracy: 0.5773 - val_loss: 1.4025 - val_accuracy: 0.6780\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 1.1102 - accuracy: 0.7790 - val_loss: 0.8259 - val_accuracy: 0.8830\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.6486 - accuracy: 0.8967 - val_loss: 0.4779 - val_accuracy: 0.9260\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.3884 - accuracy: 0.9355 - val_loss: 0.3118 - val_accuracy: 0.9430\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.2636 - accuracy: 0.9473 - val_loss: 0.2391 - val_accuracy: 0.9450\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.2053 - accuracy: 0.9528 - val_loss: 0.2063 - val_accuracy: 0.9490\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1747 - accuracy: 0.9557 - val_loss: 0.1871 - val_accuracy: 0.9490\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1559 - accuracy: 0.9590 - val_loss: 0.1764 - val_accuracy: 0.9500\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1431 - accuracy: 0.9617 - val_loss: 0.1681 - val_accuracy: 0.9530\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1341 - accuracy: 0.9628 - val_loss: 0.1620 - val_accuracy: 0.9520\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1255 - accuracy: 0.9643 - val_loss: 0.1577 - val_accuracy: 0.9550\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1193 - accuracy: 0.9650 - val_loss: 0.1539 - val_accuracy: 0.9560\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1144 - accuracy: 0.9645 - val_loss: 0.1502 - val_accuracy: 0.9580\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1094 - accuracy: 0.9665 - val_loss: 0.1477 - val_accuracy: 0.9590\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1056 - accuracy: 0.9693 - val_loss: 0.1455 - val_accuracy: 0.9590\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1019 - accuracy: 0.9697 - val_loss: 0.1429 - val_accuracy: 0.9600\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0989 - accuracy: 0.9693 - val_loss: 0.1414 - val_accuracy: 0.9600\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0960 - accuracy: 0.9707 - val_loss: 0.1400 - val_accuracy: 0.9590\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 64us/step - loss: 0.0934 - accuracy: 0.9710 - val_loss: 0.1389 - val_accuracy: 0.9590\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0906 - accuracy: 0.9722 - val_loss: 0.1368 - val_accuracy: 0.9600\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0880 - accuracy: 0.9725 - val_loss: 0.1382 - val_accuracy: 0.9600\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0859 - accuracy: 0.9737 - val_loss: 0.1344 - val_accuracy: 0.9600\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0839 - accuracy: 0.9745 - val_loss: 0.1329 - val_accuracy: 0.9610\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0820 - accuracy: 0.9745 - val_loss: 0.1336 - val_accuracy: 0.9600\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0803 - accuracy: 0.9762 - val_loss: 0.1318 - val_accuracy: 0.9610\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0783 - accuracy: 0.9770 - val_loss: 0.1303 - val_accuracy: 0.9630\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0766 - accuracy: 0.9772 - val_loss: 0.1353 - val_accuracy: 0.9600\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0756 - accuracy: 0.9790 - val_loss: 0.1303 - val_accuracy: 0.9610\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0737 - accuracy: 0.9790 - val_loss: 0.1295 - val_accuracy: 0.9630\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0724 - accuracy: 0.9787 - val_loss: 0.1284 - val_accuracy: 0.9610\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0712 - accuracy: 0.9803 - val_loss: 0.1290 - val_accuracy: 0.9600\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0692 - accuracy: 0.9808 - val_loss: 0.1279 - val_accuracy: 0.9610\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.0687 - accuracy: 0.9800 - val_loss: 0.1293 - val_accuracy: 0.9580\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0674 - accuracy: 0.9808 - val_loss: 0.1294 - val_accuracy: 0.9600\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0657 - accuracy: 0.9812 - val_loss: 0.1278 - val_accuracy: 0.9610\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0643 - accuracy: 0.9820 - val_loss: 0.1269 - val_accuracy: 0.9590\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0635 - accuracy: 0.9835 - val_loss: 0.1269 - val_accuracy: 0.9630\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0626 - accuracy: 0.9822 - val_loss: 0.1264 - val_accuracy: 0.9610\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0612 - accuracy: 0.9840 - val_loss: 0.1265 - val_accuracy: 0.9630\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0611 - accuracy: 0.9833 - val_loss: 0.1272 - val_accuracy: 0.9600\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0594 - accuracy: 0.9843 - val_loss: 0.1267 - val_accuracy: 0.9630\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 64us/step - loss: 0.0585 - accuracy: 0.9837 - val_loss: 0.1262 - val_accuracy: 0.9630\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0572 - accuracy: 0.9850 - val_loss: 0.1261 - val_accuracy: 0.9630\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0568 - accuracy: 0.9847 - val_loss: 0.1270 - val_accuracy: 0.9630\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0557 - accuracy: 0.9847 - val_loss: 0.1257 - val_accuracy: 0.9650\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0545 - accuracy: 0.9852 - val_loss: 0.1262 - val_accuracy: 0.9630\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0536 - accuracy: 0.9855 - val_loss: 0.1262 - val_accuracy: 0.9610\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0531 - accuracy: 0.9858 - val_loss: 0.1258 - val_accuracy: 0.9620\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.0520 - accuracy: 0.9858 - val_loss: 0.1293 - val_accuracy: 0.9620\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0509 - accuracy: 0.9855 - val_loss: 0.1256 - val_accuracy: 0.9630\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0504 - accuracy: 0.9877 - val_loss: 0.1253 - val_accuracy: 0.9630\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0495 - accuracy: 0.9865 - val_loss: 0.1299 - val_accuracy: 0.9630\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0497 - accuracy: 0.9868 - val_loss: 0.1265 - val_accuracy: 0.9650\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0480 - accuracy: 0.9880 - val_loss: 0.1272 - val_accuracy: 0.9620\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0470 - accuracy: 0.9877 - val_loss: 0.1273 - val_accuracy: 0.9610\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0470 - accuracy: 0.9883 - val_loss: 0.1270 - val_accuracy: 0.9610\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0459 - accuracy: 0.9875 - val_loss: 0.1260 - val_accuracy: 0.9610\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0451 - accuracy: 0.9890 - val_loss: 0.1276 - val_accuracy: 0.9630\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0445 - accuracy: 0.9887 - val_loss: 0.1277 - val_accuracy: 0.9600\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0436 - accuracy: 0.9902 - val_loss: 0.1289 - val_accuracy: 0.9600\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0438 - accuracy: 0.9880 - val_loss: 0.1301 - val_accuracy: 0.9620\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0422 - accuracy: 0.9895 - val_loss: 0.1285 - val_accuracy: 0.9600\n",
      "Epoch 63/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0421 - accuracy: 0.9898 - val_loss: 0.1289 - val_accuracy: 0.9620\n",
      "Epoch 64/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0409 - accuracy: 0.9895 - val_loss: 0.1278 - val_accuracy: 0.9650\n",
      "Epoch 65/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0406 - accuracy: 0.9893 - val_loss: 0.1290 - val_accuracy: 0.9610\n",
      "Epoch 66/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0398 - accuracy: 0.9898 - val_loss: 0.1274 - val_accuracy: 0.9640\n",
      "Epoch 67/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0392 - accuracy: 0.9900 - val_loss: 0.1295 - val_accuracy: 0.9610\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.0385 - accuracy: 0.9910 - val_loss: 0.1302 - val_accuracy: 0.9640\n",
      "Epoch 69/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0379 - accuracy: 0.9910 - val_loss: 0.1289 - val_accuracy: 0.9620\n",
      "Epoch 70/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0374 - accuracy: 0.9902 - val_loss: 0.1298 - val_accuracy: 0.9620\n",
      "Epoch 71/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0368 - accuracy: 0.9908 - val_loss: 0.1299 - val_accuracy: 0.9610\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6694445046278731\n",
      "F1 Micro: 0.9564\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 234us/step - loss: 0.6818 - accuracy: 0.8123 - val_loss: 0.3590 - val_accuracy: 0.9050\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 0.3000 - accuracy: 0.9193 - val_loss: 0.2929 - val_accuracy: 0.9240\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.2450 - accuracy: 0.9370 - val_loss: 0.2522 - val_accuracy: 0.9310\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.2125 - accuracy: 0.9442 - val_loss: 0.2251 - val_accuracy: 0.9370\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1885 - accuracy: 0.9498 - val_loss: 0.2060 - val_accuracy: 0.9420\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1718 - accuracy: 0.9532 - val_loss: 0.1958 - val_accuracy: 0.9460\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1619 - accuracy: 0.9563 - val_loss: 0.1797 - val_accuracy: 0.9460\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.1495 - accuracy: 0.9572 - val_loss: 0.1713 - val_accuracy: 0.9450\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.1410 - accuracy: 0.9595 - val_loss: 0.1682 - val_accuracy: 0.9470\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1338 - accuracy: 0.9617 - val_loss: 0.1623 - val_accuracy: 0.9470\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.1272 - accuracy: 0.9622 - val_loss: 0.1608 - val_accuracy: 0.9480\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.1235 - accuracy: 0.9638 - val_loss: 0.1446 - val_accuracy: 0.9520\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.1172 - accuracy: 0.9665 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.1103 - accuracy: 0.9680 - val_loss: 0.1383 - val_accuracy: 0.9550\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.1080 - accuracy: 0.9665 - val_loss: 0.1356 - val_accuracy: 0.9560\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.1015 - accuracy: 0.9695 - val_loss: 0.1352 - val_accuracy: 0.9570\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.1004 - accuracy: 0.9700 - val_loss: 0.1295 - val_accuracy: 0.9610\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0938 - accuracy: 0.9700 - val_loss: 0.1357 - val_accuracy: 0.9540\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0917 - accuracy: 0.9710 - val_loss: 0.1411 - val_accuracy: 0.9540\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0876 - accuracy: 0.9718 - val_loss: 0.1251 - val_accuracy: 0.9630\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0859 - accuracy: 0.9718 - val_loss: 0.1247 - val_accuracy: 0.9630\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0823 - accuracy: 0.9735 - val_loss: 0.1216 - val_accuracy: 0.9620\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0807 - accuracy: 0.9743 - val_loss: 0.1218 - val_accuracy: 0.9630\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0747 - accuracy: 0.9765 - val_loss: 0.1256 - val_accuracy: 0.9590\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0737 - accuracy: 0.9768 - val_loss: 0.1256 - val_accuracy: 0.9630\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0689 - accuracy: 0.9793 - val_loss: 0.1182 - val_accuracy: 0.9650\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0674 - accuracy: 0.9783 - val_loss: 0.1225 - val_accuracy: 0.9610\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0627 - accuracy: 0.9820 - val_loss: 0.1177 - val_accuracy: 0.9640\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0615 - accuracy: 0.9815 - val_loss: 0.1170 - val_accuracy: 0.9650\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0578 - accuracy: 0.9822 - val_loss: 0.1179 - val_accuracy: 0.9660\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0535 - accuracy: 0.9847 - val_loss: 0.1265 - val_accuracy: 0.9640\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.0503 - accuracy: 0.9860 - val_loss: 0.1361 - val_accuracy: 0.9580\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0481 - accuracy: 0.9865 - val_loss: 0.2015 - val_accuracy: 0.9550\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 0.0506 - accuracy: 0.9843 - val_loss: 0.1179 - val_accuracy: 0.9640\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.0411 - accuracy: 0.9900 - val_loss: 0.1238 - val_accuracy: 0.9650\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0382 - accuracy: 0.9898 - val_loss: 0.1258 - val_accuracy: 0.9620\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0363 - accuracy: 0.9915 - val_loss: 0.1223 - val_accuracy: 0.9660\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0313 - accuracy: 0.9920 - val_loss: 0.1245 - val_accuracy: 0.9660\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0307 - accuracy: 0.9920 - val_loss: 0.1260 - val_accuracy: 0.9640\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0272 - accuracy: 0.9927 - val_loss: 0.1352 - val_accuracy: 0.9630\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0252 - accuracy: 0.9942 - val_loss: 0.1222 - val_accuracy: 0.9680\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0248 - accuracy: 0.9950 - val_loss: 0.1327 - val_accuracy: 0.9650\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0205 - accuracy: 0.9967 - val_loss: 0.1359 - val_accuracy: 0.9640\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0185 - accuracy: 0.9960 - val_loss: 0.1428 - val_accuracy: 0.9630\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0167 - accuracy: 0.9977 - val_loss: 0.1558 - val_accuracy: 0.9610\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0153 - accuracy: 0.9975 - val_loss: 0.1584 - val_accuracy: 0.9620\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 186us/step - loss: 0.0144 - accuracy: 0.9980 - val_loss: 0.1483 - val_accuracy: 0.9650\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.1428 - val_accuracy: 0.9640\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.0125 - accuracy: 0.9980 - val_loss: 0.1465 - val_accuracy: 0.9640\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6529540530698305\n",
      "F1 Micro: 0.9583\n",
      "\n",
      "**********model5**********\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6656912888857307\n",
      "F1 Micro: 0.9523\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7054184558769832\n",
      "F1 Micro: 0.9593\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 10 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.4128 - accuracy: 0.8997 - val_loss: 0.2297 - val_accuracy: 0.9369\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 178us/step - loss: 0.1924 - accuracy: 0.9454 - val_loss: 0.2096 - val_accuracy: 0.9370\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1478 - accuracy: 0.9556 - val_loss: 0.1295 - val_accuracy: 0.9609\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.1277 - accuracy: 0.9606 - val_loss: 0.1209 - val_accuracy: 0.9638\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.1168 - accuracy: 0.9636 - val_loss: 0.1193 - val_accuracy: 0.9643\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.1062 - accuracy: 0.9668 - val_loss: 0.1080 - val_accuracy: 0.9668\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0996 - accuracy: 0.9675 - val_loss: 0.1070 - val_accuracy: 0.9676\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0937 - accuracy: 0.9695 - val_loss: 0.0994 - val_accuracy: 0.9704\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0882 - accuracy: 0.9714 - val_loss: 0.0969 - val_accuracy: 0.9691\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0839 - accuracy: 0.9723 - val_loss: 0.0994 - val_accuracy: 0.9702\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0793 - accuracy: 0.9739 - val_loss: 0.0966 - val_accuracy: 0.9708\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0742 - accuracy: 0.9748 - val_loss: 0.0924 - val_accuracy: 0.9715\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0704 - accuracy: 0.9772 - val_loss: 0.1139 - val_accuracy: 0.9685\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0641 - accuracy: 0.9783 - val_loss: 0.0953 - val_accuracy: 0.9713\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0607 - accuracy: 0.9794 - val_loss: 0.1008 - val_accuracy: 0.9681\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0555 - accuracy: 0.9810 - val_loss: 0.1067 - val_accuracy: 0.9651\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0519 - accuracy: 0.9822 - val_loss: 0.0887 - val_accuracy: 0.9704\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0466 - accuracy: 0.9841 - val_loss: 0.0864 - val_accuracy: 0.9730\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0423 - accuracy: 0.9851 - val_loss: 0.0884 - val_accuracy: 0.9715\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0372 - accuracy: 0.9881 - val_loss: 0.1022 - val_accuracy: 0.9657\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 0.0915 - val_accuracy: 0.9733\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 0.0279 - accuracy: 0.9905 - val_loss: 0.1013 - val_accuracy: 0.9725\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0254 - accuracy: 0.9914 - val_loss: 0.1037 - val_accuracy: 0.9722\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.1055 - val_accuracy: 0.9719\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.1111 - val_accuracy: 0.9727\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.1194 - val_accuracy: 0.9720\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.1156 - val_accuracy: 0.9736\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.1555 - val_accuracy: 0.9711\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.1227 - val_accuracy: 0.9723\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.1212 - val_accuracy: 0.9719\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.1300 - val_accuracy: 0.9725\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.1326 - val_accuracy: 0.9717\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1449 - val_accuracy: 0.9673\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.1486 - val_accuracy: 0.9722\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1660 - val_accuracy: 0.9697\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.1409 - val_accuracy: 0.9724\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.1550 - val_accuracy: 0.9704\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.1441 - val_accuracy: 0.9734\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8304228060508363\n",
      "F1 Micro: 0.9725\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7987909960679224\n",
      "F1 Micro: 0.9666\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.5339 - accuracy: 0.8751 - val_loss: 0.1593 - val_accuracy: 0.9573\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1462 - accuracy: 0.9569 - val_loss: 0.1323 - val_accuracy: 0.9616\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.1285 - accuracy: 0.9602 - val_loss: 0.1222 - val_accuracy: 0.9631\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.1199 - accuracy: 0.9630 - val_loss: 0.1168 - val_accuracy: 0.9654\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1138 - accuracy: 0.9643 - val_loss: 0.1132 - val_accuracy: 0.9656\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1090 - accuracy: 0.9662 - val_loss: 0.1109 - val_accuracy: 0.9663\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.1055 - accuracy: 0.9674 - val_loss: 0.1086 - val_accuracy: 0.9667\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1023 - accuracy: 0.9679 - val_loss: 0.1090 - val_accuracy: 0.9667\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0995 - accuracy: 0.9688 - val_loss: 0.1068 - val_accuracy: 0.9689\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0976 - accuracy: 0.9700 - val_loss: 0.1050 - val_accuracy: 0.9689\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0952 - accuracy: 0.9706 - val_loss: 0.1048 - val_accuracy: 0.9683\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0939 - accuracy: 0.9707 - val_loss: 0.1025 - val_accuracy: 0.9690\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0920 - accuracy: 0.9707 - val_loss: 0.1015 - val_accuracy: 0.9697\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0902 - accuracy: 0.9714 - val_loss: 0.1026 - val_accuracy: 0.9686\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0888 - accuracy: 0.9719 - val_loss: 0.1009 - val_accuracy: 0.9696\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0873 - accuracy: 0.9726 - val_loss: 0.0996 - val_accuracy: 0.9702\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0862 - accuracy: 0.9725 - val_loss: 0.1012 - val_accuracy: 0.9703\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0847 - accuracy: 0.9728 - val_loss: 0.1003 - val_accuracy: 0.9698\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0837 - accuracy: 0.9736 - val_loss: 0.0992 - val_accuracy: 0.9709\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0827 - accuracy: 0.9740 - val_loss: 0.0993 - val_accuracy: 0.9704\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0813 - accuracy: 0.9743 - val_loss: 0.0982 - val_accuracy: 0.9703\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0802 - accuracy: 0.9748 - val_loss: 0.0987 - val_accuracy: 0.9694\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0793 - accuracy: 0.9748 - val_loss: 0.0979 - val_accuracy: 0.9706\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0784 - accuracy: 0.9749 - val_loss: 0.0975 - val_accuracy: 0.9710\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0772 - accuracy: 0.9749 - val_loss: 0.0996 - val_accuracy: 0.9710\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0763 - accuracy: 0.9758 - val_loss: 0.0972 - val_accuracy: 0.9702\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0757 - accuracy: 0.9763 - val_loss: 0.0957 - val_accuracy: 0.9706\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0746 - accuracy: 0.9764 - val_loss: 0.0969 - val_accuracy: 0.9703\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0737 - accuracy: 0.9761 - val_loss: 0.0963 - val_accuracy: 0.9714\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0727 - accuracy: 0.9770 - val_loss: 0.1005 - val_accuracy: 0.9714\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0723 - accuracy: 0.9768 - val_loss: 0.0971 - val_accuracy: 0.9715\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0714 - accuracy: 0.9778 - val_loss: 0.0958 - val_accuracy: 0.9720\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0704 - accuracy: 0.9780 - val_loss: 0.0950 - val_accuracy: 0.9715\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0695 - accuracy: 0.9781 - val_loss: 0.0972 - val_accuracy: 0.9706\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0690 - accuracy: 0.9785 - val_loss: 0.0945 - val_accuracy: 0.9711\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0678 - accuracy: 0.9783 - val_loss: 0.0956 - val_accuracy: 0.9712\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0675 - accuracy: 0.9789 - val_loss: 0.0952 - val_accuracy: 0.97130673 - accuracy: 0.\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0667 - accuracy: 0.9795 - val_loss: 0.0945 - val_accuracy: 0.9714\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0658 - accuracy: 0.9793 - val_loss: 0.0958 - val_accuracy: 0.9707\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0655 - accuracy: 0.9797 - val_loss: 0.0948 - val_accuracy: 0.9708\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0644 - accuracy: 0.9804 - val_loss: 0.0954 - val_accuracy: 0.9707\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0639 - accuracy: 0.9799 - val_loss: 0.0949 - val_accuracy: 0.9724\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0629 - accuracy: 0.9804 - val_loss: 0.0961 - val_accuracy: 0.9716\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0625 - accuracy: 0.9803 - val_loss: 0.0962 - val_accuracy: 0.9715\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0617 - accuracy: 0.9805 - val_loss: 0.0949 - val_accuracy: 0.9711\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0610 - accuracy: 0.9811 - val_loss: 0.0950 - val_accuracy: 0.9710\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0605 - accuracy: 0.9808 - val_loss: 0.0954 - val_accuracy: 0.9714\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0600 - accuracy: 0.9815 - val_loss: 0.0951 - val_accuracy: 0.9714\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0591 - accuracy: 0.9817 - val_loss: 0.0972 - val_accuracy: 0.9714\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0584 - accuracy: 0.9815 - val_loss: 0.0970 - val_accuracy: 0.9704\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0577 - accuracy: 0.9820 - val_loss: 0.0964 - val_accuracy: 0.9711\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0573 - accuracy: 0.9824 - val_loss: 0.0978 - val_accuracy: 0.9708\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0563 - accuracy: 0.9828 - val_loss: 0.0990 - val_accuracy: 0.9707\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0560 - accuracy: 0.9829 - val_loss: 0.0982 - val_accuracy: 0.9703\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0552 - accuracy: 0.9833 - val_loss: 0.0972 - val_accuracy: 0.9721\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0546 - accuracy: 0.9832 - val_loss: 0.0964 - val_accuracy: 0.9724\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0541 - accuracy: 0.9833 - val_loss: 0.0959 - val_accuracy: 0.9709\n",
      "Epoch 58/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0533 - accuracy: 0.9837 - val_loss: 0.0958 - val_accuracy: 0.9704\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8247221754481552\n",
      "F1 Micro: 0.9707\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.2588 - accuracy: 0.9288 - val_loss: 0.1543 - val_accuracy: 0.9565\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.1454 - accuracy: 0.9553 - val_loss: 0.1312 - val_accuracy: 0.9603\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.1259 - accuracy: 0.9605 - val_loss: 0.1166 - val_accuracy: 0.9643\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.1145 - accuracy: 0.9639 - val_loss: 0.1109 - val_accuracy: 0.9659\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.1064 - accuracy: 0.9664 - val_loss: 0.1036 - val_accuracy: 0.9682\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.1002 - accuracy: 0.9678 - val_loss: 0.0983 - val_accuracy: 0.9708\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0931 - accuracy: 0.9702 - val_loss: 0.0952 - val_accuracy: 0.9700\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0877 - accuracy: 0.9718 - val_loss: 0.0991 - val_accuracy: 0.9702\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0804 - accuracy: 0.9740 - val_loss: 0.0930 - val_accuracy: 0.9709\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0753 - accuracy: 0.9756 - val_loss: 0.0855 - val_accuracy: 0.9736\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0707 - accuracy: 0.9773 - val_loss: 0.0836 - val_accuracy: 0.9747\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0649 - accuracy: 0.9790 - val_loss: 0.0828 - val_accuracy: 0.9748\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0594 - accuracy: 0.9805 - val_loss: 0.0867 - val_accuracy: 0.9725\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0529 - accuracy: 0.9826 - val_loss: 0.0889 - val_accuracy: 0.9728\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0461 - accuracy: 0.9852 - val_loss: 0.0940 - val_accuracy: 0.9711\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0399 - accuracy: 0.9876 - val_loss: 0.0915 - val_accuracy: 0.9742\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0332 - accuracy: 0.9900 - val_loss: 0.0979 - val_accuracy: 0.9725\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0260 - accuracy: 0.9922 - val_loss: 0.1057 - val_accuracy: 0.9730\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.1135 - val_accuracy: 0.9689\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.1096 - val_accuracy: 0.9730\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.1198 - val_accuracy: 0.9738\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.1288 - val_accuracy: 0.9726\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.1338 - val_accuracy: 0.9736\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.1411 - val_accuracy: 0.9722\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.1492 - val_accuracy: 0.9728\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.1469 - val_accuracy: 0.9746\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1421 - val_accuracy: 0.9727\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.1590 - val_accuracy: 0.9705\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.1710 - val_accuracy: 0.9708\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1584 - val_accuracy: 0.9731\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.1502 - val_accuracy: 0.9733\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.2503 - val_accuracy: 0.9663\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8252783084856663\n",
      "F1 Micro: 0.9716\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8140384036838825\n",
      "F1 Micro: 0.9675\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8474560721079412\n",
      "F1 Micro: 0.9746\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 10 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.2313 - accuracy: 0.9375 - val_loss: 0.1251 - val_accuracy: 0.9617\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.1157 - accuracy: 0.9640 - val_loss: 0.1048 - val_accuracy: 0.9670\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0994 - accuracy: 0.9676 - val_loss: 0.1012 - val_accuracy: 0.9670\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0906 - accuracy: 0.9703 - val_loss: 0.0857 - val_accuracy: 0.9719\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0822 - accuracy: 0.9727 - val_loss: 0.0813 - val_accuracy: 0.9739\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0753 - accuracy: 0.9749 - val_loss: 0.0802 - val_accuracy: 0.9737\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0694 - accuracy: 0.9764 - val_loss: 0.0755 - val_accuracy: 0.9753\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0635 - accuracy: 0.9780 - val_loss: 0.0765 - val_accuracy: 0.9740\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0592 - accuracy: 0.9797 - val_loss: 0.0715 - val_accuracy: 0.9742\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0548 - accuracy: 0.9805 - val_loss: 0.0689 - val_accuracy: 0.9760\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0511 - accuracy: 0.9818 - val_loss: 0.0667 - val_accuracy: 0.9778\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0467 - accuracy: 0.9832 - val_loss: 0.0692 - val_accuracy: 0.9775\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0430 - accuracy: 0.9845 - val_loss: 0.0680 - val_accuracy: 0.9773\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0390 - accuracy: 0.9857 - val_loss: 0.0713 - val_accuracy: 0.9765\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0357 - accuracy: 0.9870 - val_loss: 0.0720 - val_accuracy: 0.9767\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0312 - accuracy: 0.9886 - val_loss: 0.0841 - val_accuracy: 0.9772\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0273 - accuracy: 0.9902 - val_loss: 0.0842 - val_accuracy: 0.9770\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0245 - accuracy: 0.9911 - val_loss: 0.0853 - val_accuracy: 0.9749\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0205 - accuracy: 0.9927 - val_loss: 0.0829 - val_accuracy: 0.9770\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0172 - accuracy: 0.9941 - val_loss: 0.1129 - val_accuracy: 0.9748\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.0954 - val_accuracy: 0.9756\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.1082 - val_accuracy: 0.9770\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.1141 - val_accuracy: 0.9770\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.1092 - val_accuracy: 0.9769\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.1059 - val_accuracy: 0.9765\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.1183 - val_accuracy: 0.9768\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.1154 - val_accuracy: 0.9757\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.1368 - val_accuracy: 0.9758\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.1222 - val_accuracy: 0.9766\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 24s 184us/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1199 - val_accuracy: 0.9765\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 24s 185us/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.1382 - val_accuracy: 0.9754\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8610520819691243\n",
      "F1 Micro: 0.9766\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8084875416393644\n",
      "F1 Micro: 0.9687\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.2392 - accuracy: 0.9393 - val_loss: 0.1240 - val_accuracy: 0.9619\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.1140 - accuracy: 0.9647 - val_loss: 0.1077 - val_accuracy: 0.9662\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.1043 - accuracy: 0.9671 - val_loss: 0.1026 - val_accuracy: 0.9678\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0986 - accuracy: 0.9690 - val_loss: 0.0985 - val_accuracy: 0.9688\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0947 - accuracy: 0.9699 - val_loss: 0.0957 - val_accuracy: 0.9689\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0915 - accuracy: 0.9709 - val_loss: 0.0932 - val_accuracy: 0.9698\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0892 - accuracy: 0.9715 - val_loss: 0.0914 - val_accuracy: 0.9699\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0869 - accuracy: 0.9725 - val_loss: 0.0908 - val_accuracy: 0.9707\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0849 - accuracy: 0.9731 - val_loss: 0.0910 - val_accuracy: 0.9708\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0833 - accuracy: 0.9734 - val_loss: 0.0876 - val_accuracy: 0.9713\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0817 - accuracy: 0.9736 - val_loss: 0.0869 - val_accuracy: 0.9717\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0804 - accuracy: 0.9742 - val_loss: 0.0855 - val_accuracy: 0.9721\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0791 - accuracy: 0.9744 - val_loss: 0.0855 - val_accuracy: 0.9722\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0780 - accuracy: 0.9750 - val_loss: 0.0840 - val_accuracy: 0.9730\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0768 - accuracy: 0.9754 - val_loss: 0.0838 - val_accuracy: 0.9730\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0757 - accuracy: 0.9755 - val_loss: 0.0835 - val_accuracy: 0.9726\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0745 - accuracy: 0.9758 - val_loss: 0.0844 - val_accuracy: 0.9724\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0736 - accuracy: 0.9762 - val_loss: 0.0832 - val_accuracy: 0.9725\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0728 - accuracy: 0.9765 - val_loss: 0.0833 - val_accuracy: 0.9731\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0717 - accuracy: 0.9768 - val_loss: 0.0822 - val_accuracy: 0.9735\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0712 - accuracy: 0.9768 - val_loss: 0.0817 - val_accuracy: 0.9733\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0703 - accuracy: 0.9775 - val_loss: 0.0823 - val_accuracy: 0.9731\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0696 - accuracy: 0.9776 - val_loss: 0.0815 - val_accuracy: 0.9735 ETA: 0s - los\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0686 - accuracy: 0.9777 - val_loss: 0.0814 - val_accuracy: 0.9736\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0679 - accuracy: 0.9777 - val_loss: 0.0816 - val_accuracy: 0.9736\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0670 - accuracy: 0.9783 - val_loss: 0.0822 - val_accuracy: 0.9732\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0665 - accuracy: 0.9783 - val_loss: 0.0801 - val_accuracy: 0.9742\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0657 - accuracy: 0.9787 - val_loss: 0.0824 - val_accuracy: 0.9737 - accuracy: 0.97\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0650 - accuracy: 0.9791 - val_loss: 0.0812 - val_accuracy: 0.9737\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0644 - accuracy: 0.9791 - val_loss: 0.0817 - val_accuracy: 0.9738: 0. - ETA: 1s - l - ETA: \n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0636 - accuracy: 0.9795 - val_loss: 0.0802 - val_accuracy: 0.9739\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0630 - accuracy: 0.9794 - val_loss: 0.0805 - val_accuracy: 0.9735\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0623 - accuracy: 0.9800 - val_loss: 0.0814 - val_accuracy: 0.9736ss:\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0617 - accuracy: 0.9799 - val_loss: 0.0816 - val_accuracy: 0.9737TA: 0s - loss: 0.061\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0610 - accuracy: 0.9801 - val_loss: 0.0827 - val_accuracy: 0.97359 - accuracy: 0.97 - ETA: 2s - loss: 0\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0604 - accuracy: 0.9804 - val_loss: 0.0805 - val_accuracy: 0.9742\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0599 - accuracy: 0.9805 - val_loss: 0.0820 - val_accuracy: 0.9738\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0593 - accuracy: 0.9809 - val_loss: 0.0808 - val_accuracy: 0.9746\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0586 - accuracy: 0.9806 - val_loss: 0.0820 - val_accuracy: 0.9736\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0579 - accuracy: 0.9812 - val_loss: 0.0811 - val_accuracy: 0.9733\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0576 - accuracy: 0.9814 - val_loss: 0.0823 - val_accuracy: 0.9732\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0569 - accuracy: 0.9816 - val_loss: 0.0818 - val_accuracy: 0.9736\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0563 - accuracy: 0.9815 - val_loss: 0.0817 - val_accuracy: 0.97360.0563 - accuracy: \n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0558 - accuracy: 0.9818 - val_loss: 0.0817 - val_accuracy: 0.9738\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0554 - accuracy: 0.9822 - val_loss: 0.0816 - val_accuracy: 0.9736\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 0.0834 - val_accuracy: 0.9734\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0539 - accuracy: 0.9824 - val_loss: 0.0838 - val_accuracy: 0.9732\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8366119102029196\n",
      "F1 Micro: 0.9714\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.1703 - accuracy: 0.9505 - val_loss: 0.1129 - val_accuracy: 0.9645\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.1026 - accuracy: 0.9671 - val_loss: 0.0967 - val_accuracy: 0.9693\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0860 - accuracy: 0.9723 - val_loss: 0.0859 - val_accuracy: 0.9732\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0779 - accuracy: 0.9741 - val_loss: 0.0783 - val_accuracy: 0.9744\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0715 - accuracy: 0.9762 - val_loss: 0.0768 - val_accuracy: 0.9749\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0662 - accuracy: 0.9775 - val_loss: 0.0779 - val_accuracy: 0.9755\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0607 - accuracy: 0.9795 - val_loss: 0.0725 - val_accuracy: 0.9761\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0560 - accuracy: 0.9805 - val_loss: 0.0713 - val_accuracy: 0.9764\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0502 - accuracy: 0.9827 - val_loss: 0.0720 - val_accuracy: 0.9776\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0444 - accuracy: 0.9845 - val_loss: 0.0705 - val_accuracy: 0.9762\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0380 - accuracy: 0.9871 - val_loss: 0.0717 - val_accuracy: 0.9757\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0320 - accuracy: 0.9889 - val_loss: 0.0744 - val_accuracy: 0.9778\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0264 - accuracy: 0.9910 - val_loss: 0.0884 - val_accuracy: 0.9724\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.0887 - val_accuracy: 0.9766\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.1026 - val_accuracy: 0.9767\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.1061 - val_accuracy: 0.9766\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.1023 - val_accuracy: 0.9771\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.1067 - val_accuracy: 0.9755\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1134 - val_accuracy: 0.9756\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.1147 - val_accuracy: 0.9760\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.1325 - val_accuracy: 0.9771\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1283 - val_accuracy: 0.9744\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.1251 - val_accuracy: 0.9762\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1338 - val_accuracy: 0.9765\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1563 - val_accuracy: 0.9751- loss: 0.0047 - accu\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1323 - val_accuracy: 0.9749\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1516 - val_accuracy: 0.9759\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1386 - val_accuracy: 0.9747\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1397 - val_accuracy: 0.9765\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.1436 - val_accuracy: 0.9752\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.851975653194247\n",
      "F1 Micro: 0.9773999999999999\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8147017805875029\n",
      "F1 Micro: 0.9679\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8617244208963102\n",
      "F1 Micro: 0.9768\n",
      "\n",
      "\n",
      " 50.61643682718277 min per replication\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "savefile = '0522'\n",
    "model_list = ['model1', 'model2', 'model3', 'model4', 'model5','model6']\n",
    "pattern_list = [0, 1, 2, 3, 4, 5, 6, 7 ,8]\n",
    "\n",
    "n_trnval_list = [500, 5000, 50000, 162946]\n",
    "coeff_dict = {}\n",
    "f1_dict = {}\n",
    "cm_dict = {}\n",
    "model6_list = []\n",
    "\n",
    "for k in n_trnval_list:\n",
    "    cm_dict[k] ={}\n",
    "    for model in model_list:\n",
    "        cm_dict[k][model] = np.zeros([9,9],dtype=int)\n",
    "\n",
    "for k in n_trnval_list:\n",
    "    coeff_dict[k] = []\n",
    "for t in n_trnval_list:\n",
    "    f1_dict[t] = {}\n",
    "    for label in pattern_list:\n",
    "        f1_dict[t][label] = {}\n",
    "        for model in model_list:\n",
    "            f1_dict[t][label][str(model)] = []\n",
    "replication=10\n",
    "random_seed=429\n",
    "if not os.path.exists('./'+savefile):\n",
    "    os.makedirs('./'+savefile)\n",
    "for rep in range(replication):\n",
    "    RANDON_STATE = 20200430+rep+random_seed\n",
    "    np.random.seed(random_seed) \n",
    "    X_trainval_cnn_big, X_test_cnn, y_trainval_big, y_test = train_test_split(X_cnn, y, \n",
    "                                   test_size=10000, random_state=RANDON_STATE,stratify=y)\n",
    "    X_trainval_fe_big, X_test_fe = train_test_split(X_fe, test_size=10000, \n",
    "                                                    random_state=RANDON_STATE,stratify=y)\n",
    "    start_time = time.time()\n",
    "    print('\\n','&'*20,rep+1,'replication','&'*20,'\\n\\n')\n",
    "    idx_list = [np.where(np.argmax(y_test,axis=1)==i)[0] for i in range(9)]\n",
    "    for n_trnval in n_trnval_list:\n",
    "        # Sampling\n",
    "        print('\\n','@'*20,rep+1,'replication',n_trnval,'@'*20,'\\n\\n')\n",
    "        global fn\n",
    "        fn = './'+savefile+'/result_{rep}_{ts:04d}_{model}.png'\n",
    "        np.random.seed(20200321+n_trnval*(rep+random_seed))\n",
    "        rand_id = np.random.choice(len(X_trainval_fe_big), n_trnval, replace=False)\n",
    "        X_trainval_cnn = X_trainval_cnn_big[rand_id]\n",
    "        X_trainval_fe = X_trainval_fe_big[rand_id]\n",
    "\n",
    "        y_trainval = y_trainval_big[rand_id]\n",
    "        # Split\n",
    "        X_train_cnn, X_val_cnn, y_train, y_val= train_test_split(X_trainval_cnn, \n",
    "                                                y_trainval, test_size=0.2, random_state=RANDON_STATE)\n",
    "        X_train_fe, X_val_fe = train_test_split(X_trainval_fe, test_size=0.2, random_state=RANDON_STATE)\n",
    "\n",
    "        mean, std = np.mean(X_train_fe,axis=0), np.std(X_train_fe,axis=0)\n",
    "        X_train_fe_n, X_val_fe_n, X_test_fe_n, X_trainval_fe_n = (X_train_fe-mean)/std, (X_val_fe-mean)/std, (X_test_fe-mean)/std, (X_trainval_fe-mean)/std\n",
    "\n",
    "        # Train and Evaluate Each Model\n",
    "        result_dict = {'macro':[],'micro':[]}\n",
    "        label_list = list(set(np.argmax(y_trainval,axis=1)))\n",
    "        print('label_list',list(set(np.argmax(y_trainval,axis=1))))\n",
    "        print('label_list',list(set(np.argmax(y_train,axis=1))))\n",
    "\n",
    "        result_dict, cm1, model1 = create_model1(X_train_cnn, y_train, X_val_cnn, y_val, \n",
    "                                          X_test_cnn, y_test,result_dict, n_trnval, rep)\n",
    "        result_dict, cm2, model2 = create_model2(X_trainval_fe, y_trainval, \n",
    "                                          X_test_fe, y_test, result_dict, n_trnval, rep)\n",
    "        result_dict, cm3 ,model3= create_model3(X_train_fe_n, y_train, X_val_fe_n, y_val, \n",
    "                                         X_test_fe_n, y_test, result_dict,  n_trnval, rep)\n",
    "        result_dict, cm4, model4= create_model4(X_train_cnn, X_train_fe_n, y_train, X_val_cnn, X_val_fe_n, y_val, \n",
    "                                         X_test_cnn, X_test_fe_n, y_test, result_dict, n_trnval, rep)\n",
    "        result_dict, cm5, model5, prob_test_concat5 = create_model5(model1, model2, X_trainval_cnn, X_trainval_fe, y_trainval, \n",
    "                                         X_test_cnn, X_test_fe, y_test, result_dict, n_trnval, rep)\n",
    "        result_dict, cm6, coeff, model6, prob_test_concat6 = create_model6(model1, model3, X_trainval_cnn, X_trainval_fe_n, \n",
    "                     y_trainval, X_test_cnn, X_test_fe_n, y_test, result_dict, n_trnval, rep)\n",
    "        cm_dict[n_trnval]['model1'] = cm_dict[n_trnval]['model1'] + cm1\n",
    "        cm_dict[n_trnval]['model2'] = cm_dict[n_trnval]['model2'] + cm2\n",
    "        cm_dict[n_trnval]['model3'] = cm_dict[n_trnval]['model3'] + cm3\n",
    "        cm_dict[n_trnval]['model4'] = cm_dict[n_trnval]['model4'] + cm4\n",
    "        cm_dict[n_trnval]['model5'] = cm_dict[n_trnval]['model5'] + cm5\n",
    "        cm_dict[n_trnval]['model6'] = cm_dict[n_trnval]['model6'] + cm6\n",
    "        for pattern_num in pattern_list:\n",
    "            for model in model_list:\n",
    "                if model == 'model2':\n",
    "                    y_hat = np.argmax(model2.predict_proba(X_test_fe[idx_list[pattern_num]]),axis=1)\n",
    "                elif model == 'model4':\n",
    "                    y_hat = np.argmax(model4.predict([X_test_cnn[idx_list[pattern_num]], \n",
    "                                   X_test_fe_n[idx_list[pattern_num]]]),axis=1)\n",
    "                elif model == 'model6':\n",
    "                    y_hat = np.argmax(model6.predict(prob_test_concat6[idx_list[pattern_num]]),axis=1)    \n",
    "                elif model =='model1':\n",
    "                    y_hat = np.argmax(model1.predict(X_test_cnn[idx_list[pattern_num]]),axis=1)\n",
    "                elif model == 'model3':\n",
    "                    y_hat = np.argmax(model3.predict(X_test_fe_n[idx_list[pattern_num]]),axis=1)\n",
    "                elif model == 'model5':\n",
    "                    y_hat = np.argmax(model5.predict(prob_test_concat5[idx_list[pattern_num]]),axis=1)\n",
    "                y_true = np.argmax(y_test[idx_list[pattern_num]],axis=1)\n",
    "                fscore = np.max(f1_score(y_true, y_hat, average=None))\n",
    "                f1_dict[n_trnval][pattern_num][str(model)].append(fscore)\n",
    "\n",
    "        model6_list.append(model6)\n",
    "        coeff_dict[n_trnval].append(coeff)\n",
    "        # Record result\n",
    "        with open(savefile+'.csv', 'a', newline='') as csvfile:\n",
    "            fieldnames = ['training_size', \n",
    "                          'model1_macro','model2_macro','model3_macro',\n",
    "                          'model4_macro','model5_macro','model6_macro',\n",
    "                          'model1_micro','model2_micro','model3_micro',\n",
    "                          'model4_micro','model5_micro','model6_micro']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writerow({'training_size': n_trnval, \n",
    "                             'model1_macro': result_dict['macro'][0],'model2_macro': result_dict['macro'][1],\n",
    "                             'model3_macro': result_dict['macro'][2],'model4_macro': result_dict['macro'][3],\n",
    "                             'model5_macro': result_dict['macro'][4],'model6_macro': result_dict['macro'][5],\n",
    "                             'model1_micro': result_dict['micro'][0],'model2_micro': result_dict['micro'][1],\n",
    "                             'model3_micro': result_dict['micro'][2],'model4_micro': result_dict['micro'][3],\n",
    "                             'model5_micro': result_dict['micro'][4],'model6_micro': result_dict['micro'][5],\n",
    "                             })\n",
    "\n",
    "    print('\\n\\n',(time.time()-start_time)/60,'min per replication\\n\\n')\n",
    "\"\"\"\n",
    "for n_trnval in n_trnval_list:\n",
    "    for pattern in pattern_list:\n",
    "        for model in model_list:\n",
    "            f1_dict[n_trnval][pattern][model] = [np.mean(f1_dict[n_trnval][pattern][model]),np.std(f1_dict[n_trnval][pattern][model])]\n",
    "\"\"\"\n",
    "\n",
    "with open(savefile+'_f1.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['pattern', 'rep',\n",
    "                  'MFE+FNN','CNN','Joint NN','Stacking']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for n_trnval in n_trnval_list:\n",
    "        writer.writerow({'pattern':n_trnval})\n",
    "        for pattern in pattern_list:\n",
    "            for rep in range(replication):\n",
    "                writer.writerow({'pattern': pattern,\n",
    "                                 'rep': rep,\n",
    "                                 'MFE+FNN':f1_dict[n_trnval][pattern]['model3'][rep],\n",
    "                                 'CNN':f1_dict[n_trnval][pattern]['model1'][rep],\n",
    "                                 'Joint NN':f1_dict[n_trnval][pattern]['model4'][rep],\n",
    "                                 'Stacking':f1_dict[n_trnval][pattern]['model6'][rep]})\n",
    "        for pattern in pattern_list:\n",
    "            writer.writerow({'pattern': pattern,\n",
    "                             'rep': 'mean',\n",
    "                             'MFE+FNN':np.mean(f1_dict[n_trnval][pattern]['model3']),\n",
    "                             'CNN':np.mean(f1_dict[n_trnval][pattern]['model1']),\n",
    "                             'Joint NN':np.mean(f1_dict[n_trnval][pattern]['model4']),\n",
    "                             'Stacking':np.mean(f1_dict[n_trnval][pattern]['model6'])})\n",
    "        for pattern in pattern_list:\n",
    "            writer.writerow({'pattern': pattern,\n",
    "                             'rep': 'std',\n",
    "                             'MFE+FNN':np.std(f1_dict[n_trnval][pattern]['model3']),\n",
    "                             'CNN':np.std(f1_dict[n_trnval][pattern]['model1']),\n",
    "                             'Joint NN':np.std(f1_dict[n_trnval][pattern]['model4']),\n",
    "                             'Stacking':np.std(f1_dict[n_trnval][pattern]['model6'])})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T03:15:46.394565Z",
     "start_time": "2020-05-26T03:15:43.433611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "Normalized confusion matrix\n",
      "Normalized confusion matrix\n",
      "Normalized confusion matrix\n",
      "Normalized confusion matrix\n",
      "Normalized confusion matrix\n",
      "Normalized confusion matrix\n",
      "Normalized confusion matrix\n",
      "Normalized confusion matrix\n"
     ]
    }
   ],
   "source": [
    "for data_size in [5000,50000,162946]:\n",
    "    for model in ['model1', 'model3', 'model6']:\n",
    "        plot_confusion_matrix(cm_dict[data_size][model], normalize=True)\n",
    "        file_name = 'CM'+str(data_size)+model+'.png'\n",
    "        plt.savefig(file_name, dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T03:13:07.726139Z",
     "start_time": "2020-05-26T03:13:07.177579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix((cm_dict[50000]['model6']),normalize=True)\n",
    "plt.savefig('cm_162946.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T12:21:39.669405Z",
     "start_time": "2020-05-27T12:21:39.659444Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "ts_list = [500,5000,50000,162946]\n",
    "f_list = []\n",
    "f = open('result1.csv', 'r', encoding='UTF8')\n",
    "rdr = csv.reader(f)\n",
    "for line in rdr:\n",
    "    f_list.append(line)\n",
    "f.close()\n",
    "f_list[0][0] = f_list[0][0][1:]\n",
    "f_list = np.array(f_list, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T12:21:40.059880Z",
     "start_time": "2020-05-27T12:21:40.055874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56, 0.7 , 0.84, 0.86, 0.94, 0.96, 0.97, 0.97])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_list[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T12:21:59.511610Z",
     "start_time": "2020-05-27T12:21:59.305073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd1zV1f/A8dcBmQKKA2QJKC5cCI7ULLU0R0sz08yyIndpqalZarlyZGmZZn21ZZptzf1LqbQ0xS2Ke7CHqGy43PP74yACoiJwWZ7n43Ef3M/nfj6fe243P+971vsIKSWapmmaBmBW1gXQNE3Tyg8dFDRN07QcOihomqZpOXRQ0DRN03LooKBpmqblqFLWBbhbtWrVkl5eXkU6Nzk5mapVq5ZsgbRi099L+aO/k/KpON9LcHBwnJSy9p2Oq3BBwcvLi3379hXp3KCgIDp37lyyBdKKTX8v5Y/+Tsqn4nwvQogLhTlONx9pmqZpOUwaFIQQPYQQoUKI00KISQW87imE+EMIcVgIESSEcDdleTRN07TbM1lQEEKYA0uAnoAvMFAI4ZvvsAXA11LKFsB7wBxTlUfTNE27M1PWFNoCp6WUZ6WUGcAa4Il8x/gCf2Q/31HA65qmaVopMmVQcAMu5doOy96X2yHgqeznfQB7IURNE5ZJ0zRNuw1Tjj4SBezLn31vPPCJEGII8BcQDhhuupAQQ4GhAM7OzgQFBRWpQElJSUU+VzMd/b2UP/o7KT9WA42BVtz4Xg4AJ4CBJng/UwaFMMAj17Y7EJH7ACllBNAXQAhhBzwlpbya/0JSyuXAcoDWrVvLog7J0sPsyif9vZQ/+jspP2RCAv1DQljr64vdoUPIli2Znb3d2dGxxN/PlEFhL9BACOGNqgEMAJ7NfYAQohZwWUppBCYDK0xYHk3TtAojyWDgUno6mVLyiY8P/UNC6Alsyg4IXUwQEMCEQUFKaRBCjAa2AObACinlMSHEe8A+KeU6oDMwRwghUc1Ho0xVHk3TtPJCSokQgoTMTH6Pj+dSerp6pKVxMfv5FcONlvRlDRsywtWVGRcu8I6rq8kCAph4RrOUciOwMd++qbme/wj8aMoyaJqmlaZMo5GIjAwupaXl3OybVq1K75o1uWYw4LNnD1M8PRnj7k5sZibPnzgBQM0qVfCwtsbL2ppO1arhYWWFh7U1HlZWXM7M5O1z5xgMLI2IoEv16hWvpqBpmlYZRaanY5ASD2trjFIy/syZnF/5l9LTicrIwJjvnKEuLvSuWRN7c3P61a6Nr60tAN7W1oS2bYu7lRW25uYFvt+OhAReOXmStb6+iEOHeNHXN6ePwRSBQQcFTdM0VJNOXGZmnqac68+dLS350McHgAcPHsTPzo61TZtiJgQ/xsZiY2aGh5UV3WvUUL/wrz+yf+k7VFG3WiEEnzZsmPOeFmZmNMwOELeyNzExJwAEAV0cHVnr68vexEQdFDRN04rrv2vXiEhP58naKmHosNBQtl+5Qlh6OmnGvL/xLYTA3cqKjtWq5eybX78+NavcuHVebN/epOV9s27dm/Z1cXTUzUeapmm3kpyVleeXff5f+vGZmUR16KB+qYeH88eVKzlBoXqVKgTY2fFkrVo5v/Dds/86WVpiJvJOuXqiVq1S/3yrVsGUKXDx4oO4Noqk8dAZxNv+y4FhB0r8vXRQ0DStXEs3GglLT8fdygorMzP+vHKF72NiWOzjQxUzM944fZoPw8JuOq+OpSUeVlY0sbXF3cqKTCmxFIIZ3t7MzHXc3Pr1S+/DFMGqVTB0KKSYRUKvGYT7rST8shGuZZjk/XRQ0DStTF3JzORYSsotf+nHZGYCcCAgAD97e06kpPB9TAzTvLxwtrTkkRo1cLKwyGm/97Cyws3KCkuzgrP4eFhbl+bHK7KE1AQORB1g5I9BpLy8GmqcAaM5mN+U9KFE6aCgaZpJGKUkOiODS+npXExLw9/enno2NhxITGTkqVMsadAAf3t71sfH5wzLBHAwN8/ppPW3t89zowc1kmeYq2vO8Y/UqMEjNWqU+ucrSbHJseyP3K8eUfsJjgjm3JVz6kU/VIIggckDAuigoGlatnkXL9LG3j5PB+aOhAT2Jibe1NkppcQgJRZmZsRnZrImJuamX/rh2bNxr/u0QQNGuLlR1dwcWzMzDNmvPeToyKbmzW8aqXMrQhSUVq3iiEyMJDgy+EYQiNzPpWs3codaJdfnsdatGRowlLO7/Pn2UzdSm30KrVaCyIIqpmk2uk4HBU3TAGhjb58z/j0ZWBERwetnzhDo4sLbZ8/iZ2dHPycnrhkMOP/zDzO9vRnn4UFCZiajT53CQgjcrKyoa2VFRweHPM05HlZW1LexAaChrS1/+PnlvK+rlRWu2bWAykRKyaVrl9gfqX75749SASAqKQoAgcDdpiEppzsxvZ8/DzTw58KeVvzwTXWWTYSaNYH74UF3GDp0CSl/vQMPzDB5cNBBQdM0QA1z/NjHhx6HD5MBcPIkAAvDwjADRrq50c/JCXtzc8a4udHa3h4AbxsbItq3x7mAkTr3CiklZxPO5vzyv14TiE+NB8BMmOFb25f7anfn+OEAxj7jz6CHWhJ6xJ4xv8FTr0Ezb8AbhgzIe+1B4+pASlemMJuLGz/G7a8hNHrgWeK9z5vks+igoGkaWVLyaXg4k8+eRWY36/StVYtxHh54WFnhYmlJleyOWyEE7+casWMuBC6V8Jf+rRilkVPxp25qArqarhI8W5hZ0MypGU82fhJfR382fBHACz2a8/xAWxIS4MEF4DkA7K2gdWvYtesObxgdzSBWM4jVajuJG8mDPin5z6eDgqZpvH/xIm+fO0drOzvOpqXR22Bg09WrjHZzqzCjdUzBYDRwIu5Eniagg1EHScpIAsDK3IqWdVoysNlA/F38aVXHny9mN8PHxorxw0BKWDMOUjuo6zk6wuHDt3iz+Hg4dgzCwyEi4sbfUqaDgqbdozKMRmIyMnC3tma4qyspWVksj4zkx6ZNSyXHTnmTkZXBsZhjeZqADkUfIs2QBoCthS1+dfx40e9F/F388Xfxp0mtJny00IKo4/DKB+o6M8PBoap6LrIM/LdLgoUFXLoE69fnvemHh8NXX6kqw++/w5AhNwpkawtu+RerND0dFDTtHtXr8GGuGAz8FxBATQsLqlWpUqo5dspSmiGNw9GH8zT/HIk5QkaW6ry1t7TH38WfEa1H4O/iT4BLAA1rNsTczJzvv4ffv5MMWXwFjocSFurNxfiqcPEivP8+vxIBO8LBNRyio+H776FfPzh1CkaNAnNzcHEBV1do1Aiuj7bq1g22bVOBwNUVHBxACPUoRTooaNo9JDkrCyshqGJmxlh3d4CczuHSzrFTWpIzkjkUfSjPCKBjMcfIklkAOFo7EuAawNh2Y1UNwNGX+qnWmEVGQUQEf1/yY8rGRqxaGI3N808TGdKNkMu9Sf62E1VJYdHChfD663AqXQWA6zf1Fi3U80aNVEHat1c1BCcnFRjyc3VVjzKmg4Km3SO2Xr7M0NBQRrm5MaFuXR4tgxw+pnY17SoHow7mGQF0Iu4EMnt5+NrWNQmwb8hjTn3xT62O/2UrPOt2QAwcCBkZ4OLCycs1GcLbTOU9fDjDtSc/5/CRRly84kAjMzPGdDvOWLer4DZT3cTbtFFv3qCB6he4FRsb9bhbzs6qxlHQfhPQQUHTKrn4zEzeOH2ar6OjaWRjQ3sHh7IuUom4nHo5T/NPcGQwpy+fznndLasq/kn29K/agYDnJuLv4o9r/ZaIuH9vXMTMjMuDzJn2z0CeesqSzi++iLmsx6bl/Rk0uSk+T1jTy92D3tUAbCAoiFIfdBsVlfO0NNbO1kFB0yopKSXfx8Tw2unTJBgMvO3pyZS6dbG+xWIu5VJaGly+TEy1KurGv3kl+6MPsN8YwXnL5JzDvKp74e/iz5CdSQTsj6JVJDhbWoJbLXi4DTR6TB34yRKMltZM/b0NTQNsGDjUnqpZVfjeA3x9ofOCBdSTED0fzMwCAEo/CJQxHRQ0rRIKS0tjxKlT/B4fTxt7e/6vUSNa2NmVdbFuMBohJka1scfGwiOPACA/+YSIrT+xP/08+82jCa6eyn43M8Ltbqxz4HNN0O6qLSMMXvhbeuJfryM1xsxSL/oeVU00Li5q9E62pUtV69CYMc9gBqyfDskOMLAKWFWByMgbzfxl0LdbruigoGmViFFKPouIYOLZsxik5IP69Rnj7o55Ye5yderktF13zr3f2TlPE8ZtSQnXrqmbfe6x9uPGqWGZCxbAokUQFYU0GLhQHfa7wP7Fk9kffZDguD+JCUgBQEhoLGrTuaoPAR2fxt/FH7/qjahWzfnWd+1mzQD47TcIDob33lO7t22D1FQYM0ZtBwffGPQDBff73qt0UNC0SkQAP8bG0s7Bgc8aNqTe3XRsFtSZmX9/QgIcP573hh8eDvPnq1/nH3wAEybcdAnjswM5a5dJsMMl9verzn6HKuw3j+GyVAHA/J95NHVqSq9W/fGv40+AawAtnFtgZ1m42s3u3bBmDSxcCGZmanv1anjnHRWL1qwBS8sbx98h5949Tf+n0bQKLtNoZGFYGIOcnHC3tubnZs1wMDcv2Wyi//0HbdvCxo3w3HM39ltaqhE4cXEqKHTuTNa8uZysLdhve5VgYzj7k09z4LsWXEu/pk6paUlzp+Y85dItZxJYc6fm2FgUPoCdPg2ffQaTJqnEcSdOwMqVamSopydMmwazZ9+oUOQOCNrt6aCgaRVceHo6754/TxUhGOfhQTVT/Ay+3r7SpYsKDNlj8TOrO3A8/gT7I4PZv+lzgiODOZh5kJQLqgZgXcWals4tea75czkBoKlTUyzN7+4uHRcHy5bBk0+qFqLYWFi8GHr2hK5dYeBAFauuf/R7ODNHsemgoGkVUEpWFqtjYnipTh28bGw41qYN3kUZA39dATl2Iu1gxoPwr7ta9SzdkM4xEUWwUxj7L65j/3/7ORx9OCcNRFWLqrRyaUVgq0ACXAPwd/Gnca3GVDG7+9tMRgYsX65GBHXtqvZNmwa1aqmg0Latasm63pd8D+XjMzkdFDStgvkjIYGhoaGcTUujRdWqtHFwKHpAiIqCsWNh06acXZF2MK0zfOUHWQKyzMH/M3+Oxhwl06iWxqxmVQ1/F39GtRmVkwbCp4YP5mZF77FdvVq1//frp37xz5ihagBdu6pgEB8P1aurY83N8wwu0kqQDgqaVkEkZGYy7swZVkZF0cDGhiA/P9oUdSKa0Qiffw4TJ6phOVOmEPnlx0zwi2N1czAK8gzQr2Vbi3Htx+U0AdVzrFfsPovt2+HsWQgMVNtLlqjRpP36qc7ikJDshWayXQ8ImmnpoKBp5ZyUkp9iYxl96hRxmZlMqluXqZ6e2BR1HGVqqkq+tmuX6iNYupTLdWvTxm454YkFn7J18Naif4Bshw7Bjh2qYgLw3XeweTO8/LLqEP75Z1UjuC53QNBKj1lZF0DTtFuLSE+n77FjPB0SgpuVFXsDAphTr17RAoIxewKYjQ0EBMCXX5K+ZSMLL2/AZ7EPEYkRNKnZBOsq1lQRxf+9eOGCGqGanq62t26F8eNvpAd6/304c+bGCCEnJ1VD0MqW/go0rZwKTkykyX//sfnyZebWq8cef39aZS+Bede2bYOmTXNWeJEffcTa1jY0+dSXcVvH0c69HYeGHyJkdAjnxpyjt0tvbKrY3NUoocuXVYtUeLjaPnRIBYEDB9R2YKAKCNdrALVq6Q7i8kgHBU0rZzKzf9E3q1qVZ5ycONK6NW/WrZuzHOZdiYlRYzW7d4esLEhJ4Z9L/9BhRQee+fEZ7K3s2fLcFjYN2kRz5+YA1LGrw9gGYzk75iyBrQLxq+NX4KXT0+GHH26sJBYbC0OHqhoBqBaqsDC47z617egI1ard/UfQSpcOCppWjnwVFUWzvXtJNBiwMjNjeaNG+BR1mM1XX0HjxrB2LbzzDqf//IWnL31AxxUduXj1IiseX8H+ofvpXr97zimrVoGXF3Tt+iD3NatDhytLODBM/dSXUt3w//5bHWs0wuDB8M03arthQzXZ+friYTY2ZbJwmFZMuqNZ08oBKSVCCBrZ2NC8alXSjEaK2FB0w+nT0LQp8YvnMjP6B5Z80QpLc0ve6/web7R/g6qWVfMcvmqV+qWfkgIguHBBNfkcOgTz5qm2/1dfVTf/Tp3UTX//frUN6vXGjYtbaK2s6aCgaWUoNSuL6efPk2o0srhBA+6rVo0fi9rGkpYGc+aoFb569CD9rYl80qMaM7f25lr6NQJbBfJul3epY1enwNOnTLkeEPJe8sMPVVAA+PVXyL1Am69v0YqqlV86KGhaGQlKSOCVkyc5nZrKKy4uGKXMWRrzru3YAcOHw8mTyDcnsNb9KpP+mMT5K+fp1aAX8x5WCedu5+LFgvdnZd143qRJ0YqnVRy6T0HTStmVzEyGhobS5dAhjFLyR8uWLG/UqGgBIS5ONeJ37QoGAzt/+ID2Df5iwE8DqGZVjW2Dt7Hh2Q13DAiQtwZQmP1a5aRrCppWin6JjWXUqVNEZ2Qw3sODd728sC1OMv/162HVKk69NYxJzaL4+dg43Ozd+PKJL3muxXOFSjuRkKD6pGfNyt2noNjaqv3avUPXFDStFESlp9Pv6FH6HjuGk4UF/wUEML9+/aIFhJMnVTAA4p7uzZivB+Jr/T+2nv+DmV1mcvLVk7zg90Kh8xB9/TW8+Sa0aKGS0Hl6ghAST0+1PWjQ3RdRq7h0TUHTSsGMCxf4PT6e2d7ejPfwwKIocw7S01WP76xZpLk68XH1Y8za9T6JGYkM9R/K9M7TcbZzLvTl0tJUiulXX4WHH1Zz25o3V0EgKOhPky8Qr5VPJq0pCCF6CCFChRCnhRCTCni9rhBihxDigBDisBCilynLo2ml6UxqKiHJanH5Gd7eHGrThsmenkULCH//Da1aYZw2ldWDW9F4lOTN7ZO5v+79HBlxhKWPLr2rgPC//6kAEBurUks0vXOXg3aPMFlQEEKYA0uAnoAvMFAIkX8A29vAWillK2AA8KmpyqNppSlLSrofOsTIkycBqGFhQaOiTkI7fhweeIC/7C9z37yGPOu+mxp2tfnj+T/4/dnf8a199+NCmzdX6Y+KswSDVjmZsqbQFjgtpTwrpcwA1gBP5DtGAtdz/1YDbl7pQ9MqkGPJyWQajZgLwVeNG7OqqAP5pYSDBwE46WROn/mtebBXNJHmKXz95NfsG7qPrt5d7+qScXEqLQWoRWrWrAG7wi2BrN1DhJTSNBcWoh/QQ0oZmL09GGgnpRyd6xgXYCvgCFQFHpZSBhdwraHAUABnZ+eANWvWFKlMSUlJ2Ol/BeVOZfheMoCvUb98hgL9i3Et6/BwGn70EYYTwYx+tys/JwVhaWbJsx7P0s+9H9bmRVtrcvFiHzZtcuG773bj6Jh522Mrw3dSGRXne+nSpUuwlLL1HQ+UUprkATwNfJFrezDwcb5j3gDGZT9vD4QAZre7bkBAgCyqHTt2FPlczXQq+vfyV0KCbLh7t2THDjnk+HEZl5FRtAulp0s5e7ZMrWol3+9qKR3etZbm75rLEb+PkFGJUUUun8Gg/iYlSRkcXLhzKvp3UlkV53sB9slC3LtNOfooDPDIte3Ozc1DLwM9AKSU/wohrIFaQIwJy6VpJeKawcDEs2dZFhGBl7U1W1u0oFuNGkW7mMGAsf19rM48wFtjbLlomcJjDR5j7sNzaVK76NOIFy6EDRvUYjZVq4K/f5Evpd0jTBkU9gINhBDeQDiqI/nZfMdcBB4CvhRCNAGsgVgTlknTSsT6uDhGnDxJZEYGr7u7M8Pbm6pFmXOQkgK2tvwZtotxfeIIzgJ/l8Z82W0BXby7FLucTk7qYTCo9Y817U5MFhSklAYhxGhgC2AOrJBSHhNCvIeqxqwDxgGfCyFeR3U6D8mu5mhauZSSlcVLJ07wfWwszapW5edmzWhblHWSpYS1azkxfTQTh/uw7spuPBw8+Oahb3i2+bOYiaKPAYmMVCua3X+/Wkph0KAbq5tp2p2YdPKalHIjsDHfvqm5nocAHU1ZBk0rSTZmZiRlZTHDy4s369bFsihzDs6dI2ZMIO9mbeez/mCblMqch+Ywpt0YbCyKP0Y0MFANXDp7Vq1spgOCdjf0jGZNu4OLaWm8fvo0H/n44GFtzfrmzRFFvNOmLvmIj36awJz7DKRYmTG89XCmdp6GU1WnYpdTShUAPv1U5TPSS11qRaGDgqbdQZaU7Lp6lcPJyXhYWxcpIBilkVWHVzElYQaXHjTwRN3uzH1sMY1qNSp2+aSEd99V8xA++UTlLvL0LPZltXuUDgqaVoAjSUl8Gx3N+/Xq4W1jw/n77sO6KB3J166xY/oLjK+5n/2Gi7R2bc033X7mQa8HS6ysQqj+6uRktfZBcZKuapoOCpqWS7rRyKwLF5hz8SLVq1RhlJsbda2t7z4gSMnx7xYz8Y+JrPdMp26mA6ueWsWAZgOK1Ymc26VLKkeejw+8/74KDrr/QCsuHRQ0Lds/V68SGBrK8ZQUnnN25sP69allaXnX14kJ3c+0j/vyec0LVHU1Y26j0bzWbz7WVYo2E7kgRiP06qXWO9i9WyW107SSoIOCds9LNBh469w5loSH42FlxcbmzelZs+ZdXyclM4WPdn/E+3/OIrVGCiOt7uedUWupXc2lxMtsZgaffQaOjrp2oJUsHRS0e9rG+HiGnzxJWHo6o93cmOXtjX2Vu/tnYZRGvl03gymHPyLMeIUnGz/J3IBJNPRpV6JlzcqCt96CevVg2DDo0KFEL69pgA4K2j3sp9hY+h07RhNbW3a1akX7atXu+hp/HFvP+DUvc7BKLG1iLfnuta10atjNBKVVjhxR/QiaZio6KGj3FCklERkZuFlZ8VjNmizy8WGYqytWd9koHxIbwoRvn2fjtWA8k2C16Eb/md9jVt2xxMt89izUrAnVqsGvv0IRujk0rdB095R2T3n99GnaBQdzzWDA0syM19zd7yogRCdFM/z34TRf2pxdMcHMP1yHE0/tYMDCrSYJCMnJ0LEjjBihtnVA0ExN1xS0Si9LSjKMRmzMzXnW2Zl6NjZ3nbwuJTOFhbsWMPfv90kjk9FtRjPVqhs133vEpJnmqlaFRYt0dlOt9OigoFVqIcnJBIaG0tLOjqUNG9LWweGuEthlGbP45vA3TNnyJhFpsfQNgfeHrqXBQ0+brMwGA0yYAH36wAMPQP/irNijaXdJNx9plVKG0ch758/Tat8+QlNS6FiETKb/d/b/CFjWihd/exH3M7H8/XN1fuqzmgZd+5mgxDckJ8OmTRAUZNK30bQC6ZqCVunszp6EdiwlhYFOTnzk44PTXTTGH405ypvb3mTT6U14JVuyZiP07xCICJqnJgaYyPnz4OGhOpT37gV7e5O9labdUqGCghDCBqgrpQw1cXk0rciSDAbePneOxeHhuFlZsb5ZMx6tVavQ50cmRjItaBr/O/A/HKwcWNBtAaMjPbB63FUtTmBCYWHg5wdjx8L06TogaGXnjkFBCPEYsACwBLyFEH7Ae1LKx01dOE0rrC2XLzMsNJQL6emMdHVlTr16OBRyElpyRjIf/PsB83bNIyMzjdeCq/B298nU7DDOxKW+wd0dpkzR/Qda2StMn8J0oC1wBUBKeRDwMl2RNO3u/RATg7WZGX/7+bGkYcNCBYQsYxYrDqygwccNmBY0jZ6XrAhZnMWHKZ2o2aOvycuckQFvvKGajUB1LuuU11pZK8xPKYOU8mpRFxXRNFOQUrI2NpYGNjb429vzoY8PFkIUOpvp1jNbGb91PEdijnCfuSc/fmlOhyQzWPRNqa1fGRYGK1dCgwY35iFoWlkrTFA4KoR4FjAXQjQAXgP+MW2xNO32krOyeP30aXrUqMGKxo0Lna/oSPQRJmybwJYzW/Cu7s3afmvpF+mIOPsdzJ+vpg6bWHQ0ODurHEahoeBU/EXXNK3EFKb56FWgKZAOfAdcBcaaslCaVhCjlKyKjibTaMSuShWC/Pz4vFHhVi6LSIwgcF0gfp/58V/YHhbGtOJ4ZF+ebvo04uGHYcWKUgkIBw6o9Q/WrFHbOiBo5c1tf14JIcyBd6WUE4AppVMkTbvZieRkXjl5kp1Xr2KUksF16tDQ1vaO5yVlJLHgnwXM/2c+mVmZjLV9iCkL9lAj4RhMfaoUSp5Xs2bw0ktqUpqmlUe3DQpSyiwhREBpFUbT8ss0Gpl36RLvnT9PVXNzVjZqxHPOznc8L8uYxcqDK3lnxztEJUXxtEcP5qyJpf62bdC5MyxbBoWsZRRXairMng0TJ4KdnUpboWnlVWEaYg8IIdYBPwDJ13dKKX82Wak0Ddh37Rovh4ZyODmZp2vXZrGPD3WsrO543ubTm5mwbQJHY47SwaMDP/f/mfZJ1eHth1TP7gsvlOrKNPv2qeUyW7WCvqYf1KRpxVKYoFADiAe65tonAR0UNJNIycpi6rlzfBgWRh1LS35t1ownCjEJ7VDUISZsm8C2s9uo71ifHxtNpe/+FMRL7dUB585BIYJKSbl2DRwcoFMnOHkSvL1L7a01rcjuGBSklC+WRkE0DSAqPZ2OBw5wNi2NYS4uzK1fn2p3GFkUfi2cd3a8w5cHv8TRxpEPO85g5FchWH77nurVnfyWSk9RigHh//5PTUTbvBnattUBQas4CjOj2R34GOiIqiHsBMZIKcNMXDatEpt38SJt7O3pkp1LKEtK/rpyhf+uXaOboyMDnZ15sHr1214jMT2R+f/MZ8E/C8iSWbxx3+tMCfPG8ZlpkJgI77yj1q+0ti6Nj5SHnx/06gVeXqX+1ppWLIVpPlqJGop6PVfwc9n7TLfmoFbptbG3p39ICGt9fTkMDPr3X9KMRn5s2pSJd5jWazAaWHFgBVN3TCU6OZoBzQYwu+tsvI0OMLABNG2qVrX39S2dD5MtORmWL4cxY6BWLfj221J9e00rEYUJCrWllCtzbX8phNDzFLRi6eLoyFpfX/qHhPAAEJuZyfKGDXNqDgWRUrLp9CYmbJtASGwIHT068ttTP9BuawhU8wQzM9i9WzUZ3WWjH4sAACAASURBVOXymiXhhx9g/Hi47z5o377U317TSkRhgkKcEOI5YHX29kBUx7OmFYmUktUxMWy6fJnhLi7MvHiRd+rWZYiLyy3PORh1kPFbx/PHuT/wqeHDT/1/ok+UI6JH4I1e3O7doWHDUvwkSnq66q544QU1wqhly1IvgqaVmML8nHoJ6A9EAZFAv+x9mnbXotLT6XvsGIOOHyc4MZGlEREMBpZGRLAjIeGm48OuhfHiby/i/5k/B6IOsKjHIo498xd95/+O6NpVLVO2ZYsKCGXgxx+hSRMID1ejXHVA0Cq6wow+ugjoNNlasUgpWRMTw+hTp0jOymKYiws/xcXxQ9OmiEOHeDG7KWmtry9dHB1JTE9k3q55fPDvB2TJLMZ3GM9bnd6iunV16NBBrUIzaZLqTC7EzGZTadQIWrQAG5syK4KmlajCjD76CjXa6Er2tiPwgZRS1xa0QonOyGDEyZP8EhdHO3t7vmzcmHXx8TkBIIgbfQx7rl3l5Jm1TA2aSkxyDAObDWT2Q7Pxis0EY/bqaQsXqhXtmzcvk89z9apaLnPAAFWEX38tk2JomkkUpk+hxfWAACClTBBCtDJhmbRKQkrJ99m1g6SsLObVq8cbHh6YC0HjqlXzHBtxLYL5GwPZfm476VnpdKrbifUD19O2th/MmwczZ6pe3JkzVU9uGZo/XxXpvvv0kFOt8ilMUDATQjhKKRMAhBA1Cnmedo9bGxvLwOPHaWdvz8rGjWmSLxCAWgJz+rHp/P3X3xilEYBfnvmFJxo9gdi1C7r5wfHjaibYqFGl/RHyyMoCc3N4+2149FEdELTKqTAdzR8A/wghZgghZqDWUphn2mJpFZWUkqj0dAD61qrF5w0bsrNVq5sCQmRiJC/++iIeH3rwZ9yfOQEB4MnGTyIWLVL5IVJSYMMG+P57uM3oJFP74gt48EGV3M7auswrK5pmMoXpaP5aCLEPlftIAH2llCEmL5lWIb117hxfR0VxrE0bqltYEOjqetMxUkq6fNWF0PjQW1/okUfU+pTTpqn+gzJWq5bKlGEwlHVJNM20CtPRXB84I6UMEUJ0Bh4WQkTk7mfQtEyjEQszM/rVrk01c3PsbrEs5vkr5xn++3BC40NxToQrNip3Skb+/xObNFEN92Xo8mU4ckTVEJ58Ep54olSTq2pamShM89FPQJYQwgf4AvBGpb24IyFEDyFEqBDitBBiUgGvfyiEOJj9OCmE0IGmgonNyODpY8cYdeoUAAH29kzy9KRKvhnFWcYsPtr9EU0/bcquS7v4eCOEL4TzH0HgfrDJBMvrv8KlLOVPUbDRo1Wq68REta0DgnYvKExQMEopDUBfYJGU8nXgjo272au2LQF6Ar7AQCFEnmQ0UsrXpZR+Uko/VNI9nY67AvkhJgbfvXtZFxdHPWtr5C1u5keij9BhRQde3/I6nb06c2zkMUb/B+YS6iTBko1wdpEKDn6RlPnd9/rH+OAD+P13sLcv0+JoWqkqzCiiTCHEQOB54LHsfRaFOK8tcFpKeRZACLEGeAK4VX/EQGBaIa6rlbHYjAxGnTrFD7GxtM6ed9C0gHb/NEMaM/+aydxdc6luXZ3v+n7HgGYDEAXc9K8HBwCWmfgD3MaHH8Lhw2rJZheXMu3b1rQyUZig8CIwHJglpTwnhPAGCpP/0Q24lGs7DGhX0IFCCE9Us9T2W7w+FBgK4OzsTFBQUCHe/mZJSUlFPldT/gQ+ApKAl4GBiYnE7t1LUL7jDl85zIKTC7iUeonuzt0ZWX8k1eKrcXTOHJy3buV269WX5Xd05IgnZ8/asW1bCJaW5aMZqyzofyvlU6l8L1JKkzxQqba/yLU9GPj4FsdOvNVr+R8BAQGyqHbs2FHkc+91Menpsv/Ro5IdO2TA3r3ySGJigcddSb0ih68fLpmO9PrIS245vUW9EBkp5dNPSwlSNmum/t7qUcqio6UMCVHPjUYps7JKvQjljv63Uj4V53sB9slC3GNNmV84DPDIte0ORNzi2AHcyMKqlUOzL17kl7g4Znp786+/P83s7G465rcTv+H7qS/L9y/njfve4OiIo3Sv100N8m/SBNatUzOSg4PB2bngN7rVfhOREvr0UR3KWVmqO6MMsm5rWrlhypnJe4EG2c1N4agb/7P5DxJCNAIcgX9NWBatCOIyMog3GGhka8u7Xl68VKcOzQsIBlFJUby66VV+DPmRFs4t+PWZX2nj1ka9mJYGc+eq9KHLl99IbR0VlXN+UFAQnTt3LoVPdDMhYPFiFRxuMYpW0+4pJgsKUkqDEGI0sAUwB1ZIKY8JId5DVWPWZR86EFiTXb3RygkpJd0PH0YA+wICcKhS5aaAIKVk5cGVjNs6jtTMVGZ1ncWEDhOwyJKqx3boUDXx7M8/oU6dcvMTXEqYM0etgTBuHAQElHWJNK38KFJQEEIsl1IOvdNxUsqNwMZ8+6bm255elDJophGfmYmDuTkWZmZ86OODY5UqBY4WOn35NMN+H8b2c9t5wPMBlj+6nEa1GsG//8Irr8CxY1C7Njz3HBQwq7ksSQkHD6p0FVKW+QhYTStXbhkUshPfFfgS0Ms0xdHK0i+xsQw/eZJRbm5M9fLiwerVbzrGYDSw8N+FTAuahqW5JZ89+hmB/oGYJSaphHVLl4K7uxrg37t3GXyKW4uIAAsLFau++QYsLXVA0LT8bldTiAUuoILAdTJ7+3YjCrUKJj4zk9dOneK7mBha2dnxZK1aBR63P3I/gesCORB1gCcbP8mSXktwtc+uBQQGqmXIXntNdSYX0PdQljIy4IEH1KI4GzaopiNN0252u6BwFnhIqpXX8hBCXCrgeK0C+jW7dhBvMPCulxeT69bFIl/bf0pmCtODprPw34XUrlqbn/r/RN8mfdVP79QYcHK6sd5B27Zl9Eluz9ISFiyAevXKuiSaVr7dLih8hBoVdFNQQKfOrvBy1w787OzY0rIlLQv4db/93HaGrh/KmYQzvOL/CnMfnoujVTX47DOYOFEtLPDttzdGFZUjRqNKstqhA/TsqZLaaZp2e7cMClLKJbd57WPTFEcrDb/FxTEsNJR4g4HpXl68VUDtICE1gfFbx7Pi4Ap8aviw/fntdPHuoha8Gfo47NwJXbuqu245lZamujaSklRQ0DTtzm7X0TxbSvlW9vNuUsptpVcszVSklHwWEYGLlVWBtQMpJT+G/Mirm14lLiWOSR0nMfXBqdhY2MAvv6iFiatWhZUr4YUXymVPbViYatGytVWjYXVCO00rvNsNHO+R6/lcUxdEM611cXGcT01FCMG3TZqwx9//poAQdi2MJ79/kv4/9sfNwY19Q/cx5+E52MjsWV0dO6pAcOIEDBlSLgNCfLyadzBxotp2cCiXxdS0cqt8zCbSTCo+M5NBx48z75IaH1DDwgLLXM1FRmlk6d6l+C7xZduZbSzotoA9gXvws/GGkSOhSxeVA8LJSc1Kdiq/g89q1oTJk2HYsLIuiaZVTLfraHYSQrxB9hDU7Oc5pJQLTVoyrdj+uXqV9g4O1LSwYPstOpJPxJ3glfWvsPPiTh6u9zCfPfoZ9Rzrqaai0aNVOorXXoPMzHKbByIrS3VtDB6shpyOHVvWJdK0iut2NYXPAXvALtfz3A+tnErIzOSF48fpeOAAa2NjAWjj4JCndpCRlcHMv2bScllLjsUcY+UTK9n63FbqGaup7HB9+6pZXrt3q5QV1tZl9XHuKDpaVWB+1ks0aVqx3W700bulWRCtZGyIj2doaCjRGRm84+lJnwImou0J20Pg+kCOxhzlmabPsKjHIpztsrOT2trCmTPw/vvwxhtqCnA5FZM9RcLVVa2lXMoJVjWtUtJ9CpVEQmYmQ44f59EjR6hpYcF/AQG85+2dp3aQlJHE2M1jaf+/9lxJu8K6AetY028NzhfiYOBASE4GGxvYv1/11JbjgHDyJDRurGoIoAOCppUUU6bO1kpJ7trB256evOPpmScYAGw+vZnhvw/nwtULjGozitkPzcYBK5g6VdUK7O0hJATatCm3fQe51a+vBkI9/HBZl0TTKhddU6jAkgwGXjxxgkePHKGGhQV7AgKYka92EJcSx3M/P0fPVT2xtbBl54s7+aTXJzj8d0itcTBjBvTvr4aZtmlThp/mzjIz4d13ISFBxa0PP9RpKzStpN2xpiCEqAZMBzpl7/oTeE9KedWE5dIKwcrMjGPJyUypW5d3vLywyhUMpJR8d+Q7xm4Zy9W0q0x9YCpvdXoLqypWKl/0229Dejps2gQ9etzmXcqPI0dg1iyoWxdefLGsS6NplVNhmo9WAEeB/tnbg4GVQF9TFUq7tSuZmbx74QJTPT1xtLBgV6tWN6WouHDlAsM3DGfz6c20c2vHF49/QbPaTdXwnA4dwMUFVq0CR0c1O7mcS0xUrVv+/irLRv36ZV0iTau8CtN8VF9KOU1KeTb78S6gK+1l5FxaGkvDw9l+5QpAnoCQZcxi0e5FNP20KX9f+JvFPRaz66VdNMuorrLB9esHH32kDnZ3rxABYfdu8PaGoCC1rQOCpplWYWoKqUKI+6WUOwGEEB2BVNMWS8vtqsHAb3FxPF+nDq3s7Tl/333UybcgwNGYowSuC2RP+B56+vRk2aPLqGvvrha9mTwZDAaYP7/Czexq0gS6ddN9B5pWWgoTFIYDX2f3LQAkAC+YrkhablsuXyYwNJTI9HQ6VqtGfRubPAEhzZDG7L9nM2fnHKpbV+e7vt8xoNkAtYTme++pqb7dusGyZRXmzpqermLZ6NFQrRqsXl3WJdK0e8dtg4IQwgxoJKVsKYRwAJBSXiuVkt3jrhoMjDt9mv9FReFra8vP/v7Ut7HJc8zOizt5Zf0rnIg7weAWg1n4yEJqmdmpxW/c3GDECNXe8uyzFSor3MaN8PrrqpbwyCNlXRpNu7fctk9BSmkERmc/v6YDQunYcvkyzfbuZWVUFJPq1iU4IIA2Dg45r19Lv8bIDSPptLITqZmpbB60ma/7fE2tvcfUMNN+/dQIo9q1YdCgChMQMjLU3z591Pw5HRA0rfQVpqN5mxBivBDCQwhR4/rD5CW7B10zGHglNJQehw9jb27Ov/7+zKlXD+tck8nWha7Dd4kvnwV/xuv3vc7RkUd5pGZbeOUV6Nz5xmD+ChAIVq0CLy/o2vVBnJ1VuoqzZ9VrrVqVadE07Z5VmD6Fl7L/jsq1T6JHIJWow0lJPHrkCOHp6Uz08GC6l1eeYBCVFMVrm17jh5AfaO7UnJ+f+Zm2bm3h8GHo3h3i4mDCBNWHUAFGFa1aBUOHQkoKgCAmBszM1LSJUaPudLamaaZyx6AgpfQujYLc67ysrfG1teWHpk1pl6upSErJyoMrGbd1HKmZqczqOosJHSZgcb2S17AhPPggTJpUoX5eT5lyPSDcYDSqAVI6KGha2blj85EQYpQQonqubUchxEjTFuvesCMhgV6HD5NuNOJQpQqbW7bMExDOXD7Dw988zMvrXqa5U3MODT/EWx0mYrFkqQoAyckqpfX331eogABw8eLd7dc0rXQUpk/hFSnllesbUsoE4BXTFenekWo0ci4tjYj09Dz7DUYD83fNp/nS5uyL2Mey3ssIGhJEo8gMtSTmmDGqAT4pqYxKXjypqSpVRUFutV/TtNJRmKBgJsSNXkshhDlgaboiVW7/d/kyn4SFAdCrZk0Ot26Nd66hpgciD9D287a8+X9v0r1+d0JGhjCs5UuYvf2OyvNw5gx8+61qfK+A+aJnzYK2bVVyVlvbvK/Z2qrXNU0rO4UJCluAtUKIh4QQXYHVwGbTFqvySTQYGB4aSrfDh/ksMpIMoxG4kaYiNTOVidsm0ubzNkQmRfLj0z/yyzO/4ObgplKC7typhpeeOFGhhpnm17YtdOqkPsLy5eDpCUJIPD3V9qBBZV1CTbu3FWb00URgGDACtV7zVuALUxaqsvkjIYGXT5zgYno649zdb0pvvf3cdoauH8qZhDMEtgpkXrd5OKZKNaV3yhTVVLRlS7leEvN2du1SfQUDB6rJ1d26qf2DBqlHUNCfdO7cuUzLqGmaUpjRR0ZgafZDuwuJBgNvnj3LsogIGtrYsLNVKzpUq5bzekJqAuO3jmfFwRX41PBh+/Pb6eLVWXUcjxkD8fGqD+HZZytsQACYPRsuXICnn4YqelknTSvXCrOeQgNgDuAL5NyZpJR6nsJtbE9I4KV8tQOb7HkHUkp+Ov4TozeOJi4ljokdJzLtwWnYRMTAo4+qPA9t2sDWrWqGcgWUlKSGmDo4wNdfqxYwHRA0rfwrzD/TlcA04EOgC/AiqhlJu4XlEREMO3mywNpB+LVwRm0cxW+hv+Hv4s+mQZto5ZI9nHTGDPjzT7Wk2KuvVohlMQuSmQn33w8+PvDjj1CzZlmXSNO0wipMR7ONlPIPQEgpL0gppwNdTVusiikzu/O4d82aTKpbl4OtW+cEBKM0smzfMnw/9WXrma3M7zafPYF7aBVjptZGBrVW8rFjKr11BQ0IABYWMHKkysenaVrFUpigkJadLfWUEGK0EKIP4GTiclU4k86coefhwxilxM3Kijn16uU0F4XGhdL5y86M2DCCNq5tODLiCONbjaLKlHcgIAAmTlQXqVVLDcepgDIz4c034Z9/1PbQofDQQ2VbJk3T7l5hgsJYwBZ4DQhALcep11PIx8fGhuZ2dhikzNmXkZXBrL9m0WJZC47GHGXF4yvYNngb9Q+ch+bNVc3ghRfgq6/KruAlJCVFrfa5dWtZl0TTtOIozOijvdlPk1D9CRqQZDAw+dw5/OzseNnFhUBX1zyv/xf+H4HrAjkSc4T+TfuzqMci6tjVgZ9+UqmtfXxg+3bo0qWMPkHJOHQImjVTi+EEB6u/mqZVXLcMCkKIdbc7UUr5eMkXp2L488oVXjxxgvNpaUzJ19yTlJHEO9vfYdGeRbjau/LbgN94vOFjEB0NdkDv3jB3rupIzrdoTkVz9Khq/Zo/Xy2KowOCplV8t6sptAcuoWYw76EII46EED2ARYA58IWU8v0CjukPTEel4z4kpXz2bt+ntCRnZTHp7Fk+CQ/Hx8aGP/386FQ9J1cgW05vYdjvw7hw9QIjW49kzsNzcIi8rAJBSIjqRK5aVTW+VwJNm8LixXoWsqZVJrcLCnWAbsBA4FlgA7BaSnmsMBfOzpG0JPsaYcBeIcQ6KWVIrmMaAJOBjlLKBCFEue3A/vPKFV46cYJzaWmMcXNjdr162GZ3JMelxPHGljf45vA3NK7VmL9f/Jv7Xe+Djz+Gt99WKSlmz67QE9CuO3EChg9X6Zfc3dUoI03TKo9bBgUpZRYqx9FmIYQVKjgECSHek1J+XIhrtwVOSynPAggh1gBPACG5jnkFWJKdeRUpZUzRPobpJGdlMfnsWT4OD6e+tTVBfn48kF07kFKy+uhqxmwew9W0q0x9YCpvdXoLq4RrcN99qpG9d2/49NNKlf4zLAzCw1VQ0DStcrltR3N2MOiNCghewGLg50Je2w3V/HRdGNAu3zENs99nF6qJabqUslwl23vh+HF+iovjtezaQdXs2sGFKxcYsWEEm05vop1bO754/Aua1W6qagU1a0K9eqqZ6OmnK2zyuusyM2HzZnjsMWjcWNUW9OxkTauchMw1hDLPC0J8BTQDNgFrpJRH7+rCQjwNPCKlDMzeHgy0lVK+muuY34FMoD/gDvwNNMu9fkP2cUOBoQDOzs4Ba9asuZui5EhKSsLOzu6Ox6UCWah+4XPANeB6soksmcWv4b/yxTmVEzDQO5An3Z6kVvAB6i1fzpHZs8moVatI5Suv1q51Z+lSHz7/fC8+Psklfv3Cfi9a6dHfSflUnO+lS5cuwVLK1nc8UEpZ4AMwAonZj2u5HonAtVudl+v89sCWXNuTgcn5jlkGDMm1/QfQ5nbXDQgIkEW1Y8eOOx6TnpUlm+zZI58PCbnptSPRR2S7z9tJpiN7fttTnk84L2VsrJTPPy8lSNmwoZQHDhS5fOVNZqb6m5Ym5YYNpnufwnwvWunS30n5VJzvBdgn73DfllLeevKalNJMSmmf/XDI9bCXUjrc6rxc9gINhBDeQghLYACQf5jrr6h8SgghaqGak84W4tol7nqKCkszM0a6uvJinTo5r6Ub0pm6Yyr+n/lzJuEMq/quYsOzG/DcsBOaNIHvvlMprg8dAj+/sih+ifv0U+jQQa2SZmUFvXqVdYk0TSsNJmsZllIahBCjUYv0mAMrpJTHhBDvoSLWuuzXugshQlAtNhOklPGmKtOt7LxyhZdCQ1ns40OPmjUZnasHddfFXQSuD+RE3AkGtxjMwkcWUss2u3lo82aoXx8+/1zNUK5EPD3Vw2Ao65JomlaaTNpdKKXcCGzMt29qrucSeCP7UepSsrKYcu4ci8LC8LK2zulEBriWfo3J/zeZT/d9imc1TzYP2swjXg/BRx9B9+7QogUsXaomoFXg5HW5HTsGp0/DE0+oQVO9e5d1iUwjMzOTsLAw0tLSyroo5Va1atU4fvx4WRdDy6cw34u1tTXu7u5YWFgU6T3u2TEku65e5cUTJziVmsooV1fer1cPu+whNetD1zNiwwgiEiMY224sM7rOwO7oSbWW5IEDcPmyCgqVrCNu4kQ4fhx69gTLSrwKd1hYGPb29nh5eSEq+MgwU0lMTMTe3r6si6Hlc6fvRUpJfHw8YWFheHt7F+k9Kn1QmHfxIm3s7eni6Aio2sELx4/zY1wcXtbWbG/ZMue16KRoXtv8GmuPraW5U3N+6v8T7RybwVvT1BoHTk7www/w1FNl+ZFKVEaGaiKytYX//Q+ysip3QABIS0vTAUGrlIQQ1KxZk9jY2CJfo9IHhTb29vQPCWGtry9Hgef27CE8I4PHa9ZkVZMm2FWpgpSSLw9+ybit40jOTGZml5lM6DgBS3NLmDcPPvhA5YKeOxdypbWo6LKy4OGH1RLQq1eDs3NZl6j06ICgVVbF/X+70geFLo6OrPX1pX9ICGlASkYGC+rXZ5yHBwBnLp9h2O/D+OPcH3Sq24nljy2nsawJh46Cvz+89ppaRqxDh7L9ICZgbg59+6qgoO+RmqZB4dZTqPC6ODoywtWVJGC8hwfjPDwwGA0s+GcBzZc2Z2/EXpb1XkbQCztovPE/Ncx0wAD1U9raulIFBClVVtO92QnRx46F/v3LtkzlWp06KmLmf+QaslwUQggGDx6cs20wGKhduzaPPvooAF9++SW1a9fGz88PPz8/nn/+eQCGDBmCt7d3zv4Od/H/prm5ec55fn5+nD9/nqCgIIQQrF+/Pue4Rx99lL///huAzp0707r1jflO+/bto3PnzsX56Fo5V+lrCgA7EhJYGhHBYOCLyAj2HP6Y/0KWk2pI5YlGT7Ck1xLc4tKhR0/Ytg3at1fDTCvJqKLcrl2DJUtU7qI2bcq6NBVAdPTd7S+kqlWrcvToUVJTU7GxsWHbtm24ubnlOeaZZ57hk08+uenc+fPn069fv1tee8iQIQwZMuSmm7eNjQ0HDx7Ms+/8+fO4u7sza9YsHnvssQKvFxMTw6ZNm+jZs2chP51WkVX6msKOhAT6h4Sw1LsOl0MXcGX/6/xZtTOpdo344ekf+OWZX3C7cFmtFLN7t7pj7typ8kJXImfPgtGo1jz491/Vb65l69z55sennxbu3Li4m88tpJ49e7JhwwYAVq9ezcCBA++i0CWnZcuWVKtWjW3bthX4+oQJE5g5c2Ypl0orK5U+KPwRF06Ha1sZtMKXDVEbMCYEw/F3wb4x/dy6qU6ZZs1g/Hi15sHIkWBWuf6zhIaquXWLFqltFxfdh1AeDBgwgDVr1pCWlsbhw4dp1y5vvsjvv/8+p6ln5cqVOfsnTJiQs3/QXSxmkZqamnNenz598rz29ttv3/LG3759e6ysrNixY8ddfDqtoqr0zUd/L/BnZ51MjLnv81cOqke9rXDkiOppfe+9MiujqTVsqJZ1KKMfouVfUFDRz61Vq8jnt2jRgvPnz7N69Wp6FZBH5G6aj7Zs2cLEiRMBuHjxIjt37sTOzg4rKyv27NkDFNx8dF2nTp0AcvoS8rseNObOnVv4D6hVSJXrJ3EBvv8uk+H7wCYTLPOnbHj6abUSWiUUFgZ9+kBUlKoVTJ5c7L5RzQQef/xxxo8fX+ymo0ceeYSDBw9y8OBBHn/8cb744gsOHjyYExAKY8qUKcyaNavA17p27UpaWhq7d+8uVjm18q/SB4U6SbBkI5xdBIH78wWHZcsq7cLCCQmq7+BYodbJ027pVpM3SmhSx0svvcTUqVNpXg5yZ3Xv3p2EhAQOHTpU4OtTpkxh3rx5pVwqrbRV+qBwXf7g4BdZ1iUqeUYj/PWXet68OZw7Bw89VLZlqvCiotQ43vyPqKgSuby7uztjxoy5q3Ny9yn4+fmRkZFRImUBdeMPCwsr8LVevXpRu3btEnsvrXy65SI75VXr1q3lvn37Cn/C7XpUK9hnv5MlS2D0aDUHofWdl9IoN4KCgkp17Pvx48dp0qRJqb1fRaRzH5VPhf1eCvp/XAhRqEV2Kn1H871AShX7XnoJHBwgIKCsS6RpWkVV+ZuPTNwmXNZWr4auXSE9XWXxHjxYDzfVNK3oKn9QyNUmHLRjR4m3CZc1a2v1N7nkl07WNO0eVPmDQiV08SJs3aqe9+kD27dDjRplWyZN0yoH3adQAY0eDcHBcOaMqino5iJN00qKDgoVhNEImZlgZaVWAU1OvtF0pGmaVlJ081EFYDSqZqKhQ1V3iJubSl2hlY5Vq8DLS6XE8vJS28UVFRXFgAEDqF+/Pr6+vvTq1YuTJ08ihODjjz/OOW706NF8+eWXgMp+6ubmRnp6OgBxcXF4eXkVvzCalosOChWAmZlaHlqnui59q1apYHzhggrIFy6o7eIEBiklffr0oXPnzpw5c4aQkBBmz55NdHQ0Tk5Oy2hXmAAAG9NJREFULFq06JYT0szNzVmxYkXR31zT7kAHhXLsq6/gev6yKVNUX4LuPyh5nTtD9o9xMjPV9rffqu3JkyElJe/xKSlqcSK4kTn7+ho1hRnUtmPHDiwsLBg+fHjOPj8/Pzw8PKhduzYPPfQQX331VYHnjh07lg8//BCDIX8iL00rGToolFOJiSoQLF5c1iW5t90i4wPx8UW/5tGjRwm4zQzDSZMm8cEHH5CVlXXTa3Xr1uX+++/nm2++KXoBNO02dEdzORMdDU5OYG+v8hjVrVvWJar8cme+trDIu123rmoyyu/695I/c3ZJZKL19vambdu2fPfddwW+/tZbb/H444/Tu3fv4r+ZpuWjawrlyLlz4Ot7o3ZQrx5U0WG7TM2aBba2effZ2qr9RdW0aVOCg4Nve8xbb73F3LlzMRqNN73m4+ODn58fa9euLXohNO0WdFAoR7y8IDAQClhvRSsjgwbB8uXg6an6czw91fZdLHh2k65du5Kens7nn3+es2/v3r1cyFUlady4Mb6+vvz+++8FXmPKlCksWLCg6IXQtFvQQaGMXb4ML78MsbHqpjN3LjRoUNal0nIbNAjOn1dDg8+fL15AABBC8Msvv7Bt2zbq169P06ZNmT59Oq6urnmOu10a66ZNm+Lv71+8gmhaAXTjRBn7//bOPLqKKmv0v01IAAEBRSZRIK3gSsjEEESRkE4g8uCpIIKoQORrMdig2N0MfvphK6AILtuHzRL4QMCGJUGax0MRZTCA6eaDQAwBosxhCjILxAyQZL8/qlLchJsBknAznN9ate6pM+zadXdS+55z6uxz7BisWAFPPglPPOFpbQy3i1atWrkd/tmzZ4+TDgoKKjB8lL9eIZ+VK1dWmH6GmotxCh4iORkCAyE42Pr12aSJpzUyGAwGM3zkERYutJxB/na3xiEYDIbKgukpeIDBg+HSJbNC2WAwVD5MT+E28e231rzBtWtQv761ItbLy9NaGQwGQ0GMU7hN/PqrtQjq3DlPa2IwGAxFY5xCBXL+PMTHW+lnn4WEBGjZ0rM6GQwGQ3EYp1CBjBoFAwdeD6jm7e1ZfQxl59SVU7yy5hVC5oaUSU6DBg2KLEtLS2PQoEElynjvvfeKLGvbti1PP/20c75ixQqio6MB69XWWrVqkZyc7JR37NiR1NTUkhU3VHuMU6gA8uOYffQRfP31jWESDFWPfGfgO8uXBT8uIOmXpAq7VqtWrVixYkWJ9YpzCgA7duxg7969bstat27NtLLE6jBUW8zbR+WIKrz0kjWBPHeuFRKhTRtPa2UojnHfjiv2AZ+dk83RS0c5/dtpVBVFnbJei3q5bRPcIpiPH/+4xGurKhMmTGDt2rWICG+99RZDhgwhNTWV/v37s2fPHhYtWsTq1avJyMjg0KFDDBgwgBkzZjBp0iQyMzMJDg7G39+fpW42ePjLX/7Ce++957asf//+bNmyhX379tGhQ4cSdTXUHExPoRwRgebNrSinqiXXN1R+fjr3E6fST5GneQUcQnmwcuVKkpKS2LVrFxs2bGD8+PGcOnXqhnpJSUnExsaye/duYmNjOX78ONOnT6devXokJSW5fegDDB48mMTERA4ePHhDWa1atZgwYUKJvQ1DzaNCewoi8jjwfwAvYL6qTi9UHg3MBE7aWX9X1fkVqVNFsGaNFczO3x+mTjUb4VQlSvpF/0v6L0zZPIWFSQvJ1Vyu5l7fEW1T9KYyXTs+Pp6hQ4fi5eVF8+bNCQsLIyEhgcDAwAL1IiIiaNSoEQB+fn4cPXqU++67r0T5Xl5ejB8/nvfff5++ffveUP7cc88xbdo0jhw5Uqb7MFQvKqynICJewGygL+AHDBURPzdVY1U12D6qnEPIyLCGjN591zo3DqF60aJBC2b3m83h1w7zh5A/UK92PXy8fMpFtpayO1mnTh0n7eXldVO7rg0bNowtW7Zw7NixG8pq167Nn//8Zz744INSyzNUfypy+CgUOKiqh1X1KrAMeLICr3dbuXzZGiK64w5Yv/76do6G6klh5xDcIrjMMnv27ElsbCy5ubmcPXuWLVu2EBoaWur23t7eXLt2rcQ6r7/+Oh9/7L5HFB0dzYYNGzh79uxN6W6ovlTk8NG9wHGX8xNANzf1nhaRnsB+4HVVPV64goiMAkYBNG/enE2uW13dBOnp6bfc1pWzZ+swdmwIQ4YcY8CANDuvzGJrLOVll9LSqFEjrly5cktt61Of6T2tUdBblZGTk4OPjw+RkZFs3ryZgIAARIR33nmH+vXrc+7cOfLy8rhy5QpZWVlcvXrVuVZOTg4ZGRlcuXKF6OhoOnbsSFBQEAsWLChwDVUlPT2dOnXqMHjwYKZMmcK1a9fcyhw1ahQTJ04kPT3dycvNzb3l+zNUHKW1S1ZW1q3/T6lqhRzAM1jzCPnnw4BPCtW5G6hjp2OA70uS27lzZ71V4uLibrmtK7m5qjExqjt2lIu4Gk952aW0pKSk3NbrFSYpKUm7du3qUR1K4vLly55WweCG0trF3d84sENL8eyuyOGjE4DrbFhrIK2QQzqvqtn26X8DRe9m7mEyMmDCBGtTnFq14NNPoZi91w0Gt8yZM4ehQ4cydepUT6tiMLilIp1CAvCgiLQTER/gWWC1awURcQ368ATwUwXqUyZ+/hk++QS++87TmhiqMjExMaSkpNCnTx9Pq2IwuKXC5hRUNUdExgDfYb2S+pmq7hWRd7G6MauBV0XkCSAHuABEV5Q+t0pqqvW6aadOcPAg3HuvpzUyGAyGiqNC1ymo6jfAN4XyJruk3wDeqEgdysLy5dZ+vFu2QPfuxiEYDIbqj1nRXAx9+8Ibb0BI2WKfGQwGQ5XBOIVCbNsGw4dDTg40bGgtSqtb19NaGQwGw+3BOIVC/Pwz/PADpKWVXNdQ/Zlx7BhxFy8WyIu7eJEZblYI3wzTpk3D39+fwMBAgoOD2bZtGwAff/wxGfmx1m+SRYsWMWbMmBvy58yZw+eff14mfSsTRd0nFB+SPJ/MzEzCwsLIzQ9nXIWIiYlxIug+++yzHDhwoNyvYZwC1uumiYlWesQI2LMH7r/fszoZKgddGzZkcEqK4xjiLl5kcEoKXRs2vGWZW7du5euvvyYxMZHk5GQ2bNjgxDIqi1MoipiYGIYPH16uMqsyn332GQMHDsTrJvbDrYwOZPTo0cyYMaPc5RqngLUZTlQU5C8UrF/fs/oYbi+9fvyxyOOd1FRa+fjwv3fvZvKRIwxOSaGVjw9Hs7IAOHf16g1tSuLUqVM0bdrUiWnUtGlTWrVqxaxZs0hLSyM8PJzw8HDA+sfv0qUL/v7+vP32246MhIQEHnnkEYKCgggNDb1hleuaNWvo3r07586d469//Ssffvihda+9ejFx4kRCQ0Np3749P/zwAwAZGRkMHjyYwMBAhgwZQnh4ODt27LhB9507dxIWFkbnzp2JiopyoroWJXfv3r2EhoYSHBxMYGCg88t2yZIlTv7LL7/sPHQbNGjAxIkT6dy5M5GRkWzfvp1evXrh6+vL6tXX32g/fvw4jz/+OB06dOCdd95x+z3PnDmTrl27EhgYWOC7W7p0KU8+aUXc2bRpEz179mTAgAH4+fkRExNDXl6eo8vkyZPp1q0bW7duZePGjYSEhBAQEMDIkSPJzraWWLVt29a599DQUCcq7dGjR4mIiCAwMJCIiAgn/tSXX37prETv2bMnYDmd8ePHO/rOnTsXsBYXjxkzBj8/P/r161cgHMljjz3Ghg0bbioWVqkozQq3ynSU54rmvDzr8+BB1W+/vWWxhjLi6RXNYYmJJR6RP/6oxMXpfx0+rGGJibowLU1VVc9mZ99QtySuXLmiQUFB+uCDD+ro0aN106ZNTlmbNm307Nmzzvn58+dVVTUnJ0fDwsJ0165dmp2dre3atdPt27erquqlS5f02rVrunDhQv3jH/+oK1eu1B49euiFCxdUVfXtt9/WmTNnWvcaFqZ/+tOfVFV1zZo1GhERoaqqM2fO1FGjRqmq6u7du9XLy0sTEhIK6H316lXt3r27njlzRlVVly1bpi+++GKxcseMGaNLlixRVdXs7GzNyMjQlJQU7d+/v169elVVVUePHq2LFy9WVVVAv/nmG1VVfeqpp7R379569epVTUpK0qCgIFVVXbhwobZo0ULPnTunGRkZ6u/v7+hav359VVX97rvv9KWXXtK8vDzNzc3Vfv366ebNmzU7O1ubN2/u3FNcXJzWqVNHDx06pDk5ORoZGalffvmlo0tsbKyqqmZmZmrr1q113759qqo6bNgw/dvf/ubYbOrUqaqqunjxYu3Xr5+qqvbv318XLVqkqqoLFizQJ598UlVVO3bsqCdOnFBV1YsXL6qq6ty5c3XKlCmqqpqVlaWdO3fWw4cP6z//+U+NjIzUnJwcPXnypDZq1MjRT1U1MjJSd7gJrVCWFc01cpMdVfjP/4TffoNZs+B3v7MOQ81kUwmvl+UPGf1XmzZ8mpbGcj8/wps0AaCpj0+J7QvToEEDdu7cyQ8//EBcXBxDhgxh+vTpznaZrixfvpx58+aRk5PDqVOnSElJQURo2bIlXbt2BeDOO++8rmtcHDt27GDdunUF8l0ZOHAgAJ07d3a24IyPj+e1114DrK05O3bseEO7ffv2sWfPHnr37g1Yv25bumw67k5u9+7dmTZtGidOnGDgwIE8+OCDbNy4kZ07dzr6Z2Zm0qxZMwB8fHx4/PHHAQgICKBOnTp4e3sTEBBQYLvQ3r17c/fddzvXjY+Pp0uXLk75unXrWLduHSG2bdLT0zlw4AAPPPAAjRs3LnBfoaGh+Pr6AjB06FDi4+MZNGgQXl5ezpam+/bto127drRv3x6AESNGMHv2bMaNG+e0y/98/fXXAWuYcOXKlYAVrXbChAkAPProo0RHRzN48GDnO1u3bh3JycnOfMGlS5c4cOAAW7ZsccKrt2rVyulZ5NOsWTPS0tLoXI7hFWqEU1i6FN58E44dC+P++2HaNMjOto68PCtshcHgjnyHkO8Iwhs3LnB+q3h5edGrVy969epFQEAAixcvvsEpHDlyhA8//JCEhASaNGlCdHQ0WVlZqCpSRIx2X19fDh8+zP79+ws8JF3JH7ZyDcOtpQjjrar4+/uzdevWUst97rnn6NatG2vWrCEqKor58+ejqowYMYL333//Bhne3t7OvdWqVcuRWatWrQLDJIXvv/C5qvLGG2/w8ssvF8i/ePEiWfbQX0my6tat68w7lPT9uMooyjb5+XPmzGHbtm2sWbOG4OBgkpKSUFU++eQToqKiCrT55ptvipQHVuC7evXqFavbzVLtH4dLl1pzBkePgqpw9Kh13qmTtWWmcQiG4ki4cqWAAwhv0oTlfn4klCGC6L59+wq8NZKUlEQbe9/Whg0bOvMDly9fpn79+jRq1IjTp0+zdu1aAB566CHS0tJISEgArGit+Q/MNm3asHLlSoYPH17k/szu6NGjB8uXLwcgJSXFbdsOHTpw9uxZxylcu3atxGscPnwYX19fXn31VZ544gmSk5OJiIhgxYoVnDlzBoALFy5w9OjRUusKsH79ei5cuEBmZiarVq3i0UcfLVAeFRXFZ599Rnp6OgAnT57kzJkzNGnShNzc3AKOYfv27Rw5coS8vDxiY2Pp0aPHDdd76KGHSE1NdeYL/vGPfxAWFuaUx8bGOp/du3cH4JFHHmHZsmWANY+RL/fQoUN069aNd999l6ZNm3L8+HGioqL49NNPnVDo+/fv57fffqNnz54sW7aM3NxcTp065czV5LN//378/f1v6rsriWrfU3jzTevtIlcyMuCtt+CFFzyjk6HqMMHNa2jhTZqUqZeQnp7O2LFj+fXXX6lduzYPPPAA8+bNA6ww1n379qVly5bExcUREhKCv78/vr6+zoPPx8eH2NhYxo4dS2ZmJvXq1WPDhg2O/A4dOrB06VKeeeYZvvrqq1Lp9MorrzBixAgCAwMJCQmhY8eOzm5v+fj4+LBixQpeffVVLl26RE5ODuPGjSv2oRQbG8uSJUvw9vamRYsWTJ48mbvuuoupU6fSp08f8vLy8Pb2Zvbs2Y5jLA09evRg2LBhHDx4kOeee+6GXlGfPn346aefnAd0gwYNWLJkCc2aNaNPnz7Ex8cTGRkJWENckyZNYvfu3c6kc2Hq1q3LwoULeeaZZ8jJyaFr167ExMQ45dnZ2XTr1o28vDy++OILAGbNmsXIkSOZOXMm99xzDwsXLgRg/PjxHDhwAFUlIiKCoKAgAgMDSU1NpVOnTqgq99xzD6tWrWLAgAF8//33BAQE0L59+wLO7/Tp09SrV6/AEF65UJqJh8p03OxEs4iqNYtQ8BC5KTGGCsTTE80GayI7MzNTVVUPHjyo999/v2ZnZ3tYq4ohMTFRX3jhBVW1/vbyJ4ZvlcIvB1QkrqGzP/roI50/f77bemaiuRjuv98aOnKXbzAYLDIyMggPD+fatWuoKh999BE+PuWz7WhlIyQkhPDw8Eq59uBmaNy4McOGDSt3udXeKUybZs0huA4h3XGHlW8wGCwaNmxYYF1Cdd91beTIkQDOZH9ZcH0r6nby4osvVojcaj/N+vzzMG8etGkDIkqbNtb58897WjODJ9FSvG1jMFRFyvq3Xe2dAlgOIDUVvv9+M6mpxiHUdOrWrcv58+eNYzBUO1SV8+fPU7cMUTyr/fCRwVCY1q1bc+LEiQIhAwwFycrKKtODxVAxlMYudevWpXXr1rd8DeMUDDUOb29v2rVr52k1KjWbNm1yVgMbKg+3wy41YvjIYDAYDKXDOAWDwWAwOBinYDAYDAYHqWpvYIjIWeDmAqVcpylwrhzVMZQPxi6VD2OTyklZ7NJGVe8pqVKVcwplQUR2qKr70JEGj2HsUvkwNqmc3A67mOEjg8FgMDgYp2AwGAwGh5rmFOZ5WgGDW4xdKh/GJpWTCrdLjZpTMBgMBkPx1LSegsFgMBiKwTgFg8FgMDhUO6cgIqkisltEkkRkh513l4isF5ED9mcTO19EZJaIHBSRZBHp5Fntqw/lZQcRGWHXPyAiIzx1P1WViraDiHS25R+02xa9y3wNRkQ+E5EzIrKnUP5YEdknIntFZIad11tEdtrf604R+b1L/SG2bZz6heQNEhEVkS4ueYEistVus1tEio+oV5rt2arSAaQCTQvlzQAm2elJwAd2+n8BawEBHga2eVr/6nKUhx2Au4DD9mcTO93E0/dWlY6KtgOwHehut1kL9PX0PVfGA+gJdAL2uOSFAxuAOvZ5M/szBGhlpzsCJ+303cAx4B77fDEQ4SKvIbAF+B+gi51XG0gGglxkeBWna7XrKRTBk1hfIPbnUy75n6vF/wCNRaScd8E2uHCzdogC1qvqBVW9CKwHHr/dSldDysUOdtmdqrpVrSfO5y6yDC6o6hbgQqHs0cB0Vc2265yxP39U1TS7zl6grojUAXyB/aqaH/N9A/C0i7wpWA4/yyWvD5Csqrts2edVtdh9SKujU1Bgnd3tGmXnNVfVUwD2ZzM7/17guEvbE3aeoeyUhx2MfcpORdrhXjtdON9QOtoDj4nINhHZLCJd3dR5GvjRdhwHgYdEpK2I1MZywPcBiEgIcJ+qfu3mGioi34lIoohMKEmp6rifwqOqmiYizYD1IvJzMXXdjX+ad3TLh/Kwg7FP2alIOxj7lI3aWMNxDwNdgeUi4mv3uhARf+ADrF/7qOpFERkNxAJ5wL8BXxGpBfwNiC7iGj1s+RnARhHZqaobi1Kq2vUU8rtddlfs/wKhwOn8YSH784xd/QS2p7VpDaRhKDPlZAdjnzJSwXY4YacL5xtKxwlgpT1ctx3rQd8UQERaY9lruKoeym+gql+pajdV7Q7sAw5gzSV0BDaJSCqWk1ltTzafADar6jlVzQC+wZrbKJJq5RREpL6INMxPY3nYPcBqIP+NiRHA/7PTq4Hh9lsXDwOX8rvVhlunHO3wHdBHRJrYb8j0sfMMpaCi7WCXXRGRh+23joa7yDKUzCrg9wAi0h7wAc6JSGNgDfCGqv7LtYHd48O2wyvAfFW9pKpNVbWtqrbFmmh+QlV3YNkuUETusIecwoCUYrXy9Kx8eR5YEzG77GMv8KZen3HfiOVVNwJ35ffQgNnAIWA39oy9OSqPHYCRWGOpB4EXPX1vVem4HXYAumA5mkPA37GjJJjjBlt8AZwCrmH9ev8P2wkssb+/ROD3dt23gN+AJJejmYucFPt4tohrbSpkuxds++8BZpSkqwlzYTAYDAaHajV8ZDAYDIayYZyCwWAwGByMUzAYDAaDg3EKBoPBYHAwTsFgMBgMDsYpGCotInK3Hd0zSUR+EZGTLuc+pZSxUEQ6lFDnjyLyfPloXUBupIisKqFOJxEpl3hOdiiDhuUhy1BzqY5hLgzVBFU9DwQDiMhfgXRV/dC1jr1oSlQ1rwgZL5biOrPLru0t0wlrNeq3ZRWkqlFlV8dQ0zE9BUOVQ0QeEJE9IjIHa9FPSxGZJyI77Jjxk13qxotIsIjUFpFfRWS6iOyy48vnrw6dKiLjXOpPF5HtYsW5f8TOry8i/7TbfmFfK9iNbv3sdvFYUUfz8x+2r/mjiPxLRB4UkXrAZOB5u/czyF09N9e419Yzyf4e8nU8ISKN7Z5Pfo8qVUTW2+V9bdmJIhJrr3I2GApgnIKhquIHLFDVEFU9ibU/QBcgCOgtIn5u2jTCigMTBGzFWqXrDlHVUGA81kMbYCzwi912OlbM+4KNRO4A5mLtS/AY0Mql+Cegh6qGYIU4nqqqmcC7wFJVDVbVFe7qudHvBeArVQ227zfZtVBVZ9tloVixiD6yHeAkrPj7new2rxVx/4YajBk+MlRVDqlqgsv5UBH5D6y/6VZYTqNwjJdMVV1rp3diPbjdsdKlTls73QMrYiWquktE9rpp54cV7/4QgIgsxYoHBNAY+FxEflfCfZWmXgIwV6wdtFapHSvfDX8H1qrqWhF5ytbv39aIGz5AfAm6GGogpqdgqKr8lp+wh1hew4odE4g1Pu9uy8GrLulciv5RlO2mTmm3mSwqbsw0rCByHbHi4Be1JWKJ9VT1e6AXViydpe4myUXkD0ALrvc0BPjW7pEEq6qfqo4q3M5gME7BUB24E7gCXJbrO4WVN/HAYAARCcD61V2YFKC9iLSzJ8CHupQ1Ak7a6WiX/CtYoY9LqucgIm2whrLmAYsoNJQlIqFYTnKYXg9u9m8gTER87Tr13c1XGAzGKRiqA4lYD+Q9wH8D/yq++i3xCXCviCQDf7avdcm1glrx6mOw9ir+AWsv43w+AGaKSGHdvgeC7InlQcXUcyUC2CUiP2JNZn9SqHws1n7Km+3J5jmqehorMmesiOzCchLtS3nvhhqEiZJqMJQCOxZ9bVXNsn9hrwMeVNUcD6tmMJQrZqLZYCgdDbC2MqyNNT7/snEIhuqI6SkYDAaDwcHMKRgMBoPBwTgFg8FgMDgYp2AwGAwGB+MUDAaDweBgnILBYDAYHP4/eEjHsPqTBP8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f_list[:4,0],'rs--', label='MFE+FNN')\n",
    "plt.plot(f_list[:4,1],'bo:', label='CNN')\n",
    "plt.plot(f_list[:4,2],'g<-', label='Joint NN')\n",
    "plt.plot(f_list[:4,3],'cx-.', label='Stacking ensemble(proposed)')\n",
    "plt.xticks(np.arange(4),['500','5000','50000','162946'])\n",
    "plt.ylabel('Macro F1 score')\n",
    "plt.xlabel('Training data size')\n",
    "plt.legend(loc=4)\n",
    "plt.grid()\n",
    "plt.savefig('macrof1.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T12:21:59.766927Z",
     "start_time": "2020-05-27T12:21:59.555466Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f_list[4:,0],'rs--', label='MFE+FNN')\n",
    "plt.plot(f_list[4:,1],'bo:', label='CNN')\n",
    "plt.plot(f_list[4:,2],'g<-', label='Joint NN')\n",
    "plt.plot(f_list[4:,3],'cx-.', label='Stacking ensemble(proposed)')\n",
    "plt.xticks(np.arange(4),['500','5000','50000','162946'])\n",
    "plt.ylabel('Micro F1 score')\n",
    "plt.xlabel('Training data size')\n",
    "plt.legend(loc=4)\n",
    "plt.grid()\n",
    "plt.savefig('microf1.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:15:09.982708Z",
     "start_time": "2020-05-28T01:15:09.460996Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_size_list = [500,5000,50000,162946]\n",
    "bar_width = 0.3\n",
    "pattern_list = ['Center', 'Donut', 'Edge-loc', 'Edge-ring','Local','Random','Scratch','Near-full','None']\n",
    "for data_size in data_size_list:\n",
    "    coeff_sum = coeff_dict[data_size][9]\n",
    "    for i in range(9):\n",
    "        coeff_sum = np.add(coeff_sum, coeff_dict[data_size][i])\n",
    "    coeff_mean = np.divide(coeff_sum,10)\n",
    "    coeff = np.array(coeff_mean)\n",
    "    co_list = []\n",
    "    for k in range(9):\n",
    "        co_list.append(coeff[k][k])\n",
    "        co_list.append(coeff[k][k+9])\n",
    "    plt.bar(pattern_list, co_list[9:],bar_width, color='b',hatch='/',edgecolor='black',label='MFE+FNN')\n",
    "    plt.bar(np.arange(9)+bar_width, co_list[:9],bar_width, color='r',hatch='',edgecolor='black', label='CNN')\n",
    "    plt.legend()\n",
    "    plt.xticks(np.arange(9)+bar_width/2,rotation=-20)\n",
    "    plt.xlabel('Defect Class')\n",
    "    plt.ylabel('Linear Coefficient')\n",
    "    plt.title('Training data size:'+ str(data_size))\n",
    "    plt.savefig('coeff'+str(data_size)+'.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:37:15.928992Z",
     "start_time": "2020-05-28T01:37:15.129104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAARuCAYAAABEJCeWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdfZClZ3kf6N/tGYvvD2MN8Voz0iiO8CI7DpApwa5qYxJgLcmO5GSTrGSTBBsjkljYcVivhZfFlGLiELsWO0HGyJiPyDaylmB7FmsjymtccTCiNISPtSTLOytAMxYsAwLMlxEy9/5xzqAzPT0zre7TfU73c11VXXXOe5737XtOzfQ9/TvP87zV3QEAAABgZ/u6RRcAAAAAwOYTAgEAAAAMQAgEAAAAMAAhEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwACEQO1JVPamqfrOqvlBVH62q71t0TQAsj6q6pqoOVdWXq+rNi64HgOVRVY+oql+Z/h7xuap6f1Vduui6YB52L7oA2CTXJ3kgyV9K8rQkv1NVH+zuO2YHVdXu7n5wEQUCsFD3JfnpJN+V5FGnGqRPAAxpd5IjSb4zyb1JLktyc1X91e7+yOxAfYLtxkwgdpyqekyS/yHJ/9rdn+/u/5zkYJJ/WFUvqKp3V9Vrqur+JK+cnvODVXVXVX26qm6tqvNmrtdV9SNVdU9VfbKqfraq/NsB2Ma6++3d/VtJPjV7vKqeXVVHq+onqurjSd40Pf49VfWBqvpMVf1hVX3HzDkfqaqXVdWd0z7ypqp65Nb+iQCYl+7+Qne/srs/0t1f7e53JPlwkr+uT7Dd+UWWnegpSf6iu/9k5tgHk3zb9PEzk9yT5MlJXlVV35vkJ5P83SR7kvxBkreuuObfSXIgyTOSXJHkBzetegAW7ZuSPCnJeUmurqpnJHljkhcn+cYkr09ysKoeMXPO92cyq+hbMulDL9/SigHYNFX1lzL52X58VYE+wbYlBGInemySz6449tkkj5s+vq+7/113P9jdX8rkh/XPdPdd06mc/yrJ02ZnAyV5dXff3933Jvn5JFdt8p8BgMX5apKf6u4vT/vEi5K8vrvf291/0d1vSfLlJM+aOee13X2ku+9P8qroEwA7QlV9fZJfS/KW7v7j6WF9gm1LCMRO9Pkkj19x7PFJPjd9fGTFa+cl+YXp1M3PJLk/SSU5Z2bM7DkfTfLN8ysXgCVzrLv/fOb5eUleerxPTHvFvpzYC/QJgB1mugXEjZnsNXrNzEv6BNuWjaHZif4kye6quqC7/5/psb+Wh6Zv9orxR5K8qrt/7TTX3Ddz/rmZbCgKwM50qj7xqtOcs2/msT4BsM1VVSX5lUxuNHNZd39l5mV9gm3LTCB2nO7+QpK3J7muqh5TVRdnso/Pjac45ZeSvKyqvi1JquoJVfX3V4z58ar6hqral+RHk/zGJpUPwBaoqt3TTTl3JdlVVY+sqlN9OPbLSf5JVT2zJh5TVd9dVY+bGfPDVbW3qp6UyT5z+gTA9va6JE9N8renS75OR59g2xACsVP9s0xu+fuJTDZ5/qcrbw9/XHf/ZpJXJ7mpqv4syR8luXTFsN9O8r4kH0jyO5l8KgDA9vXyJF9Kcm2S508fr7pJZ3cfymS/h9cm+XSSw0lesGLYryd5ZyY3Hrgnk9vPA7ANTfcGfXGSpyX5eFV9fvr1/auN1yfYTqp75Uw2YFZVdZILuvvwomsBYPlU1UeS/FB3/+6iawFg+egTLBMzgQAAAAAGIAQCAAAAGIDlYAAAAAADMBMIAAAAYABCIAAAAIAB7F7UNz777LN7//79i/r2AEvrfe973ye7e8+i61g0fQJgdfrEhD4BsLrT9YmFhUD79+/PoUOHFvXtAZZWVX100TUsA30CYHX6xIQ+AbC60/UJy8EAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABrB70QUAS6hqfed1z7cOYHH8HAAA1ms9/4/wf4gtYSYQAAAAwACEQAAAAAADEAIBAAAADEAIBAAAADAAIRAAAADAAIRAAAAAAAMQAgEAAAAMQAgEAAAAMAAhEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADGD3ogsAAAAAlk/V+s7r+ZbBHJkJBAAAADAAIRAAAADAAIRAAAAAAAMQAgEAAAAMQAgEAAAAMAAhEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwgN2LLgDYPFXrO6/nWwYAAABLQAjE3KwncGhpAwAAAGwJIRAAwJmse2qlTzsAthM/7tnp7AkEAAAAMAAhEAAAAMAAhEAAbFhVXVJVd1fV4aq6dpXXz62qd1XV+6vqQ1V12SLqBACAkQmBANiQqtqV5Poklya5MMlVVXXhimEvT3Jzdz89yZVJfnFrqwQAAIRAAGzURUkOd/c93f1AkpuSXLFiTCd5/PTxE5Lct4X1AQAAEQIBsHHnJDky8/zo9NisVyZ5flUdTXJLkpesdqGqurqqDlXVoWPHjm1GrQAAMCwhEAAbtdrNVFfeKPWqJG/u7r1JLktyY1Wd1IO6+4buPtDdB/bs2bMJpQIAwLiEQABs1NEk+2ae783Jy71emOTmJOnu9yR5ZJKzt6Q6AAAgiRAIgI27PckFVXV+VZ2VycbPB1eMuTfJc5Kkqp6aSQhkvRfAINxFEmA5CIEA2JDufjDJNUluTXJXJncBu6Oqrquqy6fDXprkRVX1wSRvTfKC7l65ZAyAHchdJAGWx+5FFwDA9tfdt2Sy4fPssVfMPL4zycVbXRewSWq1rcDOQO47sq/dRTJJqur4XSTvnBnjLpIAW0AIBAAAbKbV7iL5zBVjXpnknVX1kiSPSfLcrSkNYCyWgwEAAJtpbneRrKqrq+pQVR06dszWcgAPlxCIHafq4X8BALBp5nYXye6+obsPdPeBPXv2bFK5ADuXEAgA2BJCehiWu0gCLAkhEAAAsGncRRJgeaxpY+iquiTJLyTZleQN3f2vV7x+bpK3JHnidMy10zvFAAAAg3MXSYDlcMaZQFW1K8n1SS5NcmGSq6rqwhXDXp5Jov/0TKZ3/uK8CwUAAABg/dayHOyiJIe7+57ufiDJTUmuWDGmkzx++vgJOXmjNwAAAAAWaC3Lwc5JcmTm+dEkz1wx5pVJ3llVL0nymCTPXe1CVXV1kquT5Nxzz324tTJP691t09JsAAAA2JbWMhNotbRgZRJwVZI3d/feJJclubGqTrq2WzoCAAAALMZaQqCjSfbNPN+bk5d7vTDJzUnS3e/J5JaOZ8+jQAAAAAA2bi0h0O1JLqiq86vqrEw2fj64Ysy9SZ6TJFX11ExCoGPzLBQAAACA9TtjCNTdDya5JsmtSe7K5C5gd1TVdVV1+XTYS5O8qKo+mOStSV7QbfMYAAAAgGWxlo2h0923JLllxbFXzDy+M8nF8y0NAAAAgHlZy3IwAAAAALY5IRAAAADAAIRAAAAAAANY055AADtB1frOs809AACwEwiBAAAAAM5gJ3yobDkYAAAAwACEQAAAAAADsBwMAACA7WknrM+BLWQmEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADGD3ogsAAAAAmLuqh39O9/zrWCJmAgEAAAAMQAgEAAAAMAAhEAAAAMAA7AkEAADAw7OevVaSHb/fCiw7M4EAAAAABiAEAgAAABiAEAgAAABgAPYEYrGsJeZ01vP3w98NAACAVZkJBAAAADAAIRAAAADAAIRAAAAAAAMQAgEAAAAMwMbQAAAALNS67xcz3zJgxzMTCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABrB70QXAUqha33nd860DAAAANokQCAAYynpyf5E/ALATWA4GAAAAMAAhEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBsGFVdUlV3V1Vh6vq2lOM+QdVdWdV3VFVv77VNQInq1rfFwCwPe1edAEAbG9VtSvJ9Umel+Roktur6mB33zkz5oIkL0tycXd/uqqevJhqAQBgXNtyJpBPrQCWykVJDnf3Pd39QJKbklyxYsyLklzf3Z9Oku7+xBbXCAAAw9uWIRAAS+WcJEdmnh+dHpv1lCRPqap3V9VtVXXJaheqqqur6lBVHTp27NgmlQsAAGMSAgGwUavNtewVz3cnuSDJs5NcleQNVfXEk07qvqG7D3T3gT179sy9UAAWw95xAMvBnkAAbNTRJPtmnu9Nct8qY27r7q8k+XBV3Z1JKHT71pQIwKLYOw5geZgJBMBG3Z7kgqo6v6rOSnJlkoMrxvxWkr+ZJFV1dibLw+7Z0ioBWBR7xwEsCSEQABvS3Q8muSbJrUnuSnJzd99RVddV1eXTYbcm+VRV3ZnkXUl+vLs/tZiKAdhic9s7DoCNsRwMgA3r7luS3LLi2CtmHneSfzH9AmAsD3fvuL1J/qCqvr27P3PChaquTnJ1kpx77rnzrxRghzMTCAAA2Exr3Tvut7v7K9394STH9447gRsIAGzMmkIgu/kDAADrZO84gCVxxuVgdvMHAADWq7sfrKrje8ftSvLG43vHJTnU3Qenr/33073j/iL2jgPYFGvZE+hru/knSVUd383/zpkxdvMHAABWZe84gOWwluVgc9vNv6qurqpDVXXo2LFj66sYAAAAgIdtLSHQw93N/6okb6iqJ550ko3cAAAAABZiLSHQ3HbzBwAAAGAx1hIC2c0fgJ2van1fAACwTZwxBOruB5Mc383/riQ3H9/Nv6ounw67Ncmnprv5vyt28wcAAABYKmu5O5jd/AEAAAC2ubUsBwMAAABgmxMCAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADGBNt4gHgO2k6uGf0/MvAwAAloqZQAAAAAADEAIBAAAADMByMAAA2Ih1rUG1CBWArWcmEAAAAMAAhEAAAAAAAxACAQAAAAzAnkAAwPJaz14rif1WAABWYSYQAAAAwADMBAIAAICNMHOVbcJMIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAG4OxgAADCU9dzIyU2cgJ1ACAQAANnAHZ7nWwYAbBohEABsEp80A3A6+gSw1ewJBAAAADAAM4EAANieTKMAgIfFTCAAAACAAQiBAAAAAAZgORgAwBZb912orGQCADbATCAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAiADauqS6rq7qo6XFXXnmbc36uqrqoDW1kfAAAgBAJgg6pqV5Lrk1ya5MIkV1XVhauMe1ySH0ny3q2tEAAASIRAAGzcRUkOd/c93f1AkpuSXLHKuH+Z5N8k+fOtLA4AAJgQAgGwUeckOTLz/Oj02NdU1dOT7Ovud5zuQlV1dVUdqqpDx44dm3+lACyEZcMAy0EIBMBG1SrH+msvVn1dktckeemZLtTdN3T3ge4+sGfPnjmWCMCiWDYMsDyEQABs1NEk+2ae701y38zzxyX59iS/X1UfSfKsJAd9ygscV7W+L7YNy4YBloQQCICNuj3JBVV1flWdleTKJAePv9jdn+3us7t7f3fvT3Jbksu7+9BiygVgi1k2DLAk1hQCWcMLwKl094NJrklya5K7ktzc3XdU1XVVdfliqwNgCVg2DLAkdp9pwMwa3udlktrfXlUHu/vOFeOs4QUYVHffkuSWFcdecYqxz96KmgBYGg9n2XCSfFMmy4bNGgWYs7XMBLKGFwAAWC/LhgGWxFpCIGt4AQCAdbFsGGB5nHE5WNa+hvcFZ7pQd9+Q5IYkOXDgQJ9hOAAAsANYNgywHNYyE8itfwEAAAC2ubWEQNbwAgAAAGxzZwyBrOEFAAAA2P7WsieQNbynUKvtlnQGbSckAAAAYAHWshwMAAAAgG1OCAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADEAIBAAAADCANd0iHgAAYGhV6zuve751AGyAmUAAAAAAAxACAQAAAAzAcjAAAICBrWelm0VusD2ZCQQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADEAIBAAAADAAIRAAAADAAIRAAAAAAAPYvegCAAAAWKOq9Z3XPd86gG3JTCAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABjHV3sPXspG8XfQAAAGAHMBMIAAAAYABCIAAAAIABCIEAAAAABjDWnkAAMKB1bYk3/zIAAMa0RPsTmwkEAAAAMAAzgQDOZImSewAAgPUyEwgAAABgAEIgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGsHvRBQAAsEZV6zuve751AADbkplAAAAAAAMwE2ir+QQPAAAAWAAzgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAANqyqLqmqu6vqcFVdu8rr/6Kq7qyqD1XV/1VV5y2iTgAAGJkQCIANqapdSa5PcmmSC5NcVVUXrhj2/iQHuvs7krwtyb/Z2ioBAAAhEAAbdVGSw919T3c/kOSmJFfMDujud3X3F6dPb0uyd4trBGCBzBgFWA5CIAA26pwkR2aeH50eO5UXJvk/N7UiAJaGGaMAy2NNIZDkHoDTqFWO9aoDq56f5ECSnz3F61dX1aGqOnTs2LE5lgjAApkxCrAkzhgCSe4BOIOjSfbNPN+b5L6Vg6rquUn+lySXd/eXV7tQd9/Q3Qe6+8CePXs2pVgAttzcZoz6sABgY9YyE0hyv+SqHv4XwBzdnuSCqjq/qs5KcmWSg7MDqurpSV6fSQD0iQXUCMDizG3GqA8LADZmLSGQ5B7WQTjHKLr7wSTXJLk1yV1Jbu7uO6rquqq6fDrsZ5M8Nsn/XlUfqKqDp7gcADvP3GaMArAxu9cwZj3J/Xeu9np335DkhiQ5cODAqtcAYPvp7luS3LLi2CtmHj93y4sCYFl8bcZokj/NZMbo980OmJkxeokZowCbZy0h0MNN7r9Tcg8AACSTGaNVdXzG6K4kbzw+YzTJoe4+mBNnjCbJvd19+SkvCsC6rCUEktwDAADrZsYowHI4455A9noAAAAA2P7WMhNIcg8AAABbZL03jWk773IGa7k7GAAAAADbnBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAAuxddAAAwo2p953XPtw4AAHYcM4EAAAAABiAEAgAAABiA5WDAplv36pb5lgEAADA0M4EAAAAABmAmEAAAALC0rCyYHzOBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAHsXnQBwIyq9Z3XPd86AAAA2HHMBAIAAAAYgBAIAAAAYABCIAAAAIAB2BMIAAAAdoL17DFqf9GhmAkEAAAAMAAhEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADEAIBAAAADAAIRAAAADAAIRAAAAAAAMQAgEAAAAMQAgEAAAAMAAhEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADEAIBAAAADAAIRAAAADAAIRAAAAAAAMQAgEAAAAMQAgEAAAAMAAhEAAAAMAA1hQCVdUlVXV3VR2uqmtXef0RVfUb09ffW1X7510oAMtLnwDgdPQJgOVwxhCoqnYluT7JpUkuTHJVVV24YtgLk3y6u/9KktckefW8CwVgOekTAJyOPgGwPNYyE+iiJIe7+57ufiDJTUmuWDHmiiRvmT5+W5LnVFXNr0wAlpg+AcDp6BMAS2L3Gsack+TIzPOjSZ55qjHd/WBVfTbJNyb55Oygqro6ydXTp5+vqrvXU/QZnL3y+37t+6/nanPuPeu+2vrrWPX9WEAdq19u3Seu68z5/t1Yfx2nvty6T/R+zKGGZfrZcd5GTl6AHdEntvXf+8TPgZNO9H6ceOISvB+b8Pu8PrFt6BNztK1/Dqy/jlNfbt0nej/mUMMy/Vxc/ZLrOmlHvB+n7BNrCYFW+869jjHp7huS3LCG77luVXWouw9s5vfYTrwfD/FenMj7cSLvx4boE9uU9+JE3o8TeT9O5P3YEH1im/JenMj7cSLvx4m2y/uxluVgR5Psm3m+N8l9pxpTVbuTPCHJ/fMoEIClp08AcDr6BMCSWEsIdHuSC6rq/Ko6K8mVSQ6uGHMwyT+ePv57SX6vu09K7gHYkfQJAE5HnwBYEmdcDjZdk3tNkluT7Eryxu6+o6quS3Kouw8m+ZUkN1bV4UwS+ys3s+gz2NTpoduQ9+Mh3osTeT9O5P1YJ31iW/NenMj7cSLvx4m8H+ukT2xr3osTeT9O5P040bZ4P0rADgAAALDzrWU5GAAAAADbnBAIAAAAYAA7JgSqqkuq6u6qOlxV1y66nkWqqn1V9a6ququq7qiqH110TcugqnZV1fur6h2LrmXRquqJVfW2qvrj6d+T/2bRNS1SVf3Y9N/KH1XVW6vqkYuuifnTJx6iT6xOn3iIPvEQPWIc+sRD9ImT6REn0icest36xI4IgapqV5Lrk1ya5MIkV1XVhYutaqEeTPLS7n5qkmcl+eHB34/jfjTJXYsuYkn8QpL/2N3/dZK/loHfl6o6J8mPJDnQ3d+eyYaVi9yMkk2gT5xEn1idPvEQfSJ6xEj0iZPoEyfTI06kT2R79okdEQIluSjJ4e6+p7sfSHJTkisWXNPCdPfHuvu/TB9/LpN/kOcstqrFqqq9Sb47yRsWXcuiVdXjk/yNTO7Cke5+oLs/s9iqFm53kkdV1e4kj05y34LrYf70iRn6xMn0iYfoEyfRI8agT8zQJ06kR5xInzjJtuoTOyUEOifJkZnnRzPwD6lZVbU/ydOTvHexlSzczyf5n5N8ddGFLIG/nORYkjdNp7S+oaoes+iiFqW7/zTJzyW5N8nHkny2u9+52KrYBPrEKegTX6NPPESfmNIjhqJPnII+kUSPWEmfmNqOfWKnhEC1yrHe8iqWTFU9Nsl/SPLPu/vPFl3PolTV9yT5RHe/b9G1LIndSZ6R5HXd/fQkX0gy7Lr3qvqGTD7pOz/JNyd5TFU9f7FVsQn0iVXoExP6xEn0iSk9Yij6xCr0CT3iFPSJqe3YJ3ZKCHQ0yb6Z53uz5FOwNltVfX0mP7B/rbvfvuh6FuziJJdX1Ucymdr7t6rqVxdb0kIdTXK0u49/mvO2TH6Ij+q5ST7c3ce6+ytJ3p7kv11wTcyfPrGCPnECfeJE+sRD9Ihx6BMr6BNfo0ecTJ94yLbrEzslBLo9yQVVdX5VnZXJRkwHF1zTwlRVZbI+867u/t8WXc+idffLuntvd+/P5O/G73X3Uqezm6m7P57kSFV96/TQc5LcucCSFu3eJM+qqkdP/+08J4NubLfD6RMz9IkT6RMn0idOoEeMQ5+YoU88RI84mT5xgm3XJ3YvuoB56O4Hq+qaJLdmshv3G7v7jgWXtUgXJ/mHSf7vqvrA9NhPdvctC6yJ5fKSJL82/U/OPUl+YMH1LEx3v7eq3pbkv2RyJ4z3J7lhsVUxb/rESfQJzkSfiB4xEn3iJPoEZ6JPZHv2ieoefqkrAAAAwI63U5aDAQAAAHAaQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgdqSq+tWq+lhV/VlV/UlV/dCiawJgsarqI1X1QFWdveL4B6qqq2r/YioDYNlU1e9X1Z9X1eenX3cvuiaYByEQO9XPJNnf3Y9PcnmSn66qv75yUFXt3vLKAFikDye56viTqvqrSR61uHIAWGLXdPdjp1/futoAv0+w3QiB2JG6+47u/vLxp9Ovb6mqZ1fV0ar6iar6eJI3JUlVfc/0k+DPVNUfVtV3HL/W9JPjl1XVnVX16ap6U1U9cuv/VADMwY1J/tHM83+c5N8ff1JVj6iqn6uqe6vq/6uqX6qqR01f+4aqekdVHZv2g3dU1d6Zc3+/qv5lVb27qj5XVe9cOesIgO2tql4w/Tn/mqq6P8krp8d/sKrumvaHW6vqvJlzuqp+pKruqapPVtXPVpXfxVkIf/HYsarqF6vqi0n+OMnHktwyfembkjwpyXlJrq6qZyR5Y5IXJ/nGJK9PcrCqHjFzue9P8l1JviXJU5K8fEv+EADM221JHl9VT62qXUn+xyS/OvP6qzP5Of+0JH8lyTlJXjF97esy+fDgvCTnJvlSkteuuP73JfmBJE9OclaS/2lz/hgAbIGfmYY2766qZ88cf2aSezL5Wf+qqvreJD+Z5O8m2ZPkD5K8dcW1/k6SA0mekeSKJD+4ybXDqoRA7Fjd/c+SPC7Jf5fk7UmOzwz6apKf6u4vd/eXkrwoyeu7+73d/Rfd/Zbp2AO7L2gAACAASURBVGfNXO613X2ku+9P8qrMLCUAYNs5PhvoeZl8UPCn0+OVSU/4se6+v7s/l+RfJbkySbr7U939H7r7i9PXXpXkO1dc+03d/SfT/nJzJmESANvPTyT5y5l8GHBDkv+jqr5l+tp93f3vuvvB6c/7Fyf5me6+q7sfzKR3PG12NlCSV097y71Jfj5+n2BBhEDsaNNQ5z8n2Zvkn04PH+vuP58Zdl6Sl06Xgn2mqj6TZF+Sb54Zc2Tm8UdXvAbA9nJjJjN2XpCZpWCZfHr76CTvm+kH/3F6PFX16Kp6fVV9tKr+LMl/SvLE6Yyi4z4+8/iLSR67eX8MADbL9APiz00/OH5LkncnuWz68pEVw89L8gszveP+TD5YOGdmjN8nWApCIEaxO5OlXMlkf6BZR5K8qrufOPP16O6encK5b+bxuUnu28RaAdhE3f3RTDaIviyTmaLHfTKTJV7fNtMPntDdx4Oclyb51iTPnN544G9Mj9cWlQ7A4nQe+nm/2u8TL17x+8SjuvsPZ8b4fYKlIARix6mqJ1fVlVX12KraVVXflcl0y987xSm/nOSfVNUza+IxVfXdVfW4mTE/XFV7q+pJmaz3/Y1N/mMAsLlemORvdfcXZo59NZOe8JqqenKSVNU50z6STJYYfynJZ6b94Ke2smAAtkZVPbGqvquqHllVu6vq+zMJ/m89xSm/lORlVfVt0/OfUFV/f8WYH5/eYGBfkh+N3ydYECEQO1FnsvTraJJPJ/m5JP+8u3971cHdhzLZA+K10/GHM1kiMOvXk7wzkw3g7kny05tROABbo7v/3+nP/5V+IpM+cNt0ydfvZjL7J5ns4fCoTGYM3ZbJUjEAdp6vz+T/+8cy+Zn/kiTf2913rza4u38zkxsL3DTtHX+U5NIVw347yfuSfCDJ7yT5lc0pHU6vulfOZANmVdVHkvxQd//uomsBAAC2l6rqJBd09+FF1wJmAgEAAAAMQAgEAAAAMADLwQAAAAAGYCYQAAAAwAB2L+obn3322b1///5FfXuApfW+973vk929Z9F1LJo+AbA6fWJCnwBY3en6xMJCoP379+fQodXuzAowtqr66KJrWAb6BMDq9IkJfQJgdafrE5aDAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADEAIBAAAADAAIRAAAADAAIRAAAAAAAMQAgEAAAAM4IwhUFW9sao+UVV/dIrXq6r+bVUdrqoPVdUz5l8mAAAAABuxlplAb05yyWlevzTJBdOvq5O8buNlAQAAADBPZwyBuvs/Jbn/NEOuSPLve+K2JE+sqv9qXgUCAAAAsHHz2BPonCRHZp4fnR47SVVdXVWHqurQsWPH5vCtAQAAAFiLeYRAtcqxXm1gd9/Q3Qe6+8CePXvm8K0BAAAAWIvdc7jG0ST7Zp7vTXLfHK4LLEqtlu2uQa+a/wKw06ynT+gRwE7m/89sE/OYCXQwyT+a3iXsWUk+290fm8N1AQAAAJiTM84Eqqq3Jnl2krOr6miSn0ry9UnS3b+U5JYklyU5nOSLSX5gs4oFAAAAYH3OGAJ191VneL2T/PDcKgIAAABg7uaxHAwAAACAJScEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAA2rKouqaq7q+pwVV27yuvnVtW7qur9VfWhqrpsEXUCAMDIdi+6AAC2t6raleT6JM9LcjTJ7VV1sLvvnBn28iQ3d/frqurCJLck2b/lxbJ2Ves7r3u+dQAwBG0HtoaZQABs1EVJDnf3Pd39QJKbklyxYkwnefz08ROS3LeF9QEAADETCICNOyfJkZnnR5M8c8WYVyZ5Z1W9JMljkjx3a0oDAACOMxMIgI1abQL3ysnZVyV5c3fvTXJZkhur6qQeVFVXV9Whqjp07NixTSgVAADGJQQCYKOOJtk383xvTl7u9cIkNydJd78nySOTnL3yQt19Q3cf6O4De/bs2aRyAQBgTEIgADbq9iQXVNX5VXVWkiuTHFwx5t4kz0mSqnpqJiGQqT6wYFXr+wIAtichEAAb0t0PJrkmya1J7srkLmB3VNV1VXX5dNhLk7yoqj6Y5K1JXtDtfh4Ao6iqS6rq7qo6XFXXrvL6uVX1rqp6f1V9qKouW0SdADudjaEB2LDuviWT277PHnvFzOM7k1y81XUBsHhVtSvJ9Umel8kS4tur6uC0Nxz38kw+RHhdVV2YSU/Zv+XFAuxwZgIBAACb6aIkh7v7nu5+IMlNSa5YMaaTPH76+Ak5eW85AOZACAQAAGymc5IcmXl+dHps1iuTPL+qjmYyC+glq13IXSQBNkYIBAAAbKbVthNfuS/cVUne3N17k1yW5MaqOul3FXeRhG3CXQeWlhAIAADYTEeT7Jt5vjcnL/d6YZKbk6S735PJXSTP3pLqAAYiBGLHEToDACyV25NcUFXnV9VZSa5McnDFmHuTPCdJquqpmYRA1nsBzJkQCAAA2DTd/WCSa5LcmuSuTO4CdkdVXVdVl0+HvTTJi6rqg0nemuQF3b1yyRgAG+QW8QAAwKbq7lsy2fB59tgrZh7fmeTira4LYDRmAgEAAAAMQAgEAAAAMAAhEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADGD3ogsAADilqvWd1z3fOgAAdgAzgQAAAAAGYCYQAAAAD4+ZmrAtmQkEAAAAMIA1hUBVdUlV3V1Vh6vq2lVeP7eq3lVV76+qD1XVZfMvFQAAAID1OmMIVFW7klyf5NIkFya5qqouXDHs5Ulu7u6nJ7kyyS/Ou1AAAAAA1m8tM4EuSnK4u+/p7geS3JTkihVjOsnjp4+fkOS++ZUIAAAAwEatJQQ6J8mRmedHp8dmvTLJ86vqaJJbkrxktQtV1dVVdaiqDh07dmwd5QIAAACwHmsJgVbb9n3llu5XJXlzd+9NclmSG6vqpGt39w3dfaC7D+zZs+fhV8vOU7W+L1gHf90AAICRrSUEOppk38zzvTl5udcLk9ycJN39niSPTHL2PAoEAAAAYOPWEgLdnuSCqjq/qs7KZOPngyvG3JvkOUlSVU/NJASy3gsAAABgSew+04DufrCqrklya5JdSd7Y3XdU1XVJDnX3wSQvTfLLVfVjmSwVe0F3r1wyBgAMbD3LK/1nAgBgfs4YAiVJd9+SyYbPs8deMfP4ziQXz7c0AAAAAOZlLcvBAAAAANjmhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwADWdHcwYHtaz+2YE7dkBgAA2ImEQADAUNYTkLd0HGAIPkQ9kfdj57EcDAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABuEU8AADb03ruXdxuXAzAuMwEAgAAABiAEAgAAABgAJaDAQBA1re6LLHCDIDtw0wgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGIASCJKla3xeQJKmqS6rq7qo6XFXXnmLMP6iqO6vqjqr69a2uEQAARrd70QUAsL1V1a4k1yd5XpKjSW6vqoPdfefMmAuSvCzJxd396ap68mKqBQCAcQmBRrXeWSzdc73kqa8GbCMXJTnc3fckSVXdlOSKJHfOjHlRkuu7+9NJ0t2f2PIqAQBgcJaDAbBR5yQ5MvP86PTYrKckeUpVvbuqbquqS1a7UFVdXVWHqurQsWPH1l2Q1Z0AAHAyIRAAG7VahLJyot/uJBckeXaSq5K8oaqeeNJJ3Td094HuPrBnz565FwrAYtg7DmA5WA4GwEYdTbJv5vneJPetMua27v5Kkg9X1d2ZhEK3b02JACyKveOAnWITdlXZcmYCAbBRtye5oKrOr6qzklyZ5OCKMb+V5G8mSVWdncnysHu2tEoAFuVre8d19wNJju8dN8vecQBbQAgEwIZ094NJrklya5K7ktzc3XdU1f/P3h1HWX6e9WH/PuyiOBiDIRoSsruy1HSdsrg04swRbtwEEZvDyqRST+tytKkLJsbbtMgGbGjklAoqklNwe3AhCMLiGhsTWygOB7buNqIpdkMocrXExkFSlW7XxjsIjgcjmwQw8sLTP2ZWujs7uzM7c+/cmXk/n3Pu0f397nvvPHu1e5+Z77zv+7u/qu5cHfZwkk9W1eNJ3p/ku7r7k/OpGIAdNrW94wDYHsvBANi27j6T5Myac/dN3O8kb1y9ATCW69077nCSX6qql3T3py57oaqTSU4myU033TT9SgH2OTOBAACAWdrs3nE/392f7e6PJrm0d9xlXEAAYHuEQAAAwCzZO47ZqdraDQYlBAIAAGbG3nEAu4c9gQAAgJmydxzA7mAmEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADEAIBAAAADCATYVAVXW8qp6sqnNVde9VxnxDVT1eVY9V1bunWyYAAAAA23FwowFVdSDJA0m+NslSkker6nR3Pz4x5miSNyd5WXc/XVVfMquCAQAAALh+m5kJdFuSc919vrufSfJgkrvWjHldkge6++kk6e5PTLdMAAAAALZjMyHQoSQXJo6XVs9NenGSF1fVL1fVI1V1fFoFAgAAALB9Gy4HS1LrnOt1XudoktuTHE7yS1X1ku7+1GUvVHUyyckkuemmm667WAAAgO2q9X7C2UCv/QkIYA/azEygpSRHJo4PJ3lqnTE/392f7e6PJnkyK6HQZbr7VHcvdvfiwsLCVmsGRlF1/TcAAADWtZkQ6NEkR6vqlqq6IcndSU6vGfNzSb4mSarqxqwsDzs/zUIBAAAA2LoNQ6DuvpjkniQPJ3kiyUPd/VhV3V9Vd64OezjJJ6vq8STvT/Jd3f3JWRUNAAAAwPXZzJ5A6e4zSc6sOXffxP1O8sbVGwAAAAC7zGaWgwEAAACwxwmBAAAAAAawqeVgu81WLwDkso4AAADAqMwEAgAAABjAnpwJBAAAsKMsR4C9Zyv/bvf5v1kzgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGcHDeBQAAAADsW1XX/5zu6dcRIRAAAMBc7KKfC4FBWA4GAAAAMAAhEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADEAIBAAAADAAIRAAAADAAIRAAAAAAAMQAgEAAAAMQAgEAAAAMAAhEAAAAMAAhEAAAAAAAzg47wL2sqrrf0739OsAAGZsK00/0fgBgF1FCAQAiR/yAQDY9ywHAwAAABiAEAiAbauq41X1ZFWdq6p7rzHuVVXVVbW4k/XNS9X13wAAYFaEQABsS1UdSPJAkjuSHEtyoqqOrTPuBUnekOSDO1shAACQCIEA2L7bkpzr7vPd/UySB5Pctc6470vyliSf2cniAACAFUIgALbrUJILE8dLq+eeVVW3JjnS3e+71gtV1cmqOltVZ5eXl6dfKQBzYdkwwO4gBAJgu9bbyebZS2ZV1eckeWuSN230Qt19qrsXu3txYWFhiiUCMC+WDQPsHkIgALZrKcmRiePDSZ6aOH5Bkpck+UBVfSzJS5Oc9ltegGFYNgywSwiBANiuR5McrapbquqGJHcnOX3pwe7+dHff2N03d/fNSR5Jcmd3n51PuQDssKktGwZge4RAAGxLd19Mck+Sh5M8keSh7n6squ6vqjvnWx0Au8DUlg3bOw5gew7OuwAA9r7uPpPkzJpz911l7O07URMAu8b1LBtOkj+XlWXDV8wa7e5TSU4lyeLiYgeA62ImEAAAMEuWDQPsEkIgAABgZiwbBtg9LAcDAABmyrJhgN3BTCAAAACAAQiBAAAAAAawqRCoqo5X1ZNVda6q7r3GuFdVVVfV4vRKBAAAAGC7NgyBqupAkgeS3JHkWJITVXVsnXEvSPKGJB+cdpEAAAAAbM9mZgLdluRcd5/v7meSPJjkrnXGfV+StyT5zBTrAwAAAGAKNhMCHUpyYeJ4afXcs6rq1iRHuvt9U6wNYHeouv4bAABs0Va+/fQtKJuxmRBovb9K/eyDVZ+T5K1J3rThC1WdrKqzVXV2eXl581UCAAAAsC2bCYGWkhyZOD6c5KmJ4xckeUmSD1TVx5K8NMnp9TaH7u5T3b3Y3YsLCwtbrxoAAACA63JwE2MeTXK0qm5J8ptJ7k7yNy492N2fTnLjpeOq+kCS7+zus9MtFQBgf9jqlP3ujccAAFzNhjOBuvtiknuSPJzkiSQPdfdjVXV/Vd056wIBAAAA2L7NzARKd59JcmbNufuuMvb27ZcFAAAAwDRtKgRiisz/BgDYX7by/Z3v7QCYg81sDA0AAADAHicEAgAAABiA5WAAsM9taaXK9MsAYBpsLwFsg5lAAAAAAAMQAgEAAAAMQAgEAAAAMAAhEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADODjvAgAAAACupmprz+vplrEvCIH2ga38g/CPAQAAAMZiORgAAADAAIRAAAAAAAMQAgEAAAAMQAgEAAAAMAAhEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADODgvAvYUVXX/5zu6dcBAAAAsMPMBAIAAAAYwFgzgQAAALjMlhZMTL8MpsHqFzZgJhAAAADAAIRAAAAAAAMQAgEAAAAMQAgEAAAAMAAhEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADEAIBAAAADCAg/MuANj/qrb2vJ5uGQAAAEMzEwgAAABgAGYCAcBusuWpc+bOAQBwbWYCAQAAAAxACATAtlXV8ap6sqrOVdW96zz+xqp6vKo+UlX/R1W9aB51ArtT1dZuAMD1EQIBsC1VdSDJA0nuSHIsyYmqOrZm2IeSLHb3VyR5b5K37GyVAACAEAiA7botybnuPt/dzyR5MMldkwO6+/3d/Qerh48kObzDNQIwR2aMAuwOQiAAtutQkgsTx0ur567mtUn+t5lWBMCuYcYowO4hBAJgu9bbmWPdS1VV1auTLCb5H67y+MmqOltVZ5eXl6dYIgBzZMYowC4hBAJgu5aSHJk4PpzkqbWDquoVSf6bJHd29x+t90Ldfaq7F7t7cWFhYSbFArDjpjZj1C8LALZHCATAdj2a5GhV3VJVNyS5O8npyQFVdWuSH89KAPSJOdQIwPxMbcaoXxYAbM/BeRcAwN7W3Rer6p4kDyc5kOTt3f1YVd2f5Gx3n87KN/Ofn+Qf1cp1nT/e3XfOrWgAdtL1zhj96qvNGAVgezYVAlXV8SQ/lJVv7t/W3d+/5vE3JvmWJBeTLCf5m939G1OuFYBdqrvPJDmz5tx9E/dfseNFAbBbPDtjNMlvZmXG6N+YHDAxY/S4GaMAs7PhcjC7+QMAAFvV3ReTXJox+kSShy7NGK2qS7NCJ2eMfriqTl/l5QDYhs3MBHp2N/8kqapLu/k/fmlAd79/YvwjSV49zSIBAIC9y4xRgN1hMxtD280fAAAAYI/bTAhkN38AAACAPW4zy8Hs5g8AAACwx21mJtCzu/lX1Q1Z2c3/so3aJnbzv9Nu/rCi6vpvAAAAMCsbhkB28wcAAADY+zazHMxu/gAAAAB73GaWgwEAAACwxwmBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGIAQCAAAAGMDBeRcAAMAmVW3ted3TrQMA2JPMBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABrCpEKiqjlfVk1V1rqruXefxP1VVP7P6+Aer6uZpFwrA7qVPAHAt+gTA7rBhCFRVB5I8kOSOJMeSnKiqY2uGvTbJ0939byd5a5IfmHahMISqrd1gjvQJAK5FnwDYPTYzE+i2JOe6+3x3P5PkwSR3rRlzV5J3rt5/b5KXV/nJFGAQ+gQA16JPAOwSBzcx5lCSCxPHS0m+6mpjuvtiVX06yZ9J8juTg6rqZJKTq4f/pqqe3ErRG7hx7dd99utv5dWm3Hu2/Gpbr2Pd92MOdaz/clt+4paeOd2/G1uv4+ovt+Unej+mUMNu+ux40XaePAf7ok/s6b/3ic+BK57o/bj8ibvg/ZjBz/P6xJ6hT0zRnv4c2HodV3+5LT/R+zGFGnbT5+L6L7mlJ+2L9+OqfWIzIdB6X7m3MCbdfSrJqU18zS2rqrPdvTjLr7GXeD+e4724nPfjct6PbdEn9ijvxeW8H5fzflzO+7Et+sQe5b24nPfjct6Py+2V92Mzy8GWkhyZOD6c5Kmrjamqg0m+MMnvTqNAAHY9fQKAa9EnAHaJzYRAjyY5WlW3VNUNSe5OcnrNmNNJvmn1/quS/GJ3X5HcA7Av6RMAXIs+AbBLbLgcbHVN7j1JHk5yIMnbu/uxqro/ydnuPp3kf07yrqo6l5XE/u5ZFr2BmU4P3YO8H8/xXlzO+3E578cW6RN7mvfict6Py3k/Luf92CJ9Yk/zXlzO+3E578fl9sT7UQJ2AAAAgP1vM8vBAAAAANjjhEAAAAAAA9g3IVBVHa+qJ6vqXFXdO+965qmqjlTV+6vqiap6rKq+bd417QZVdaCqPlRV75t3LfNWVS+sqvdW1f+z+vfk3593TfNUVd+x+m/l16vqPVX1vHnXxPTpE8/RJ9anTzxHn3iOHjEOfeI5+sSV9IjL6RPP2Wt9Yl+EQFV1IMkDSe5IcizJiao6Nt+q5upikjd195cleWmSbx38/bjk25I8Me8idokfSvJPuvvfSfLvZeD3paoOJXlDksXufklWNqyc52aUzIA+cQV9Yn36xHP0iegRI9EnrqBPXEmPuJw+kb3ZJ/ZFCJTktiTnuvt8dz+T5MEkd825prnp7t/q7n+xev9fZ+Uf5KH5VjVfVXU4ydcnedu8a5m3qvqCJH81K1fhSHc/092fmm9Vc3cwyZ+uqoNJPi/JU3Ouh+nTJyboE1fSJ56jT1xBjxiDPjFBn7icHnE5feIKe6pP7JcQ6FCSCxPHSxn4Q2pSVd2c5NYkH5xvJXP3PyX5r5P8ybwL2QX+rSTLSX5ydUrr26rq+fMual66+zeT/I9JPp7kt5J8urt/Yb5VMQP6xFXoE8/SJ56jT6zSI4aiT1yFPpFEj1hLn1i1F/vEfgmBap1zveNV7DJV9flJ/nGSb+/u35t3PfNSVX89ySe6+1fnXcsucTDJVyb5se6+NcnvJxl23XtVfVFWftN3S5I/n+T5VfXq+VbFDOgT69AnVugTV9AnVukRQ9En1qFP6BFXoU+s2ot9Yr+EQEtJjkwcH84un4I1a1X1uVn5wP6H3f2z865nzl6W5M6q+lhWpvb+tar66fmWNFdLSZa6+9Jvc96blQ/xUb0iyUe7e7m7P5vkZ5P85TnXxPTpE2voE5fRJy6nTzxHjxiHPrGGPvEsPeJK+sRz9lyf2C8h0KNJjlbVLVV1Q1Y2Yjo955rmpqoqK+szn+juH5x3PfPW3W/u7sPdfXNW/m78Ynfv6nR2lrr7t5NcqKq/uHrq5Uken2NJ8/bxJC+tqs9b/bfz8gy6sd0+p09M0Ccup09cTp+4jB4xDn1igj7xHD3iSvrEZfZcnzg47wKmobsvVtU9SR7Oym7cb+/ux+Zc1jy9LMl/nuRfVtWHV8/9ne4+M8ea2F1en+Qfrn6Tcz7JN8+5nrnp7g9W1XuT/IusXAnjQ0lOzbcqpk2fuII+wUb0iegRI9EnrqBPsBF9InuzT1T38EtdAQAAAPa9/bIcDAAAAIBrEAIBAAAADEAIBAAAADAAIRAAAADAAIRAAAAAAAMQAgEAAAAMQAgEAAAAMAAhEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADEAIBAAAADAAIRAAAADAAIRAAAAAAAMQAgEAAAAMQAgEAAAAMAAhEAAAAMAAhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADEAIBAAAADAAIRAAAADAAIRAAAAAAAMQAgEAAAAMQAgEAAAAMAAhEAAAAMAAhEAAAAAAAxACsW9V1d1V9URV/X5V/X9V9VfmXRMA81dV/2bN7Y+r6u/Puy4Ado+qurmqzlTV01X121X1I1V1cN51wXYJgdiXquprk/xAdMvwgwAAIABJREFUkm9O8oIkfzXJ+XXG+SAHGEx3f/6lW5I/m+QPk/yj9cbqEwDD+tEkn0jypUn+UpKvTvJfrR2kT7DXCIHYr/67JPd39yPd/Sfd/Zvd/ZtVdXtVLVXV366q307yk0lSVX+9qj5cVZ+qqv+rqr7i0gtV1ceq6s1V9fjqbwJ+sqqeN68/GABT9aqsfJP/S0miTwCw6pYkD3X3Z7r7t5P8kyRfvjpDqKvqtVX18SS/mCRV9dLV/vCpqvq1qrr90gtV1Qeq6r+vqv+7qj5dVT9fVV88lz8VwxMCse9U1YEki0kWqurc6jfzP1JVf3p1yJ9L8sVJXpTkZFV9ZZK3J/kvkvyZJD+e5HRV/amJl/3Pknxdkr+Q5MVJvntn/jQAzNg3Jfmp7u6Jc/oEAD+U5O6q+ryqOpTkjqwEQZd8dZIvS/J1q4//r0n+blb6x3cm+cdVtTAx/huT/M0kfz7JxSQ/PPs/AlxJCMR+9GeTfG5Wfrv7V7IyffPWPPcN+Z8k+Z7u/qPu/sMkr0vy4939we7+4+5+Z5I/SvLSidf8ke6+0N2/m+TvJTmxQ38WAGakqm7Kyjfx71zzkD4BwP+Z5MuT/F6SpSRnk/zcxOPf292/v9onXp3kTHefWV2F8L+vjn/lxPh3dfevd/fvJ/lvk3zD6i+vYUcJgdiP/nD1v3+/u3+ru38nyQ/muQ/h5e7+zMT4FyV50+rUzU9V1aeSHMlKSn/JhYn7v7HmMQD2pm9M8s+7+6NrzusTAAOrqs9J8nCSn03y/CQ3JvmirOw5esnk5/6Lkvyna/rEf5CV/YTWG/8bWfml9Y0zKB+uSQjEvtPdT2clre+rDVlzfCHJ3+vuF07cPq+73zMx5sjE/ZuSPDW9igGYk2/MlbOAEn0CYHRfnJXP9R9ZnRX6yazsETc5s2eyV1zIykyfyT7x/O7+/okxa/vEZ5P8zozqh6sSArFf/WSS11fVl1TVFyX59iTvu8rYn0jyt6rqq2rF86vq66vqBRNjvrWqDq9u4PZ3kvzMbMsHYJaq6i8nOZSrXBVsDX0CYCCrKwk+muS/rKqDVfXCrOwh92tXecpPJ/kPq+rrqupAVT1v9UIDhyfGvLqqjlXV5yW5P8l7u/uPZ/oHgXUIgdivvi/Jo0n+VZInknwoK3s0XKG7z2Zlv4cfSfJ0knNJXrNm2LuT/EJWLjN/PiubvgGwd31Tkp/t7n+90UB9AmBI/3GS40mWs/K5fzHJd6w3sLsvJLkrK78EWM7KzKDvyuU/b78ryTuS/HaS5yV5w4zqhmuqyy+GAaxVVR9L8i3d/U/nXQsAu48+AcC1VNUHkvx0d79t3rWAmUAAAAAAAxACAQAAAAzAcjAAAACAAZgJBAAAADCAg/P6wjfeeGPffPPN8/ryALvWr/7qr/5Ody/Mu4550ycA1qdPrNAnANZ3rT4xtxDo5ptvztmzZ+f15QF2rar6jXnXsBvoEwDr0ydW6BMA67tWn7AcDAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABrBhCFRVb6+qT1TVr1/l8aqqH66qc1X1kar6yumXCQAAAMB2bGYm0DuSHL/G43ckObp6O5nkx7ZfFgAAAADTtGEI1N3/LMnvXmPIXUl+qlc8kuSFVfWl0yoQAAAAgO2bxp5Ah5JcmDheWj13hao6WVVnq+rs8vLyFL40AAAAAJsxjRCo1jnX6w3s7lPdvdjdiwsLC1P40gAAAABsxjRCoKUkRyaODyd5agqvCwAAAMCUTCMEOp3kG1evEvbSJJ/u7t+awuvCzqna2g0ARqRnAlPm23HYGQc3GlBV70lye5Ibq2opyfck+dwk6e5/kORMklcmOZfkD5J886yKBQAAAGBrNgyBuvvEBo93km+dWkUAAAAATN00loMBAAAAsMsJgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAWx4dTAAAAC4TNXWntc93TqA62ImEAAAAMAAhEAAAAAAAxACAQAAM1VVx6vqyao6V1X3rvP4TVX1/qr6UFV9pKpeOY86AfY7IRAAADAzVXUgyQNJ7khyLMmJqjq2Zth3J3mou29NcneSH93ZKmGbqrZ2gx0mBAIAAGbptiTnuvt8dz+T5MEkd60Z00m+YPX+FyZ5agfrAxiGEAgAAJilQ0kuTBwvrZ6b9L1JXl1VS0nOJHn9ei9UVSer6mxVnV1eXp5FrQD7mhAIAACYpfXWvKy9TviJJO/o7sNJXpnkXVV1xc8q3X2quxe7e3FhYWEGpQLsb0IgAABglpaSHJk4Ppwrl3u9NslDSdLdv5LkeUlu3JHqAAYiBAIAAGbp0SRHq+qWqrohKxs/n14z5uNJXp4kVfVlWQmBrPcCmDIhEAAAMDPdfTHJPUkeTvJEVq4C9lhV3V9Vd64Oe1OS11XVryV5T5LXdPfaJWMAbNPBeRcAAADsb919JisbPk+eu2/i/uNJXrbTdQGMxkwgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCIBtqaq3V9UnqurXr/J4VdUPV9W5qvpIVX3lTtcIAAAIgQDYvnckOX6Nx+9IcnT1djLJj+1ATQAAwBpCIAC2pbv/WZLfvcaQu5L8VK94JMkLq+pLd6Y6AADgEiEQALN2KMmFieOl1XNXqKqTVXW2qs4uLy/vSHEAADAKIRAAs1brnOv1Bnb3qe5e7O7FhYWFGZcFAABjEQIBMGtLSY5MHB9O8tScagEAgGEJgQCYtdNJvnH1KmEvTfLp7v6teRcFAACjOTjvAgDY26rqPUluT3JjVS0l+Z4kn5sk3f0PkpxJ8sok55L8QZJvnk+lAAAwNiEQANvS3Sc2eLyTfOsOlQMAAFyF5WAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADcHWwUVVt7Xnd060DgN1JnwAA2HfMBAIAAAAYgJlAwJXMAAAAANh3zAQCAAAAGIAQCAAAAGAAloMxNVtZQWT1EAAAAOwMM4EAAAAABiAEAgAAABiAEAgAAABgAPYEAgAAAKbHhrG7lplAAADATFXV8ap6sqrOVdW96zz+1qr68OrtX1XVp+ZRJ8B+ZyYQAAAwM1V1IMkDSb42yVKSR6vqdHc/fmlMd3/HxPjXJ7l1xwsFGICZQAAAwCzdluRcd5/v7meSPJjkrmuMP5HkPTtSGcBghEAAAMAsHUpyYeJ4afXcFarqRUluSfKLO1AXwHCEQAAAwCytt0Ps1XaAvTvJe7v7j9d9oaqTVXW2qs4uLy9PrUCAUQiBAACAWVpKcmTi+HCSp64y9u5cYylYd5/q7sXuXlxYWJhiiQBjEAIBAACz9GiSo1V1S1XdkJWg5/TaQVX1F5N8UZJf2eH6AIYhBAIAAGamuy8muSfJw0meSPJQdz9WVfdX1Z0TQ08kebC7r7ZUDIBt2tQl4qvqeJIfSnIgydu6+/vXPH5TkncmeeHqmHu7+8yUawUAAPag1Z8Nzqw5d9+a4+/dyZoARrThTKCqOpDkgSR3JDmW5ERVHVsz7LuzkujfmpXpnT867UIBAAAA2LrNLAe7Lcm57j7f3c8keTDJXWvGdJIvWL3/hbn6Rm8AAAAAzMFmloMdSnJh4ngpyVetGfO9SX6hql6f5PlJXjGV6gAAAACYis3MBKp1zq3drO1Eknd09+Ekr0zyrqq64rWr6mRVna2qs8vLy9dfLQAAAABbspkQaCnJkYnjw7lyuddrkzyUJN39K0mel+TGtS/U3ae6e7G7FxcWFrZWMQAAAADXbTMh0KNJjlbVLVV1Q1Y2fj69ZszHk7w8Sarqy7ISApnqAwAAALBLbBgCdffFJPckeTjJE1m5CthjVXV/Vd25OuxNSV5XVb+W5D1JXtPda5eMAQAAADAnm9kYOt19JsmZNefum7j/eJKXTbc0AAAAAKZlM8vBAAAAANjjhEAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADODgvAsAAAAAdp+qrT2vp1sGU2QmEAAAAMAAhEAAbFtVHa+qJ6vqXFXdu87jN1XV+6vqQ1X1kap65TzqBACAkQmBANiWqjqQ5IEkdyQ5luREVR1bM+y7kzzU3bcmuTvJj+5slQAAgBAIgO26Lcm57j7f3c8keTDJXWvGdJIvWL3/hUme2sH6AACACIEA2L5DSS5MHC+tnpv0vUleXVVLSc4kef16L1RVJ6vqbFWdXV5enkWtAAAwLCEQANu13nUj1l4U4kSSd3T34SSvTPKuqrqiB3X3qe5e7O7FhYWFGZQKAADjEgIBsF1LSY5MHB/Olcu9XpvkoSTp7l9J8rwkN+5IdQAAQBIhEADb92iSo1V1S1XdkJWNn0+vGfPxJC9Pkqr6sqyEQNZ7AQDADjo47wIA2Nu6+2JV3ZPk4SQHkry9ux+rqvuTnO3u00nelOQnquo7srJU7DXdvXbJGADsiFpvIfMGdC1gK58dye76/BACAbBt3X0mKxs+T567b+L+40lettN1AQAwMInvFSwHAwAAABiAEAgAAABgAEIgAABgpqrqeFU9WVXnqureq4z5hqp6vKoeq6p373SNACOwJxAAADAzVXUgyQNJvjbJUpJHq+r06n5xl8YcTfLmJC/r7qer6kvmUy3A/mYmEAAAMEu3JTnX3ee7+5kkDya5a82Y1yV5oLufTpLu/sQO1wgwBCEQALAjqq7/xmxt5f+J/y9swaEkFyaOl1bPTXpxkhdX1S9X1SNVdXy9F6qqk1V1tqrOLi8vz6hcgP1LCAQAAMzSetHh2mswH0xyNMntSU4keVtVvfCKJ3Wf6u7F7l5cWFiYeqEA+50QCAAAmKWlJEcmjg8neWqdMT/f3Z/t7o8meTIroRAAUyQEAgB2L+uVYD94NMnRqrqlqm5IcneS02vG/FySr0mSqroxK8vDzu9olQADEAIBAAAz090Xk9yT5OEkTyR5qLsfq6r7q+rO1WEPJ/lkVT2e5P1Jvqu7PzmfigH2L5eIBwAAZqq7zyQ5s+bcfRP3O8kbV28AzIiZQAAAAAADMBMIAGAjW91nqNdeAAkAYH7MBAIAAAAYgBAIAAAAYABCIAAAAIAB2BMIAAAAso0t4KZbBsyMmUAAAAAAAxACAQAAAAxACAQAAAAwACEQAAAAwABsDM2+s5XN3GzkBgAAwH5nJhAAAADAAIRAAAAAAAOwHAwAAIC9aSt7QSRJ2xCCMZkJBAAAADAAIRAAAADAAIRAAAAAAAMQAgEAAAAMQAgEAAAAMABXB4N9bMsXS5huGQAAAOwCZgIBAAAADEAIBAAAADAAIRAAAADAAIRAAAAAAAPYVAhUVcer6smqOldV915lzDdU1eNV9VhVvXu6ZQIAAACwHRteHayqDiR5IMnXJllK8mhVne7uxyfGHE3y5iQv6+6nq+pLZlXwytfb2vPaJY8AAICt8EMIsA9sZibQbUnOdff57n4myYNJ7loz5nVJHujup5Okuz8x3TIBAAAA2I7NhECHklyYOF5aPTfpxUleXFW/XFWPVNXx9V6oqk5W1dmqOru8vLy1irej6vpvAADAtmy0vURVvaaqlqvqw6u3b5lHnQD73YbLwZKsl4SsndN4MMnRJLcnOZzkl6rqJd39qcue1H0qyakkWVxcNC8SAAD2uc1sL7HqZ7r7nh0vEGAgm5kJtJTkyMTx4SRPrTPm57v7s9390SRPZiUUAgAAxraZ7SUA2AGbCYEeTXK0qm6pqhuS3J3k9JoxP5fka5Kkqm7MyvKw89MsFIDdy1UkAbiGzWwvkST/SVV9pKreW1VH1nl8/ttLAOxxG4ZA3X0xyT1JHk7yRJKHuvuxqrq/qu5cHfZwkk9W1eNJ3p/ku7r7k7MqGoDdY2Ka/x1JjiU5UVXH1oyZvIrklyf59h0vFIB52cz2Ev9Lkpu7+yuS/NMk71zvhbr7VHcvdvfiwsLClMsE2P82sydQuvtMkjNrzt03cb+TvHH1BsBYnp3mnyRVdWma/+ReD64iCUzfVi7i4XLd87Dh9hJrfoH8E0l+YAfqAhjOZpaDAcC17J+rSAIwCxtuL1FVXzpxeGdWViAAMGWbmgkEANfgKpIAXFV3X6yqS9tLHEjy9kvbSyQ5292nk7xhdauJi0l+N8lr5lYwwD4mBAJguzZ7FclHuvuzST5aVZeuIvnoLAqyQoRr2dLfj+mXwS60lb8bic+PzdjE9hJvzsrecQDMkOVgAGyXq0gCAMAeIAQCYFtcRRIAAPYGy8EA2DZXkQQAgN3PTCAAAACAAQiBAAAAAAYgBAIAAAAYgD2BgGG49C8AADAyM4EAAAAABiAEAgAAABiAEAgAAABgAPYEAtjIVjYTspEQAACwywiBAAAAYBdxQRNmxXIwAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABCIEAAAAABiAEAgAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGcHDeBQAAAIyo6vqf0z39OoBxmAkEAADMVFUdr6onq+pcVd17jXGvqqquqsWdrA9gFEIgAABgZqrqQJIHktyR5FiSE1V1bJ1xL0jyhiQf3NkKAcYhBAIAAGbptiTnuvt8dz+T5MEkd60z7vuSvCXJZ3ayOICRCIEAAIBZOpTkwsTx0uq5Z1XVrUmOdPf7drIwgNHYGBoAkq3tzpnYoRNgY+t9wD774VlVn5PkrUles+ELVZ1McjJJbrrppimVBzAOM4EAAIBZWkpyZOL4cJKnJo5fkOQlST5QVR9L8tIkp9fbHLq7T3X3YncvLiwszLBk2KOqrv/GUIRAAADALD2a5GhV3VJVNyS5O8npSw9296e7+8buvrm7b07ySJI7u/vsfMoF2L+EQMDu5TcZALDndffFJPckeTjJE0ke6u7Hqur+qrpzvtUBjMWeQAAAwEx195kkZ9acu+8qY2/fiZoARiQEAgAAAJiVraxYmNHFRywHAwAAABiAEAgAAABgAEIgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAALhEPADOyi64GCgAAZgIBsH1Vdbyqnqyqc1V17zXGvaqquqoWd7I+2G2qtnYDANgOIRAA21JVB5I8kOSOJMeSnKiqY+uMe0GSNyT54M5WCAAAJEKgbfEbPIAkyW1JznX3+e5+JsmDSe5aZ9z3JXlLks/sZHEAAOxtZtBOjxAIgO06lOTCxPHS6rlnVdWtSY509/uu9UJVdbKqzlbV2eXl5elXCgAAAxMCAbBd6/2e5dntjavqc5K8NcmbNnqh7j7V3YvdvbiwsDDFEgFmyK+nAdgjNhUC2fATgGtYSnJk4vhwkqcmjl+Q5CVJPlBVH0vy0iSn9QoAANhZG4ZANvwEYAOPJjlaVbdU1Q1J7k5y+tKD3f3p7r6xu2/u7puTPJLkzu4+O59yAQBgTJuZCWTDTwCuqrsvJrknycNJnkjyUHc/VlX3V9Wd860OAAC45OAmxqy34edXTQ6Y3PCzqr5zivUBsAd095kkZ9acu+8qY2/fiZoAAIDLbWYm0NQ2/HTVFwAAAID52EwINLUNP131BQAAAGA+NhMC2fATAAAAYI/bcE+g7r5YVZc2/DyQ5O2XNvxMcra7T1/7FWBMtd5Cyg10bzxmL9rKe5FMrDsFAABg2zazMbQNPwEAAAD2uM0sBwMAAABgjxMCAQAAAAxACAQAAAAwACEQAAAAwACEQAAAAAADEAIBAAAADEAIBAAAzFRVHa+qJ6vqXFXdu87jf6uq/mVVfbiq/nlVHZtHnQD7nRAIAACYmao6kOSBJHckOZbkxDohz7u7+9/t7r+U5C1JfnCHywQYghAIAACYpduSnOvu8939TJIHk9w1OaC7f2/i8PlJegfrAxjGwXkXAAAA7GuHklyYOF5K8lVrB1XVtyZ5Y5Ibkvy19V6oqk4mOZkkN91009QLBdjvzAQCAABmqdY5d8VMn+5+oLv/QpK/neS713uh7j7V3YvdvbiwsDDlMgH2PyEQAAAwS0tJjkwcH07y1DXGP5jkP5ppRQCDEgIBAACz9GiSo1V1S1XdkOTuJKcnB1TV0YnDr0/y/+5gfQDDsCcQAAAwM919saruSfJwkgNJ3t7dj1XV/UnOdvfpJPdU1SuSfDbJ00m+aX4VA+xfQiAA2Odqvd04NuCyPMA0dfeZJGfWnLtv4v637XhRAAOyHAwAAABgAEIgAAAAgAEIgQAAAAAGIAQCAAAAGIAQCAAAAGAAQiAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAIABHJx3AQAAjK1qa8/r6ZYBAPueEAgAAGCv2HJqKjYFLAcDAAAAGIIQCAAAAGAAloMBAAAMbCsrzCwug73JTCAAAACAAQiBAAAAAAYgBAIAAAAYgBAIAAAAYABCIAAAAOD/b+/+Yiy9yzqAf5/sWhSIaHBv3F1gDY26MZjq2KAkkNhetNF0byBukxI0TfbGKoqJqZL0oldCjchFY9gABhGtsHKxMYs1gd6W7JYSdFubbFZkx2JYBPEPgbrh8WJOmXNmztBhZs6+Z+b9fJJNzvu+v/PON7+ZnWfOc37veRkBTSAAAACAEdAEAmDXququqnquqq5U1YNzjr+rqp6pqi9U1aer6rVD5AQAgDHTBGJYVTv7ByyNqjqU5NEkdyc5meTeqjq5YdjTSVa6+w1JziV5781NCQAAaAIBsFu3J7nS3Ve7+4UkjyU5NT2gu5/o7m9ONp9McuwmZwQAgNHTBAJgt44muTa1vTrZt5X7k3xq3oGqOlNVl6rq0vXr1/cwIgAAoAkEwG7Nu0az5w6sui/JSpJH5h3v7rPdvdLdK0eOHNnDiAAAwOGhAwCw760mOT61fSzJ8xsHVdWdSd6d5C3d/e2blA0AAJiwEgiA3bqY5NaqOlFVtyQ5neT89ICqui3JB5Lc091fGSAjAANyF0mA5aAJBMCudPeNJA8keTzJs0k+3t2Xq+rhqrpnMuyRJK9M8omq+nxVnd/idAAcMO4iCbA8XA4GwK5194UkFzbse2jq8Z03PRQAy+K7d5FMkqp68S6Sz7w4oLufmBr/ZJL7bmpCgJGwEggAAFgkd5EEWBKaQAAAwCK5iyTAknA5GAAAsEjuIgmwJKwEAgAAFsldJAGWhCYQAACwMO4iCbA8XA4GAAAslLtIAiwHK4EAAAAARkATCAAAAGAEttUEqqq7quq5qrpSVQ/OOf6uqnqmqr5QVZ+uqtfufVQAAAAAduolm0BVdSjJo0nuTnIyyb1VdXLDsKeTrHT3G5KcS/LevQ4KAAAAwM5tZyXQ7UmudPfV7n4hyWNJTk0P6O4nuvubk80nkxzb25gAAAAA7MZ2mkBHk1yb2l6d7NvK/Uk+Ne9AVZ2pqktVden69evbTwkAAADArmynCVRz9vXcgVX3JVlJ8si84919trtXunvlyJEj208JAAAAwK4c3saY1STHp7aPJXl+46CqujPJu5O8pbu/vTfxAAAAANgL21kJdDHJrVV1oqpuSXI6yfnpAVV1W5IPJLmnu7+y9zEBAAAA2I2XbAJ1940kDyR5PMmzST7e3Zer6uGqumcy7JEkr0zyiar6fFWd3+J0AAAAAAxgO5eDpbsvJLmwYd9DU4/v3ONcAAAAAOyh7VwOBgAAAMA+pwkEAAAAMAKaQAAAAAAjsK3PBGK5VX3/z+m9jwEAAAAsMSuBAAAAAEbASiBYJjtZ1pUkbW0XAAAA35uVQAAAAAAjYCUQACwTKwIBAFgQK4EAAAAARkATCAAAAGAENIEAAAAARsBnAt1sPusBAAAAGICVQAAAAAAjoAkEAAAAMAKaQAAAAAAjoAkEAAAAMAKaQAAAwEJV1V1V9VxVXamqB+ccf3NVfa6qblTVW4fICDAGmkAAAMDCVNWhJI8muTvJyST3VtXJDcO+lOTXk/zVzU0HMC5uEQ8AACzS7UmudPfVJKmqx5KcSvLMiwO6+4uTY98ZIiDAWFgJBAAALNLRJNemtlcn+wC4yTSBAACARao5+3pHJ6o6U1WXqurS9evXdxkLYHw0gQAAgEVaTXJ8avtYkud3cqLuPtvdK929cuTIkT0JBzAmmkAAAMAiXUxya1WdqKpbkpxOcn7gTACjpAkEAAAsTHffSPJAkseTPJvk4919uaoerqp7kqSqfqGqVpO8LckHqurycIkBDi53BwNg16rqriTvT3IoyQe7+482HH9Zkr9I8vNJ/iPJr714JxgADr7uvpDkwoZ9D009vpi1y8QAWCArgQDYlao6lOTRJHcnOZnk3qo6uWHY/Um+3t2vT/K+JO+5uSkBAABNIAB26/YkV7r7ane/kOSxJKc2jDmV5COTx+eS3FFV8+4WAwAALIgmEAC7dTTJtant1cm+uWMmnw3xjSSvvinpAACAJD4TCIDdm7eip3cwJlV1JsmZJHnNa16z40C96czbetaOv96WZ5Rj9oxy7DJDkp0uoNviC+44x7LMxwHNAQCLYiUQALu1muT41PaxJM9vNaaqDid5VZKvbTxRd5/t7pXuXjly5MiC4gIAwDhpAgGwWxeT3FpVJ6rqliSnk5zfMOZ8kndMHr81yWe6d/6eOwAA8P1zORgAu9LdN6rqgSSPZ+0W8R/u7stV9XCSS919PsmHkny0qq5kbQXQ6eESAwDAOGkCAbBr3X0hyYUN+x6aevytJG+72bkAAIB1LgcDAAAAGAFNIAAAAIAR0AQCAAAAGAFNIAAAAIAR0AQCAAAAGAFNIAAAAIAR0AQCAAAAGAFNIAAAAIARODx0AAAAtql76AQAwD5mJRAAAADACGgCAQAAAIyAJhAAAADACGgCAQAAAIyAJhAAAADACGgCAQAAAIyAJhAAAADACGgCAQAAAIyAJhAAAADACGgCAQCSXuDRAAAF/ElEQVQAAIzAtppAVXVXVT1XVVeq6sE5x19WVX8zOf7ZqnrdXgcFAAD2J68nAJbDSzaBqupQkkeT3J3kZJJ7q+rkhmH3J/l6d78+yfuSvGevgwIAAPuP1xMAy2M7K4FuT3Klu6929wtJHktyasOYU0k+Mnl8LskdVVV7FxMAANinvJ4AWBLbaQIdTXJtant1sm/umO6+keQbSV69FwEBAIB9zesJgCVxeBtj5nXgewdjUlVnkpyZbP5PVT23ja///fqxJF+dd2BHbyXs8RsQOz7bznPMnY8Bcsw/3Y6fuKNn7u3Pxs5zbH26HT/RfOxBhmX63fHa3Tz5oHjqqae+WlX/uoBTb/m9HiFzMct8zDIfs5ZpPvZbnTgQryf29d9Hib8XNz3RfOxBhmX6+3n+KXf0pAMxH1vWie00gVaTHJ/aPpbk+S3GrFbV4SSvSvK1jSfq7rNJzm7ja+5YVV3q7pVFfo39xHysMxezzMcs87F8uvvIIs7re73OXMwyH7PMxyzzsSteT+xT5mKW+ZhlPmbtl/nYzuVgF5PcWlUnquqWJKeTnN8w5nySd0wevzXJZ7p7U+ceAAAYHa8nAJbES64E6u4bVfVAkseTHEry4e6+XFUPJ7nU3eeTfCjJR6vqStY69qcXGRoAANgfvJ4AWB7buRws3X0hyYUN+x6aevytJG/b22g7ttDlofuQ+VhnLmaZj1nmYzx8r9eZi1nmY5b5mGU+dsHriX3LXMwyH7PMx6x9MR9llSUAAADAwbedzwQCAAAAYJ87ME2gqrqrqp6rqitV9eDQeYZUVcer6omqeraqLlfVO4fOtAyq6lBVPV1Vfzd0lqFV1Y9U1bmq+ufJz8kvDp1pSFX1u5P/K/9UVX9dVT84dCb2njqxTp2YT51Yp06sUyPGQ51Yp05spkbMUifW7bc6cSCaQFV1KMmjSe5OcjLJvVV1cthUg7qR5Pe6+6eTvDHJb458Pl70ziTPDh1iSbw/yd93908l+dmMeF6q6miS306y0t0/k7UPrPRhlAeMOrGJOjGfOrFOnYgaMSbqxCbqxGZqxCx1IvuzThyIJlCS25Nc6e6r3f1CkseSnBo402C6+8vd/bnJ4//O2n/Io8OmGlZVHUvyK0k+OHSWoVXVDyd5c9buwpHufqG7/3PYVIM7nOSHqupwkpcneX7gPOw9dWKKOrGZOrFOndhEjRgHdWKKOjFLjZilTmyyr+rEQWkCHU1ybWp7NSP+JTWtql6X5LYknx02yeD+NMnvJ/nO0EGWwE8kuZ7kzydLWj9YVa8YOtRQuvvfkvxxki8l+XKSb3T3PwybigVQJ7agTnyXOrFOnZhQI0ZFndiCOpFEjdhInZjYj3XioDSBas6+0d/2rKpemeRvk/xOd//X0HmGUlW/muQr3f3U0FmWxOEkP5fkz7r7tiT/m2S0171X1Y9m7Z2+E0l+PMkrquq+YVOxAOrEHOrEGnViE3ViQo0YFXViDnVCjdiCOjGxH+vEQWkCrSY5PrV9LEu+BGvRquoHsvYL+2Pd/cmh8wzsTUnuqaovZm1p7y9X1V8OG2lQq0lWu/vFd3POZe2X+FjdmeRfuvt6d/9fkk8m+aWBM7H31IkN1IkZ6sQsdWKdGjEe6sQG6sR3qRGbqRPr9l2dOChNoItJbq2qE1V1S9Y+iOn8wJkGU1WVteszn+3uPxk6z9C6+w+6+1h3vy5rPxuf6e6l7s4uUnf/e5JrVfWTk113JHlmwEhD+1KSN1bVyyf/d+7ISD/Y7oBTJ6aoE7PUiVnqxAw1YjzUiSnqxDo1YjN1Ysa+qxOHhw6wF7r7RlU9kOTxrH0a94e7+/LAsYb0piRvT/KPVfX5yb4/7O4LA2ZiufxWko9N/si5muQ3Bs4zmO7+bFWdS/K5rN0J4+kkZ4dNxV5TJzZRJ3gp6kTUiDFRJzZRJ3gp6kT2Z52o7tFf6goAAABw4B2Uy8EAAAAA+B40gQAAAABGQBMIAAAAYAQ0gQAAAABGQBMIAAAAYAQ0gQAAAABGQBMIAAAAYAQ0gQAAAABG4P8B/FmvhqlQQt4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x1440 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    data_size = 50000\n",
    "    fig, ax = plt.subplots(nrows = 3, ncols = 3, figsize=(20, 20))\n",
    "    ax = ax.ravel(order='C')\n",
    "    for rep in range(9):\n",
    "        if rep != 4:\n",
    "            coeff = np.array(coeff_dict[data_size])[rep]\n",
    "            co_list = []\n",
    "            for k in range(9):\n",
    "                co_list.append(coeff[k][k])\n",
    "                co_list.append(coeff[k][k+9])\n",
    "\n",
    "            bar_width = 0.4\n",
    "            ax[rep].bar(np.arange(9), co_list[:9],bar_width, color='b')\n",
    "            ax[rep].bar(np.arange(9)+bar_width, co_list[9:],bar_width, color='r')\n",
    "            ax[rep].title.set_text(str(rep)+'rep')\n",
    "        else:\n",
    "            \n",
    "            coeff = np.array(coeff_mean)\n",
    "            co_list = []\n",
    "            for k in range(9):\n",
    "                co_list.append(coeff[k][k])\n",
    "                co_list.append(coeff[k][k+9])\n",
    "\n",
    "            bar_width = 0.4\n",
    "            ax[rep].bar(np.arange(9), co_list[:9],bar_width, color='b')\n",
    "            ax[rep].bar(np.arange(9)+bar_width, co_list[9:],bar_width, color='r')\n",
    "            ax[rep].title.set_text('Mean')\n",
    "            \n",
    "    print(data_size)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T01:34:25.761779Z",
     "start_time": "2020-04-09T01:34:25.372818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data_size in data_size_list:\n",
    "    coeff_sum = coeff_dict[data_size][9]\n",
    "    for i in range(9):\n",
    "        coeff_sum = np.add(coeff_sum, coeff_dict[data_size][i])\n",
    "    coeff = np.divide(coeff_sum,10)\n",
    "    co_list = []\n",
    "    for k in range(9):\n",
    "        co_list.append(coeff[k][k])\n",
    "        co_list.append(coeff[k][k+9])\n",
    "    r,c = rep % 3 , (rep- r) // 3\n",
    "\n",
    "    bar_width = 0.4\n",
    "    plt.bar(np.arange(9), co_list[:9],bar_width, color='b')\n",
    "    plt.bar(np.arange(9)+bar_width, co_list[9:],bar_width, color='r')\n",
    "    plt.ylim(-1,3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "471.333px",
    "left": "47px",
    "top": "88px",
    "width": "371.563px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
