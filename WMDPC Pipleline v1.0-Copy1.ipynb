{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries / Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:30:47.530423Z",
     "start_time": "2020-05-05T08:30:47.524440Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, Input, models\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPool2D, Dropout, Flatten, Activation, concatenate, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.metrics import f1_score,precision_recall_fscore_support\n",
    "from matplotlib import gridspec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:30:48.824527Z",
     "start_time": "2020-05-05T08:30:48.814525Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def plot_history(history):\n",
    "    # accuracy plot \n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    # loss plot\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_cm(y_true, y_hat, label_list):\n",
    "    cnf_matrix = confusion_matrix(y_true, y_hat)\n",
    "    np.set_printoptions(precision=2)\n",
    "    from matplotlib import gridspec\n",
    "    fig = plt.figure(figsize=(15, 8)) \n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[1, 1]) \n",
    "    plt.subplot(gs[0])\n",
    "    plot_confusion_matrix(cnf_matrix, title='Confusion matrix')\n",
    "    plt.subplot(gs[1])\n",
    "    plot_confusion_matrix(cnf_matrix, normalize=True, title='Normalized confusion matrix')\n",
    "    print(\"F1 Macro:\", f1_score(y_true, y_hat, label_list, average='macro'))\n",
    "    print(\"F1 Micro:\", f1_score(y_true, y_hat, label_list, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:40:47.920726Z",
     "start_time": "2020-05-05T08:40:41.640103Z"
    }
   },
   "outputs": [],
   "source": [
    "dim = 64\n",
    "import pickle\n",
    "with open('features_fe.pickle','rb') as f:\n",
    "    X_fe = pickle.load(f)\n",
    "with open('X_cnn_64.pickle','rb') as f:\n",
    "    X_cnn = pickle.load(f)\n",
    "with open('X_bin.pickle','rb') as f:\n",
    "    X_bin = pickle.load(f)\n",
    "X_cnn = X_cnn.reshape(-1,dim,dim,1)\n",
    "with open('y.pickle','rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:52:35.160642Z",
     "start_time": "2020-05-05T08:52:30.459154Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDON_STATE = 777\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X_cnn, y, \n",
    "                                       test_size=10000, random_state=RANDON_STATE,stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, \n",
    "                                       test_size=0.2, random_state=RANDON_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:52:35.165598Z",
     "start_time": "2020-05-05T08:52:35.161609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((130356, 64, 64, 1), (32590, 64, 64, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def FCN_model(len_classes=5, dropout_rate=0.2):\n",
    "    \n",
    "    # Input layer\n",
    "    input = tf.keras.layers.Input(shape=(None, None, 3))\n",
    "\n",
    "    # A convolution block\n",
    "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)(input)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    # Stack of convolution blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:54:45.931748Z",
     "start_time": "2020-05-05T08:54:45.921775Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model_bin():\n",
    "    input_wbm_tensor = Input((None,None, 1))\n",
    "    conv_1 = Conv2D(16, (3,3), activation='relu', padding='same')(input_wbm_tensor)\n",
    "    pool_1 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_1)\n",
    "    conv_2 = Conv2D(32, (3,3), activation='relu', padding='same')(pool_1)\n",
    "    pool_2 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_2)\n",
    "    conv_3 = Conv2D(64, (3,3), activation='relu', padding='same')(pool_2)\n",
    "    pool_3 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_3)\n",
    "    conv_4 = Conv2D(128, (3,3), activation='relu', padding='same')(pool_3)\n",
    "    pool_4 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_4)\n",
    "    conv_5 = Conv2D(256, (3,3), activation='relu', padding='same')(pool_4)\n",
    "    pool_5 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_5)\n",
    "    \"\"\"x = tf.keras.layers.Conv2D(filters=len_classes, kernel_size=1, strides=1)(x)\n",
    "x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "predictions = tf.keras.layers.Activation('softmax')(x)\"\"\"\n",
    "    \n",
    "    dense_1 = Conv2D(128, (1,1), activation='relu')(pool_5)\n",
    "    dense_2 = Conv2D(128, (1,1), activation='relu')(dense_1)\n",
    "    prediction = Conv2D(9, (1,1), activation='softmax')(dense_2)\n",
    "\n",
    "    model = models.Model(input_wbm_tensor, prediction)\n",
    "    model.compile(optimizer=Adam(lr=lr),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "def train_model_bin(model, X_train, y_train, X_val, y_val):\n",
    "    epoch=1000\n",
    "    batch_size = 32\n",
    "    es = EarlyStopping(monitor='val_loss', patience=20, mode='auto', restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train,\n",
    "         validation_data=[X_val, y_val],\n",
    "         epochs=epoch,\n",
    "         batch_size=batch_size,callbacks=[es]\n",
    "         )\n",
    "    return model, list(set(np.argmax(y_train, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:54:46.531824Z",
     "start_time": "2020-05-05T08:54:46.436775Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected conv2d_58 to have 4 dimensions, but got array with shape (130356, 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-0c8421a9ac48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_bin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model_bin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model_bin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_bin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-73dba7becde4>\u001b[0m in \u001b[0;36mtrain_model_bin\u001b[1;34m(model, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     history = model.fit(X_train, y_train,\n\u001b[1;32m---> 33\u001b[1;33m          \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m          )\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\tf2.0\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\tf2.0\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\tf2.0\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected conv2d_58 to have 4 dimensions, but got array with shape (130356, 9)"
     ]
    }
   ],
   "source": [
    "lr=0.0001\n",
    "model_bin = build_model_bin()\n",
    "model, y_hat = train_model_bin(model_bin, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T08:52:46.500364Z",
     "start_time": "2020-05-05T08:52:46.490363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 48, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_bin)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:12:36.374046Z",
     "start_time": "2020-04-29T13:12:36.364100Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - CNN only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:12:36.453858Z",
     "start_time": "2020-04-29T13:12:36.381027Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model1():\n",
    "    dim = 64\n",
    "    input_wbm_tensor = Input((dim, dim, 1))\n",
    "    conv_1 = Conv2D(16, (3,3), activation='relu', padding='same')(input_wbm_tensor)\n",
    "    pool_1 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_1)\n",
    "    conv_2 = Conv2D(32, (3,3), activation='relu', padding='same')(pool_1)\n",
    "    pool_2 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_2)\n",
    "    conv_3 = Conv2D(64, (3,3), activation='relu', padding='same')(pool_2)\n",
    "    pool_3 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_3)\n",
    "    conv_4 = Conv2D(128, (3,3), activation='relu', padding='same')(pool_3)\n",
    "    pool_4 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_4)\n",
    "    conv_5 = Conv2D(256, (3,3), activation='relu', padding='same')(pool_4)\n",
    "    pool_5 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_5)\n",
    "    GAP = GlobalAveragePooling2D()(pool_5)\n",
    "    dense_1 = Dense(128, activation='tanh')(GAP)\n",
    "    dense_2 = Dense(128, activation='tanh')(dense_1)\n",
    "    prediction = Dense(9, activation='softmax')(dense_2)\n",
    "\n",
    "    model = models.Model(input_wbm_tensor, prediction)\n",
    "    model.compile(optimizer=Adam(lr=lr),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model1(model, X_train, y_train, X_val, y_val):\n",
    "    epoch=1000\n",
    "    batch_size = 32\n",
    "    es = EarlyStopping(monitor='val_loss', patience=20, mode='auto', restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train,\n",
    "         validation_data=[X_val, y_val],\n",
    "         epochs=epoch,\n",
    "         batch_size=batch_size,callbacks=[es]\n",
    "         )\n",
    "    return model, list(set(np.argmax(y_train, axis=1)))\n",
    "\n",
    "def evaluate_model1(model, X_test, y_test, label_list, filename, result_dict, plot=True):\n",
    "    y_hat=model.predict(X_test)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "    y_test_label = np.argmax(y_test,axis=1)\n",
    "    result_dict['macro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='macro'))\n",
    "    result_dict['micro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='micro'))\n",
    "    cm = confusion_matrix(y_test_label, y_hat)\n",
    "    plot_cm(y_test_label, y_hat, label_list)\n",
    "    plt.savefig(filename)\n",
    "    if plot != True:\n",
    "        plt.close()\n",
    "    return result_dict, cm\n",
    "\n",
    "def create_model1(X_train_cnn, y_train, X_val_cnn, y_val, X_test_cnn, y_test, result_dict, n_trnval, rep):\n",
    "    print('\\n'+'*'*10+'model1'+'*'*10+'\\n')\n",
    "    modelname = 'model1'\n",
    "    filename = fn.format(ts=n_trnval, rep=rep, model=modelname)\n",
    "    model1 = build_model1()\n",
    "    model1, label_list = train_model1(model1, X_train_cnn, y_train, X_val_cnn, y_val)\n",
    "    result_dict, cm = evaluate_model1(model1, X_test_cnn, y_test, label_list, filename, result_dict,plot=False)\n",
    "    return result_dict, cm, model1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - FE+RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:12:36.469790Z",
     "start_time": "2020-04-29T13:12:36.455827Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model2():\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    return model\n",
    "\n",
    "def train_model2(model, X_trainval, y_trainval):\n",
    "    y_trainval_label = np.argmax(y_trainval, axis=1)\n",
    "    model.fit(X_trainval, y_trainval_label)\n",
    "    return model, list(set(np.argmax(y_trainval, axis=1)))\n",
    "\n",
    "def evaluate_model2(model, X_test_fe, y_test, label_list, filename, result_dict, plot=True):\n",
    "    y_hat = model.predict(X_test_fe)\n",
    "    y_test_label = np.argmax(y_test,axis=1)\n",
    "    result_dict['macro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='macro'))\n",
    "    result_dict['micro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='micro'))\n",
    "    cm = confusion_matrix(y_test_label, y_hat)\n",
    "    plot_cm(y_test_label, y_hat, label_list)\n",
    "    plt.savefig(filename)\n",
    "    if plot != True:\n",
    "        plt.close()\n",
    "    return result_dict, cm\n",
    "\n",
    "def create_model2(X_trainval_fe, y_trainval, X_test_fe, y_test, result_dict, n_trnval, rep):\n",
    "    print('\\n'+'*'*10+'model2'+'*'*10+'\\n')\n",
    "    modelname = 'model2'\n",
    "    filename = fn.format(ts=n_trnval, rep=rep, model=modelname)\n",
    "    model2 = build_model2()\n",
    "    model2, label_list = train_model2(model2, X_trainval_fe, y_trainval)\n",
    "    result_dict, cm = evaluate_model2(model2, X_test_fe, y_test, label_list, filename, result_dict,plot=False)\n",
    "    return result_dict, cm, model2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - FE+NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:12:36.488784Z",
     "start_time": "2020-04-29T13:12:36.471784Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model3():\n",
    "    input_feature_vector = Input((59,))\n",
    "    hidden_1 = Dense(128, activation='tanh')(input_feature_vector)\n",
    "    hidden_2= Dense(128, activation='tanh')(hidden_1)\n",
    "    prediction = layers.Dense(9, activation='softmax')(hidden_2)\n",
    "\n",
    "    model = models.Model(input_feature_vector, prediction)\n",
    "    model.compile(optimizer=Adam(lr=lr),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model3(model, X_train, y_train, X_val, y_val):\n",
    "    epoch=1000\n",
    "    batch_size = 32\n",
    "    es = EarlyStopping(monitor='val_loss', patience=20, mode='auto', restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train,\n",
    "         validation_data=[X_val, y_val],\n",
    "         epochs=epoch,\n",
    "         batch_size=batch_size,callbacks=[es]\n",
    "         )\n",
    "    return model, list(set(np.argmax(y_train, axis=1)))\n",
    "\n",
    "def evaluate_model3(model, X_test, y_test, label_list, filename, result_dict, plot=True):\n",
    "    y_hat=model.predict(X_test)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "    y_test_label = np.argmax(y_test,axis=1)\n",
    "    result_dict['macro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='macro'))\n",
    "    result_dict['micro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='micro'))\n",
    "    cm = confusion_matrix(y_test_label, y_hat)\n",
    "    plot_cm(y_test_label, y_hat, label_list)\n",
    "    plt.savefig(filename)\n",
    "    if plot != True:\n",
    "        plt.close()\n",
    "    return result_dict, cm\n",
    "\n",
    "def create_model3(X_train_fe_n, y_train, X_val_fe_n, y_val, X_test_fe_n, y_test, result_dict, n_trnval, rep):\n",
    "    print('\\n'+'*'*10+'model3'+'*'*10+'\\n')\n",
    "    modelname = 'model3'\n",
    "    filename = fn.format(ts=n_trnval, rep=rep, model=modelname)\n",
    "    model3 = build_model3()\n",
    "    model3, label_list = train_model3(model3, X_train_fe_n, y_train,  X_val_fe_n, y_val)\n",
    "    result_dict, cm = evaluate_model3(model3, X_test_fe_n, y_test, label_list, filename, result_dict, plot=False)\n",
    "    return result_dict, cm, model3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 - Joint Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:12:36.519463Z",
     "start_time": "2020-04-29T13:12:36.490350Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model4():\n",
    "    dim = 64\n",
    "    input_wbm_tensor = Input((dim, dim, 1))\n",
    "    conv_1 = Conv2D(16, (3,3), activation='relu', padding='same')(input_wbm_tensor)\n",
    "    pool_1 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_1)\n",
    "    conv_2 = Conv2D(32, (3,3), activation='relu', padding='same')(pool_1)\n",
    "    pool_2 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_2)\n",
    "    conv_3 = Conv2D(64, (3,3), activation='relu', padding='same')(pool_2)\n",
    "    pool_3 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_3)\n",
    "    conv_4 = Conv2D(128, (3,3), activation='relu', padding='same')(pool_3)\n",
    "    pool_4 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_4)\n",
    "    conv_5 = Conv2D(256, (3,3), activation='relu', padding='same')(pool_4)\n",
    "    pool_5 = MaxPool2D(pool_size=(2, 2),strides=2 ,padding='same')(conv_5)\n",
    "    GAP = GlobalAveragePooling2D()(pool_5)\n",
    "\n",
    "    input_feature_vector = Input((59,))\n",
    "\n",
    "    concat_vector = concatenate([GAP, input_feature_vector])\n",
    "\n",
    "    concat_hidden_1 = layers.Dense(128, activation='tanh')(concat_vector)\n",
    "    concat_hidden_2 = layers.Dense(128, activation='tanh')(concat_hidden_1)\n",
    "    prediction = layers.Dense(9, activation='softmax')(concat_hidden_2)\n",
    "\n",
    "    model = models.Model([input_wbm_tensor, input_feature_vector], prediction)\n",
    "    model.compile(optimizer=Adam(lr=lr),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model4(model, X_train, y_train, X_val, y_val):\n",
    "    epoch=1000\n",
    "    batch_size = 32\n",
    "    es = EarlyStopping(monitor='val_loss', patience=20, mode='auto', restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train,\n",
    "             validation_data=[X_val, y_val],\n",
    "             epochs=epoch,\n",
    "             batch_size=batch_size,callbacks=[es]\n",
    "             )\n",
    "    return model, list(set(np.argmax(y_train, axis=1)))\n",
    "\n",
    "def evaluate_model4(model, X_test, y_test, label_list, filename, result_dict, plot=True):\n",
    "    y_hat=model.predict(X_test)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "    y_test_label = np.argmax(y_test,axis=1)\n",
    "    result_dict['macro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='macro'))\n",
    "    result_dict['micro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='micro'))\n",
    "    cm = confusion_matrix(y_test_label, y_hat)\n",
    "    plot_cm(y_test_label, y_hat, label_list)\n",
    "    plt.savefig(filename)\n",
    "    if plot != True:\n",
    "        plt.close()\n",
    "    return result_dict, cm\n",
    "\n",
    "\n",
    "def create_model4(X_train_cnn, X_train_fe_n, y_train, X_val_cnn, X_val_fe_n, y_val, \n",
    "           X_test_cnn, X_test_fe_n, y_test, result_dict, n_trnval, rep):\n",
    "    print('\\n'+'*'*10+'model4'+'*'*10+'\\n')\n",
    "    modelname = 'model4'\n",
    "    filename = fn.format(ts=n_trnval, rep=rep, model=modelname)\n",
    "    model4 = build_model4()\n",
    "    model4, label_list = train_model4(model4, [X_train_cnn, X_train_fe_n], y_train, [X_val_cnn, X_val_fe_n], y_val)\n",
    "    result_dict, cm = evaluate_model4(model4, [X_test_cnn, X_test_fe_n], y_test, label_list, filename, result_dict,plot=False)\n",
    "    return result_dict, cm, model4\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5 - Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:12:36.536347Z",
     "start_time": "2020-04-29T13:12:36.521360Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model5():\n",
    "    from sklearn.linear_model import Ridge\n",
    "    model = Ridge(alpha=0.0001, fit_intercept=False)\n",
    "    return model\n",
    "\n",
    "def train_model5_val(model5, model1, model2, X_val_cnn, X_val_fe, X_test_cnn, X_test_fe, \n",
    "                 y_val, y_test):\n",
    "    prob_val_cnn = model1.predict(X_val_cnn) \n",
    "    prob_test_cnn = model1.predict(X_test_cnn)\n",
    "    \n",
    "    prob_val_fe = model2.predict_proba(X_val_fe) \n",
    "    prob_test_fe = model2.predict_proba(X_test_fe)\n",
    "    \n",
    "    y_val_label = np.argmax(y_val, axis=1)\n",
    "    y_test_label = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    prob_val_concat = np.concatenate((prob_val_cnn, prob_val_fe), axis=1)\n",
    "    prob_test_concat = np.concatenate((prob_test_cnn, prob_test_fe), axis=1)\n",
    "    model5.fit(prob_val_concat, y_val)\n",
    "    return model5, prob_test_concat, list(set(np.argmax(y_val, axis=1)))\n",
    "\n",
    "def evaluate_model5(model, prob_test_concat, y_test, label_list, filename, result_dict, plot=True):\n",
    "    prob = model.predict(prob_test_concat)\n",
    "    y_hat = np.argmax(prob, axis=1)\n",
    "    y_test_label = np.argmax(y_test,axis=1)\n",
    "    result_dict['macro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='macro'))\n",
    "    result_dict['micro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='micro'))\n",
    "    cm = confusion_matrix(y_test_label, y_hat)\n",
    "    plot_cm(y_test_label, y_hat, label_list)\n",
    "    plt.savefig(filename)\n",
    "    if plot != True:\n",
    "        plt.close()\n",
    "    return result_dict, cm\n",
    "\n",
    "\n",
    "def create_model5(model_1, model_2, X_val_cnn, X_val_fe, y_val,\n",
    "           X_test_cnn, X_test_fe, y_test, result_dict, n_trnval, rep):\n",
    "    print('\\n'+'*'*10+'model5'+'*'*10+'\\n')\n",
    "    modelname = 'model5'\n",
    "    filename = fn.format(ts=n_trnval, rep=rep, model=modelname)\n",
    "    model5 = build_model5()\n",
    "    model5, prob_test_concat5, label_list =train_model5_val(model5, model_1, model_2, X_val_cnn, X_val_fe, \n",
    "                                     X_test_cnn, X_test_fe, y_val, y_test)\n",
    "    result_dict, cm = evaluate_model5(model5, prob_test_concat5, y_test, label_list,\n",
    "                                      filename, result_dict,plot=False)\n",
    "    return result_dict, cm, model5, prob_test_concat5\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:12:36.556305Z",
     "start_time": "2020-04-29T13:12:36.541333Z"
    }
   },
   "outputs": [],
   "source": [
    "# train, val이 나눠짐\n",
    "def build_model6():\n",
    "    from sklearn.linear_model import Ridge\n",
    "    model = Ridge(alpha=0.0001, fit_intercept=False)\n",
    "    return model\n",
    "\n",
    "def train_model6_val(model6, model1, model3, X_val_cnn, X_val_fe_n, X_test_cnn, \n",
    "                 X_test_fe_n, y_val,y_test):\n",
    "    prob_val_cnn = model1.predict(X_val_cnn) \n",
    "    prob_test_cnn = model1.predict(X_test_cnn)\n",
    "    \n",
    "    prob_val_fnn = model3.predict(X_val_fe_n) \n",
    "    prob_test_fnn = model3.predict(X_test_fe_n)\n",
    "    \n",
    "    y_val_label = np.argmax(y_val, axis=1)\n",
    "    y_test_label = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    prob_val_concat = np.concatenate((prob_val_cnn, prob_val_fnn), axis=1)\n",
    "    prob_test_concat = np.concatenate((prob_test_cnn, prob_test_fnn), axis=1)\n",
    "    model6.fit(prob_val_concat, y_val)\n",
    "    return model6, prob_test_concat, list(set(np.argmax(y_val, axis=1)))\n",
    "\n",
    "def evaluate_model6(model, prob_test_concat, y_test, label_list, filename, result_dict, plot=True):\n",
    "    prob = model.predict(prob_test_concat)\n",
    "    y_hat = np.argmax(prob, axis=1)\n",
    "    y_test_label = np.argmax(y_test,axis=1)\n",
    "    result_dict['macro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='macro'))\n",
    "    result_dict['micro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='micro'))\n",
    "    cm = confusion_matrix(y_test_label, y_hat)\n",
    "    plot_cm(y_test_label, y_hat, label_list)\n",
    "    plt.savefig(filename)\n",
    "    if plot != True:\n",
    "        plt.close()\n",
    "    return result_dict, cm\n",
    "\n",
    "\n",
    "def create_model6_val(model_1, model_3, X_val_cnn, X_val_fe_n, y_val,\n",
    "           X_test_cnn, X_test_fe_n, y_test, result_dict, n_trnval, rep):\n",
    "    print('\\n'+'*'*10+'model6'+'*'*10+'\\n')\n",
    "    modelname = 'model6'\n",
    "    filename = fn.format(ts=n_trnval, rep=rep, model=modelname)\n",
    "    model6 = build_model6()\n",
    "    model6, prob_test_concat6, label_list =train_model6_val(model6, model_1, model_3, X_val_cnn, \n",
    "                                         X_val_fe_n, X_test_cnn, X_test_fe_n, y_val, y_test)\n",
    "    result_dict, cm = evaluate_model6(model6, prob_test_concat6, y_test, label_list,\n",
    "                                      filename, result_dict,plot=False)\n",
    "    return result_dict, cm, model6.coef_, model6, prob_test_concat6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:12:36.570231Z",
     "start_time": "2020-04-29T13:12:36.558291Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model6():\n",
    "    from sklearn.linear_model import Ridge\n",
    "    model = Ridge(alpha=0.1, fit_intercept=False)\n",
    "    return model\n",
    "\n",
    "def train_model6(model6, model1, model3, X_trainval_cnn, X_trainval_fe_normalized, X_test_cnn, \n",
    "                 X_test_fe_normalized, y_trainval,y_test):\n",
    "    prob_trainval_cnn = model1.predict(X_trainval_cnn) \n",
    "    prob_test_cnn = model1.predict(X_test_cnn)\n",
    "    \n",
    "    prob_trainval_fnn = model3.predict(X_trainval_fe_normalized) \n",
    "    prob_test_fnn = model3.predict(X_test_fe_normalized)\n",
    "    \n",
    "    y_trainval_label = np.argmax(y_trainval, axis=1)\n",
    "    y_test_label = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    prob_trainval_concat = np.concatenate((prob_trainval_cnn, prob_trainval_fnn), axis=1)\n",
    "    prob_test_concat = np.concatenate((prob_test_cnn, prob_test_fnn), axis=1)\n",
    "    model6.fit(prob_trainval_concat, y_trainval)\n",
    "    return model6, prob_test_concat, list(set(np.argmax(y_trainval, axis=1)))\n",
    "\n",
    "def evaluate_model6(model, prob_test_concat, y_test, label_list, filename, result_dict, plot=True):\n",
    "    prob = model.predict(prob_test_concat)\n",
    "    y_hat = np.argmax(prob, axis=1)\n",
    "    y_test_label = np.argmax(y_test,axis=1)\n",
    "    result_dict['macro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='macro'))\n",
    "    result_dict['micro'].append(f1_score(y_test_label, y_hat, labels=label_list, average='micro'))\n",
    "    cm = confusion_matrix(y_test_label, y_hat)\n",
    "    plot_cm(y_test_label, y_hat, label_list)\n",
    "    plt.savefig(filename)\n",
    "    if plot != True:\n",
    "        plt.close()\n",
    "    return result_dict, cm\n",
    "\n",
    "\n",
    "def create_model6(model_1, model_3, X_trainval_cnn, X_trainval_fe_n, y_trainval,\n",
    "           X_test_cnn, X_test_fe_n, y_test, result_dict, n_trnval, rep):\n",
    "    print('\\n'+'*'*10+'model6'+'*'*10+'\\n')\n",
    "    modelname = 'model6'\n",
    "    filename = fn.format(ts=n_trnval, rep=rep, model=modelname)\n",
    "    model6 = build_model6()\n",
    "    model6, prob_test_concat6, label_list =train_model6(model6, model_1, model_3, X_trainval_cnn, \n",
    "                                         X_trainval_fe_n, X_test_cnn, X_test_fe_n, y_trainval, y_test)\n",
    "    result_dict, cm = evaluate_model6(model6, prob_test_concat6, y_test, label_list,\n",
    "                                      filename, result_dict,plot=False)\n",
    "    return result_dict, cm, model6.coef_, model6, prob_test_concat6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T23:41:15.075313Z",
     "start_time": "2020-04-12T23:41:15.050379Z"
    }
   },
   "outputs": [],
   "source": [
    "def experiment(savefile, replication=5, random_seed=3):\n",
    "    model_list = ['model1', 'model2', 'model3', 'model4', 'model5','model6']\n",
    "    pattern_list = [0, 1, 2, 3, 4, 5, 6, 7 ,8]\n",
    "    n_trnval_list = [500,5000,50000,162946]\n",
    "    f1_dict = {}\n",
    "    model6_list = []\n",
    "    for t in n_trnval_list:\n",
    "        f1_dict[t] = {}\n",
    "        for label in pattern_list:\n",
    "            f1_dict[t][label] = {}\n",
    "            for model in model_list:\n",
    "                f1_dict[t][label][str(model)] = []\n",
    "    \n",
    "    with open(savefile+'.csv', 'w', newline='') as csvfile:\n",
    "                fieldnames = ['training_size', \n",
    "                              'model1_macro','model2_macro','model3_macro','model4_macro','model5_macro','model6_macro',\n",
    "                              'model1_micro','model2_micro','model3_micro','model4_micro','model5_micro','model6_micro']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "    with open(savefile+'2.csv', 'w', newline='') as csvfile:\n",
    "                fieldnames = ['training_size', \n",
    "                              'model1','model2','model3','model4','model5','model6']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "    if not os.path.exists('./savefile'):\n",
    "        os.makedirs('./'+savefile)\n",
    "    for rep in range(replication):\n",
    "        RANDON_STATE = 20200321+rep+random_seed\n",
    "        X_trainval_cnn_big, X_test_cnn, y_trainval_big, y_test = train_test_split(X_cnn, y, \n",
    "                                       test_size=10000, random_state=RANDON_STATE,stratify=y)\n",
    "        X_trainval_fe_big, X_test_fe = train_test_split(X_fe, test_size=10000, \n",
    "                                                        random_state=RANDON_STATE,stratify=y)\n",
    "        start_time = time.time()\n",
    "        print('\\n','&'*20,rep+1,'replication','&'*20,'\\n\\n')\n",
    "        idx_list = [np.where(np.argmax(y_test,axis=1)==i)[0] for i in range(9)]\n",
    "        for n_trnval in n_trnval_list:\n",
    "            # Sampling\n",
    "            print('\\n','@'*20,rep+1,'replication',n_trnval,'@'*20,'\\n\\n')\n",
    "            global fn\n",
    "            fn = './'+savefile+'/result_{rep}_{ts:04d}_{model}.png'\n",
    "            np.random.seed(20200321+n_trnval*(rep+random_seed))\n",
    "            rand_id = np.random.choice(len(X_trainval_fe_big), n_trnval, replace=False)\n",
    "            X_trainval_cnn = X_trainval_cnn_big[rand_id]\n",
    "            X_trainval_fe = X_trainval_fe_big[rand_id]\n",
    "\n",
    "            y_trainval = y_trainval_big[rand_id]\n",
    "            # Split\n",
    "            X_train_cnn, X_val_cnn, y_train, y_val= train_test_split(X_trainval_cnn, \n",
    "                                                    y_trainval, test_size=0.2, random_state=RANDON_STATE)\n",
    "            X_train_fe, X_val_fe = train_test_split(X_trainval_fe, test_size=0.2, random_state=RANDON_STATE)\n",
    "            \n",
    "            mean, std = np.mean(X_train_fe,axis=0), np.std(X_train_fe,axis=0)\n",
    "            X_train_fe_n, X_val_fe_n, X_test_fe_n, X_trainval_fe_n = (X_train_fe-mean)/std, (X_val_fe-mean)/std, (X_test_fe-mean)/std, (X_trainval_fe-mean)/std\n",
    "            \n",
    "            # Train and Evaluate Each Model\n",
    "            result_dict = {'macro':[],'micro':[]}\n",
    "            label_list = list(set(np.argmax(y_trainval,axis=1)))\n",
    "            print('label_list',list(set(np.argmax(y_trainval,axis=1))))\n",
    "            print('label_list',list(set(np.argmax(y_train,axis=1))))\n",
    "\n",
    "            result_dict, cm, model1 = create_model1(X_train_cnn, y_train, X_val_cnn, y_val, \n",
    "                                              X_test_cnn, y_test,result_dict, n_trnval, rep)\n",
    "            result_dict, cm, model2 = create_model2(X_trainval_fe, y_trainval, \n",
    "                                              X_test_fe, y_test, result_dict, n_trnval, rep)\n",
    "            result_dict, cm ,model3= create_model3(X_train_fe_n, y_train, X_val_fe_n, y_val, \n",
    "                                             X_test_fe_n, y_test, result_dict,  n_trnval, rep)\n",
    "            result_dict, cm, model4= create_model4(X_train_cnn, X_train_fe_n, y_train, X_val_cnn, X_val_fe_n, y_val, \n",
    "                                             X_test_cnn, X_test_fe_n, y_test, result_dict, n_trnval, rep)\n",
    "            result_dict, cm, model5, prob_test_concat5 = create_model5(model1, model2, X_val_cnn, X_val_fe, y_trainval, \n",
    "                                             X_test_cnn, X_test_fe, y_test, result_dict, n_trnval, rep)\n",
    "            result_dict, cm, coeff, model6, prob_test_concat6 = create_model6(model1, model3, X_val_cnn, \n",
    "                        X_val_fe_n, y_val, X_test_cnn, X_test_fe_n, y_test, result_dict, n_trnval, rep)\n",
    "            \n",
    "            for pattern_num in pattern_list:\n",
    "                for model in model_list:\n",
    "                    if model == 'model2':\n",
    "                        y_hat = np.argmax(model2.predict_proba(X_test_fe[idx_list[pattern_num]]),axis=1)\n",
    "                    elif model == 'model4':\n",
    "                        y_hat = np.argmax(model4.predict([X_test_cnn[idx_list[pattern_num]], \n",
    "                                       X_test_fe_n[idx_list[pattern_num]]]),axis=1)\n",
    "                    elif model == 'model6':\n",
    "                        y_hat = np.argmax(model6.predict(prob_test_concat6[idx_list[pattern_num]]),axis=1)    \n",
    "                    elif model =='model1':\n",
    "                        y_hat = np.argmax(model1.predict(X_test_cnn[idx_list[pattern_num]]),axis=1)\n",
    "                    elif model == 'model3':\n",
    "                        y_hat = np.argmax(model3.predict(X_test_fe_n[idx_list[pattern_num]]),axis=1)\n",
    "                    elif model == 'model5':\n",
    "                        y_hat = np.argmax(model5.predict(prob_test_concat5[idx_list[pattern_num]]),axis=1)\n",
    "                    y_true = np.argmax(y_test[idx_list[pattern_num]],axis=1)\n",
    "                    fscore = np.max(f1_score(y_true, y_hat, average=None))\n",
    "                    f1_dict[n_trnval][pattern_num][str(model)].append(fscore)\n",
    "            \n",
    "            model6_list.append(model6)\n",
    "            # Record result\n",
    "            with open(savefile+'.csv', 'a', newline='') as csvfile:\n",
    "                fieldnames = ['training_size', \n",
    "                              'model1_macro','model2_macro','model3_macro','model4_macro','model5_macro',\n",
    "                              'model6_macro',\n",
    "                              'model1_micro','model2_micro','model3_micro','model4_micro','model5_micro',\n",
    "                              'model6_micro']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writerow({'training_size': n_trnval, \n",
    "                                 'model1_macro': result_dict['macro'][0],'model2_macro': result_dict['macro'][1],\n",
    "                                 'model3_macro': result_dict['macro'][2],'model4_macro': result_dict['macro'][3],\n",
    "                                 'model5_macro': result_dict['macro'][4],'model6_macro': result_dict['macro'][5],\n",
    "                                 'model1_micro': result_dict['micro'][0],'model2_micro': result_dict['micro'][1],\n",
    "                                 'model3_micro': result_dict['micro'][2],'model4_micro': result_dict['micro'][3],\n",
    "                                 'model5_micro': result_dict['micro'][4],'model6_micro': result_dict['micro'][5],\n",
    "                                 })\n",
    "        \n",
    "        print('\\n\\n',(time.time()-start_time)/60,'min per replication\\n\\n')\n",
    "    for n_trnval in n_trnval_list:\n",
    "        for pattern in pattern_list:\n",
    "            for model in model_list:\n",
    "                f1_dict[n_trnval][pattern][model] = np.mean(f1_dict[n_trnval][pattern][model])\n",
    "    with open(savefile+'_2.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['pattern', \n",
    "                      'model1','model2','model3','model4','model5','model6']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        for n_trnval in n_trnval_list:\n",
    "            writer.writerow({'pattern':n_trnval})\n",
    "            for pattern in pattern_list:\n",
    "                writer.writerow({'pattern': pattern,\n",
    "                                 'model1':f1_dict[n_trnval][pattern]['model1'],\n",
    "                                 'model2':f1_dict[n_trnval][pattern]['model2'],\n",
    "                                 'model3':f1_dict[n_trnval][pattern]['model3'],\n",
    "                                 'model4':f1_dict[n_trnval][pattern]['model4'],\n",
    "                                 'model5':f1_dict[n_trnval][pattern]['model5'],\n",
    "                                 'model6':f1_dict[n_trnval][pattern]['model6']})\n",
    "    return model6_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T13:19:39.445364Z",
     "start_time": "2020-04-02T12:39:08.050861Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 1 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 1 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/500\n",
      "400/400 [==============================] - 0s 706us/step - loss: 1.8799 - accuracy: 0.7925 - val_loss: 1.3507 - val_accuracy: 0.8700\n",
      "Epoch 2/500\n",
      "400/400 [==============================] - 0s 227us/step - loss: 1.0300 - accuracy: 0.8425 - val_loss: 0.7208 - val_accuracy: 0.8700\n",
      "Epoch 3/500\n",
      "400/400 [==============================] - 0s 238us/step - loss: 0.8244 - accuracy: 0.8425 - val_loss: 0.6969 - val_accuracy: 0.8700\n",
      "Epoch 4/500\n",
      "400/400 [==============================] - 0s 236us/step - loss: 0.7507 - accuracy: 0.8425 - val_loss: 0.7076 - val_accuracy: 0.8700\n",
      "Epoch 5/500\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.7417 - accuracy: 0.8425 - val_loss: 0.6764 - val_accuracy: 0.8700\n",
      "Epoch 6/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.7169 - accuracy: 0.8425 - val_loss: 0.6664 - val_accuracy: 0.8700\n",
      "Epoch 7/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.7073 - accuracy: 0.8425 - val_loss: 0.6654 - val_accuracy: 0.8700\n",
      "Epoch 8/500\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.6952 - accuracy: 0.8425 - val_loss: 0.6579 - val_accuracy: 0.8700\n",
      "Epoch 9/500\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.6913 - accuracy: 0.8425 - val_loss: 0.6528 - val_accuracy: 0.8700\n",
      "Epoch 10/500\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.6892 - accuracy: 0.8425 - val_loss: 0.6463 - val_accuracy: 0.8700\n",
      "Epoch 11/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.6791 - accuracy: 0.8425 - val_loss: 0.6441 - val_accuracy: 0.8700\n",
      "Epoch 12/500\n",
      "400/400 [==============================] - 0s 208us/step - loss: 0.6742 - accuracy: 0.8425 - val_loss: 0.6411 - val_accuracy: 0.8700\n",
      "Epoch 13/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.6618 - accuracy: 0.8425 - val_loss: 0.6356 - val_accuracy: 0.8700\n",
      "Epoch 14/500\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.6559 - accuracy: 0.8425 - val_loss: 0.6270 - val_accuracy: 0.8700\n",
      "Epoch 15/500\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.6487 - accuracy: 0.8425 - val_loss: 0.6221 - val_accuracy: 0.8700\n",
      "Epoch 16/500\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.6358 - accuracy: 0.8425 - val_loss: 0.6092 - val_accuracy: 0.8700\n",
      "Epoch 17/500\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.6181 - accuracy: 0.8425 - val_loss: 0.5918 - val_accuracy: 0.8700\n",
      "Epoch 18/500\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.6108 - accuracy: 0.8425 - val_loss: 0.5767 - val_accuracy: 0.8700\n",
      "Epoch 19/500\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.5917 - accuracy: 0.8425 - val_loss: 0.5706 - val_accuracy: 0.8700\n",
      "Epoch 20/500\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.5641 - accuracy: 0.8425 - val_loss: 0.5485 - val_accuracy: 0.8700\n",
      "Epoch 21/500\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.5317 - accuracy: 0.8450 - val_loss: 0.5489 - val_accuracy: 0.8800\n",
      "Epoch 22/500\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.5047 - accuracy: 0.8575 - val_loss: 0.5014 - val_accuracy: 0.8700\n",
      "Epoch 23/500\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.4691 - accuracy: 0.8775 - val_loss: 0.4771 - val_accuracy: 0.8900\n",
      "Epoch 24/500\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.4387 - accuracy: 0.8900 - val_loss: 0.4553 - val_accuracy: 0.9000\n",
      "Epoch 25/500\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.4083 - accuracy: 0.9000 - val_loss: 0.4356 - val_accuracy: 0.9100\n",
      "Epoch 26/500\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.3895 - accuracy: 0.9025 - val_loss: 0.4175 - val_accuracy: 0.9100\n",
      "Epoch 27/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3918 - accuracy: 0.9000 - val_loss: 0.4179 - val_accuracy: 0.9100\n",
      "Epoch 28/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.3684 - accuracy: 0.9025 - val_loss: 0.4107 - val_accuracy: 0.9100\n",
      "Epoch 29/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.3413 - accuracy: 0.9125 - val_loss: 0.4258 - val_accuracy: 0.9100\n",
      "Epoch 30/500\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.3538 - accuracy: 0.9025 - val_loss: 0.3829 - val_accuracy: 0.9100\n",
      "Epoch 31/500\n",
      "400/400 [==============================] - 0s 208us/step - loss: 0.3153 - accuracy: 0.9075 - val_loss: 0.3622 - val_accuracy: 0.9100\n",
      "Epoch 32/500\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.3008 - accuracy: 0.9175 - val_loss: 0.3898 - val_accuracy: 0.9100\n",
      "Epoch 33/500\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.3139 - accuracy: 0.9200 - val_loss: 0.3804 - val_accuracy: 0.9100\n",
      "Epoch 34/500\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.2875 - accuracy: 0.9250 - val_loss: 0.3579 - val_accuracy: 0.9100\n",
      "Epoch 35/500\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.2807 - accuracy: 0.9175 - val_loss: 0.3364 - val_accuracy: 0.9100\n",
      "Epoch 36/500\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.2559 - accuracy: 0.9275 - val_loss: 0.3420 - val_accuracy: 0.9100\n",
      "Epoch 37/500\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2472 - accuracy: 0.9225 - val_loss: 0.3163 - val_accuracy: 0.9300\n",
      "Epoch 38/500\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2329 - accuracy: 0.9350 - val_loss: 0.3261 - val_accuracy: 0.9200\n",
      "Epoch 39/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2331 - accuracy: 0.9300 - val_loss: 0.3199 - val_accuracy: 0.9200\n",
      "Epoch 40/500\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.2188 - accuracy: 0.9375 - val_loss: 0.3164 - val_accuracy: 0.9300\n",
      "Epoch 41/500\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2139 - accuracy: 0.9450 - val_loss: 0.3164 - val_accuracy: 0.9200\n",
      "Epoch 42/500\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.2105 - accuracy: 0.9400 - val_loss: 0.3406 - val_accuracy: 0.9200\n",
      "Epoch 43/500\n",
      "400/400 [==============================] - 0s 203us/step - loss: 0.1993 - accuracy: 0.9375 - val_loss: 0.3273 - val_accuracy: 0.9300\n",
      "Epoch 44/500\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.2063 - accuracy: 0.9425 - val_loss: 0.3030 - val_accuracy: 0.9300\n",
      "Epoch 45/500\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1974 - accuracy: 0.9475 - val_loss: 0.3145 - val_accuracy: 0.9200\n",
      "Epoch 46/500\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1808 - accuracy: 0.9500 - val_loss: 0.3465 - val_accuracy: 0.9200\n",
      "Epoch 47/500\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2181 - accuracy: 0.9350 - val_loss: 0.3416 - val_accuracy: 0.9300\n",
      "Epoch 48/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1830 - accuracy: 0.9525 - val_loss: 0.2968 - val_accuracy: 0.9300\n",
      "Epoch 49/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1664 - accuracy: 0.9550 - val_loss: 0.3173 - val_accuracy: 0.9300\n",
      "Epoch 50/500\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1707 - accuracy: 0.9425 - val_loss: 0.2904 - val_accuracy: 0.9200\n",
      "Epoch 51/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1697 - accuracy: 0.9500 - val_loss: 0.3071 - val_accuracy: 0.9200\n",
      "Epoch 52/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1699 - accuracy: 0.9475 - val_loss: 0.3060 - val_accuracy: 0.9200\n",
      "Epoch 53/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1498 - accuracy: 0.9575 - val_loss: 0.3000 - val_accuracy: 0.9200\n",
      "Epoch 54/500\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.1437 - accuracy: 0.9550 - val_loss: 0.2998 - val_accuracy: 0.9200\n",
      "Epoch 55/500\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.1346 - accuracy: 0.9625 - val_loss: 0.3078 - val_accuracy: 0.9200\n",
      "Epoch 56/500\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.1337 - accuracy: 0.9600 - val_loss: 0.3135 - val_accuracy: 0.9200\n",
      "Epoch 57/500\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.1326 - accuracy: 0.9625 - val_loss: 0.3662 - val_accuracy: 0.9200\n",
      "Epoch 58/500\n",
      "400/400 [==============================] - 0s 203us/step - loss: 0.1657 - accuracy: 0.9575 - val_loss: 0.3064 - val_accuracy: 0.9200\n",
      "Epoch 59/500\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.1348 - accuracy: 0.9650 - val_loss: 0.3001 - val_accuracy: 0.9200\n",
      "Epoch 60/500\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.1253 - accuracy: 0.9625 - val_loss: 0.2958 - val_accuracy: 0.9200\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.3905358395292149\n",
      "F1 Micro: 0.9265\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5439739883493477\n",
      "F1 Micro: 0.9352\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/500\n",
      "400/400 [==============================] - 0s 278us/step - loss: 2.2427 - accuracy: 0.0975 - val_loss: 2.1108 - val_accuracy: 0.2500\n",
      "Epoch 2/500\n",
      "400/400 [==============================] - 0s 84us/step - loss: 1.9766 - accuracy: 0.3900 - val_loss: 1.8850 - val_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.7847 - accuracy: 0.5425 - val_loss: 1.7261 - val_accuracy: 0.5400\n",
      "Epoch 4/500\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.6554 - accuracy: 0.6050 - val_loss: 1.6178 - val_accuracy: 0.5900\n",
      "Epoch 5/500\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.5678 - accuracy: 0.6325 - val_loss: 1.5317 - val_accuracy: 0.6100\n",
      "Epoch 6/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 1.4944 - accuracy: 0.6600 - val_loss: 1.4619 - val_accuracy: 0.6300\n",
      "Epoch 7/500\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.4269 - accuracy: 0.6800 - val_loss: 1.3975 - val_accuracy: 0.6600\n",
      "Epoch 8/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.3653 - accuracy: 0.6850 - val_loss: 1.3357 - val_accuracy: 0.6800\n",
      "Epoch 9/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.3052 - accuracy: 0.6950 - val_loss: 1.2752 - val_accuracy: 0.7100\n",
      "Epoch 10/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.2437 - accuracy: 0.7150 - val_loss: 1.2162 - val_accuracy: 0.7300\n",
      "Epoch 11/500\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.1854 - accuracy: 0.7275 - val_loss: 1.1560 - val_accuracy: 0.7500\n",
      "Epoch 12/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.1270 - accuracy: 0.7500 - val_loss: 1.0948 - val_accuracy: 0.7600\n",
      "Epoch 13/500\n",
      "400/400 [==============================] - 0s 84us/step - loss: 1.0666 - accuracy: 0.7775 - val_loss: 1.0342 - val_accuracy: 0.7700\n",
      "Epoch 14/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.0095 - accuracy: 0.7925 - val_loss: 0.9749 - val_accuracy: 0.7900\n",
      "Epoch 15/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.9526 - accuracy: 0.8125 - val_loss: 0.9190 - val_accuracy: 0.8300\n",
      "Epoch 16/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.8972 - accuracy: 0.8325 - val_loss: 0.8638 - val_accuracy: 0.8400\n",
      "Epoch 17/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.8436 - accuracy: 0.8550 - val_loss: 0.8092 - val_accuracy: 0.8500\n",
      "Epoch 18/500\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.7913 - accuracy: 0.8675 - val_loss: 0.7570 - val_accuracy: 0.8600\n",
      "Epoch 19/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.7428 - accuracy: 0.8775 - val_loss: 0.7080 - val_accuracy: 0.8800\n",
      "Epoch 20/500\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.6964 - accuracy: 0.8875 - val_loss: 0.6624 - val_accuracy: 0.8800\n",
      "Epoch 21/500\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.6518 - accuracy: 0.8925 - val_loss: 0.6205 - val_accuracy: 0.8900\n",
      "Epoch 22/500\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.6111 - accuracy: 0.8950 - val_loss: 0.5803 - val_accuracy: 0.8900\n",
      "Epoch 23/500\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.5735 - accuracy: 0.9025 - val_loss: 0.5445 - val_accuracy: 0.9000\n",
      "Epoch 24/500\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.5383 - accuracy: 0.9075 - val_loss: 0.5116 - val_accuracy: 0.9100\n",
      "Epoch 25/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.5054 - accuracy: 0.9150 - val_loss: 0.4809 - val_accuracy: 0.9100\n",
      "Epoch 26/500\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.4760 - accuracy: 0.9175 - val_loss: 0.4542 - val_accuracy: 0.9100\n",
      "Epoch 27/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.4491 - accuracy: 0.9300 - val_loss: 0.4303 - val_accuracy: 0.9200\n",
      "Epoch 28/500\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.4241 - accuracy: 0.9325 - val_loss: 0.4085 - val_accuracy: 0.9200\n",
      "Epoch 29/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.4021 - accuracy: 0.9325 - val_loss: 0.3902 - val_accuracy: 0.9200\n",
      "Epoch 30/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.3795 - accuracy: 0.9350 - val_loss: 0.3713 - val_accuracy: 0.9200\n",
      "Epoch 31/500\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.3601 - accuracy: 0.9375 - val_loss: 0.3570 - val_accuracy: 0.9200\n",
      "Epoch 32/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.3409 - accuracy: 0.9375 - val_loss: 0.3392 - val_accuracy: 0.9200\n",
      "Epoch 33/500\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.3236 - accuracy: 0.9400 - val_loss: 0.3242 - val_accuracy: 0.9200\n",
      "Epoch 34/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.3087 - accuracy: 0.9450 - val_loss: 0.3142 - val_accuracy: 0.9200\n",
      "Epoch 35/500\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2927 - accuracy: 0.9450 - val_loss: 0.3022 - val_accuracy: 0.9200\n",
      "Epoch 36/500\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.2794 - accuracy: 0.9500 - val_loss: 0.2927 - val_accuracy: 0.9200\n",
      "Epoch 37/500\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.2667 - accuracy: 0.9500 - val_loss: 0.2825 - val_accuracy: 0.9200\n",
      "Epoch 38/500\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.2544 - accuracy: 0.9525 - val_loss: 0.2747 - val_accuracy: 0.9200\n",
      "Epoch 39/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2433 - accuracy: 0.9550 - val_loss: 0.2674 - val_accuracy: 0.9200\n",
      "Epoch 40/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2331 - accuracy: 0.9575 - val_loss: 0.2575 - val_accuracy: 0.9200\n",
      "Epoch 41/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2231 - accuracy: 0.9575 - val_loss: 0.2533 - val_accuracy: 0.9200\n",
      "Epoch 42/500\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2143 - accuracy: 0.9600 - val_loss: 0.2446 - val_accuracy: 0.9300\n",
      "Epoch 43/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2062 - accuracy: 0.9625 - val_loss: 0.2424 - val_accuracy: 0.9300\n",
      "Epoch 44/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1968 - accuracy: 0.9650 - val_loss: 0.2349 - val_accuracy: 0.9300\n",
      "Epoch 45/500\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.1895 - accuracy: 0.9675 - val_loss: 0.2276 - val_accuracy: 0.9300\n",
      "Epoch 46/500\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.1823 - accuracy: 0.9700 - val_loss: 0.2239 - val_accuracy: 0.9300\n",
      "Epoch 47/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1757 - accuracy: 0.9725 - val_loss: 0.2214 - val_accuracy: 0.9300\n",
      "Epoch 48/500\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.1692 - accuracy: 0.9725 - val_loss: 0.2148 - val_accuracy: 0.9300\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 78us/step - loss: 0.1632 - accuracy: 0.9725 - val_loss: 0.2105 - val_accuracy: 0.9400\n",
      "Epoch 50/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1584 - accuracy: 0.9750 - val_loss: 0.2088 - val_accuracy: 0.9300\n",
      "Epoch 51/500\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.1525 - accuracy: 0.9750 - val_loss: 0.2040 - val_accuracy: 0.9300\n",
      "Epoch 52/500\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.1479 - accuracy: 0.9750 - val_loss: 0.2005 - val_accuracy: 0.9300\n",
      "Epoch 53/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.1429 - accuracy: 0.9750 - val_loss: 0.1988 - val_accuracy: 0.9300\n",
      "Epoch 54/500\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.1386 - accuracy: 0.9750 - val_loss: 0.1958 - val_accuracy: 0.9300\n",
      "Epoch 55/500\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.1346 - accuracy: 0.9750 - val_loss: 0.1927 - val_accuracy: 0.9300\n",
      "Epoch 56/500\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.1308 - accuracy: 0.9750 - val_loss: 0.1898 - val_accuracy: 0.9300\n",
      "Epoch 57/500\n",
      "400/400 [==============================] - 0s 88us/step - loss: 0.1278 - accuracy: 0.9750 - val_loss: 0.1870 - val_accuracy: 0.9300\n",
      "Epoch 58/500\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.1240 - accuracy: 0.9750 - val_loss: 0.1824 - val_accuracy: 0.9300\n",
      "Epoch 59/500\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.1201 - accuracy: 0.9750 - val_loss: 0.1818 - val_accuracy: 0.9300\n",
      "Epoch 60/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.1173 - accuracy: 0.9750 - val_loss: 0.1806 - val_accuracy: 0.9300\n",
      "Epoch 61/500\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.1143 - accuracy: 0.9750 - val_loss: 0.1768 - val_accuracy: 0.9300\n",
      "Epoch 62/500\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1112 - accuracy: 0.9750 - val_loss: 0.1751 - val_accuracy: 0.9300\n",
      "Epoch 63/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1086 - accuracy: 0.9750 - val_loss: 0.1721 - val_accuracy: 0.9300\n",
      "Epoch 64/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1065 - accuracy: 0.9750 - val_loss: 0.1713 - val_accuracy: 0.9300\n",
      "Epoch 65/500\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.1040 - accuracy: 0.9750 - val_loss: 0.1689 - val_accuracy: 0.9300\n",
      "Epoch 66/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1014 - accuracy: 0.9750 - val_loss: 0.1681 - val_accuracy: 0.9300\n",
      "Epoch 67/500\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.0992 - accuracy: 0.9750 - val_loss: 0.1660 - val_accuracy: 0.9300\n",
      "Epoch 68/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0976 - accuracy: 0.9750 - val_loss: 0.1677 - val_accuracy: 0.9300\n",
      "Epoch 69/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0950 - accuracy: 0.9750 - val_loss: 0.1649 - val_accuracy: 0.9300\n",
      "Epoch 70/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0932 - accuracy: 0.9750 - val_loss: 0.1624 - val_accuracy: 0.9400\n",
      "Epoch 71/500\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.0911 - accuracy: 0.9775 - val_loss: 0.1614 - val_accuracy: 0.9400\n",
      "Epoch 72/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0895 - accuracy: 0.9775 - val_loss: 0.1592 - val_accuracy: 0.9400\n",
      "Epoch 73/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0876 - accuracy: 0.9825 - val_loss: 0.1592 - val_accuracy: 0.9400\n",
      "Epoch 74/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0860 - accuracy: 0.9825 - val_loss: 0.1576 - val_accuracy: 0.9400\n",
      "Epoch 75/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0843 - accuracy: 0.9850 - val_loss: 0.1564 - val_accuracy: 0.9400\n",
      "Epoch 76/500\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0828 - accuracy: 0.9850 - val_loss: 0.1553 - val_accuracy: 0.9400\n",
      "Epoch 77/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0814 - accuracy: 0.9850 - val_loss: 0.1551 - val_accuracy: 0.9400\n",
      "Epoch 78/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0799 - accuracy: 0.9850 - val_loss: 0.1547 - val_accuracy: 0.9400\n",
      "Epoch 79/500\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0786 - accuracy: 0.9875 - val_loss: 0.1526 - val_accuracy: 0.9400\n",
      "Epoch 80/500\n",
      "400/400 [==============================] - 0s 89us/step - loss: 0.0773 - accuracy: 0.9875 - val_loss: 0.1527 - val_accuracy: 0.9400\n",
      "Epoch 81/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0759 - accuracy: 0.9900 - val_loss: 0.1519 - val_accuracy: 0.9400\n",
      "Epoch 82/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0744 - accuracy: 0.9900 - val_loss: 0.1510 - val_accuracy: 0.9400\n",
      "Epoch 83/500\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0737 - accuracy: 0.9900 - val_loss: 0.1496 - val_accuracy: 0.9400\n",
      "Epoch 84/500\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0721 - accuracy: 0.9900 - val_loss: 0.1506 - val_accuracy: 0.9400\n",
      "Epoch 85/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0709 - accuracy: 0.9900 - val_loss: 0.1498 - val_accuracy: 0.9400\n",
      "Epoch 86/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0698 - accuracy: 0.9900 - val_loss: 0.1484 - val_accuracy: 0.9400\n",
      "Epoch 87/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0686 - accuracy: 0.9900 - val_loss: 0.1469 - val_accuracy: 0.9400\n",
      "Epoch 88/500\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0676 - accuracy: 0.9900 - val_loss: 0.1467 - val_accuracy: 0.9400\n",
      "Epoch 89/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0665 - accuracy: 0.9900 - val_loss: 0.1472 - val_accuracy: 0.9400\n",
      "Epoch 90/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0654 - accuracy: 0.9900 - val_loss: 0.1467 - val_accuracy: 0.9400\n",
      "Epoch 91/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0647 - accuracy: 0.9925 - val_loss: 0.1457 - val_accuracy: 0.9400\n",
      "Epoch 92/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0634 - accuracy: 0.9925 - val_loss: 0.1464 - val_accuracy: 0.9400\n",
      "Epoch 93/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0623 - accuracy: 0.9925 - val_loss: 0.1458 - val_accuracy: 0.9400\n",
      "Epoch 94/500\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.0616 - accuracy: 0.9925 - val_loss: 0.1449 - val_accuracy: 0.9400\n",
      "Epoch 95/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0606 - accuracy: 0.9925 - val_loss: 0.1437 - val_accuracy: 0.9400\n",
      "Epoch 96/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0596 - accuracy: 0.9925 - val_loss: 0.1442 - val_accuracy: 0.9400\n",
      "Epoch 97/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0588 - accuracy: 0.9925 - val_loss: 0.1435 - val_accuracy: 0.9400\n",
      "Epoch 98/500\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0582 - accuracy: 0.9925 - val_loss: 0.1424 - val_accuracy: 0.9400\n",
      "Epoch 99/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0571 - accuracy: 0.9925 - val_loss: 0.1435 - val_accuracy: 0.9400\n",
      "Epoch 100/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0563 - accuracy: 0.9925 - val_loss: 0.1427 - val_accuracy: 0.9400\n",
      "Epoch 101/500\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0556 - accuracy: 0.9925 - val_loss: 0.1426 - val_accuracy: 0.9400\n",
      "Epoch 102/500\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0548 - accuracy: 0.9925 - val_loss: 0.1421 - val_accuracy: 0.9400\n",
      "Epoch 103/500\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0538 - accuracy: 0.9925 - val_loss: 0.1436 - val_accuracy: 0.9400\n",
      "Epoch 104/500\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0535 - accuracy: 0.9925 - val_loss: 0.1444 - val_accuracy: 0.9400\n",
      "Epoch 105/500\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0525 - accuracy: 0.9925 - val_loss: 0.1423 - val_accuracy: 0.9400\n",
      "Epoch 106/500\n",
      "400/400 [==============================] - 0s 89us/step - loss: 0.0516 - accuracy: 0.9925 - val_loss: 0.1410 - val_accuracy: 0.9400\n",
      "Epoch 107/500\n",
      "400/400 [==============================] - 0s 88us/step - loss: 0.0509 - accuracy: 0.9925 - val_loss: 0.1408 - val_accuracy: 0.9400\n",
      "Epoch 108/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0503 - accuracy: 0.9925 - val_loss: 0.1406 - val_accuracy: 0.9400\n",
      "Epoch 109/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0495 - accuracy: 0.9925 - val_loss: 0.1413 - val_accuracy: 0.9400\n",
      "Epoch 110/500\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0488 - accuracy: 0.9925 - val_loss: 0.1423 - val_accuracy: 0.9400\n",
      "Epoch 111/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0483 - accuracy: 0.9925 - val_loss: 0.1419 - val_accuracy: 0.9400\n",
      "Epoch 112/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0478 - accuracy: 0.9925 - val_loss: 0.1401 - val_accuracy: 0.9400\n",
      "Epoch 113/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0469 - accuracy: 0.9925 - val_loss: 0.1410 - val_accuracy: 0.9400\n",
      "Epoch 114/500\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0462 - accuracy: 0.9925 - val_loss: 0.1411 - val_accuracy: 0.9400\n",
      "Epoch 115/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0458 - accuracy: 0.9925 - val_loss: 0.1424 - val_accuracy: 0.9400\n",
      "Epoch 116/500\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0449 - accuracy: 0.9925 - val_loss: 0.1402 - val_accuracy: 0.9400\n",
      "Epoch 117/500\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.0443 - accuracy: 0.9925 - val_loss: 0.1403 - val_accuracy: 0.9400\n",
      "Epoch 118/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0437 - accuracy: 0.9925 - val_loss: 0.1400 - val_accuracy: 0.9400\n",
      "Epoch 119/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0434 - accuracy: 0.9925 - val_loss: 0.1416 - val_accuracy: 0.9400\n",
      "Epoch 120/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0425 - accuracy: 0.9925 - val_loss: 0.1397 - val_accuracy: 0.9400\n",
      "Epoch 121/500\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0418 - accuracy: 0.9925 - val_loss: 0.1390 - val_accuracy: 0.9400\n",
      "Epoch 122/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0415 - accuracy: 0.9925 - val_loss: 0.1386 - val_accuracy: 0.9400\n",
      "Epoch 123/500\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0411 - accuracy: 0.9925 - val_loss: 0.1407 - val_accuracy: 0.9400\n",
      "Epoch 124/500\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0403 - accuracy: 0.9925 - val_loss: 0.1404 - val_accuracy: 0.9400\n",
      "Epoch 125/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0398 - accuracy: 0.9925 - val_loss: 0.1395 - val_accuracy: 0.9400\n",
      "Epoch 126/500\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.0395 - accuracy: 0.9925 - val_loss: 0.1409 - val_accuracy: 0.9400\n",
      "Epoch 127/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0388 - accuracy: 0.9925 - val_loss: 0.1391 - val_accuracy: 0.9400\n",
      "Epoch 128/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0383 - accuracy: 0.9925 - val_loss: 0.1390 - val_accuracy: 0.9400\n",
      "Epoch 129/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0378 - accuracy: 0.9925 - val_loss: 0.1403 - val_accuracy: 0.9400\n",
      "Epoch 130/500\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0373 - accuracy: 0.9925 - val_loss: 0.1387 - val_accuracy: 0.9400\n",
      "Epoch 131/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0367 - accuracy: 0.9925 - val_loss: 0.1396 - val_accuracy: 0.9400\n",
      "Epoch 132/500\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0363 - accuracy: 0.9925 - val_loss: 0.1400 - val_accuracy: 0.9400\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5837915180348018\n",
      "F1 Micro: 0.9445\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/500\n",
      "400/400 [==============================] - 0s 719us/step - loss: 2.0462 - accuracy: 0.2850 - val_loss: 1.5839 - val_accuracy: 0.7900\n",
      "Epoch 2/500\n",
      "400/400 [==============================] - 0s 240us/step - loss: 1.1050 - accuracy: 0.8775 - val_loss: 0.4969 - val_accuracy: 0.8900\n",
      "Epoch 3/500\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.5329 - accuracy: 0.8550 - val_loss: 0.4220 - val_accuracy: 0.8900\n",
      "Epoch 4/500\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.4462 - accuracy: 0.8750 - val_loss: 0.3648 - val_accuracy: 0.9100\n",
      "Epoch 5/500\n",
      "400/400 [==============================] - 0s 238us/step - loss: 0.3850 - accuracy: 0.8900 - val_loss: 0.3468 - val_accuracy: 0.9200\n",
      "Epoch 6/500\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3586 - accuracy: 0.9000 - val_loss: 0.3266 - val_accuracy: 0.9200\n",
      "Epoch 7/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3376 - accuracy: 0.9050 - val_loss: 0.3114 - val_accuracy: 0.9200\n",
      "Epoch 8/500\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.3209 - accuracy: 0.9100 - val_loss: 0.3011 - val_accuracy: 0.9200\n",
      "Epoch 9/500\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.3055 - accuracy: 0.9150 - val_loss: 0.2902 - val_accuracy: 0.9200\n",
      "Epoch 10/500\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2918 - accuracy: 0.9225 - val_loss: 0.2805 - val_accuracy: 0.9200\n",
      "Epoch 11/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2797 - accuracy: 0.9225 - val_loss: 0.2728 - val_accuracy: 0.9200\n",
      "Epoch 12/500\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2693 - accuracy: 0.9300 - val_loss: 0.2662 - val_accuracy: 0.9200\n",
      "Epoch 13/500\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.2580 - accuracy: 0.9250 - val_loss: 0.2562 - val_accuracy: 0.9200\n",
      "Epoch 14/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2493 - accuracy: 0.9300 - val_loss: 0.2516 - val_accuracy: 0.9200\n",
      "Epoch 15/500\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.2407 - accuracy: 0.9325 - val_loss: 0.2441 - val_accuracy: 0.9200\n",
      "Epoch 16/500\n",
      "400/400 [==============================] - 0s 206us/step - loss: 0.2336 - accuracy: 0.9425 - val_loss: 0.2397 - val_accuracy: 0.9200\n",
      "Epoch 17/500\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.2244 - accuracy: 0.9425 - val_loss: 0.2339 - val_accuracy: 0.9200\n",
      "Epoch 18/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2161 - accuracy: 0.9450 - val_loss: 0.2287 - val_accuracy: 0.9300\n",
      "Epoch 19/500\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2100 - accuracy: 0.9475 - val_loss: 0.2235 - val_accuracy: 0.9300\n",
      "Epoch 20/500\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.2035 - accuracy: 0.9475 - val_loss: 0.2191 - val_accuracy: 0.9300\n",
      "Epoch 21/500\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1973 - accuracy: 0.9475 - val_loss: 0.2125 - val_accuracy: 0.9400\n",
      "Epoch 22/500\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1912 - accuracy: 0.9475 - val_loss: 0.2086 - val_accuracy: 0.9400\n",
      "Epoch 23/500\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1859 - accuracy: 0.9500 - val_loss: 0.2048 - val_accuracy: 0.9400\n",
      "Epoch 24/500\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1821 - accuracy: 0.9550 - val_loss: 0.2015 - val_accuracy: 0.9400\n",
      "Epoch 25/500\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1791 - accuracy: 0.9475 - val_loss: 0.1978 - val_accuracy: 0.9400\n",
      "Epoch 26/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1728 - accuracy: 0.9575 - val_loss: 0.1959 - val_accuracy: 0.9500\n",
      "Epoch 27/500\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1678 - accuracy: 0.9525 - val_loss: 0.1909 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1646 - accuracy: 0.9600 - val_loss: 0.1897 - val_accuracy: 0.9500\n",
      "Epoch 29/500\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1585 - accuracy: 0.9575 - val_loss: 0.1870 - val_accuracy: 0.9400\n",
      "Epoch 30/500\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1552 - accuracy: 0.9600 - val_loss: 0.1833 - val_accuracy: 0.9500\n",
      "Epoch 31/500\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.1505 - accuracy: 0.9600 - val_loss: 0.1816 - val_accuracy: 0.9400\n",
      "Epoch 32/500\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1480 - accuracy: 0.9600 - val_loss: 0.1794 - val_accuracy: 0.9500\n",
      "Epoch 33/500\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.1463 - accuracy: 0.9600 - val_loss: 0.1783 - val_accuracy: 0.9500\n",
      "Epoch 34/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1443 - accuracy: 0.9675 - val_loss: 0.1747 - val_accuracy: 0.9500\n",
      "Epoch 35/500\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1394 - accuracy: 0.9625 - val_loss: 0.1717 - val_accuracy: 0.9500\n",
      "Epoch 36/500\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1374 - accuracy: 0.9725 - val_loss: 0.1691 - val_accuracy: 0.9500\n",
      "Epoch 37/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1329 - accuracy: 0.9625 - val_loss: 0.1668 - val_accuracy: 0.9500\n",
      "Epoch 38/500\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1290 - accuracy: 0.9725 - val_loss: 0.1636 - val_accuracy: 0.9400\n",
      "Epoch 39/500\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1254 - accuracy: 0.9725 - val_loss: 0.1629 - val_accuracy: 0.9400\n",
      "Epoch 40/500\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1257 - accuracy: 0.9650 - val_loss: 0.1638 - val_accuracy: 0.9500\n",
      "Epoch 41/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1228 - accuracy: 0.9700 - val_loss: 0.1619 - val_accuracy: 0.9400\n",
      "Epoch 42/500\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1190 - accuracy: 0.9725 - val_loss: 0.1586 - val_accuracy: 0.9400\n",
      "Epoch 43/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1171 - accuracy: 0.9700 - val_loss: 0.1574 - val_accuracy: 0.9400\n",
      "Epoch 44/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1159 - accuracy: 0.9725 - val_loss: 0.1566 - val_accuracy: 0.9400\n",
      "Epoch 45/500\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.1116 - accuracy: 0.9775 - val_loss: 0.1549 - val_accuracy: 0.9400\n",
      "Epoch 46/500\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.1082 - accuracy: 0.9775 - val_loss: 0.1553 - val_accuracy: 0.9400\n",
      "Epoch 47/500\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1074 - accuracy: 0.9775 - val_loss: 0.1541 - val_accuracy: 0.9300\n",
      "Epoch 48/500\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1051 - accuracy: 0.9775 - val_loss: 0.1523 - val_accuracy: 0.9300\n",
      "Epoch 49/500\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1043 - accuracy: 0.9775 - val_loss: 0.1509 - val_accuracy: 0.9400\n",
      "Epoch 50/500\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1005 - accuracy: 0.9775 - val_loss: 0.1497 - val_accuracy: 0.9300\n",
      "Epoch 51/500\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0989 - accuracy: 0.9800 - val_loss: 0.1503 - val_accuracy: 0.9300\n",
      "Epoch 52/500\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0982 - accuracy: 0.9775 - val_loss: 0.1492 - val_accuracy: 0.9300\n",
      "Epoch 53/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0952 - accuracy: 0.9800 - val_loss: 0.1482 - val_accuracy: 0.9300\n",
      "Epoch 54/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0934 - accuracy: 0.9800 - val_loss: 0.1478 - val_accuracy: 0.9300\n",
      "Epoch 55/500\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0912 - accuracy: 0.9800 - val_loss: 0.1467 - val_accuracy: 0.9300\n",
      "Epoch 56/500\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0898 - accuracy: 0.9800 - val_loss: 0.1460 - val_accuracy: 0.9300\n",
      "Epoch 57/500\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.0878 - accuracy: 0.9800 - val_loss: 0.1447 - val_accuracy: 0.9300\n",
      "Epoch 58/500\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0867 - accuracy: 0.9800 - val_loss: 0.1430 - val_accuracy: 0.9300\n",
      "Epoch 59/500\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0849 - accuracy: 0.9825 - val_loss: 0.1421 - val_accuracy: 0.9300\n",
      "Epoch 60/500\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0826 - accuracy: 0.9825 - val_loss: 0.1415 - val_accuracy: 0.9300\n",
      "Epoch 61/500\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.0813 - accuracy: 0.9825 - val_loss: 0.1411 - val_accuracy: 0.9300\n",
      "Epoch 62/500\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.0800 - accuracy: 0.9825 - val_loss: 0.1432 - val_accuracy: 0.9300\n",
      "Epoch 63/500\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0796 - accuracy: 0.9850 - val_loss: 0.1391 - val_accuracy: 0.9300\n",
      "Epoch 64/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0769 - accuracy: 0.9875 - val_loss: 0.1378 - val_accuracy: 0.9300\n",
      "Epoch 65/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0755 - accuracy: 0.9825 - val_loss: 0.1372 - val_accuracy: 0.9300\n",
      "Epoch 66/500\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0739 - accuracy: 0.9875 - val_loss: 0.1384 - val_accuracy: 0.9300\n",
      "Epoch 67/500\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0726 - accuracy: 0.9875 - val_loss: 0.1378 - val_accuracy: 0.9400\n",
      "Epoch 68/500\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0736 - accuracy: 0.9875 - val_loss: 0.1372 - val_accuracy: 0.9400\n",
      "Epoch 69/500\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.0705 - accuracy: 0.9900 - val_loss: 0.1404 - val_accuracy: 0.9300\n",
      "Epoch 70/500\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.0724 - accuracy: 0.9825 - val_loss: 0.1350 - val_accuracy: 0.9400\n",
      "Epoch 71/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0670 - accuracy: 0.9900 - val_loss: 0.1416 - val_accuracy: 0.9300\n",
      "Epoch 72/500\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0677 - accuracy: 0.9875 - val_loss: 0.1377 - val_accuracy: 0.9400\n",
      "Epoch 73/500\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.0645 - accuracy: 0.9875 - val_loss: 0.1355 - val_accuracy: 0.9400\n",
      "Epoch 74/500\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0631 - accuracy: 0.9875 - val_loss: 0.1354 - val_accuracy: 0.9400\n",
      "Epoch 75/500\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0615 - accuracy: 0.9875 - val_loss: 0.1367 - val_accuracy: 0.9400\n",
      "Epoch 76/500\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0613 - accuracy: 0.9875 - val_loss: 0.1372 - val_accuracy: 0.9400\n",
      "Epoch 77/500\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0599 - accuracy: 0.9900 - val_loss: 0.1346 - val_accuracy: 0.9400\n",
      "Epoch 78/500\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0592 - accuracy: 0.9875 - val_loss: 0.1331 - val_accuracy: 0.9500\n",
      "Epoch 79/500\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0582 - accuracy: 0.9900 - val_loss: 0.1327 - val_accuracy: 0.9500\n",
      "Epoch 80/500\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0560 - accuracy: 0.9900 - val_loss: 0.1372 - val_accuracy: 0.9300\n",
      "Epoch 81/500\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0574 - accuracy: 0.9875 - val_loss: 0.1331 - val_accuracy: 0.9500\n",
      "Epoch 82/500\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0572 - accuracy: 0.9900 - val_loss: 0.1425 - val_accuracy: 0.9300\n",
      "Epoch 83/500\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0556 - accuracy: 0.9875 - val_loss: 0.1328 - val_accuracy: 0.9400\n",
      "Epoch 84/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0512 - accuracy: 0.9900 - val_loss: 0.1342 - val_accuracy: 0.9400\n",
      "Epoch 85/500\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0512 - accuracy: 0.9900 - val_loss: 0.1318 - val_accuracy: 0.9500\n",
      "Epoch 86/500\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0495 - accuracy: 0.9875 - val_loss: 0.1314 - val_accuracy: 0.9500\n",
      "Epoch 87/500\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0510 - accuracy: 0.9900 - val_loss: 0.1411 - val_accuracy: 0.9400\n",
      "Epoch 88/500\n",
      "400/400 [==============================] - 0s 235us/step - loss: 0.0480 - accuracy: 0.9925 - val_loss: 0.1317 - val_accuracy: 0.9500\n",
      "Epoch 89/500\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.99 - 0s 227us/step - loss: 0.0468 - accuracy: 0.9900 - val_loss: 0.1318 - val_accuracy: 0.9500\n",
      "Epoch 90/500\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0471 - accuracy: 0.9925 - val_loss: 0.1435 - val_accuracy: 0.9400\n",
      "Epoch 91/500\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.0471 - accuracy: 0.9925 - val_loss: 0.1321 - val_accuracy: 0.9300\n",
      "Epoch 92/500\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0466 - accuracy: 0.9900 - val_loss: 0.1376 - val_accuracy: 0.9500\n",
      "Epoch 93/500\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0416 - accuracy: 0.9900 - val_loss: 0.1309 - val_accuracy: 0.9500\n",
      "Epoch 94/500\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0417 - accuracy: 0.9925 - val_loss: 0.1326 - val_accuracy: 0.9500\n",
      "Epoch 95/500\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0405 - accuracy: 0.9925 - val_loss: 0.1332 - val_accuracy: 0.9500\n",
      "Epoch 96/500\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.0402 - accuracy: 0.9925 - val_loss: 0.1354 - val_accuracy: 0.9500\n",
      "Epoch 97/500\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0404 - accuracy: 0.9900 - val_loss: 0.1307 - val_accuracy: 0.9500\n",
      "Epoch 98/500\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0371 - accuracy: 0.9925 - val_loss: 0.1389 - val_accuracy: 0.9500\n",
      "Epoch 99/500\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.0369 - accuracy: 0.9925 - val_loss: 0.1335 - val_accuracy: 0.9500\n",
      "Epoch 100/500\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0356 - accuracy: 0.9925 - val_loss: 0.1325 - val_accuracy: 0.9500\n",
      "Epoch 101/500\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0351 - accuracy: 0.9950 - val_loss: 0.1424 - val_accuracy: 0.9400\n",
      "Epoch 102/500\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.0356 - accuracy: 0.9925 - val_loss: 0.1334 - val_accuracy: 0.9500\n",
      "Epoch 103/500\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0322 - accuracy: 0.9950 - val_loss: 0.1385 - val_accuracy: 0.9500\n",
      "Epoch 104/500\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0318 - accuracy: 0.9950 - val_loss: 0.1335 - val_accuracy: 0.9500\n",
      "Epoch 105/500\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0307 - accuracy: 0.9950 - val_loss: 0.1360 - val_accuracy: 0.9500\n",
      "Epoch 106/500\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0306 - accuracy: 0.9950 - val_loss: 0.1435 - val_accuracy: 0.9400\n",
      "Epoch 107/500\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.0312 - accuracy: 0.9950 - val_loss: 0.1337 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5625644607719367\n",
      "F1 Micro: 0.9406\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5611460223619759\n",
      "F1 Micro: 0.9367\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5844787675934716\n",
      "F1 Micro: 0.9448\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 1 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/500\n",
      "4000/4000 [==============================] - 1s 283us/step - loss: 0.9002 - accuracy: 0.8310 - val_loss: 0.6188 - val_accuracy: 0.8650\n",
      "Epoch 2/500\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.6461 - accuracy: 0.8490 - val_loss: 0.5750 - val_accuracy: 0.8650\n",
      "Epoch 3/500\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.5631 - accuracy: 0.8475 - val_loss: 0.4868 - val_accuracy: 0.8640\n",
      "Epoch 4/500\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.4684 - accuracy: 0.8727 - val_loss: 0.4245 - val_accuracy: 0.8800\n",
      "Epoch 5/500\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.3815 - accuracy: 0.9015 - val_loss: 0.3642 - val_accuracy: 0.9080\n",
      "Epoch 6/500\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.3470 - accuracy: 0.9115 - val_loss: 0.3195 - val_accuracy: 0.9140\n",
      "Epoch 7/500\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.3170 - accuracy: 0.9172 - val_loss: 0.3531 - val_accuracy: 0.9190\n",
      "Epoch 8/500\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.3048 - accuracy: 0.9190 - val_loss: 0.2911 - val_accuracy: 0.9200\n",
      "Epoch 9/500\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.2799 - accuracy: 0.9245 - val_loss: 0.2705 - val_accuracy: 0.9280\n",
      "Epoch 10/500\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.2612 - accuracy: 0.9283 - val_loss: 0.2463 - val_accuracy: 0.9260\n",
      "Epoch 11/500\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.2514 - accuracy: 0.9290 - val_loss: 0.2407 - val_accuracy: 0.9270\n",
      "Epoch 12/500\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.2406 - accuracy: 0.9305 - val_loss: 0.2277 - val_accuracy: 0.9300\n",
      "Epoch 13/500\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.2235 - accuracy: 0.9375 - val_loss: 0.2286 - val_accuracy: 0.9300\n",
      "Epoch 14/500\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.2072 - accuracy: 0.9413 - val_loss: 0.2292 - val_accuracy: 0.9330\n",
      "Epoch 15/500\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.1994 - accuracy: 0.9438 - val_loss: 0.2083 - val_accuracy: 0.9380\n",
      "Epoch 16/500\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1821 - accuracy: 0.9492 - val_loss: 0.2147 - val_accuracy: 0.9370\n",
      "Epoch 17/500\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1831 - accuracy: 0.9463 - val_loss: 0.1952 - val_accuracy: 0.9400\n",
      "Epoch 18/500\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.1730 - accuracy: 0.9510 - val_loss: 0.1911 - val_accuracy: 0.9410\n",
      "Epoch 19/500\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1627 - accuracy: 0.9517 - val_loss: 0.1828 - val_accuracy: 0.9420\n",
      "Epoch 20/500\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.1539 - accuracy: 0.9570 - val_loss: 0.1883 - val_accuracy: 0.9380\n",
      "Epoch 21/500\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1413 - accuracy: 0.9597 - val_loss: 0.1892 - val_accuracy: 0.9440\n",
      "Epoch 22/500\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1479 - accuracy: 0.9553 - val_loss: 0.1967 - val_accuracy: 0.9350\n",
      "Epoch 23/500\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.1333 - accuracy: 0.9620 - val_loss: 0.1775 - val_accuracy: 0.9410\n",
      "Epoch 24/500\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1331 - accuracy: 0.9610 - val_loss: 0.1860 - val_accuracy: 0.9430\n",
      "Epoch 25/500\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1235 - accuracy: 0.9645 - val_loss: 0.1845 - val_accuracy: 0.9460\n",
      "Epoch 26/500\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1189 - accuracy: 0.9660 - val_loss: 0.2092 - val_accuracy: 0.9420\n",
      "Epoch 27/500\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1219 - accuracy: 0.9635 - val_loss: 0.1716 - val_accuracy: 0.9470\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1194 - accuracy: 0.9657 - val_loss: 0.1783 - val_accuracy: 0.9450\n",
      "Epoch 29/500\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1127 - accuracy: 0.9647 - val_loss: 0.1756 - val_accuracy: 0.9440\n",
      "Epoch 30/500\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1101 - accuracy: 0.9663 - val_loss: 0.1570 - val_accuracy: 0.9500\n",
      "Epoch 31/500\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1031 - accuracy: 0.9690 - val_loss: 0.1843 - val_accuracy: 0.9470\n",
      "Epoch 32/500\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1006 - accuracy: 0.9703 - val_loss: 0.1578 - val_accuracy: 0.9500\n",
      "Epoch 33/500\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0932 - accuracy: 0.9725 - val_loss: 0.1582 - val_accuracy: 0.9500\n",
      "Epoch 34/500\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0981 - accuracy: 0.9693 - val_loss: 0.1811 - val_accuracy: 0.9460\n",
      "Epoch 35/500\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0895 - accuracy: 0.9730 - val_loss: 0.1682 - val_accuracy: 0.9530\n",
      "Epoch 36/500\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0896 - accuracy: 0.9740 - val_loss: 0.1581 - val_accuracy: 0.9500\n",
      "Epoch 37/500\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0894 - accuracy: 0.9715 - val_loss: 0.2032 - val_accuracy: 0.9470\n",
      "Epoch 38/500\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0838 - accuracy: 0.9735 - val_loss: 0.1584 - val_accuracy: 0.9500\n",
      "Epoch 39/500\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0910 - accuracy: 0.9718 - val_loss: 0.1636 - val_accuracy: 0.9460\n",
      "Epoch 40/500\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0756 - accuracy: 0.9787 - val_loss: 0.1740 - val_accuracy: 0.9460\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5494205261663557\n",
      "F1 Micro: 0.9544\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.595380977777457\n",
      "F1 Micro: 0.9538\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/500\n",
      "4000/4000 [==============================] - 0s 97us/step - loss: 1.6891 - accuracy: 0.5412 - val_loss: 1.3596 - val_accuracy: 0.6890\n",
      "Epoch 2/500\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 1.0642 - accuracy: 0.7880 - val_loss: 0.8453 - val_accuracy: 0.8280\n",
      "Epoch 3/500\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.6261 - accuracy: 0.8932 - val_loss: 0.5169 - val_accuracy: 0.9050\n",
      "Epoch 4/500\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.3866 - accuracy: 0.9295 - val_loss: 0.3445 - val_accuracy: 0.9310\n",
      "Epoch 5/500\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.2747 - accuracy: 0.9400 - val_loss: 0.2620 - val_accuracy: 0.9390\n",
      "Epoch 6/500\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.2201 - accuracy: 0.9477 - val_loss: 0.2234 - val_accuracy: 0.9430\n",
      "Epoch 7/500\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.1917 - accuracy: 0.9525 - val_loss: 0.2029 - val_accuracy: 0.9430\n",
      "Epoch 8/500\n",
      "4000/4000 [==============================] - 0s 79us/step - loss: 0.1739 - accuracy: 0.9542 - val_loss: 0.1887 - val_accuracy: 0.9440\n",
      "Epoch 9/500\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1616 - accuracy: 0.9563 - val_loss: 0.1786 - val_accuracy: 0.9460\n",
      "Epoch 10/500\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1527 - accuracy: 0.9578 - val_loss: 0.1733 - val_accuracy: 0.9470\n",
      "Epoch 11/500\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.1451 - accuracy: 0.9597 - val_loss: 0.1677 - val_accuracy: 0.9460\n",
      "Epoch 12/500\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1391 - accuracy: 0.9603 - val_loss: 0.1637 - val_accuracy: 0.9490\n",
      "Epoch 13/500\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1340 - accuracy: 0.9590 - val_loss: 0.1627 - val_accuracy: 0.9490\n",
      "Epoch 14/500\n",
      "4000/4000 [==============================] - 0s 80us/step - loss: 0.1296 - accuracy: 0.9620 - val_loss: 0.1579 - val_accuracy: 0.9500\n",
      "Epoch 15/500\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1266 - accuracy: 0.9625 - val_loss: 0.1598 - val_accuracy: 0.9510\n",
      "Epoch 16/500\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1217 - accuracy: 0.9635 - val_loss: 0.1532 - val_accuracy: 0.9510\n",
      "Epoch 17/500\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1189 - accuracy: 0.9640 - val_loss: 0.1519 - val_accuracy: 0.9500\n",
      "Epoch 18/500\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1157 - accuracy: 0.9653 - val_loss: 0.1561 - val_accuracy: 0.9520\n",
      "Epoch 19/500\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1143 - accuracy: 0.9650 - val_loss: 0.1529 - val_accuracy: 0.9520\n",
      "Epoch 20/500\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1106 - accuracy: 0.9675 - val_loss: 0.1486 - val_accuracy: 0.9500\n",
      "Epoch 21/500\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1086 - accuracy: 0.9678 - val_loss: 0.1465 - val_accuracy: 0.9510\n",
      "Epoch 22/500\n",
      "4000/4000 [==============================] - 0s 79us/step - loss: 0.1056 - accuracy: 0.9688 - val_loss: 0.1489 - val_accuracy: 0.9530\n",
      "Epoch 23/500\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1034 - accuracy: 0.9695 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
      "Epoch 24/500\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1021 - accuracy: 0.9700 - val_loss: 0.1490 - val_accuracy: 0.9550\n",
      "Epoch 25/500\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1001 - accuracy: 0.9685 - val_loss: 0.1443 - val_accuracy: 0.9520\n",
      "Epoch 26/500\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0982 - accuracy: 0.9705 - val_loss: 0.1481 - val_accuracy: 0.9550\n",
      "Epoch 27/500\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0961 - accuracy: 0.9703 - val_loss: 0.1452 - val_accuracy: 0.9520\n",
      "Epoch 28/500\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0947 - accuracy: 0.9712 - val_loss: 0.1440 - val_accuracy: 0.9550\n",
      "Epoch 29/500\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0932 - accuracy: 0.9703 - val_loss: 0.1439 - val_accuracy: 0.9550\n",
      "Epoch 30/500\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0916 - accuracy: 0.9710 - val_loss: 0.1465 - val_accuracy: 0.9540\n",
      "Epoch 31/500\n",
      "4000/4000 [==============================] - 0s 79us/step - loss: 0.0899 - accuracy: 0.9730 - val_loss: 0.1448 - val_accuracy: 0.9550\n",
      "Epoch 32/500\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0881 - accuracy: 0.9732 - val_loss: 0.1462 - val_accuracy: 0.9530\n",
      "Epoch 33/500\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0865 - accuracy: 0.9743 - val_loss: 0.1429 - val_accuracy: 0.9570\n",
      "Epoch 34/500\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0860 - accuracy: 0.9720 - val_loss: 0.1465 - val_accuracy: 0.9540\n",
      "Epoch 35/500\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0843 - accuracy: 0.9750 - val_loss: 0.1434 - val_accuracy: 0.9560\n",
      "Epoch 36/500\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0827 - accuracy: 0.9753 - val_loss: 0.1445 - val_accuracy: 0.9560\n",
      "Epoch 37/500\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0816 - accuracy: 0.9745 - val_loss: 0.1437 - val_accuracy: 0.9560\n",
      "Epoch 38/500\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0802 - accuracy: 0.9760 - val_loss: 0.1455 - val_accuracy: 0.9540\n",
      "Epoch 39/500\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0791 - accuracy: 0.9765 - val_loss: 0.1460 - val_accuracy: 0.9580\n",
      "Epoch 40/500\n",
      "4000/4000 [==============================] - 0s 80us/step - loss: 0.0779 - accuracy: 0.9768 - val_loss: 0.1479 - val_accuracy: 0.9550\n",
      "Epoch 41/500\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0765 - accuracy: 0.9768 - val_loss: 0.1447 - val_accuracy: 0.9570\n",
      "Epoch 42/500\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0757 - accuracy: 0.9775 - val_loss: 0.1487 - val_accuracy: 0.9570\n",
      "Epoch 43/500\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0740 - accuracy: 0.9775 - val_loss: 0.1481 - val_accuracy: 0.9580\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6204081983414356\n",
      "F1 Micro: 0.9577000000000001\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/500\n",
      "4000/4000 [==============================] - 1s 259us/step - loss: 0.6931 - accuracy: 0.8115 - val_loss: 0.3492 - val_accuracy: 0.9170\n",
      "Epoch 2/500\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.3122 - accuracy: 0.9208 - val_loss: 0.2807 - val_accuracy: 0.9250\n",
      "Epoch 3/500\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.2603 - accuracy: 0.9335 - val_loss: 0.2465 - val_accuracy: 0.9310\n",
      "Epoch 4/500\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.2281 - accuracy: 0.9390 - val_loss: 0.2220 - val_accuracy: 0.9410\n",
      "Epoch 5/500\n",
      "4000/4000 [==============================] - 1s 214us/step - loss: 0.2070 - accuracy: 0.9457 - val_loss: 0.2031 - val_accuracy: 0.9440\n",
      "Epoch 6/500\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1893 - accuracy: 0.9490 - val_loss: 0.1942 - val_accuracy: 0.9410\n",
      "Epoch 7/500\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.1765 - accuracy: 0.9510 - val_loss: 0.1816 - val_accuracy: 0.9470\n",
      "Epoch 8/500\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.1656 - accuracy: 0.9535 - val_loss: 0.1743 - val_accuracy: 0.9490\n",
      "Epoch 9/500\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.1579 - accuracy: 0.9560 - val_loss: 0.1692 - val_accuracy: 0.9510\n",
      "Epoch 10/500\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.1513 - accuracy: 0.9557 - val_loss: 0.1598 - val_accuracy: 0.9510\n",
      "Epoch 11/500\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1438 - accuracy: 0.9585 - val_loss: 0.1608 - val_accuracy: 0.9510\n",
      "Epoch 12/500\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.1409 - accuracy: 0.9578 - val_loss: 0.1564 - val_accuracy: 0.9500\n",
      "Epoch 13/500\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.1346 - accuracy: 0.9607 - val_loss: 0.1496 - val_accuracy: 0.9540\n",
      "Epoch 14/500\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.1304 - accuracy: 0.9620 - val_loss: 0.1490 - val_accuracy: 0.9530\n",
      "Epoch 15/500\n",
      "4000/4000 [==============================] - 1s 211us/step - loss: 0.1250 - accuracy: 0.9643 - val_loss: 0.1478 - val_accuracy: 0.9550\n",
      "Epoch 16/500\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1222 - accuracy: 0.9650 - val_loss: 0.1481 - val_accuracy: 0.9530\n",
      "Epoch 17/500\n",
      "4000/4000 [==============================] - 1s 213us/step - loss: 0.1183 - accuracy: 0.9638 - val_loss: 0.1487 - val_accuracy: 0.9530\n",
      "Epoch 18/500\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1150 - accuracy: 0.9653 - val_loss: 0.1381 - val_accuracy: 0.9590\n",
      "Epoch 19/500\n",
      "4000/4000 [==============================] - 1s 213us/step - loss: 0.1111 - accuracy: 0.9680 - val_loss: 0.1409 - val_accuracy: 0.9570\n",
      "Epoch 20/500\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.1072 - accuracy: 0.9682 - val_loss: 0.1386 - val_accuracy: 0.9590\n",
      "Epoch 21/500\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.1049 - accuracy: 0.9685 - val_loss: 0.1378 - val_accuracy: 0.9570\n",
      "Epoch 22/500\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.1003 - accuracy: 0.9707 - val_loss: 0.1366 - val_accuracy: 0.9590\n",
      "Epoch 23/500\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0995 - accuracy: 0.9718 - val_loss: 0.1359 - val_accuracy: 0.9610\n",
      "Epoch 24/500\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0953 - accuracy: 0.9715 - val_loss: 0.1400 - val_accuracy: 0.9620\n",
      "Epoch 25/500\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.0925 - accuracy: 0.9703 - val_loss: 0.1391 - val_accuracy: 0.9610\n",
      "Epoch 26/500\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0896 - accuracy: 0.9718 - val_loss: 0.1447 - val_accuracy: 0.9550\n",
      "Epoch 27/500\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0843 - accuracy: 0.9755 - val_loss: 0.1331 - val_accuracy: 0.9600\n",
      "Epoch 28/500\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0795 - accuracy: 0.9743 - val_loss: 0.1365 - val_accuracy: 0.9540\n",
      "Epoch 29/500\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.0771 - accuracy: 0.9755 - val_loss: 0.1453 - val_accuracy: 0.9560\n",
      "Epoch 30/500\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0710 - accuracy: 0.9803 - val_loss: 0.1340 - val_accuracy: 0.9580\n",
      "Epoch 31/500\n",
      "4000/4000 [==============================] - 1s 211us/step - loss: 0.0680 - accuracy: 0.9797 - val_loss: 0.1373 - val_accuracy: 0.9580\n",
      "Epoch 32/500\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.0600 - accuracy: 0.9812 - val_loss: 0.1680 - val_accuracy: 0.9520\n",
      "Epoch 33/500\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0588 - accuracy: 0.9840 - val_loss: 0.1416 - val_accuracy: 0.9560\n",
      "Epoch 34/500\n",
      "4000/4000 [==============================] - 1s 214us/step - loss: 0.0495 - accuracy: 0.9850 - val_loss: 0.1439 - val_accuracy: 0.9560\n",
      "Epoch 35/500\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0463 - accuracy: 0.9852 - val_loss: 0.1574 - val_accuracy: 0.9590\n",
      "Epoch 36/500\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0414 - accuracy: 0.9890 - val_loss: 0.1432 - val_accuracy: 0.9560\n",
      "Epoch 37/500\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0378 - accuracy: 0.9890 - val_loss: 0.1409 - val_accuracy: 0.9590\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.615580203970643\n",
      "F1 Micro: 0.9574\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7040730757968751\n",
      "F1 Micro: 0.9534\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6353748826586411\n",
      "F1 Micro: 0.9623\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 1 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.4381 - accuracy: 0.8943 - val_loss: 0.2514 - val_accuracy: 0.9294\n",
      "Epoch 2/500\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.1943 - accuracy: 0.9445 - val_loss: 0.1585 - val_accuracy: 0.9509\n",
      "Epoch 3/500\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.1497 - accuracy: 0.9550 - val_loss: 0.1375 - val_accuracy: 0.9577\n",
      "Epoch 4/500\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.1288 - accuracy: 0.9603 - val_loss: 0.1257 - val_accuracy: 0.9600\n",
      "Epoch 5/500\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.1159 - accuracy: 0.9634 - val_loss: 0.1174 - val_accuracy: 0.9627\n",
      "Epoch 6/500\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.1073 - accuracy: 0.9665 - val_loss: 0.1198 - val_accuracy: 0.9623\n",
      "Epoch 7/500\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.1007 - accuracy: 0.9680 - val_loss: 0.1202 - val_accuracy: 0.9627\n",
      "Epoch 8/500\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0938 - accuracy: 0.9699 - val_loss: 0.1092 - val_accuracy: 0.9629\n",
      "Epoch 9/500\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0884 - accuracy: 0.9708 - val_loss: 0.1060 - val_accuracy: 0.9655\n",
      "Epoch 10/500\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0854 - accuracy: 0.9721 - val_loss: 0.1025 - val_accuracy: 0.9664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0823 - accuracy: 0.9721 - val_loss: 0.1152 - val_accuracy: 0.9613\n",
      "Epoch 12/500\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0751 - accuracy: 0.9748 - val_loss: 0.0976 - val_accuracy: 0.9672\n",
      "Epoch 13/500\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0718 - accuracy: 0.9760 - val_loss: 0.0990 - val_accuracy: 0.9678\n",
      "Epoch 14/500\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0669 - accuracy: 0.9778 - val_loss: 0.1009 - val_accuracy: 0.9651\n",
      "Epoch 15/500\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0629 - accuracy: 0.9778 - val_loss: 0.0956 - val_accuracy: 0.9665\n",
      "Epoch 16/500\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0588 - accuracy: 0.9798 - val_loss: 0.1086 - val_accuracy: 0.9660\n",
      "Epoch 17/500\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0535 - accuracy: 0.9818 - val_loss: 0.0906 - val_accuracy: 0.9712\n",
      "Epoch 18/500\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0499 - accuracy: 0.9829 - val_loss: 0.1045 - val_accuracy: 0.9652\n",
      "Epoch 19/500\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0455 - accuracy: 0.9844 - val_loss: 0.0997 - val_accuracy: 0.9708\n",
      "Epoch 20/500\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0418 - accuracy: 0.9851 - val_loss: 0.1200 - val_accuracy: 0.9603\n",
      "Epoch 21/500\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0375 - accuracy: 0.9865 - val_loss: 0.1053 - val_accuracy: 0.9688\n",
      "Epoch 22/500\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.0985 - val_accuracy: 0.9710\n",
      "Epoch 23/500\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0298 - accuracy: 0.9897 - val_loss: 0.1053 - val_accuracy: 0.9681\n",
      "Epoch 24/500\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0270 - accuracy: 0.9907 - val_loss: 0.0981 - val_accuracy: 0.9695\n",
      "Epoch 25/500\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0229 - accuracy: 0.9922 - val_loss: 0.1398 - val_accuracy: 0.9684\n",
      "Epoch 26/500\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.1175 - val_accuracy: 0.9679\n",
      "Epoch 27/500\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.1258 - val_accuracy: 0.9700\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8146031291339005\n",
      "F1 Micro: 0.9713\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7967924075411252\n",
      "F1 Micro: 0.9671\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.5303 - accuracy: 0.8744 - val_loss: 0.1738 - val_accuracy: 0.9494\n",
      "Epoch 2/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1480 - accuracy: 0.9564 - val_loss: 0.1435 - val_accuracy: 0.9554\n",
      "Epoch 3/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1290 - accuracy: 0.9613 - val_loss: 0.1323 - val_accuracy: 0.9584\n",
      "Epoch 4/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1194 - accuracy: 0.9633 - val_loss: 0.1249 - val_accuracy: 0.9602\n",
      "Epoch 5/500\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.1133 - accuracy: 0.9653 - val_loss: 0.1207 - val_accuracy: 0.9614\n",
      "Epoch 6/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1082 - accuracy: 0.9664 - val_loss: 0.1175 - val_accuracy: 0.9621\n",
      "Epoch 7/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1042 - accuracy: 0.9677 - val_loss: 0.1134 - val_accuracy: 0.9631\n",
      "Epoch 8/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1016 - accuracy: 0.9689 - val_loss: 0.1118 - val_accuracy: 0.9638\n",
      "Epoch 9/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0986 - accuracy: 0.9694 - val_loss: 0.1140 - val_accuracy: 0.9624\n",
      "Epoch 10/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0961 - accuracy: 0.9700 - val_loss: 0.1094 - val_accuracy: 0.9640\n",
      "Epoch 11/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0941 - accuracy: 0.9708 - val_loss: 0.1082 - val_accuracy: 0.9642\n",
      "Epoch 12/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0923 - accuracy: 0.9714 - val_loss: 0.1090 - val_accuracy: 0.9649\n",
      "Epoch 13/500\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0906 - accuracy: 0.9718 - val_loss: 0.1096 - val_accuracy: 0.9642\n",
      "Epoch 14/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0892 - accuracy: 0.9726 - val_loss: 0.1060 - val_accuracy: 0.9642\n",
      "Epoch 15/500\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0879 - accuracy: 0.9725 - val_loss: 0.1048 - val_accuracy: 0.9656\n",
      "Epoch 16/500\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0861 - accuracy: 0.9732 - val_loss: 0.1051 - val_accuracy: 0.9644\n",
      "Epoch 17/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0846 - accuracy: 0.9741 - val_loss: 0.1035 - val_accuracy: 0.9651\n",
      "Epoch 18/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0837 - accuracy: 0.9739 - val_loss: 0.1043 - val_accuracy: 0.9653\n",
      "Epoch 19/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0827 - accuracy: 0.9747 - val_loss: 0.1027 - val_accuracy: 0.9657\n",
      "Epoch 20/500\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0815 - accuracy: 0.9748 - val_loss: 0.1016 - val_accuracy: 0.9664\n",
      "Epoch 21/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0803 - accuracy: 0.9751 - val_loss: 0.1036 - val_accuracy: 0.9657\n",
      "Epoch 22/500\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0790 - accuracy: 0.9760 - val_loss: 0.1031 - val_accuracy: 0.9654\n",
      "Epoch 23/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0785 - accuracy: 0.9761 - val_loss: 0.1004 - val_accuracy: 0.9666\n",
      "Epoch 24/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0775 - accuracy: 0.9760 - val_loss: 0.0999 - val_accuracy: 0.9661\n",
      "Epoch 25/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0763 - accuracy: 0.9765 - val_loss: 0.1017 - val_accuracy: 0.9655\n",
      "Epoch 26/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0754 - accuracy: 0.9767 - val_loss: 0.0998 - val_accuracy: 0.9670\n",
      "Epoch 27/500\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0743 - accuracy: 0.9770 - val_loss: 0.0997 - val_accuracy: 0.9669\n",
      "Epoch 28/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0737 - accuracy: 0.9772 - val_loss: 0.0993 - val_accuracy: 0.9659\n",
      "Epoch 29/500\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0729 - accuracy: 0.9777 - val_loss: 0.0987 - val_accuracy: 0.9668\n",
      "Epoch 30/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0720 - accuracy: 0.9783 - val_loss: 0.0991 - val_accuracy: 0.9670\n",
      "Epoch 31/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0709 - accuracy: 0.9781 - val_loss: 0.0967 - val_accuracy: 0.9674\n",
      "Epoch 32/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0701 - accuracy: 0.9785 - val_loss: 0.0987 - val_accuracy: 0.9668\n",
      "Epoch 33/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0695 - accuracy: 0.9780 - val_loss: 0.0979 - val_accuracy: 0.9677\n",
      "Epoch 34/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0687 - accuracy: 0.9786 - val_loss: 0.0988 - val_accuracy: 0.9676\n",
      "Epoch 35/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0679 - accuracy: 0.9792 - val_loss: 0.0974 - val_accuracy: 0.9673\n",
      "Epoch 36/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0671 - accuracy: 0.9790 - val_loss: 0.0970 - val_accuracy: 0.9665\n",
      "Epoch 37/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0666 - accuracy: 0.9793 - val_loss: 0.0960 - val_accuracy: 0.9674\n",
      "Epoch 38/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0656 - accuracy: 0.9801 - val_loss: 0.0998 - val_accuracy: 0.9665\n",
      "Epoch 39/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0648 - accuracy: 0.9800 - val_loss: 0.0991 - val_accuracy: 0.9674\n",
      "Epoch 40/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0643 - accuracy: 0.9801 - val_loss: 0.0979 - val_accuracy: 0.9674\n",
      "Epoch 41/500\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0635 - accuracy: 0.9807 - val_loss: 0.0959 - val_accuracy: 0.9684\n",
      "Epoch 42/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0626 - accuracy: 0.9803 - val_loss: 0.0964 - val_accuracy: 0.9668\n",
      "Epoch 43/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0619 - accuracy: 0.9810 - val_loss: 0.0970 - val_accuracy: 0.9673\n",
      "Epoch 44/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0616 - accuracy: 0.9805 - val_loss: 0.0980 - val_accuracy: 0.9667\n",
      "Epoch 45/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0606 - accuracy: 0.9814 - val_loss: 0.0974 - val_accuracy: 0.9674\n",
      "Epoch 46/500\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0599 - accuracy: 0.9815 - val_loss: 0.0965 - val_accuracy: 0.9677\n",
      "Epoch 47/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0594 - accuracy: 0.9817 - val_loss: 0.0959 - val_accuracy: 0.9678\n",
      "Epoch 48/500\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0586 - accuracy: 0.9818 - val_loss: 0.0970 - val_accuracy: 0.9673\n",
      "Epoch 49/500\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0578 - accuracy: 0.9821 - val_loss: 0.0962 - val_accuracy: 0.9677\n",
      "Epoch 50/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0571 - accuracy: 0.9822 - val_loss: 0.0990 - val_accuracy: 0.9679\n",
      "Epoch 51/500\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0568 - accuracy: 0.9818 - val_loss: 0.0961 - val_accuracy: 0.9677\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8213939364420848\n",
      "F1 Micro: 0.9701\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.2699 - accuracy: 0.9274 - val_loss: 0.1769 - val_accuracy: 0.9454\n",
      "Epoch 2/500\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.1460 - accuracy: 0.9559 - val_loss: 0.1521 - val_accuracy: 0.9518\n",
      "Epoch 3/500\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.1267 - accuracy: 0.9609 - val_loss: 0.1267 - val_accuracy: 0.9585\n",
      "Epoch 4/500\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.1156 - accuracy: 0.9645 - val_loss: 0.1185 - val_accuracy: 0.9614\n",
      "Epoch 5/500\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.1085 - accuracy: 0.9665 - val_loss: 0.1125 - val_accuracy: 0.9619\n",
      "Epoch 6/500\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.1021 - accuracy: 0.9678 - val_loss: 0.1221 - val_accuracy: 0.9621\n",
      "Epoch 7/500\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0982 - accuracy: 0.9696 - val_loss: 0.1071 - val_accuracy: 0.9650\n",
      "Epoch 8/500\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0934 - accuracy: 0.9707 - val_loss: 0.1041 - val_accuracy: 0.9653\n",
      "Epoch 9/500\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0874 - accuracy: 0.9722 - val_loss: 0.0989 - val_accuracy: 0.9663\n",
      "Epoch 10/500\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0827 - accuracy: 0.9736 - val_loss: 0.0982 - val_accuracy: 0.9659\n",
      "Epoch 11/500\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0779 - accuracy: 0.9752 - val_loss: 0.1013 - val_accuracy: 0.9667\n",
      "Epoch 12/500\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0726 - accuracy: 0.9765 - val_loss: 0.0992 - val_accuracy: 0.9657\n",
      "Epoch 13/500\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0681 - accuracy: 0.9779 - val_loss: 0.0984 - val_accuracy: 0.9654\n",
      "Epoch 14/500\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0628 - accuracy: 0.9793 - val_loss: 0.1006 - val_accuracy: 0.9650\n",
      "Epoch 15/500\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0565 - accuracy: 0.9817 - val_loss: 0.0973 - val_accuracy: 0.9658\n",
      "Epoch 16/500\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0506 - accuracy: 0.9828 - val_loss: 0.1006 - val_accuracy: 0.9644\n",
      "Epoch 17/500\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0436 - accuracy: 0.9865 - val_loss: 0.1080 - val_accuracy: 0.9644\n",
      "Epoch 18/500\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0368 - accuracy: 0.9879 - val_loss: 0.1084 - val_accuracy: 0.9667\n",
      "Epoch 19/500\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 0.1222 - val_accuracy: 0.9617\n",
      "Epoch 20/500\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.1346 - val_accuracy: 0.9656\n",
      "Epoch 21/500\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 0.1294 - val_accuracy: 0.9664\n",
      "Epoch 22/500\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0181 - accuracy: 0.9946 - val_loss: 0.1521 - val_accuracy: 0.9647\n",
      "Epoch 23/500\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 0.1361 - val_accuracy: 0.9653\n",
      "Epoch 24/500\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.1471 - val_accuracy: 0.9651\n",
      "Epoch 25/500\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.1545 - val_accuracy: 0.9657\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8343621174862544\n",
      "F1 Micro: 0.9696\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8019530631356053\n",
      "F1 Micro: 0.9663\n",
      "\n",
      "**********model6**********\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\tf2.0\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.40234e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8440020590271429\n",
      "F1 Micro: 0.9735\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 1 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/500\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.2497 - accuracy: 0.9326 - val_loss: 0.1331 - val_accuracy: 0.9577\n",
      "Epoch 2/500\n",
      "130356/130356 [==============================] - 25s 191us/step - loss: 0.1212 - accuracy: 0.9612 - val_loss: 0.1185 - val_accuracy: 0.9621\n",
      "Epoch 3/500\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.1020 - accuracy: 0.9673 - val_loss: 0.0993 - val_accuracy: 0.9670\n",
      "Epoch 4/500\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0909 - accuracy: 0.9701 - val_loss: 0.0831 - val_accuracy: 0.9723\n",
      "Epoch 5/500\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.0828 - accuracy: 0.9723 - val_loss: 0.0903 - val_accuracy: 0.9704\n",
      "Epoch 6/500\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0754 - accuracy: 0.9746 - val_loss: 0.0827 - val_accuracy: 0.9712\n",
      "Epoch 7/500\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0684 - accuracy: 0.9765 - val_loss: 0.0708 - val_accuracy: 0.9764\n",
      "Epoch 8/500\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0634 - accuracy: 0.9783 - val_loss: 0.0854 - val_accuracy: 0.9736\n",
      "Epoch 9/500\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0593 - accuracy: 0.9794 - val_loss: 0.0744 - val_accuracy: 0.9756\n",
      "Epoch 10/500\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0551 - accuracy: 0.9804 - val_loss: 0.0801 - val_accuracy: 0.9724\n",
      "Epoch 11/500\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0521 - accuracy: 0.9816 - val_loss: 0.0683 - val_accuracy: 0.9773\n",
      "Epoch 12/500\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0482 - accuracy: 0.9829 - val_loss: 0.0619 - val_accuracy: 0.9791\n",
      "Epoch 13/500\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0448 - accuracy: 0.9839 - val_loss: 0.0623 - val_accuracy: 0.9792\n",
      "Epoch 14/500\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0411 - accuracy: 0.9851 - val_loss: 0.0631 - val_accuracy: 0.9790\n",
      "Epoch 15/500\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0380 - accuracy: 0.9859 - val_loss: 0.0722 - val_accuracy: 0.9769\n",
      "Epoch 16/500\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.0342 - accuracy: 0.9873 - val_loss: 0.0743 - val_accuracy: 0.9753\n",
      "Epoch 17/500\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0308 - accuracy: 0.9888 - val_loss: 0.0679 - val_accuracy: 0.9790\n",
      "Epoch 18/500\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0273 - accuracy: 0.9901 - val_loss: 0.0691 - val_accuracy: 0.9783\n",
      "Epoch 19/500\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.0243 - accuracy: 0.9914 - val_loss: 0.0825 - val_accuracy: 0.9783\n",
      "Epoch 20/500\n",
      "130356/130356 [==============================] - 25s 191us/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.0879 - val_accuracy: 0.9761\n",
      "Epoch 21/500\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.0834 - val_accuracy: 0.9773\n",
      "Epoch 22/500\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 0.0907 - val_accuracy: 0.9751\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8946048021347293\n",
      "F1 Micro: 0.9785\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8290096709671195\n",
      "F1 Micro: 0.9705\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.2562 - accuracy: 0.9350 - val_loss: 0.1218 - val_accuracy: 0.9628\n",
      "Epoch 2/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.1138 - accuracy: 0.9651 - val_loss: 0.1080 - val_accuracy: 0.9663\n",
      "Epoch 3/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.1041 - accuracy: 0.9678 - val_loss: 0.1023 - val_accuracy: 0.9677\n",
      "Epoch 4/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0985 - accuracy: 0.9691 - val_loss: 0.0980 - val_accuracy: 0.9694\n",
      "Epoch 5/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0947 - accuracy: 0.9704 - val_loss: 0.0963 - val_accuracy: 0.9688\n",
      "Epoch 6/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0918 - accuracy: 0.9710 - val_loss: 0.0928 - val_accuracy: 0.9702\n",
      "Epoch 7/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0893 - accuracy: 0.9717 - val_loss: 0.0910 - val_accuracy: 0.9709\n",
      "Epoch 8/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0872 - accuracy: 0.9724 - val_loss: 0.0904 - val_accuracy: 0.9702\n",
      "Epoch 9/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0852 - accuracy: 0.9730 - val_loss: 0.0895 - val_accuracy: 0.9706\n",
      "Epoch 10/500\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0838 - accuracy: 0.9732 - val_loss: 0.0873 - val_accuracy: 0.9714\n",
      "Epoch 11/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0823 - accuracy: 0.9735 - val_loss: 0.0865 - val_accuracy: 0.9718\n",
      "Epoch 12/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0809 - accuracy: 0.9742 - val_loss: 0.0881 - val_accuracy: 0.9710\n",
      "Epoch 13/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0796 - accuracy: 0.9744 - val_loss: 0.0859 - val_accuracy: 0.9721\n",
      "Epoch 14/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0784 - accuracy: 0.9751 - val_loss: 0.0837 - val_accuracy: 0.9728\n",
      "Epoch 15/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0773 - accuracy: 0.9752 - val_loss: 0.0834 - val_accuracy: 0.9727\n",
      "Epoch 16/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0763 - accuracy: 0.9756 - val_loss: 0.0833 - val_accuracy: 0.9726\n",
      "Epoch 17/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0753 - accuracy: 0.9759 - val_loss: 0.0834 - val_accuracy: 0.9726\n",
      "Epoch 18/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0746 - accuracy: 0.9759 - val_loss: 0.0819 - val_accuracy: 0.9731\n",
      "Epoch 19/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0736 - accuracy: 0.9762 - val_loss: 0.0808 - val_accuracy: 0.9732\n",
      "Epoch 20/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0727 - accuracy: 0.9763 - val_loss: 0.0811 - val_accuracy: 0.9733\n",
      "Epoch 21/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0718 - accuracy: 0.9771 - val_loss: 0.0812 - val_accuracy: 0.9733\n",
      "Epoch 22/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0712 - accuracy: 0.9770 - val_loss: 0.0808 - val_accuracy: 0.9732\n",
      "Epoch 23/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0703 - accuracy: 0.9773 - val_loss: 0.0811 - val_accuracy: 0.9729\n",
      "Epoch 24/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0696 - accuracy: 0.9774 - val_loss: 0.0806 - val_accuracy: 0.9734\n",
      "Epoch 25/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0689 - accuracy: 0.9777 - val_loss: 0.0832 - val_accuracy: 0.9729\n",
      "Epoch 26/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0680 - accuracy: 0.9779 - val_loss: 0.0815 - val_accuracy: 0.9725\n",
      "Epoch 27/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0676 - accuracy: 0.9780 - val_loss: 0.0788 - val_accuracy: 0.9742\n",
      "Epoch 28/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0668 - accuracy: 0.9783 - val_loss: 0.0806 - val_accuracy: 0.9732\n",
      "Epoch 29/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0661 - accuracy: 0.9785 - val_loss: 0.0806 - val_accuracy: 0.9732\n",
      "Epoch 30/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0657 - accuracy: 0.9786 - val_loss: 0.0787 - val_accuracy: 0.9743\n",
      "Epoch 31/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0650 - accuracy: 0.9786 - val_loss: 0.0795 - val_accuracy: 0.9737\n",
      "Epoch 32/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0644 - accuracy: 0.9790 - val_loss: 0.0794 - val_accuracy: 0.9737\n",
      "Epoch 33/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0637 - accuracy: 0.9791 - val_loss: 0.0790 - val_accuracy: 0.9743\n",
      "Epoch 34/500\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0633 - accuracy: 0.9794 - val_loss: 0.0799 - val_accuracy: 0.9740\n",
      "Epoch 35/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0625 - accuracy: 0.9795 - val_loss: 0.0801 - val_accuracy: 0.9739\n",
      "Epoch 36/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0620 - accuracy: 0.9798 - val_loss: 0.0794 - val_accuracy: 0.9743\n",
      "Epoch 37/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0616 - accuracy: 0.9796 - val_loss: 0.0797 - val_accuracy: 0.9743\n",
      "Epoch 38/500\n",
      "130356/130356 [==============================] - 10s 78us/step - loss: 0.0607 - accuracy: 0.9802 - val_loss: 0.0805 - val_accuracy: 0.9740\n",
      "Epoch 39/500\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0604 - accuracy: 0.9801 - val_loss: 0.0788 - val_accuracy: 0.9741\n",
      "Epoch 40/500\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0597 - accuracy: 0.9802 - val_loss: 0.0790 - val_accuracy: 0.9747\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.854706415035155\n",
      "F1 Micro: 0.9743\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/500\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.1720 - accuracy: 0.9500 - val_loss: 0.1200 - val_accuracy: 0.9622\n",
      "Epoch 2/500\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.1083 - accuracy: 0.9661 - val_loss: 0.1006 - val_accuracy: 0.9675\n",
      "Epoch 3/500\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0954 - accuracy: 0.9695 - val_loss: 0.0887 - val_accuracy: 0.9713\n",
      "Epoch 4/500\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0848 - accuracy: 0.9724 - val_loss: 0.0800 - val_accuracy: 0.9731\n",
      "Epoch 5/500\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0760 - accuracy: 0.9748 - val_loss: 0.0753 - val_accuracy: 0.9751\n",
      "Epoch 6/500\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0699 - accuracy: 0.9765 - val_loss: 0.0703 - val_accuracy: 0.9760\n",
      "Epoch 7/500\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0642 - accuracy: 0.9784 - val_loss: 0.0650 - val_accuracy: 0.9782\n",
      "Epoch 8/500\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0592 - accuracy: 0.9797 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
      "Epoch 9/500\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0542 - accuracy: 0.9812 - val_loss: 0.0612 - val_accuracy: 0.9784\n",
      "Epoch 10/500\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0487 - accuracy: 0.9831 - val_loss: 0.0627 - val_accuracy: 0.9786\n",
      "Epoch 11/500\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0439 - accuracy: 0.9846 - val_loss: 0.0635 - val_accuracy: 0.9782\n",
      "Epoch 12/500\n",
      "130356/130356 [==============================] - 27s 210us/step - loss: 0.0379 - accuracy: 0.9866 - val_loss: 0.0662 - val_accuracy: 0.9783\n",
      "Epoch 13/500\n",
      "130356/130356 [==============================] - 27s 209us/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 0.0702 - val_accuracy: 0.9782\n",
      "Epoch 14/500\n",
      "130356/130356 [==============================] - 27s 210us/step - loss: 0.0260 - accuracy: 0.9909 - val_loss: 0.0731 - val_accuracy: 0.9779\n",
      "Epoch 15/500\n",
      "130356/130356 [==============================] - 27s 210us/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 0.0803 - val_accuracy: 0.9756\n",
      "Epoch 16/500\n",
      "130356/130356 [==============================] - 27s 209us/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.0791 - val_accuracy: 0.9776\n",
      "Epoch 17/500\n",
      "130356/130356 [==============================] - 27s 211us/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0876 - val_accuracy: 0.9770\n",
      "Epoch 18/500\n",
      "130356/130356 [==============================] - 28s 212us/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.0926 - val_accuracy: 0.9780\n",
      "Epoch 19/500\n",
      "130356/130356 [==============================] - 28s 211us/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1011 - val_accuracy: 0.9776\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8822148404697312\n",
      "F1 Micro: 0.9772\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8291957928619327\n",
      "F1 Micro: 0.9696\n",
      "\n",
      "**********model6**********\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\tf2.0\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.74298e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.9001147725862668\n",
      "F1 Micro: 0.9799\n",
      "\n",
      "\n",
      " 40.44081159830093 min per replication\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Ridge(alpha=0.001, copy_X=True, fit_intercept=False, max_iter=None,\n",
       "       normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       " Ridge(alpha=0.001, copy_X=True, fit_intercept=False, max_iter=None,\n",
       "       normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       " Ridge(alpha=0.001, copy_X=True, fit_intercept=False, max_iter=None,\n",
       "       normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       " Ridge(alpha=0.001, copy_X=True, fit_intercept=False, max_iter=None,\n",
       "       normalize=False, random_state=None, solver='auto', tol=0.001)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savefile = '0403_e'\n",
    "model6_list = experiment(savefile, replication=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T10:14:28.820902Z",
     "start_time": "2020-04-30T01:03:07.636880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 1 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 1 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 2, 3, 4, 5, 6, 8]\n",
      "label_list [0, 2, 3, 4, 5, 6, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.7823 - accuracy: 0.8400 - val_loss: 1.1480 - val_accuracy: 0.9000\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 267us/step - loss: 0.8665 - accuracy: 0.8450 - val_loss: 0.5294 - val_accuracy: 0.9000\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 272us/step - loss: 0.7858 - accuracy: 0.8450 - val_loss: 0.4791 - val_accuracy: 0.9000\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 271us/step - loss: 0.7011 - accuracy: 0.8450 - val_loss: 0.4996 - val_accuracy: 0.9000\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 255us/step - loss: 0.6839 - accuracy: 0.8450 - val_loss: 0.4756 - val_accuracy: 0.9000\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 254us/step - loss: 0.6653 - accuracy: 0.8450 - val_loss: 0.4484 - val_accuracy: 0.9000\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 257us/step - loss: 0.6584 - accuracy: 0.8450 - val_loss: 0.4518 - val_accuracy: 0.9000\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 259us/step - loss: 0.6489 - accuracy: 0.8450 - val_loss: 0.4358 - val_accuracy: 0.9000\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 259us/step - loss: 0.6415 - accuracy: 0.8450 - val_loss: 0.4311 - val_accuracy: 0.9000\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 254us/step - loss: 0.6337 - accuracy: 0.8450 - val_loss: 0.4261 - val_accuracy: 0.9000\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 252us/step - loss: 0.6263 - accuracy: 0.8450 - val_loss: 0.4146 - val_accuracy: 0.9000\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 253us/step - loss: 0.6191 - accuracy: 0.8450 - val_loss: 0.3996 - val_accuracy: 0.9000\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 252us/step - loss: 0.6067 - accuracy: 0.8450 - val_loss: 0.4013 - val_accuracy: 0.9000\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.5909 - accuracy: 0.8450 - val_loss: 0.3785 - val_accuracy: 0.9000\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 259us/step - loss: 0.5664 - accuracy: 0.8450 - val_loss: 0.3766 - val_accuracy: 0.9000\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 259us/step - loss: 0.5570 - accuracy: 0.8475 - val_loss: 0.3299 - val_accuracy: 0.9000\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 244us/step - loss: 0.5250 - accuracy: 0.8500 - val_loss: 0.3153 - val_accuracy: 0.9400\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5024 - accuracy: 0.8650 - val_loss: 0.3017 - val_accuracy: 0.9300\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.4661 - accuracy: 0.8825 - val_loss: 0.2427 - val_accuracy: 0.9500\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 235us/step - loss: 0.4378 - accuracy: 0.8875 - val_loss: 0.2453 - val_accuracy: 0.9600\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 246us/step - loss: 0.4323 - accuracy: 0.8950 - val_loss: 0.2181 - val_accuracy: 0.9600\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.4021 - accuracy: 0.9025 - val_loss: 0.2146 - val_accuracy: 0.9700\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.3827 - accuracy: 0.9025 - val_loss: 0.1903 - val_accuracy: 0.9500\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.3729 - accuracy: 0.9000 - val_loss: 0.1794 - val_accuracy: 0.9600\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.3551 - accuracy: 0.9025 - val_loss: 0.1671 - val_accuracy: 0.9600\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 252us/step - loss: 0.3560 - accuracy: 0.9075 - val_loss: 0.1692 - val_accuracy: 0.9600\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 248us/step - loss: 0.3244 - accuracy: 0.9125 - val_loss: 0.1658 - val_accuracy: 0.9700\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 254us/step - loss: 0.3258 - accuracy: 0.9175 - val_loss: 0.2008 - val_accuracy: 0.9700\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.3040 - accuracy: 0.9125 - val_loss: 0.1835 - val_accuracy: 0.9600\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.2929 - accuracy: 0.9225 - val_loss: 0.1976 - val_accuracy: 0.9500\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.2820 - accuracy: 0.9150 - val_loss: 0.1334 - val_accuracy: 0.9700\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 252us/step - loss: 0.2882 - accuracy: 0.9250 - val_loss: 0.1977 - val_accuracy: 0.9600\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.2773 - accuracy: 0.9375 - val_loss: 0.1381 - val_accuracy: 0.9600\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.2739 - accuracy: 0.9225 - val_loss: 0.1334 - val_accuracy: 0.9600\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.3034 - accuracy: 0.9150 - val_loss: 0.1748 - val_accuracy: 0.9500\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.2688 - accuracy: 0.9275 - val_loss: 0.1164 - val_accuracy: 0.9700\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2450 - accuracy: 0.9300 - val_loss: 0.1229 - val_accuracy: 0.9600\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2168 - accuracy: 0.9350 - val_loss: 0.1249 - val_accuracy: 0.9700\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2160 - accuracy: 0.9325 - val_loss: 0.1216 - val_accuracy: 0.9700\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.2001 - accuracy: 0.9425 - val_loss: 0.1218 - val_accuracy: 0.9700\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.2052 - accuracy: 0.9400 - val_loss: 0.1156 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.1951 - accuracy: 0.9425 - val_loss: 0.1338 - val_accuracy: 0.9700\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.1847 - accuracy: 0.9500 - val_loss: 0.2435 - val_accuracy: 0.9300\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.2051 - accuracy: 0.9400 - val_loss: 0.1111 - val_accuracy: 0.9700\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 254us/step - loss: 0.1771 - accuracy: 0.9500 - val_loss: 0.1158 - val_accuracy: 0.9700\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.2135 - accuracy: 0.9425 - val_loss: 0.1467 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.2090 - accuracy: 0.9325 - val_loss: 0.2345 - val_accuracy: 0.9300\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 240us/step - loss: 0.1912 - accuracy: 0.9450 - val_loss: 0.1036 - val_accuracy: 0.9700\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 244us/step - loss: 0.1677 - accuracy: 0.9525 - val_loss: 0.1164 - val_accuracy: 0.9700\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.1569 - accuracy: 0.9550 - val_loss: 0.1037 - val_accuracy: 0.9700\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.1472 - accuracy: 0.9550 - val_loss: 0.0985 - val_accuracy: 0.9800\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.1522 - accuracy: 0.9550 - val_loss: 0.1550 - val_accuracy: 0.9500\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.1467 - accuracy: 0.9575 - val_loss: 0.1423 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 244us/step - loss: 0.1458 - accuracy: 0.9600 - val_loss: 0.1106 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1287 - accuracy: 0.9650 - val_loss: 0.1205 - val_accuracy: 0.9600\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1495 - accuracy: 0.9550 - val_loss: 0.0918 - val_accuracy: 0.9700\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1574 - accuracy: 0.9450 - val_loss: 0.0865 - val_accuracy: 0.9700\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1400 - accuracy: 0.9600 - val_loss: 0.1259 - val_accuracy: 0.9600\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1763 - accuracy: 0.9450 - val_loss: 0.1005 - val_accuracy: 0.9700\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1506 - accuracy: 0.9625 - val_loss: 0.0950 - val_accuracy: 0.9800\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.1117 - accuracy: 0.9675 - val_loss: 0.1129 - val_accuracy: 0.9500\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.1087 - accuracy: 0.9750 - val_loss: 0.0989 - val_accuracy: 0.9800\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.1023 - accuracy: 0.9750 - val_loss: 0.0993 - val_accuracy: 0.9800\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0973 - accuracy: 0.9775 - val_loss: 0.1062 - val_accuracy: 0.9700\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 244us/step - loss: 0.0998 - accuracy: 0.9800 - val_loss: 0.0750 - val_accuracy: 0.9800\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 240us/step - loss: 0.1284 - accuracy: 0.9625 - val_loss: 0.0664 - val_accuracy: 0.9800\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 238us/step - loss: 0.1027 - accuracy: 0.9700 - val_loss: 0.1077 - val_accuracy: 0.9600\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0964 - accuracy: 0.9725 - val_loss: 0.1425 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1060 - accuracy: 0.9700 - val_loss: 0.1148 - val_accuracy: 0.9600\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 244us/step - loss: 0.0959 - accuracy: 0.9725 - val_loss: 0.1567 - val_accuracy: 0.9500\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.1030 - accuracy: 0.9700 - val_loss: 0.1466 - val_accuracy: 0.9600\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.1056 - accuracy: 0.9700 - val_loss: 0.1225 - val_accuracy: 0.9600\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0864 - accuracy: 0.9775 - val_loss: 0.0779 - val_accuracy: 0.9800\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0800 - accuracy: 0.9775 - val_loss: 0.0866 - val_accuracy: 0.9700\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.1010 - accuracy: 0.9725 - val_loss: 0.0685 - val_accuracy: 0.9900\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0952 - accuracy: 0.9750 - val_loss: 0.1335 - val_accuracy: 0.9600\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0751 - accuracy: 0.9800 - val_loss: 0.0702 - val_accuracy: 0.9800\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0774 - accuracy: 0.9775 - val_loss: 0.1062 - val_accuracy: 0.9600\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0722 - accuracy: 0.9875 - val_loss: 0.0942 - val_accuracy: 0.9700\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0823 - accuracy: 0.9750 - val_loss: 0.0692 - val_accuracy: 0.9800\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0828 - accuracy: 0.9775 - val_loss: 0.0816 - val_accuracy: 0.9800\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 236us/step - loss: 0.0743 - accuracy: 0.9800 - val_loss: 0.0831 - val_accuracy: 0.9800\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0702 - accuracy: 0.9875 - val_loss: 0.1501 - val_accuracy: 0.9600\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 235us/step - loss: 0.0713 - accuracy: 0.9825 - val_loss: 0.1239 - val_accuracy: 0.9600\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 240us/step - loss: 0.0834 - accuracy: 0.9800 - val_loss: 0.1645 - val_accuracy: 0.9700\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.0970 - accuracy: 0.9600 - val_loss: 0.1734 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.4211227389765676\n",
      "F1 Micro: 0.924896036875595\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.49575543248147946\n",
      "F1 Micro: 0.9381231524625483\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 311us/step - loss: 2.2751 - accuracy: 0.1800 - val_loss: 2.0396 - val_accuracy: 0.4500\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 93us/step - loss: 2.0335 - accuracy: 0.4350 - val_loss: 1.7883 - val_accuracy: 0.5600\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.8707 - accuracy: 0.5200 - val_loss: 1.6276 - val_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 86us/step - loss: 1.7514 - accuracy: 0.5750 - val_loss: 1.5284 - val_accuracy: 0.6500\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.6608 - accuracy: 0.6075 - val_loss: 1.4466 - val_accuracy: 0.7000\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 1.5788 - accuracy: 0.6300 - val_loss: 1.3766 - val_accuracy: 0.7000\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 1.5018 - accuracy: 0.6450 - val_loss: 1.3131 - val_accuracy: 0.7200\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 92us/step - loss: 1.4289 - accuracy: 0.6650 - val_loss: 1.2553 - val_accuracy: 0.7200\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.3514 - accuracy: 0.6900 - val_loss: 1.1960 - val_accuracy: 0.7600\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.2775 - accuracy: 0.7050 - val_loss: 1.1370 - val_accuracy: 0.7800\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 1.2048 - accuracy: 0.7425 - val_loss: 1.0812 - val_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 1.1301 - accuracy: 0.7650 - val_loss: 1.0265 - val_accuracy: 0.8300\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 1.0590 - accuracy: 0.7850 - val_loss: 0.9707 - val_accuracy: 0.8300\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.9915 - accuracy: 0.8100 - val_loss: 0.9210 - val_accuracy: 0.8500\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.9212 - accuracy: 0.8450 - val_loss: 0.8669 - val_accuracy: 0.8500\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.8591 - accuracy: 0.8725 - val_loss: 0.8185 - val_accuracy: 0.8500\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.7987 - accuracy: 0.8900 - val_loss: 0.7703 - val_accuracy: 0.8600\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.7445 - accuracy: 0.8950 - val_loss: 0.7271 - val_accuracy: 0.8900\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.6936 - accuracy: 0.9025 - val_loss: 0.6902 - val_accuracy: 0.8900\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.6478 - accuracy: 0.9075 - val_loss: 0.6542 - val_accuracy: 0.9000\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.6059 - accuracy: 0.9200 - val_loss: 0.6191 - val_accuracy: 0.9000\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.5672 - accuracy: 0.9200 - val_loss: 0.5864 - val_accuracy: 0.9000\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.5323 - accuracy: 0.9250 - val_loss: 0.5583 - val_accuracy: 0.9000\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.5000 - accuracy: 0.9300 - val_loss: 0.5286 - val_accuracy: 0.9000\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.4717 - accuracy: 0.9350 - val_loss: 0.5040 - val_accuracy: 0.9000\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.4432 - accuracy: 0.9400 - val_loss: 0.4802 - val_accuracy: 0.9000\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.4192 - accuracy: 0.9425 - val_loss: 0.4578 - val_accuracy: 0.9100\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.3965 - accuracy: 0.9425 - val_loss: 0.4382 - val_accuracy: 0.9200\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.3746 - accuracy: 0.9425 - val_loss: 0.4200 - val_accuracy: 0.9200\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.3553 - accuracy: 0.9425 - val_loss: 0.4006 - val_accuracy: 0.9300\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.3381 - accuracy: 0.9450 - val_loss: 0.3824 - val_accuracy: 0.9400\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.3210 - accuracy: 0.9500 - val_loss: 0.3696 - val_accuracy: 0.9500\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.3052 - accuracy: 0.9500 - val_loss: 0.3528 - val_accuracy: 0.9600\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2906 - accuracy: 0.9500 - val_loss: 0.3377 - val_accuracy: 0.9600\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2772 - accuracy: 0.9500 - val_loss: 0.3220 - val_accuracy: 0.9700\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 90us/step - loss: 0.2654 - accuracy: 0.9500 - val_loss: 0.3094 - val_accuracy: 0.9700\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.2532 - accuracy: 0.9525 - val_loss: 0.2948 - val_accuracy: 0.9700\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.2430 - accuracy: 0.9575 - val_loss: 0.2830 - val_accuracy: 0.9700\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.2325 - accuracy: 0.9600 - val_loss: 0.2716 - val_accuracy: 0.9700\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2233 - accuracy: 0.9600 - val_loss: 0.2613 - val_accuracy: 0.9700\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.2148 - accuracy: 0.9600 - val_loss: 0.2519 - val_accuracy: 0.9700\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.2068 - accuracy: 0.9600 - val_loss: 0.2436 - val_accuracy: 0.9700\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.1989 - accuracy: 0.9600 - val_loss: 0.2342 - val_accuracy: 0.9700\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.1921 - accuracy: 0.9600 - val_loss: 0.2263 - val_accuracy: 0.9700\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.1857 - accuracy: 0.9600 - val_loss: 0.2180 - val_accuracy: 0.9700\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.1792 - accuracy: 0.9625 - val_loss: 0.2107 - val_accuracy: 0.9700\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1735 - accuracy: 0.9625 - val_loss: 0.2035 - val_accuracy: 0.9700\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1677 - accuracy: 0.9650 - val_loss: 0.1966 - val_accuracy: 0.9700\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1624 - accuracy: 0.9675 - val_loss: 0.1905 - val_accuracy: 0.9800\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 89us/step - loss: 0.1578 - accuracy: 0.9675 - val_loss: 0.1852 - val_accuracy: 0.9800\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.1527 - accuracy: 0.9700 - val_loss: 0.1795 - val_accuracy: 0.9800\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.1484 - accuracy: 0.9700 - val_loss: 0.1734 - val_accuracy: 0.9800\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1442 - accuracy: 0.9725 - val_loss: 0.1694 - val_accuracy: 0.9900\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1402 - accuracy: 0.9750 - val_loss: 0.1637 - val_accuracy: 0.9900\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1366 - accuracy: 0.9750 - val_loss: 0.1589 - val_accuracy: 0.9800\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.1326 - accuracy: 0.9750 - val_loss: 0.1548 - val_accuracy: 0.9800\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1292 - accuracy: 0.9750 - val_loss: 0.1513 - val_accuracy: 0.9900\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1257 - accuracy: 0.9750 - val_loss: 0.1470 - val_accuracy: 0.9900\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.1226 - accuracy: 0.9750 - val_loss: 0.1426 - val_accuracy: 0.9900\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1194 - accuracy: 0.9750 - val_loss: 0.1397 - val_accuracy: 0.9900\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.1166 - accuracy: 0.9750 - val_loss: 0.1357 - val_accuracy: 0.9900\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1137 - accuracy: 0.9750 - val_loss: 0.1332 - val_accuracy: 0.9900\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.1111 - accuracy: 0.9750 - val_loss: 0.1296 - val_accuracy: 0.9900\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1082 - accuracy: 0.9750 - val_loss: 0.1259 - val_accuracy: 0.9900\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1058 - accuracy: 0.9750 - val_loss: 0.1237 - val_accuracy: 0.9900\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1033 - accuracy: 0.9750 - val_loss: 0.1211 - val_accuracy: 0.9900\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.1010 - accuracy: 0.9750 - val_loss: 0.1183 - val_accuracy: 0.9900\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0986 - accuracy: 0.9750 - val_loss: 0.1162 - val_accuracy: 0.9900\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0962 - accuracy: 0.9775 - val_loss: 0.1129 - val_accuracy: 0.9900\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0942 - accuracy: 0.9775 - val_loss: 0.1104 - val_accuracy: 0.9900\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0923 - accuracy: 0.9775 - val_loss: 0.1086 - val_accuracy: 0.9800\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0901 - accuracy: 0.9775 - val_loss: 0.1067 - val_accuracy: 0.9900\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0883 - accuracy: 0.9775 - val_loss: 0.1048 - val_accuracy: 0.9900\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0861 - accuracy: 0.9775 - val_loss: 0.1030 - val_accuracy: 0.9900\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0847 - accuracy: 0.9800 - val_loss: 0.1011 - val_accuracy: 0.9800\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0829 - accuracy: 0.9800 - val_loss: 0.0996 - val_accuracy: 0.9800\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0812 - accuracy: 0.9800 - val_loss: 0.0974 - val_accuracy: 0.9800\n",
      "Epoch 78/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 80us/step - loss: 0.0797 - accuracy: 0.9825 - val_loss: 0.0962 - val_accuracy: 0.9900\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0779 - accuracy: 0.9825 - val_loss: 0.0949 - val_accuracy: 0.9900\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0767 - accuracy: 0.9825 - val_loss: 0.0930 - val_accuracy: 0.9800\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0750 - accuracy: 0.9825 - val_loss: 0.0908 - val_accuracy: 0.9800\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.0734 - accuracy: 0.9825 - val_loss: 0.0896 - val_accuracy: 0.9800\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0719 - accuracy: 0.9825 - val_loss: 0.0885 - val_accuracy: 0.9800\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.0704 - accuracy: 0.9825 - val_loss: 0.0871 - val_accuracy: 0.9800\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0691 - accuracy: 0.9825 - val_loss: 0.0861 - val_accuracy: 0.9800\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0679 - accuracy: 0.9825 - val_loss: 0.0848 - val_accuracy: 0.9800\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0665 - accuracy: 0.9875 - val_loss: 0.0838 - val_accuracy: 0.9900\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0652 - accuracy: 0.9875 - val_loss: 0.0821 - val_accuracy: 0.9800\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 89us/step - loss: 0.0640 - accuracy: 0.9900 - val_loss: 0.0809 - val_accuracy: 0.9800\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0629 - accuracy: 0.9900 - val_loss: 0.0796 - val_accuracy: 0.9800\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0617 - accuracy: 0.9900 - val_loss: 0.0790 - val_accuracy: 0.9800\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0605 - accuracy: 0.9900 - val_loss: 0.0774 - val_accuracy: 0.9800\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0595 - accuracy: 0.9900 - val_loss: 0.0762 - val_accuracy: 0.9800\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0584 - accuracy: 0.9900 - val_loss: 0.0757 - val_accuracy: 0.9800\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0573 - accuracy: 0.9900 - val_loss: 0.0749 - val_accuracy: 0.9800\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0565 - accuracy: 0.9900 - val_loss: 0.0742 - val_accuracy: 0.9800\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0553 - accuracy: 0.9900 - val_loss: 0.0734 - val_accuracy: 0.9800\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0542 - accuracy: 0.9925 - val_loss: 0.0727 - val_accuracy: 0.9800\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0534 - accuracy: 0.9900 - val_loss: 0.0721 - val_accuracy: 0.9800\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0524 - accuracy: 0.9900 - val_loss: 0.0715 - val_accuracy: 0.9800\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0514 - accuracy: 0.9925 - val_loss: 0.0706 - val_accuracy: 0.9800\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0505 - accuracy: 0.9925 - val_loss: 0.0696 - val_accuracy: 0.9800\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0495 - accuracy: 0.9925 - val_loss: 0.0690 - val_accuracy: 0.9800\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0490 - accuracy: 0.9925 - val_loss: 0.0685 - val_accuracy: 0.9800\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0478 - accuracy: 0.9925 - val_loss: 0.0678 - val_accuracy: 0.9800\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0470 - accuracy: 0.9925 - val_loss: 0.0673 - val_accuracy: 0.9800\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0462 - accuracy: 0.9925 - val_loss: 0.0669 - val_accuracy: 0.9800\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0454 - accuracy: 0.9925 - val_loss: 0.0663 - val_accuracy: 0.9800\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0446 - accuracy: 0.9925 - val_loss: 0.0654 - val_accuracy: 0.9800\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0438 - accuracy: 0.9925 - val_loss: 0.0648 - val_accuracy: 0.9800\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 90us/step - loss: 0.0431 - accuracy: 0.9925 - val_loss: 0.0644 - val_accuracy: 0.9800\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0424 - accuracy: 0.9950 - val_loss: 0.0636 - val_accuracy: 0.9800\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0416 - accuracy: 0.9950 - val_loss: 0.0632 - val_accuracy: 0.9800\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0409 - accuracy: 0.9950 - val_loss: 0.0631 - val_accuracy: 0.9800\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0401 - accuracy: 0.9950 - val_loss: 0.0627 - val_accuracy: 0.9800\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.0395 - accuracy: 0.9950 - val_loss: 0.0622 - val_accuracy: 0.9800\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0389 - accuracy: 0.9950 - val_loss: 0.0616 - val_accuracy: 0.9800\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0381 - accuracy: 0.9950 - val_loss: 0.0611 - val_accuracy: 0.9800\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0377 - accuracy: 0.9950 - val_loss: 0.0605 - val_accuracy: 0.9800\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0369 - accuracy: 0.9975 - val_loss: 0.0600 - val_accuracy: 0.9800\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0363 - accuracy: 0.9975 - val_loss: 0.0598 - val_accuracy: 0.9800\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0357 - accuracy: 0.9975 - val_loss: 0.0596 - val_accuracy: 0.9800\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0350 - accuracy: 0.9975 - val_loss: 0.0593 - val_accuracy: 0.9800\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0345 - accuracy: 0.9975 - val_loss: 0.0588 - val_accuracy: 0.9800\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.0339 - accuracy: 0.9975 - val_loss: 0.0589 - val_accuracy: 0.9800\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0335 - accuracy: 0.9975 - val_loss: 0.0582 - val_accuracy: 0.9800\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0327 - accuracy: 0.9975 - val_loss: 0.0577 - val_accuracy: 0.9800\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0322 - accuracy: 0.9975 - val_loss: 0.0575 - val_accuracy: 0.9800\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0318 - accuracy: 0.9975 - val_loss: 0.0566 - val_accuracy: 0.9800\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0311 - accuracy: 0.9975 - val_loss: 0.0564 - val_accuracy: 0.9800\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0307 - accuracy: 0.9975 - val_loss: 0.0563 - val_accuracy: 0.9800\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0303 - accuracy: 0.9975 - val_loss: 0.0559 - val_accuracy: 0.9800\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.0297 - accuracy: 0.9975 - val_loss: 0.0556 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0292 - accuracy: 0.9975 - val_loss: 0.0553 - val_accuracy: 0.9800\n",
      "Epoch 135/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0288 - accuracy: 0.9975 - val_loss: 0.0550 - val_accuracy: 0.9800\n",
      "Epoch 136/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0283 - accuracy: 0.9975 - val_loss: 0.0549 - val_accuracy: 0.9800\n",
      "Epoch 137/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0278 - accuracy: 0.9975 - val_loss: 0.0540 - val_accuracy: 0.9800\n",
      "Epoch 138/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0274 - accuracy: 0.9975 - val_loss: 0.0541 - val_accuracy: 0.9800\n",
      "Epoch 139/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0270 - accuracy: 0.9975 - val_loss: 0.0532 - val_accuracy: 0.9800\n",
      "Epoch 140/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0264 - accuracy: 0.9975 - val_loss: 0.0530 - val_accuracy: 0.9800\n",
      "Epoch 141/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0262 - accuracy: 0.9975 - val_loss: 0.0529 - val_accuracy: 0.9800\n",
      "Epoch 142/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0257 - accuracy: 0.9975 - val_loss: 0.0531 - val_accuracy: 0.9800\n",
      "Epoch 143/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0253 - accuracy: 0.9975 - val_loss: 0.0524 - val_accuracy: 0.9800\n",
      "Epoch 144/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0248 - accuracy: 0.9975 - val_loss: 0.0522 - val_accuracy: 0.9800\n",
      "Epoch 145/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9800\n",
      "Epoch 146/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9800\n",
      "Epoch 147/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9800\n",
      "Epoch 148/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9800\n",
      "Epoch 149/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9800\n",
      "Epoch 150/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9800\n",
      "Epoch 151/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9800\n",
      "Epoch 152/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9800\n",
      "Epoch 153/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9900\n",
      "Epoch 154/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9800\n",
      "Epoch 155/1000\n",
      "400/400 [==============================] - 0s 88us/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9900\n",
      "Epoch 156/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9900\n",
      "Epoch 157/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9900\n",
      "Epoch 158/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9900\n",
      "Epoch 159/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9900\n",
      "Epoch 160/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9900\n",
      "Epoch 161/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9900\n",
      "Epoch 162/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9900\n",
      "Epoch 163/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9900\n",
      "Epoch 164/1000\n",
      "400/400 [==============================] - 0s 90us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9900\n",
      "Epoch 165/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9900\n",
      "Epoch 166/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9900\n",
      "Epoch 167/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9900\n",
      "Epoch 168/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9900\n",
      "Epoch 169/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9900\n",
      "Epoch 170/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9900\n",
      "Epoch 171/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9900\n",
      "Epoch 172/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9900\n",
      "Epoch 173/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9900\n",
      "Epoch 174/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9900\n",
      "Epoch 175/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9900\n",
      "Epoch 176/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9900\n",
      "Epoch 177/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9900\n",
      "Epoch 178/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9900\n",
      "Epoch 179/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9900\n",
      "Epoch 180/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9900\n",
      "Epoch 181/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9900\n",
      "Epoch 182/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9900\n",
      "Epoch 183/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9900\n",
      "Epoch 184/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9900\n",
      "Epoch 185/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9900\n",
      "Epoch 186/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9900\n",
      "Epoch 187/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9900\n",
      "Epoch 188/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9900\n",
      "Epoch 189/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9900\n",
      "Epoch 191/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9900\n",
      "Epoch 192/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9900\n",
      "Epoch 193/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9900\n",
      "Epoch 194/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9900\n",
      "Epoch 195/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9900\n",
      "Epoch 196/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9900\n",
      "Epoch 197/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9900\n",
      "Epoch 198/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9900\n",
      "Epoch 199/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9900\n",
      "Epoch 200/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9900\n",
      "Epoch 201/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9900\n",
      "Epoch 202/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9900\n",
      "Epoch 203/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9900\n",
      "Epoch 204/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9900\n",
      "Epoch 205/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9900\n",
      "Epoch 206/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9900\n",
      "Epoch 207/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9900\n",
      "Epoch 208/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9900\n",
      "Epoch 209/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9900\n",
      "Epoch 210/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9900\n",
      "Epoch 211/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9900\n",
      "Epoch 212/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9900\n",
      "Epoch 213/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9900\n",
      "Epoch 214/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9900\n",
      "Epoch 215/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9900\n",
      "Epoch 216/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9900\n",
      "Epoch 217/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9900\n",
      "Epoch 218/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9900\n",
      "Epoch 219/1000\n",
      "400/400 [==============================] - 0s 92us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9900\n",
      "Epoch 220/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9900\n",
      "Epoch 221/1000\n",
      "400/400 [==============================] - 0s 89us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9900\n",
      "Epoch 222/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9900\n",
      "Epoch 223/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9900\n",
      "Epoch 224/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9900\n",
      "Epoch 225/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9900\n",
      "Epoch 226/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9900\n",
      "Epoch 227/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9900\n",
      "Epoch 228/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9900\n",
      "Epoch 229/1000\n",
      "400/400 [==============================] - 0s 90us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9900\n",
      "Epoch 230/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9900\n",
      "Epoch 231/1000\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9900\n",
      "Epoch 232/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9900\n",
      "Epoch 233/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9900\n",
      "Epoch 234/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9900\n",
      "Epoch 235/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9900\n",
      "Epoch 236/1000\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9900\n",
      "Epoch 237/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9900\n",
      "Epoch 238/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9900\n",
      "Epoch 239/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9900\n",
      "Epoch 240/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9900\n",
      "Epoch 241/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9900\n",
      "Epoch 242/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9900\n",
      "Epoch 243/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9900\n",
      "Epoch 244/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9900\n",
      "Epoch 245/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9900\n",
      "Epoch 247/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9900\n",
      "Epoch 248/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9900\n",
      "Epoch 249/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9900\n",
      "Epoch 250/1000\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9900\n",
      "Epoch 251/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9900\n",
      "Epoch 252/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9900\n",
      "Epoch 253/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9900\n",
      "Epoch 254/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9900\n",
      "Epoch 255/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9900\n",
      "Epoch 256/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9900\n",
      "Epoch 257/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9900\n",
      "Epoch 258/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9900\n",
      "Epoch 259/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9900\n",
      "Epoch 260/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9900\n",
      "Epoch 261/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9900\n",
      "Epoch 262/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9900\n",
      "Epoch 263/1000\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9900\n",
      "Epoch 264/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9900\n",
      "Epoch 265/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9900\n",
      "Epoch 266/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9900\n",
      "Epoch 267/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9900\n",
      "Epoch 268/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9900\n",
      "Epoch 269/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
      "Epoch 270/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
      "Epoch 271/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9900\n",
      "Epoch 272/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
      "Epoch 273/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9900\n",
      "Epoch 274/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9900\n",
      "Epoch 275/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9900\n",
      "Epoch 276/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 85us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9900\n",
      "Epoch 277/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9900\n",
      "Epoch 278/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9900\n",
      "Epoch 279/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
      "Epoch 280/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9900\n",
      "Epoch 281/1000\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9900\n",
      "Epoch 282/1000\n",
      "400/400 [==============================] - 0s 92us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9900\n",
      "Epoch 283/1000\n",
      "400/400 [==============================] - 0s 88us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9900\n",
      "Epoch 284/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9900\n",
      "Epoch 285/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9900\n",
      "Epoch 286/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9900\n",
      "Epoch 287/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9900\n",
      "Epoch 288/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9900\n",
      "Epoch 289/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9900\n",
      "Epoch 290/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9900\n",
      "Epoch 291/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9900\n",
      "Epoch 292/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9900\n",
      "Epoch 293/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9900\n",
      "Epoch 294/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9900\n",
      "Epoch 295/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9900\n",
      "Epoch 296/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9900\n",
      "Epoch 297/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9900\n",
      "Epoch 298/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9900\n",
      "Epoch 299/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9900\n",
      "Epoch 300/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9900\n",
      "Epoch 301/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
      "Epoch 302/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9900\n",
      "Epoch 303/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9900\n",
      "Epoch 304/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9900\n",
      "Epoch 305/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9900\n",
      "Epoch 306/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9900\n",
      "Epoch 307/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9900\n",
      "Epoch 308/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9900\n",
      "Epoch 309/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9900\n",
      "Epoch 310/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9900\n",
      "Epoch 311/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9900\n",
      "Epoch 312/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
      "Epoch 313/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9900\n",
      "Epoch 314/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9900\n",
      "Epoch 315/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9900\n",
      "Epoch 316/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9900\n",
      "Epoch 317/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9900\n",
      "Epoch 318/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9900\n",
      "Epoch 319/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9900\n",
      "Epoch 320/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9900\n",
      "Epoch 321/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9900\n",
      "Epoch 322/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9900\n",
      "Epoch 323/1000\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
      "Epoch 324/1000\n",
      "400/400 [==============================] - 0s 88us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9900\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5851950631944655\n",
      "F1 Micro: 0.9447367102560248\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 800us/step - loss: 1.8516 - accuracy: 0.4625 - val_loss: 1.1307 - val_accuracy: 0.8700\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 262us/step - loss: 0.7600 - accuracy: 0.8450 - val_loss: 0.3757 - val_accuracy: 0.9000\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 270us/step - loss: 0.5585 - accuracy: 0.8450 - val_loss: 0.3269 - val_accuracy: 0.9000\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 266us/step - loss: 0.4751 - accuracy: 0.8525 - val_loss: 0.2989 - val_accuracy: 0.9100\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 284us/step - loss: 0.4318 - accuracy: 0.8825 - val_loss: 0.2769 - val_accuracy: 0.9200\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 260us/step - loss: 0.4009 - accuracy: 0.8950 - val_loss: 0.2509 - val_accuracy: 0.9500\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 272us/step - loss: 0.3762 - accuracy: 0.8925 - val_loss: 0.2432 - val_accuracy: 0.9500\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 255us/step - loss: 0.3545 - accuracy: 0.8975 - val_loss: 0.2252 - val_accuracy: 0.9500\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 262us/step - loss: 0.3363 - accuracy: 0.8975 - val_loss: 0.2108 - val_accuracy: 0.9500\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 266us/step - loss: 0.3236 - accuracy: 0.9150 - val_loss: 0.2054 - val_accuracy: 0.9500\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 259us/step - loss: 0.3064 - accuracy: 0.9050 - val_loss: 0.1922 - val_accuracy: 0.9500\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 255us/step - loss: 0.2928 - accuracy: 0.9200 - val_loss: 0.1895 - val_accuracy: 0.9700\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 241us/step - loss: 0.2816 - accuracy: 0.9300 - val_loss: 0.1772 - val_accuracy: 0.9700\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 235us/step - loss: 0.2702 - accuracy: 0.9300 - val_loss: 0.1753 - val_accuracy: 0.9700\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 244us/step - loss: 0.2631 - accuracy: 0.9375 - val_loss: 0.1757 - val_accuracy: 0.9700\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 254us/step - loss: 0.2559 - accuracy: 0.9300 - val_loss: 0.1641 - val_accuracy: 0.9700\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 254us/step - loss: 0.2440 - accuracy: 0.9450 - val_loss: 0.1632 - val_accuracy: 0.9700\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 255us/step - loss: 0.2352 - accuracy: 0.9425 - val_loss: 0.1546 - val_accuracy: 0.9700\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 254us/step - loss: 0.2291 - accuracy: 0.9425 - val_loss: 0.1521 - val_accuracy: 0.9700\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 257us/step - loss: 0.2216 - accuracy: 0.9475 - val_loss: 0.1470 - val_accuracy: 0.9700\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 258us/step - loss: 0.2155 - accuracy: 0.9500 - val_loss: 0.1460 - val_accuracy: 0.9700\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 258us/step - loss: 0.2084 - accuracy: 0.9525 - val_loss: 0.1420 - val_accuracy: 0.9700\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 255us/step - loss: 0.2035 - accuracy: 0.9500 - val_loss: 0.1394 - val_accuracy: 0.9700\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 261us/step - loss: 0.1962 - accuracy: 0.9575 - val_loss: 0.1343 - val_accuracy: 0.9700\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 257us/step - loss: 0.1918 - accuracy: 0.9575 - val_loss: 0.1288 - val_accuracy: 0.9700\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 254us/step - loss: 0.1860 - accuracy: 0.9575 - val_loss: 0.1290 - val_accuracy: 0.9700\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 257us/step - loss: 0.1810 - accuracy: 0.9575 - val_loss: 0.1271 - val_accuracy: 0.9700\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 254us/step - loss: 0.1773 - accuracy: 0.9575 - val_loss: 0.1221 - val_accuracy: 0.9700\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 257us/step - loss: 0.1762 - accuracy: 0.9575 - val_loss: 0.1227 - val_accuracy: 0.9700\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 261us/step - loss: 0.1684 - accuracy: 0.9600 - val_loss: 0.1218 - val_accuracy: 0.9700\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 248us/step - loss: 0.1629 - accuracy: 0.9625 - val_loss: 0.1147 - val_accuracy: 0.9700\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1627 - accuracy: 0.9600 - val_loss: 0.1119 - val_accuracy: 0.9700\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1544 - accuracy: 0.9575 - val_loss: 0.1061 - val_accuracy: 0.9700\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 250us/step - loss: 0.1510 - accuracy: 0.9650 - val_loss: 0.1079 - val_accuracy: 0.9700\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 254us/step - loss: 0.1473 - accuracy: 0.9575 - val_loss: 0.1082 - val_accuracy: 0.9700\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 256us/step - loss: 0.1434 - accuracy: 0.9650 - val_loss: 0.1074 - val_accuracy: 0.9700\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 248us/step - loss: 0.1404 - accuracy: 0.9625 - val_loss: 0.0992 - val_accuracy: 0.9700\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.1386 - accuracy: 0.9600 - val_loss: 0.1084 - val_accuracy: 0.9700\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 253us/step - loss: 0.1328 - accuracy: 0.9625 - val_loss: 0.0941 - val_accuracy: 0.9700\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 256us/step - loss: 0.1304 - accuracy: 0.9625 - val_loss: 0.0973 - val_accuracy: 0.9700\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 251us/step - loss: 0.1259 - accuracy: 0.9650 - val_loss: 0.0903 - val_accuracy: 0.9700\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 254us/step - loss: 0.1232 - accuracy: 0.9650 - val_loss: 0.0925 - val_accuracy: 0.9700\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 252us/step - loss: 0.1202 - accuracy: 0.9650 - val_loss: 0.0918 - val_accuracy: 0.9700\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 250us/step - loss: 0.1207 - accuracy: 0.9675 - val_loss: 0.0811 - val_accuracy: 0.9700\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 251us/step - loss: 0.1158 - accuracy: 0.9650 - val_loss: 0.0890 - val_accuracy: 0.9700\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 253us/step - loss: 0.1148 - accuracy: 0.9625 - val_loss: 0.0885 - val_accuracy: 0.9700\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 259us/step - loss: 0.1120 - accuracy: 0.9700 - val_loss: 0.0781 - val_accuracy: 0.9700\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 252us/step - loss: 0.1062 - accuracy: 0.9700 - val_loss: 0.0878 - val_accuracy: 0.9700\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 257us/step - loss: 0.1020 - accuracy: 0.9700 - val_loss: 0.0780 - val_accuracy: 0.9700\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.1010 - accuracy: 0.9675 - val_loss: 0.0852 - val_accuracy: 0.9700\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0975 - accuracy: 0.9725 - val_loss: 0.0749 - val_accuracy: 0.9700\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 233us/step - loss: 0.0927 - accuracy: 0.9750 - val_loss: 0.0756 - val_accuracy: 0.9700\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 243us/step - loss: 0.0904 - accuracy: 0.9775 - val_loss: 0.0664 - val_accuracy: 0.9700\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.0891 - accuracy: 0.9750 - val_loss: 0.0715 - val_accuracy: 0.9700\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.0913 - accuracy: 0.9700 - val_loss: 0.0692 - val_accuracy: 0.9700\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 240us/step - loss: 0.0907 - accuracy: 0.9825 - val_loss: 0.0666 - val_accuracy: 0.9700\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.0815 - accuracy: 0.9800 - val_loss: 0.0681 - val_accuracy: 0.9700\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 244us/step - loss: 0.0801 - accuracy: 0.9825 - val_loss: 0.0619 - val_accuracy: 0.9700\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 243us/step - loss: 0.0784 - accuracy: 0.9750 - val_loss: 0.0711 - val_accuracy: 0.9700\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 241us/step - loss: 0.0757 - accuracy: 0.9875 - val_loss: 0.0590 - val_accuracy: 0.9700\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0752 - accuracy: 0.9800 - val_loss: 0.0692 - val_accuracy: 0.9700\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0699 - accuracy: 0.9825 - val_loss: 0.0561 - val_accuracy: 0.9700\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 235us/step - loss: 0.0687 - accuracy: 0.9850 - val_loss: 0.0530 - val_accuracy: 0.9700\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0648 - accuracy: 0.9850 - val_loss: 0.0601 - val_accuracy: 0.9800\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 244us/step - loss: 0.0626 - accuracy: 0.9900 - val_loss: 0.0583 - val_accuracy: 0.9800\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.0606 - accuracy: 0.9875 - val_loss: 0.0556 - val_accuracy: 0.9800\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0583 - accuracy: 0.9900 - val_loss: 0.0533 - val_accuracy: 0.9800\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 240us/step - loss: 0.0569 - accuracy: 0.9850 - val_loss: 0.0519 - val_accuracy: 0.9800\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0596 - accuracy: 0.9875 - val_loss: 0.0492 - val_accuracy: 0.9700\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0533 - accuracy: 0.9900 - val_loss: 0.0645 - val_accuracy: 0.9800\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0494 - accuracy: 0.9900 - val_loss: 0.0436 - val_accuracy: 0.9800\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0491 - accuracy: 0.9875 - val_loss: 0.0641 - val_accuracy: 0.9800\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0506 - accuracy: 0.9850 - val_loss: 0.0440 - val_accuracy: 0.9800\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.0453 - accuracy: 0.9900 - val_loss: 0.0492 - val_accuracy: 0.9800\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0445 - accuracy: 0.9900 - val_loss: 0.0484 - val_accuracy: 0.9900\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0436 - accuracy: 0.9900 - val_loss: 0.0539 - val_accuracy: 0.9800\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.0452 - accuracy: 0.9900 - val_loss: 0.0395 - val_accuracy: 0.9800\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0405 - accuracy: 0.9950 - val_loss: 0.0434 - val_accuracy: 0.9800\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0415 - accuracy: 0.9900 - val_loss: 0.0623 - val_accuracy: 0.9800\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9800\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 243us/step - loss: 0.0369 - accuracy: 0.9950 - val_loss: 0.0463 - val_accuracy: 0.9800\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 236us/step - loss: 0.0325 - accuracy: 0.9925 - val_loss: 0.0384 - val_accuracy: 0.9800\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9900\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0314 - accuracy: 0.9950 - val_loss: 0.0481 - val_accuracy: 0.9900\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0288 - accuracy: 0.9975 - val_loss: 0.0350 - val_accuracy: 0.9800\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0285 - accuracy: 0.9950 - val_loss: 0.0538 - val_accuracy: 0.9800\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.0278 - accuracy: 0.9975 - val_loss: 0.0349 - val_accuracy: 0.9800\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9800\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 245us/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9900\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9800\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9900\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9800\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9800\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9900\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9800\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9900\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9800\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9800\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9800\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 235us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9900\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9800\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9800\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9800\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9800\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 235us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9800\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9800\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9800\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9800\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9800\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9900\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 0.9800\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9800\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9800\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 0.9800\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9900\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9900\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9800\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9800\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9800\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9800\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9800\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 236us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9800\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5640313819373112\n",
      "F1 Micro: 0.9434340397815522\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5293074031904671\n",
      "F1 Micro: 0.9387243849892278\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5780334126057107\n",
      "F1 Micro: 0.9452377373615912\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 1 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 286us/step - loss: 0.8508 - accuracy: 0.8405 - val_loss: 0.6776 - val_accuracy: 0.8490\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.6183 - accuracy: 0.8547 - val_loss: 0.6205 - val_accuracy: 0.8490\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 220us/step - loss: 0.5107 - accuracy: 0.8670 - val_loss: 0.4836 - val_accuracy: 0.8880\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 214us/step - loss: 0.3783 - accuracy: 0.9028 - val_loss: 0.3549 - val_accuracy: 0.9180\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 214us/step - loss: 0.3131 - accuracy: 0.9153 - val_loss: 0.2954 - val_accuracy: 0.9240\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 0.2686 - accuracy: 0.9260 - val_loss: 0.2686 - val_accuracy: 0.9310\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.2365 - accuracy: 0.9333 - val_loss: 0.2360 - val_accuracy: 0.9440\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 217us/step - loss: 0.2093 - accuracy: 0.9413 - val_loss: 0.2149 - val_accuracy: 0.9470\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.2038 - accuracy: 0.9400 - val_loss: 0.2280 - val_accuracy: 0.9470\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 217us/step - loss: 0.2012 - accuracy: 0.9408 - val_loss: 0.2471 - val_accuracy: 0.9480\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 214us/step - loss: 0.1780 - accuracy: 0.9460 - val_loss: 0.1859 - val_accuracy: 0.9490\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 214us/step - loss: 0.1687 - accuracy: 0.9520 - val_loss: 0.1907 - val_accuracy: 0.9480\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 0.1523 - accuracy: 0.9540 - val_loss: 0.1645 - val_accuracy: 0.9610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.1451 - accuracy: 0.9550 - val_loss: 0.1574 - val_accuracy: 0.9600\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 219us/step - loss: 0.1365 - accuracy: 0.9567 - val_loss: 0.1903 - val_accuracy: 0.9530\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.1411 - accuracy: 0.9542 - val_loss: 0.1683 - val_accuracy: 0.9520\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 214us/step - loss: 0.1305 - accuracy: 0.9580 - val_loss: 0.1442 - val_accuracy: 0.9620\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 214us/step - loss: 0.1333 - accuracy: 0.9580 - val_loss: 0.1427 - val_accuracy: 0.9630\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 214us/step - loss: 0.1137 - accuracy: 0.9657 - val_loss: 0.1721 - val_accuracy: 0.9530\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 217us/step - loss: 0.1094 - accuracy: 0.9645 - val_loss: 0.1479 - val_accuracy: 0.9610\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 213us/step - loss: 0.1099 - accuracy: 0.9678 - val_loss: 0.1499 - val_accuracy: 0.9590\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 219us/step - loss: 0.0996 - accuracy: 0.9685 - val_loss: 0.1653 - val_accuracy: 0.9560\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 211us/step - loss: 0.1010 - accuracy: 0.9672 - val_loss: 0.1396 - val_accuracy: 0.9640\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 218us/step - loss: 0.0918 - accuracy: 0.9712 - val_loss: 0.1325 - val_accuracy: 0.9630\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 215us/step - loss: 0.1115 - accuracy: 0.9638 - val_loss: 0.1281 - val_accuracy: 0.9660\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 220us/step - loss: 0.0826 - accuracy: 0.9755 - val_loss: 0.1267 - val_accuracy: 0.9640\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 214us/step - loss: 0.0798 - accuracy: 0.9758 - val_loss: 0.1284 - val_accuracy: 0.9660\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 211us/step - loss: 0.0744 - accuracy: 0.9768 - val_loss: 0.1995 - val_accuracy: 0.9340\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 221us/step - loss: 0.0841 - accuracy: 0.9743 - val_loss: 0.1199 - val_accuracy: 0.9690\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.0739 - accuracy: 0.9770 - val_loss: 0.1817 - val_accuracy: 0.9440\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 218us/step - loss: 0.0695 - accuracy: 0.9783 - val_loss: 0.1300 - val_accuracy: 0.9640\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 214us/step - loss: 0.0582 - accuracy: 0.9827 - val_loss: 0.1326 - val_accuracy: 0.9620\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 0.0569 - accuracy: 0.9843 - val_loss: 0.1444 - val_accuracy: 0.9650\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 219us/step - loss: 0.0615 - accuracy: 0.9812 - val_loss: 0.1350 - val_accuracy: 0.9620\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 213us/step - loss: 0.0515 - accuracy: 0.9850 - val_loss: 0.1444 - val_accuracy: 0.9650\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 218us/step - loss: 0.0426 - accuracy: 0.9880 - val_loss: 0.1411 - val_accuracy: 0.9610\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 212us/step - loss: 0.0472 - accuracy: 0.9875 - val_loss: 0.1564 - val_accuracy: 0.9590\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 0.0433 - accuracy: 0.9870 - val_loss: 0.1509 - val_accuracy: 0.9620\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 213us/step - loss: 0.0354 - accuracy: 0.9898 - val_loss: 0.1562 - val_accuracy: 0.9620\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 215us/step - loss: 0.0319 - accuracy: 0.9918 - val_loss: 0.1354 - val_accuracy: 0.9650\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 218us/step - loss: 0.0443 - accuracy: 0.9858 - val_loss: 0.1317 - val_accuracy: 0.9650\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 213us/step - loss: 0.0281 - accuracy: 0.9935 - val_loss: 0.1322 - val_accuracy: 0.9680\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 218us/step - loss: 0.0229 - accuracy: 0.9955 - val_loss: 0.1539 - val_accuracy: 0.9620\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 212us/step - loss: 0.0203 - accuracy: 0.9960 - val_loss: 0.1361 - val_accuracy: 0.9630\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 217us/step - loss: 0.0262 - accuracy: 0.9927 - val_loss: 0.2558 - val_accuracy: 0.9530\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 213us/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 0.1497 - val_accuracy: 0.9640\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 217us/step - loss: 0.0184 - accuracy: 0.9960 - val_loss: 0.2000 - val_accuracy: 0.9560\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 218us/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.1463 - val_accuracy: 0.9650\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 212us/step - loss: 0.0143 - accuracy: 0.9977 - val_loss: 0.1428 - val_accuracy: 0.9650\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6524838737216171\n",
      "F1 Micro: 0.954929718373268\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6455460321860884\n",
      "F1 Micro: 0.9547\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 93us/step - loss: 1.7098 - accuracy: 0.5430 - val_loss: 1.2945 - val_accuracy: 0.6930\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 1.0943 - accuracy: 0.7617 - val_loss: 0.7767 - val_accuracy: 0.8670\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.6290 - accuracy: 0.8935 - val_loss: 0.4471 - val_accuracy: 0.9260\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.3800 - accuracy: 0.9302 - val_loss: 0.2995 - val_accuracy: 0.9420\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.2678 - accuracy: 0.9442 - val_loss: 0.2348 - val_accuracy: 0.9450\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.2135 - accuracy: 0.9480 - val_loss: 0.2019 - val_accuracy: 0.9490\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1844 - accuracy: 0.9520 - val_loss: 0.1849 - val_accuracy: 0.9530\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1666 - accuracy: 0.9540 - val_loss: 0.1723 - val_accuracy: 0.9520\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1543 - accuracy: 0.9563 - val_loss: 0.1637 - val_accuracy: 0.9540\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1449 - accuracy: 0.9567 - val_loss: 0.1579 - val_accuracy: 0.9560\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1374 - accuracy: 0.9595 - val_loss: 0.1546 - val_accuracy: 0.9570\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1310 - accuracy: 0.9607 - val_loss: 0.1508 - val_accuracy: 0.9580\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1263 - accuracy: 0.9620 - val_loss: 0.1457 - val_accuracy: 0.9610\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1220 - accuracy: 0.9615 - val_loss: 0.1446 - val_accuracy: 0.9600\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1182 - accuracy: 0.9645 - val_loss: 0.1401 - val_accuracy: 0.9600\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1148 - accuracy: 0.9643 - val_loss: 0.1389 - val_accuracy: 0.9580\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1114 - accuracy: 0.9653 - val_loss: 0.1397 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1079 - accuracy: 0.9668 - val_loss: 0.1352 - val_accuracy: 0.9600\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1071 - accuracy: 0.9663 - val_loss: 0.1334 - val_accuracy: 0.9580\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.1029 - accuracy: 0.9655 - val_loss: 0.1335 - val_accuracy: 0.9610\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1003 - accuracy: 0.9678 - val_loss: 0.1321 - val_accuracy: 0.9610\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0985 - accuracy: 0.9680 - val_loss: 0.1299 - val_accuracy: 0.9610\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0962 - accuracy: 0.9695 - val_loss: 0.1290 - val_accuracy: 0.9610\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0940 - accuracy: 0.9675 - val_loss: 0.1281 - val_accuracy: 0.9610\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0917 - accuracy: 0.9710 - val_loss: 0.1267 - val_accuracy: 0.9610\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0902 - accuracy: 0.9705 - val_loss: 0.1267 - val_accuracy: 0.9620\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0879 - accuracy: 0.9718 - val_loss: 0.1274 - val_accuracy: 0.9630\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0865 - accuracy: 0.9722 - val_loss: 0.1251 - val_accuracy: 0.9620\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0847 - accuracy: 0.9728 - val_loss: 0.1258 - val_accuracy: 0.9620\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0825 - accuracy: 0.9735 - val_loss: 0.1238 - val_accuracy: 0.9620\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0820 - accuracy: 0.9730 - val_loss: 0.1234 - val_accuracy: 0.9630\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0797 - accuracy: 0.9732 - val_loss: 0.1251 - val_accuracy: 0.9630\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0781 - accuracy: 0.9743 - val_loss: 0.1230 - val_accuracy: 0.9630\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0771 - accuracy: 0.9747 - val_loss: 0.1230 - val_accuracy: 0.9640\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0752 - accuracy: 0.9750 - val_loss: 0.1234 - val_accuracy: 0.9640\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0740 - accuracy: 0.9765 - val_loss: 0.1241 - val_accuracy: 0.9640\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0731 - accuracy: 0.9760 - val_loss: 0.1210 - val_accuracy: 0.9640\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0711 - accuracy: 0.9770 - val_loss: 0.1207 - val_accuracy: 0.9650\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0697 - accuracy: 0.9785 - val_loss: 0.1213 - val_accuracy: 0.9650\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0686 - accuracy: 0.9780 - val_loss: 0.1211 - val_accuracy: 0.9650\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0673 - accuracy: 0.9778 - val_loss: 0.1201 - val_accuracy: 0.9650\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0664 - accuracy: 0.9793 - val_loss: 0.1200 - val_accuracy: 0.9660\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0654 - accuracy: 0.9800 - val_loss: 0.1204 - val_accuracy: 0.9650\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0637 - accuracy: 0.9810 - val_loss: 0.1247 - val_accuracy: 0.9620\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0631 - accuracy: 0.9808 - val_loss: 0.1214 - val_accuracy: 0.9640\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0616 - accuracy: 0.9797 - val_loss: 0.1203 - val_accuracy: 0.9650\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0611 - accuracy: 0.9820 - val_loss: 0.1186 - val_accuracy: 0.9650\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0597 - accuracy: 0.9820 - val_loss: 0.1218 - val_accuracy: 0.9640\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0583 - accuracy: 0.9825 - val_loss: 0.1203 - val_accuracy: 0.9650\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0573 - accuracy: 0.9818 - val_loss: 0.1196 - val_accuracy: 0.9650\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0567 - accuracy: 0.9850 - val_loss: 0.1206 - val_accuracy: 0.9640\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0553 - accuracy: 0.9837 - val_loss: 0.1211 - val_accuracy: 0.9650\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0547 - accuracy: 0.9852 - val_loss: 0.1208 - val_accuracy: 0.9650\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0536 - accuracy: 0.9840 - val_loss: 0.1230 - val_accuracy: 0.9640\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0529 - accuracy: 0.9868 - val_loss: 0.1198 - val_accuracy: 0.9660\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0528 - accuracy: 0.9850 - val_loss: 0.1201 - val_accuracy: 0.9660\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0511 - accuracy: 0.9862 - val_loss: 0.1210 - val_accuracy: 0.9650\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0499 - accuracy: 0.9872 - val_loss: 0.1245 - val_accuracy: 0.9650\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0494 - accuracy: 0.9860 - val_loss: 0.1205 - val_accuracy: 0.9670\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0488 - accuracy: 0.9865 - val_loss: 0.1227 - val_accuracy: 0.9640\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0476 - accuracy: 0.9872 - val_loss: 0.1211 - val_accuracy: 0.9650\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0469 - accuracy: 0.9880 - val_loss: 0.1265 - val_accuracy: 0.9650\n",
      "Epoch 63/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0457 - accuracy: 0.9880 - val_loss: 0.1255 - val_accuracy: 0.9660\n",
      "Epoch 64/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0452 - accuracy: 0.9890 - val_loss: 0.1223 - val_accuracy: 0.9670\n",
      "Epoch 65/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0442 - accuracy: 0.9883 - val_loss: 0.1224 - val_accuracy: 0.9660\n",
      "Epoch 66/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0438 - accuracy: 0.9887 - val_loss: 0.1225 - val_accuracy: 0.9660\n",
      "Epoch 67/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0430 - accuracy: 0.9895 - val_loss: 0.1236 - val_accuracy: 0.9660\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7205546683013492\n",
      "F1 Micro: 0.9593316992646691\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 285us/step - loss: 0.6503 - accuracy: 0.8285 - val_loss: 0.3414 - val_accuracy: 0.8990\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 233us/step - loss: 0.2894 - accuracy: 0.9235 - val_loss: 0.2851 - val_accuracy: 0.9250\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 219us/step - loss: 0.2379 - accuracy: 0.9358 - val_loss: 0.2409 - val_accuracy: 0.9420\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 220us/step - loss: 0.2089 - accuracy: 0.9435 - val_loss: 0.2187 - val_accuracy: 0.9470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 215us/step - loss: 0.1894 - accuracy: 0.9475 - val_loss: 0.2034 - val_accuracy: 0.9500\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 226us/step - loss: 0.1753 - accuracy: 0.9510 - val_loss: 0.1987 - val_accuracy: 0.9470\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 220us/step - loss: 0.1641 - accuracy: 0.9525 - val_loss: 0.1796 - val_accuracy: 0.9480\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 0.1542 - accuracy: 0.9525 - val_loss: 0.1680 - val_accuracy: 0.9510\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 225us/step - loss: 0.1465 - accuracy: 0.9565 - val_loss: 0.1657 - val_accuracy: 0.9510\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 217us/step - loss: 0.1426 - accuracy: 0.9555 - val_loss: 0.1559 - val_accuracy: 0.9550\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 225us/step - loss: 0.1341 - accuracy: 0.9575 - val_loss: 0.1510 - val_accuracy: 0.9590\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 215us/step - loss: 0.1289 - accuracy: 0.9600 - val_loss: 0.1454 - val_accuracy: 0.9580\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 223us/step - loss: 0.1228 - accuracy: 0.9605 - val_loss: 0.1426 - val_accuracy: 0.9610\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 219us/step - loss: 0.1174 - accuracy: 0.9630 - val_loss: 0.1423 - val_accuracy: 0.9570\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 222us/step - loss: 0.1152 - accuracy: 0.9655 - val_loss: 0.1382 - val_accuracy: 0.9600\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 223us/step - loss: 0.1117 - accuracy: 0.9655 - val_loss: 0.1366 - val_accuracy: 0.9590\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 217us/step - loss: 0.1068 - accuracy: 0.9660 - val_loss: 0.1341 - val_accuracy: 0.9610\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 222us/step - loss: 0.1048 - accuracy: 0.9680 - val_loss: 0.1283 - val_accuracy: 0.9620\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 219us/step - loss: 0.1007 - accuracy: 0.9700 - val_loss: 0.1268 - val_accuracy: 0.9630\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 223us/step - loss: 0.0991 - accuracy: 0.9675 - val_loss: 0.1278 - val_accuracy: 0.9630\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 0.0947 - accuracy: 0.9710 - val_loss: 0.1283 - val_accuracy: 0.9640\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 221us/step - loss: 0.0925 - accuracy: 0.9725 - val_loss: 0.1244 - val_accuracy: 0.9630\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 0.0897 - accuracy: 0.9722 - val_loss: 0.1355 - val_accuracy: 0.9610\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 223us/step - loss: 0.0884 - accuracy: 0.9730 - val_loss: 0.1217 - val_accuracy: 0.9620\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 220us/step - loss: 0.0831 - accuracy: 0.9735 - val_loss: 0.1273 - val_accuracy: 0.9650\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 217us/step - loss: 0.0828 - accuracy: 0.9728 - val_loss: 0.1289 - val_accuracy: 0.9650\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 224us/step - loss: 0.0784 - accuracy: 0.9758 - val_loss: 0.1199 - val_accuracy: 0.9630\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 218us/step - loss: 0.0751 - accuracy: 0.9787 - val_loss: 0.1176 - val_accuracy: 0.9650\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 226us/step - loss: 0.0706 - accuracy: 0.9778 - val_loss: 0.1253 - val_accuracy: 0.9650\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 0.0686 - accuracy: 0.9772 - val_loss: 0.1186 - val_accuracy: 0.9650\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 226us/step - loss: 0.0638 - accuracy: 0.9818 - val_loss: 0.1180 - val_accuracy: 0.9620\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 224us/step - loss: 0.0602 - accuracy: 0.9818 - val_loss: 0.1315 - val_accuracy: 0.9660\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 232us/step - loss: 0.0584 - accuracy: 0.9810 - val_loss: 0.1168 - val_accuracy: 0.9650\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 219us/step - loss: 0.0522 - accuracy: 0.9847 - val_loss: 0.1253 - val_accuracy: 0.9670\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 222us/step - loss: 0.0496 - accuracy: 0.9847 - val_loss: 0.1143 - val_accuracy: 0.9660\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 226us/step - loss: 0.0431 - accuracy: 0.9885 - val_loss: 0.1238 - val_accuracy: 0.9630\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 0.0427 - accuracy: 0.9895 - val_loss: 0.1297 - val_accuracy: 0.9650\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 226us/step - loss: 0.0360 - accuracy: 0.9912 - val_loss: 0.1290 - val_accuracy: 0.9640\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 218us/step - loss: 0.0325 - accuracy: 0.9923 - val_loss: 0.1305 - val_accuracy: 0.9640\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 228us/step - loss: 0.0282 - accuracy: 0.9940 - val_loss: 0.1359 - val_accuracy: 0.9640\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 0.0287 - accuracy: 0.9937 - val_loss: 0.1215 - val_accuracy: 0.9670\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 221us/step - loss: 0.0249 - accuracy: 0.9950 - val_loss: 0.1384 - val_accuracy: 0.9630\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 221us/step - loss: 0.0224 - accuracy: 0.9948 - val_loss: 0.1453 - val_accuracy: 0.9640\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 218us/step - loss: 0.0207 - accuracy: 0.9965 - val_loss: 0.1296 - val_accuracy: 0.9630\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 228us/step - loss: 0.0198 - accuracy: 0.9960 - val_loss: 0.1478 - val_accuracy: 0.9640\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 217us/step - loss: 0.0176 - accuracy: 0.9975 - val_loss: 0.1280 - val_accuracy: 0.9640\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 226us/step - loss: 0.0169 - accuracy: 0.9985 - val_loss: 0.1626 - val_accuracy: 0.9630\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 220us/step - loss: 0.0148 - accuracy: 0.9985 - val_loss: 0.1436 - val_accuracy: 0.9630\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 226us/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.1578 - val_accuracy: 0.9630\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 218us/step - loss: 0.0132 - accuracy: 0.9990 - val_loss: 0.1610 - val_accuracy: 0.9640\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 229us/step - loss: 0.0120 - accuracy: 0.9987 - val_loss: 0.1444 - val_accuracy: 0.9650\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 222us/step - loss: 0.0103 - accuracy: 0.9992 - val_loss: 0.1484 - val_accuracy: 0.9620\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 223us/step - loss: 0.0103 - accuracy: 0.9992 - val_loss: 0.1731 - val_accuracy: 0.9660\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 222us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9610\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 215us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9640\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7401678185779115\n",
      "F1 Micro: 0.9602321044470011\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6788701973006998\n",
      "F1 Micro: 0.9556\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6561002208411663\n",
      "F1 Micro: 0.9611\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 1 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 9s 221us/step - loss: 0.4257 - accuracy: 0.8954 - val_loss: 0.2417 - val_accuracy: 0.9341\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 9s 220us/step - loss: 0.1907 - accuracy: 0.9441 - val_loss: 0.1921 - val_accuracy: 0.9429\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 9s 214us/step - loss: 0.1501 - accuracy: 0.9545 - val_loss: 0.1378 - val_accuracy: 0.9588\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 9s 214us/step - loss: 0.1293 - accuracy: 0.9603 - val_loss: 0.1261 - val_accuracy: 0.9611\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 9s 215us/step - loss: 0.1157 - accuracy: 0.9640 - val_loss: 0.1366 - val_accuracy: 0.9592\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 9s 215us/step - loss: 0.1077 - accuracy: 0.9664 - val_loss: 0.1207 - val_accuracy: 0.9602\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 9s 215us/step - loss: 0.1020 - accuracy: 0.9681 - val_loss: 0.1091 - val_accuracy: 0.9648\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 9s 215us/step - loss: 0.0933 - accuracy: 0.9700 - val_loss: 0.1083 - val_accuracy: 0.9650\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 9s 214us/step - loss: 0.0871 - accuracy: 0.9714 - val_loss: 0.1012 - val_accuracy: 0.9670\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 9s 214us/step - loss: 0.0838 - accuracy: 0.9724 - val_loss: 0.1044 - val_accuracy: 0.9652\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 9s 214us/step - loss: 0.0786 - accuracy: 0.9742 - val_loss: 0.1009 - val_accuracy: 0.9661\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 9s 214us/step - loss: 0.0743 - accuracy: 0.9750 - val_loss: 0.0967 - val_accuracy: 0.9702\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 9s 215us/step - loss: 0.0699 - accuracy: 0.9769 - val_loss: 0.0933 - val_accuracy: 0.9702\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0655 - accuracy: 0.9778 - val_loss: 0.0928 - val_accuracy: 0.9674\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.0607 - accuracy: 0.9796 - val_loss: 0.1004 - val_accuracy: 0.9686\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.0554 - accuracy: 0.9812 - val_loss: 0.0919 - val_accuracy: 0.9705\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 210us/step - loss: 0.0518 - accuracy: 0.9817 - val_loss: 0.0909 - val_accuracy: 0.9703\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 208us/step - loss: 0.0466 - accuracy: 0.9836 - val_loss: 0.0949 - val_accuracy: 0.9710\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 0.0431 - accuracy: 0.9844 - val_loss: 0.1040 - val_accuracy: 0.9667\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 211us/step - loss: 0.0369 - accuracy: 0.9876 - val_loss: 0.1175 - val_accuracy: 0.9685\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 208us/step - loss: 0.0329 - accuracy: 0.9887 - val_loss: 0.1080 - val_accuracy: 0.9704\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0276 - accuracy: 0.9903 - val_loss: 0.1133 - val_accuracy: 0.9706\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.1160 - val_accuracy: 0.9661\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.1218 - val_accuracy: 0.9658\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 212us/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.1154 - val_accuracy: 0.9703\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 208us/step - loss: 0.0171 - accuracy: 0.9940 - val_loss: 0.1267 - val_accuracy: 0.9671\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 210us/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.1223 - val_accuracy: 0.9671\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.1337 - val_accuracy: 0.9698\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.1466 - val_accuracy: 0.9693\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.1768 - val_accuracy: 0.9687\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1908 - val_accuracy: 0.9669\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 212us/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.1522 - val_accuracy: 0.9706\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 212us/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.1343 - val_accuracy: 0.9703\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.1743 - val_accuracy: 0.9707\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 9s 214us/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.1471 - val_accuracy: 0.9703\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.1777 - val_accuracy: 0.9687\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.1624 - val_accuracy: 0.9693\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8073504847135266\n",
      "F1 Micro: 0.9705\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7950901002848995\n",
      "F1 Micro: 0.9645\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.4718 - accuracy: 0.8927 - val_loss: 0.1606 - val_accuracy: 0.9541\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1467 - accuracy: 0.9566 - val_loss: 0.1351 - val_accuracy: 0.9581\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1295 - accuracy: 0.9608 - val_loss: 0.1248 - val_accuracy: 0.9619\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1208 - accuracy: 0.9631 - val_loss: 0.1180 - val_accuracy: 0.9632\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1146 - accuracy: 0.9643 - val_loss: 0.1154 - val_accuracy: 0.9644\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1096 - accuracy: 0.9658 - val_loss: 0.1121 - val_accuracy: 0.9648\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1058 - accuracy: 0.9670 - val_loss: 0.1097 - val_accuracy: 0.9668\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1027 - accuracy: 0.9679 - val_loss: 0.1093 - val_accuracy: 0.9664\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0998 - accuracy: 0.9688 - val_loss: 0.1099 - val_accuracy: 0.9671\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0979 - accuracy: 0.9697 - val_loss: 0.1066 - val_accuracy: 0.9664\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0957 - accuracy: 0.9704 - val_loss: 0.1052 - val_accuracy: 0.9671\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0936 - accuracy: 0.9711 - val_loss: 0.1049 - val_accuracy: 0.9674\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0920 - accuracy: 0.9711 - val_loss: 0.1021 - val_accuracy: 0.9684\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0903 - accuracy: 0.9716 - val_loss: 0.1044 - val_accuracy: 0.9678\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0891 - accuracy: 0.9722 - val_loss: 0.1025 - val_accuracy: 0.9681\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0875 - accuracy: 0.9725 - val_loss: 0.1023 - val_accuracy: 0.9678\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0863 - accuracy: 0.9730 - val_loss: 0.1018 - val_accuracy: 0.9684\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0848 - accuracy: 0.9736 - val_loss: 0.1040 - val_accuracy: 0.9670\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0842 - accuracy: 0.9736 - val_loss: 0.1029 - val_accuracy: 0.9681\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0826 - accuracy: 0.9738 - val_loss: 0.1035 - val_accuracy: 0.9677\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0815 - accuracy: 0.9744 - val_loss: 0.0998 - val_accuracy: 0.9693\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0805 - accuracy: 0.9744 - val_loss: 0.0997 - val_accuracy: 0.9680\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0796 - accuracy: 0.9747 - val_loss: 0.0992 - val_accuracy: 0.9690\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0784 - accuracy: 0.9752 - val_loss: 0.1005 - val_accuracy: 0.9686\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0777 - accuracy: 0.9758 - val_loss: 0.0984 - val_accuracy: 0.9694\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0768 - accuracy: 0.9758 - val_loss: 0.1004 - val_accuracy: 0.9684\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0756 - accuracy: 0.9764 - val_loss: 0.0987 - val_accuracy: 0.9682\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0748 - accuracy: 0.9761 - val_loss: 0.0972 - val_accuracy: 0.9695\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0741 - accuracy: 0.9768 - val_loss: 0.0985 - val_accuracy: 0.9695\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0731 - accuracy: 0.9773 - val_loss: 0.0999 - val_accuracy: 0.9688\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0725 - accuracy: 0.9775 - val_loss: 0.1006 - val_accuracy: 0.9688\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0718 - accuracy: 0.9773 - val_loss: 0.1004 - val_accuracy: 0.9698\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0708 - accuracy: 0.9778 - val_loss: 0.0985 - val_accuracy: 0.9691\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0702 - accuracy: 0.9786 - val_loss: 0.0969 - val_accuracy: 0.9687\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0694 - accuracy: 0.9779 - val_loss: 0.0979 - val_accuracy: 0.9689\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0686 - accuracy: 0.9786 - val_loss: 0.0966 - val_accuracy: 0.9691\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0677 - accuracy: 0.9791 - val_loss: 0.0981 - val_accuracy: 0.9678\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0674 - accuracy: 0.9791 - val_loss: 0.0966 - val_accuracy: 0.9690\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0662 - accuracy: 0.9789 - val_loss: 0.0968 - val_accuracy: 0.9697\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0658 - accuracy: 0.9795 - val_loss: 0.0985 - val_accuracy: 0.9684\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0650 - accuracy: 0.9798 - val_loss: 0.0998 - val_accuracy: 0.9676\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0644 - accuracy: 0.9797 - val_loss: 0.0959 - val_accuracy: 0.9690\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0636 - accuracy: 0.9801 - val_loss: 0.0984 - val_accuracy: 0.9689\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0630 - accuracy: 0.9801 - val_loss: 0.0968 - val_accuracy: 0.9687\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0623 - accuracy: 0.9804 - val_loss: 0.0961 - val_accuracy: 0.9687\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0619 - accuracy: 0.9808 - val_loss: 0.0967 - val_accuracy: 0.9687\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0610 - accuracy: 0.9807 - val_loss: 0.0974 - val_accuracy: 0.9692\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0604 - accuracy: 0.9814 - val_loss: 0.0974 - val_accuracy: 0.9686\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0597 - accuracy: 0.9819 - val_loss: 0.0975 - val_accuracy: 0.9690\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0592 - accuracy: 0.9817 - val_loss: 0.0973 - val_accuracy: 0.9685\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0587 - accuracy: 0.9814 - val_loss: 0.1007 - val_accuracy: 0.9686\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0579 - accuracy: 0.9817 - val_loss: 0.0971 - val_accuracy: 0.9686\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0577 - accuracy: 0.9821 - val_loss: 0.0977 - val_accuracy: 0.9686\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0567 - accuracy: 0.9826 - val_loss: 0.0994 - val_accuracy: 0.9679\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0564 - accuracy: 0.9825 - val_loss: 0.0981 - val_accuracy: 0.9680\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0557 - accuracy: 0.9826 - val_loss: 0.0983 - val_accuracy: 0.9677\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0549 - accuracy: 0.9832 - val_loss: 0.0974 - val_accuracy: 0.9690\n",
      "Epoch 58/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0547 - accuracy: 0.9833 - val_loss: 0.0976 - val_accuracy: 0.9691\n",
      "Epoch 59/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0536 - accuracy: 0.9839 - val_loss: 0.0991 - val_accuracy: 0.9676\n",
      "Epoch 60/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0533 - accuracy: 0.9839 - val_loss: 0.0986 - val_accuracy: 0.9681\n",
      "Epoch 61/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0527 - accuracy: 0.9842 - val_loss: 0.0994 - val_accuracy: 0.9677\n",
      "Epoch 62/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0518 - accuracy: 0.9844 - val_loss: 0.1006 - val_accuracy: 0.9667\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7855855023206528\n",
      "F1 Micro: 0.9697\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 0.2637 - accuracy: 0.9277 - val_loss: 0.1619 - val_accuracy: 0.9511\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.1464 - accuracy: 0.9558 - val_loss: 0.1361 - val_accuracy: 0.9587\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 0.1268 - accuracy: 0.9606 - val_loss: 0.1230 - val_accuracy: 0.9618\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 211us/step - loss: 0.1173 - accuracy: 0.9634 - val_loss: 0.1279 - val_accuracy: 0.9616\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 208us/step - loss: 0.1094 - accuracy: 0.9652 - val_loss: 0.1152 - val_accuracy: 0.9636\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.1041 - accuracy: 0.9674 - val_loss: 0.1075 - val_accuracy: 0.9661\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 9s 219us/step - loss: 0.0989 - accuracy: 0.9692 - val_loss: 0.1064 - val_accuracy: 0.9670\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 0.0941 - accuracy: 0.9703 - val_loss: 0.1106 - val_accuracy: 0.9644\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 9s 215us/step - loss: 0.0897 - accuracy: 0.9714 - val_loss: 0.1124 - val_accuracy: 0.9660\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 9s 215us/step - loss: 0.0845 - accuracy: 0.9733 - val_loss: 0.1025 - val_accuracy: 0.9683\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 210us/step - loss: 0.0798 - accuracy: 0.9741 - val_loss: 0.1068 - val_accuracy: 0.9658\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 210us/step - loss: 0.0750 - accuracy: 0.9754 - val_loss: 0.0988 - val_accuracy: 0.9689\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 0.0697 - accuracy: 0.9773 - val_loss: 0.0995 - val_accuracy: 0.9687\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 208us/step - loss: 0.0636 - accuracy: 0.9793 - val_loss: 0.1014 - val_accuracy: 0.9695\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 0.0566 - accuracy: 0.9815 - val_loss: 0.1066 - val_accuracy: 0.9659\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0490 - accuracy: 0.9837 - val_loss: 0.1034 - val_accuracy: 0.9685\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0425 - accuracy: 0.9865 - val_loss: 0.1150 - val_accuracy: 0.9690\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0356 - accuracy: 0.9893 - val_loss: 0.1185 - val_accuracy: 0.9648\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 210us/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.1307 - val_accuracy: 0.9610\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.1640 - val_accuracy: 0.9673\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 211us/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.1550 - val_accuracy: 0.9693\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.1442 - val_accuracy: 0.9635\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.1634 - val_accuracy: 0.9696\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 0.0110 - accuracy: 0.9975 - val_loss: 0.1663 - val_accuracy: 0.9667\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 211us/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 0.1722 - val_accuracy: 0.9600\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 210us/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.1722 - val_accuracy: 0.9702\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.1707 - val_accuracy: 0.9676\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 211us/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1760 - val_accuracy: 0.9673\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1825 - val_accuracy: 0.9673\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.1936 - val_accuracy: 0.9689\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.1707 - val_accuracy: 0.9692\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.1846 - val_accuracy: 0.9694\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7878453483499906\n",
      "F1 Micro: 0.9701\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.798592736263831\n",
      "F1 Micro: 0.9661\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8119518952438519\n",
      "F1 Micro: 0.9744\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 1 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.2260 - accuracy: 0.9375 - val_loss: 0.1389 - val_accuracy: 0.9569\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 27s 209us/step - loss: 0.1189 - accuracy: 0.9628 - val_loss: 0.1071 - val_accuracy: 0.9648\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.1011 - accuracy: 0.9674 - val_loss: 0.1002 - val_accuracy: 0.9682\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0903 - accuracy: 0.9704 - val_loss: 0.1001 - val_accuracy: 0.9689\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0800 - accuracy: 0.9734 - val_loss: 0.0804 - val_accuracy: 0.9727\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0720 - accuracy: 0.9757 - val_loss: 0.0886 - val_accuracy: 0.9729\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0658 - accuracy: 0.9772 - val_loss: 0.0736 - val_accuracy: 0.9733\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0602 - accuracy: 0.9790 - val_loss: 0.0725 - val_accuracy: 0.9741\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0551 - accuracy: 0.9807 - val_loss: 0.0710 - val_accuracy: 0.9758\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0511 - accuracy: 0.9822 - val_loss: 0.0702 - val_accuracy: 0.9762\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0462 - accuracy: 0.9835 - val_loss: 0.0694 - val_accuracy: 0.9753\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0416 - accuracy: 0.9854 - val_loss: 0.0834 - val_accuracy: 0.9751\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0364 - accuracy: 0.9867 - val_loss: 0.0748 - val_accuracy: 0.9746\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0323 - accuracy: 0.9885 - val_loss: 0.0783 - val_accuracy: 0.9765\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0274 - accuracy: 0.9902 - val_loss: 0.0894 - val_accuracy: 0.9716\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0228 - accuracy: 0.9917 - val_loss: 0.0881 - val_accuracy: 0.9772\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0193 - accuracy: 0.9932 - val_loss: 0.0914 - val_accuracy: 0.9770\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.1042 - val_accuracy: 0.9748\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0984 - val_accuracy: 0.9754\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.1187 - val_accuracy: 0.9751\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 0.1162 - val_accuracy: 0.9760\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.1188 - val_accuracy: 0.9759\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.1238 - val_accuracy: 0.9750\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.1246 - val_accuracy: 0.9760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1427 - val_accuracy: 0.9757\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1330 - val_accuracy: 0.9739\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.1379 - val_accuracy: 0.9743\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.1313 - val_accuracy: 0.9746\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1368 - val_accuracy: 0.9731\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.1314 - val_accuracy: 0.9750\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.1448 - val_accuracy: 0.9719\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.862490720220539\n",
      "F1 Micro: 0.9754\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8299392473583396\n",
      "F1 Micro: 0.9685\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.2455 - accuracy: 0.9376 - val_loss: 0.1266 - val_accuracy: 0.9610\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.1130 - accuracy: 0.9652 - val_loss: 0.1128 - val_accuracy: 0.9645\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.1035 - accuracy: 0.9677 - val_loss: 0.1065 - val_accuracy: 0.9660\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0980 - accuracy: 0.9693 - val_loss: 0.1025 - val_accuracy: 0.9670\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0940 - accuracy: 0.9701 - val_loss: 0.0983 - val_accuracy: 0.9681\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0908 - accuracy: 0.9713 - val_loss: 0.0987 - val_accuracy: 0.9678\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0884 - accuracy: 0.9722 - val_loss: 0.0940 - val_accuracy: 0.9693\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0861 - accuracy: 0.9728 - val_loss: 0.0947 - val_accuracy: 0.9686\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0842 - accuracy: 0.9732 - val_loss: 0.0936 - val_accuracy: 0.9692\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0825 - accuracy: 0.9737 - val_loss: 0.0909 - val_accuracy: 0.9702\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0809 - accuracy: 0.9743 - val_loss: 0.0912 - val_accuracy: 0.9697\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0797 - accuracy: 0.9747 - val_loss: 0.0874 - val_accuracy: 0.9708\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0784 - accuracy: 0.9751 - val_loss: 0.0882 - val_accuracy: 0.9704\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0772 - accuracy: 0.9755 - val_loss: 0.0880 - val_accuracy: 0.9706\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0759 - accuracy: 0.9758 - val_loss: 0.0878 - val_accuracy: 0.9707\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0750 - accuracy: 0.9759 - val_loss: 0.0865 - val_accuracy: 0.9703\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0738 - accuracy: 0.9762 - val_loss: 0.0847 - val_accuracy: 0.9717\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0730 - accuracy: 0.9768 - val_loss: 0.0853 - val_accuracy: 0.9713\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0722 - accuracy: 0.9768 - val_loss: 0.0848 - val_accuracy: 0.9723\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0713 - accuracy: 0.9771 - val_loss: 0.0836 - val_accuracy: 0.9718\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0705 - accuracy: 0.9771 - val_loss: 0.0843 - val_accuracy: 0.9727\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0696 - accuracy: 0.9774 - val_loss: 0.0864 - val_accuracy: 0.9715\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0690 - accuracy: 0.9776 - val_loss: 0.0834 - val_accuracy: 0.9722\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0684 - accuracy: 0.9779 - val_loss: 0.0834 - val_accuracy: 0.9719\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0674 - accuracy: 0.9783 - val_loss: 0.0831 - val_accuracy: 0.9722\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0666 - accuracy: 0.9784 - val_loss: 0.0845 - val_accuracy: 0.9724\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0659 - accuracy: 0.9788 - val_loss: 0.0826 - val_accuracy: 0.9722\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0653 - accuracy: 0.9790 - val_loss: 0.0842 - val_accuracy: 0.9724\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0646 - accuracy: 0.9791 - val_loss: 0.0840 - val_accuracy: 0.9731\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0643 - accuracy: 0.9792 - val_loss: 0.0837 - val_accuracy: 0.9720\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0634 - accuracy: 0.9795 - val_loss: 0.0836 - val_accuracy: 0.9719\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0628 - accuracy: 0.9795 - val_loss: 0.0832 - val_accuracy: 0.9722\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0623 - accuracy: 0.9799 - val_loss: 0.0837 - val_accuracy: 0.9725\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0616 - accuracy: 0.9801 - val_loss: 0.0834 - val_accuracy: 0.9720\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0612 - accuracy: 0.9801 - val_loss: 0.0833 - val_accuracy: 0.9725\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0603 - accuracy: 0.9808 - val_loss: 0.0822 - val_accuracy: 0.9726\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0600 - accuracy: 0.9806 - val_loss: 0.0843 - val_accuracy: 0.9719\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0593 - accuracy: 0.9806 - val_loss: 0.0833 - val_accuracy: 0.9724\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0828 - val_accuracy: 0.9730\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0582 - accuracy: 0.9810 - val_loss: 0.0836 - val_accuracy: 0.9722\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0576 - accuracy: 0.9813 - val_loss: 0.0839 - val_accuracy: 0.9721\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0570 - accuracy: 0.9813 - val_loss: 0.0845 - val_accuracy: 0.9721\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0565 - accuracy: 0.9818 - val_loss: 0.0828 - val_accuracy: 0.9726\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0560 - accuracy: 0.9820 - val_loss: 0.0843 - val_accuracy: 0.9722\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0554 - accuracy: 0.9819 - val_loss: 0.0853 - val_accuracy: 0.9722\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.0838 - val_accuracy: 0.9728\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0544 - accuracy: 0.9823 - val_loss: 0.0823 - val_accuracy: 0.9729\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0540 - accuracy: 0.9823 - val_loss: 0.0843 - val_accuracy: 0.9726\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0532 - accuracy: 0.9827 - val_loss: 0.0849 - val_accuracy: 0.9730\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 0.0869 - val_accuracy: 0.9717\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0524 - accuracy: 0.9832 - val_loss: 0.0887 - val_accuracy: 0.9717\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0517 - accuracy: 0.9832 - val_loss: 0.0848 - val_accuracy: 0.9726\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0512 - accuracy: 0.9832 - val_loss: 0.0857 - val_accuracy: 0.9728\n",
      "Epoch 54/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0505 - accuracy: 0.9838 - val_loss: 0.0856 - val_accuracy: 0.9730\n",
      "Epoch 55/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0502 - accuracy: 0.9836 - val_loss: 0.0855 - val_accuracy: 0.9728\n",
      "Epoch 56/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0496 - accuracy: 0.9840 - val_loss: 0.0855 - val_accuracy: 0.9724\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8476302143567376\n",
      "F1 Micro: 0.9754\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.1714 - accuracy: 0.9501 - val_loss: 0.1219 - val_accuracy: 0.9624\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.1082 - accuracy: 0.9664 - val_loss: 0.1122 - val_accuracy: 0.9637\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0971 - accuracy: 0.9697 - val_loss: 0.0987 - val_accuracy: 0.9686\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 27s 211us/step - loss: 0.0878 - accuracy: 0.9718 - val_loss: 0.0885 - val_accuracy: 0.9707\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0803 - accuracy: 0.9737 - val_loss: 0.0825 - val_accuracy: 0.9726\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0738 - accuracy: 0.9759 - val_loss: 0.0778 - val_accuracy: 0.9737\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0688 - accuracy: 0.9772 - val_loss: 0.0983 - val_accuracy: 0.9661\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0635 - accuracy: 0.9786 - val_loss: 0.0767 - val_accuracy: 0.9739\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0583 - accuracy: 0.9803 - val_loss: 0.0728 - val_accuracy: 0.9752\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0531 - accuracy: 0.9822 - val_loss: 0.0720 - val_accuracy: 0.9761\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 28s 217us/step - loss: 0.0472 - accuracy: 0.9836 - val_loss: 0.0769 - val_accuracy: 0.9763\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 27s 209us/step - loss: 0.0416 - accuracy: 0.9853 - val_loss: 0.0692 - val_accuracy: 0.9771\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0353 - accuracy: 0.9880 - val_loss: 0.0838 - val_accuracy: 0.9757\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0293 - accuracy: 0.9897 - val_loss: 0.0757 - val_accuracy: 0.9773\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0799 - val_accuracy: 0.9755\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.0866 - val_accuracy: 0.9761\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 28s 216us/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.0928 - val_accuracy: 0.9757\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 28s 212us/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.1013 - val_accuracy: 0.9743\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 28s 217us/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.1072 - val_accuracy: 0.9753\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 28s 217us/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1302 - val_accuracy: 0.9756\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 28s 215us/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.1225 - val_accuracy: 0.9753\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 28s 216us/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.1220 - val_accuracy: 0.9759\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1290 - val_accuracy: 0.9758\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.1353 - val_accuracy: 0.9747\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 28s 217us/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.1363 - val_accuracy: 0.9757\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1305 - val_accuracy: 0.9742\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 28s 215us/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.1397 - val_accuracy: 0.9756\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1641 - val_accuracy: 0.9753\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 28s 211us/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1502 - val_accuracy: 0.9732\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 28s 213us/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1506 - val_accuracy: 0.9762\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 28s 215us/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1419 - val_accuracy: 0.9751\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 27s 210us/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1400 - val_accuracy: 0.9742\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.876432904862922\n",
      "F1 Micro: 0.9794\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8321441986808435\n",
      "F1 Micro: 0.9685\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8614884642009851\n",
      "F1 Micro: 0.9783\n",
      "\n",
      "\n",
      " 58.153347563743594 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 2 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 2 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.9030 - accuracy: 0.8400 - val_loss: 1.4951 - val_accuracy: 0.7900\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 1.0898 - accuracy: 0.8475 - val_loss: 1.1349 - val_accuracy: 0.7900\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.8600 - accuracy: 0.8475 - val_loss: 1.0960 - val_accuracy: 0.7900\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.7954 - accuracy: 0.8475 - val_loss: 0.9772 - val_accuracy: 0.7900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 236us/step - loss: 0.7550 - accuracy: 0.8475 - val_loss: 0.9531 - val_accuracy: 0.7900\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.7246 - accuracy: 0.8475 - val_loss: 0.9174 - val_accuracy: 0.7900\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.7032 - accuracy: 0.8475 - val_loss: 0.8892 - val_accuracy: 0.7900\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6910 - accuracy: 0.8475 - val_loss: 0.8676 - val_accuracy: 0.7900\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6783 - accuracy: 0.8475 - val_loss: 0.8607 - val_accuracy: 0.7900\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6734 - accuracy: 0.8475 - val_loss: 0.8555 - val_accuracy: 0.7900\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.6754 - accuracy: 0.8475 - val_loss: 0.8387 - val_accuracy: 0.7900\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6654 - accuracy: 0.8475 - val_loss: 0.8361 - val_accuracy: 0.7900\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6595 - accuracy: 0.8475 - val_loss: 0.8241 - val_accuracy: 0.7900\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6523 - accuracy: 0.8475 - val_loss: 0.8165 - val_accuracy: 0.7900\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.6476 - accuracy: 0.8475 - val_loss: 0.8069 - val_accuracy: 0.7900\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6329 - accuracy: 0.8475 - val_loss: 0.7875 - val_accuracy: 0.7900\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 238us/step - loss: 0.6248 - accuracy: 0.8475 - val_loss: 0.7964 - val_accuracy: 0.7900\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6085 - accuracy: 0.8475 - val_loss: 0.7536 - val_accuracy: 0.7900\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.5908 - accuracy: 0.8475 - val_loss: 0.7178 - val_accuracy: 0.7900\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.5776 - accuracy: 0.8475 - val_loss: 0.6990 - val_accuracy: 0.7900\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.5562 - accuracy: 0.8500 - val_loss: 0.6807 - val_accuracy: 0.7900\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.5528 - accuracy: 0.8450 - val_loss: 0.6725 - val_accuracy: 0.7900\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5260 - accuracy: 0.8500 - val_loss: 0.6498 - val_accuracy: 0.8100\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.5189 - accuracy: 0.8475 - val_loss: 0.6291 - val_accuracy: 0.8100\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.5108 - accuracy: 0.8525 - val_loss: 0.6362 - val_accuracy: 0.8200\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.4864 - accuracy: 0.8575 - val_loss: 0.6092 - val_accuracy: 0.8100\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.4762 - accuracy: 0.8575 - val_loss: 0.6276 - val_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.4533 - accuracy: 0.8675 - val_loss: 0.5875 - val_accuracy: 0.8500\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.4446 - accuracy: 0.8725 - val_loss: 0.6699 - val_accuracy: 0.8200\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.4564 - accuracy: 0.8750 - val_loss: 0.5796 - val_accuracy: 0.8600\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.4335 - accuracy: 0.8750 - val_loss: 0.5524 - val_accuracy: 0.8600\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.4148 - accuracy: 0.8950 - val_loss: 0.5428 - val_accuracy: 0.8700\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.3950 - accuracy: 0.9000 - val_loss: 0.5414 - val_accuracy: 0.8500\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.3881 - accuracy: 0.8875 - val_loss: 0.5593 - val_accuracy: 0.8500\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.3969 - accuracy: 0.8925 - val_loss: 0.5447 - val_accuracy: 0.8800\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.4201 - accuracy: 0.8900 - val_loss: 0.5233 - val_accuracy: 0.8800\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.3615 - accuracy: 0.9050 - val_loss: 0.5178 - val_accuracy: 0.8700\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.3596 - accuracy: 0.9125 - val_loss: 0.5047 - val_accuracy: 0.8700\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3439 - accuracy: 0.9100 - val_loss: 0.5254 - val_accuracy: 0.8600\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3471 - accuracy: 0.9125 - val_loss: 0.4996 - val_accuracy: 0.8600\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3190 - accuracy: 0.9275 - val_loss: 0.4955 - val_accuracy: 0.8600\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3161 - accuracy: 0.9150 - val_loss: 0.5493 - val_accuracy: 0.8500\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3625 - accuracy: 0.9000 - val_loss: 0.4938 - val_accuracy: 0.8500\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.3723 - accuracy: 0.91 - 0s 227us/step - loss: 0.3542 - accuracy: 0.9075 - val_loss: 0.4941 - val_accuracy: 0.8600\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3399 - accuracy: 0.9100 - val_loss: 0.4882 - val_accuracy: 0.8600\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3017 - accuracy: 0.9225 - val_loss: 0.4687 - val_accuracy: 0.8500\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2837 - accuracy: 0.9300 - val_loss: 0.4761 - val_accuracy: 0.8600\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2824 - accuracy: 0.9225 - val_loss: 0.5091 - val_accuracy: 0.8500\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.2844 - accuracy: 0.9275 - val_loss: 0.4719 - val_accuracy: 0.8500\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.2725 - accuracy: 0.9350 - val_loss: 0.4771 - val_accuracy: 0.8500\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2611 - accuracy: 0.9325 - val_loss: 0.4702 - val_accuracy: 0.8500\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2755 - accuracy: 0.9275 - val_loss: 0.4505 - val_accuracy: 0.8500\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2593 - accuracy: 0.9300 - val_loss: 0.6079 - val_accuracy: 0.8400\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2787 - accuracy: 0.9300 - val_loss: 0.5649 - val_accuracy: 0.8400\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2464 - accuracy: 0.9375 - val_loss: 0.4977 - val_accuracy: 0.8500\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2841 - accuracy: 0.9275 - val_loss: 0.6511 - val_accuracy: 0.8300\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2962 - accuracy: 0.9250 - val_loss: 0.6585 - val_accuracy: 0.8400\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2788 - accuracy: 0.9200 - val_loss: 0.6005 - val_accuracy: 0.8400\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2745 - accuracy: 0.9350 - val_loss: 0.4714 - val_accuracy: 0.8500\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2347 - accuracy: 0.9350 - val_loss: 0.4538 - val_accuracy: 0.8600\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2401 - accuracy: 0.9300 - val_loss: 0.4523 - val_accuracy: 0.8800\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2321 - accuracy: 0.9350 - val_loss: 0.4434 - val_accuracy: 0.8500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2269 - accuracy: 0.9350 - val_loss: 0.5034 - val_accuracy: 0.8500\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2420 - accuracy: 0.9300 - val_loss: 0.6354 - val_accuracy: 0.8400\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2756 - accuracy: 0.9300 - val_loss: 0.5496 - val_accuracy: 0.8500\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2248 - accuracy: 0.9325 - val_loss: 0.4379 - val_accuracy: 0.8700\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2142 - accuracy: 0.9375 - val_loss: 0.4588 - val_accuracy: 0.8600\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.2010 - accuracy: 0.9475 - val_loss: 0.4469 - val_accuracy: 0.8600\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2004 - accuracy: 0.9475 - val_loss: 0.4286 - val_accuracy: 0.8700\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1848 - accuracy: 0.9475 - val_loss: 0.4314 - val_accuracy: 0.8700\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1820 - accuracy: 0.9425 - val_loss: 0.4605 - val_accuracy: 0.8700\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2123 - accuracy: 0.9325 - val_loss: 0.4734 - val_accuracy: 0.8500\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2613 - accuracy: 0.9350 - val_loss: 0.4479 - val_accuracy: 0.8700\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1992 - accuracy: 0.9375 - val_loss: 0.4522 - val_accuracy: 0.8600\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1824 - accuracy: 0.9500 - val_loss: 0.4324 - val_accuracy: 0.8700\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1639 - accuracy: 0.9500 - val_loss: 0.4312 - val_accuracy: 0.8500\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1753 - accuracy: 0.9575 - val_loss: 0.4323 - val_accuracy: 0.8800\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1699 - accuracy: 0.9550 - val_loss: 0.5139 - val_accuracy: 0.8500\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1869 - accuracy: 0.9400 - val_loss: 0.4407 - val_accuracy: 0.8500\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1565 - accuracy: 0.9500 - val_loss: 0.4567 - val_accuracy: 0.8700\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1539 - accuracy: 0.9575 - val_loss: 0.4281 - val_accuracy: 0.8600\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1684 - accuracy: 0.9550 - val_loss: 0.4518 - val_accuracy: 0.8500\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1982 - accuracy: 0.9375 - val_loss: 0.5055 - val_accuracy: 0.8500\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.2029 - accuracy: 0.9400 - val_loss: 0.4712 - val_accuracy: 0.8600\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1802 - accuracy: 0.9525 - val_loss: 0.4154 - val_accuracy: 0.8600\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1758 - accuracy: 0.9525 - val_loss: 0.5163 - val_accuracy: 0.8700\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1663 - accuracy: 0.9450 - val_loss: 0.4572 - val_accuracy: 0.8800\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1423 - accuracy: 0.9600 - val_loss: 0.4542 - val_accuracy: 0.8700\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1596 - accuracy: 0.9600 - val_loss: 0.4490 - val_accuracy: 0.8600\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1657 - accuracy: 0.9500 - val_loss: 0.4123 - val_accuracy: 0.8700\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1477 - accuracy: 0.9600 - val_loss: 0.4625 - val_accuracy: 0.8700\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1480 - accuracy: 0.9550 - val_loss: 0.4114 - val_accuracy: 0.9100\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1442 - accuracy: 0.9600 - val_loss: 0.4253 - val_accuracy: 0.8700\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1382 - accuracy: 0.9575 - val_loss: 0.4154 - val_accuracy: 0.8700\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1636 - accuracy: 0.9550 - val_loss: 0.4062 - val_accuracy: 0.8700\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1186 - accuracy: 0.9625 - val_loss: 0.4047 - val_accuracy: 0.8700\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1380 - accuracy: 0.9650 - val_loss: 0.4273 - val_accuracy: 0.8600\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1255 - accuracy: 0.9750 - val_loss: 0.4248 - val_accuracy: 0.8900\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1379 - accuracy: 0.9600 - val_loss: 0.4482 - val_accuracy: 0.8800\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1376 - accuracy: 0.9600 - val_loss: 0.5003 - val_accuracy: 0.8600\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1311 - accuracy: 0.9700 - val_loss: 0.4285 - val_accuracy: 0.8700\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1204 - accuracy: 0.9675 - val_loss: 0.4453 - val_accuracy: 0.8700\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1090 - accuracy: 0.9700 - val_loss: 0.4232 - val_accuracy: 0.8700\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1081 - accuracy: 0.9725 - val_loss: 0.4115 - val_accuracy: 0.8700\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1169 - accuracy: 0.9575 - val_loss: 0.4834 - val_accuracy: 0.8700\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1140 - accuracy: 0.9675 - val_loss: 0.4221 - val_accuracy: 0.8700\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1041 - accuracy: 0.9750 - val_loss: 0.4628 - val_accuracy: 0.8700\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1093 - accuracy: 0.9650 - val_loss: 0.4335 - val_accuracy: 0.8900\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0949 - accuracy: 0.9725 - val_loss: 0.4128 - val_accuracy: 0.8700\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0965 - accuracy: 0.9750 - val_loss: 0.4029 - val_accuracy: 0.8700\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0865 - accuracy: 0.9800 - val_loss: 0.4186 - val_accuracy: 0.8700\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1134 - accuracy: 0.9700 - val_loss: 0.4059 - val_accuracy: 0.8700\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0992 - accuracy: 0.9750 - val_loss: 0.4287 - val_accuracy: 0.8700\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0918 - accuracy: 0.9825 - val_loss: 0.4355 - val_accuracy: 0.8700\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0814 - accuracy: 0.9800 - val_loss: 0.4578 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0826 - accuracy: 0.9750 - val_loss: 0.4222 - val_accuracy: 0.8800\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0793 - accuracy: 0.9800 - val_loss: 0.4049 - val_accuracy: 0.8900\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0755 - accuracy: 0.9825 - val_loss: 0.4336 - val_accuracy: 0.8800\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0858 - accuracy: 0.9775 - val_loss: 0.4287 - val_accuracy: 0.8700\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0722 - accuracy: 0.9800 - val_loss: 0.4314 - val_accuracy: 0.8500\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0840 - accuracy: 0.9725 - val_loss: 0.4652 - val_accuracy: 0.8500\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0909 - accuracy: 0.9725 - val_loss: 0.4897 - val_accuracy: 0.8700\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0857 - accuracy: 0.9775 - val_loss: 0.5470 - val_accuracy: 0.8500\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0747 - accuracy: 0.9875 - val_loss: 0.4449 - val_accuracy: 0.8800\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0684 - accuracy: 0.9800 - val_loss: 0.5386 - val_accuracy: 0.8800\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1134 - accuracy: 0.9675 - val_loss: 0.4680 - val_accuracy: 0.8700\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0866 - accuracy: 0.9775 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0760 - accuracy: 0.9800 - val_loss: 0.4544 - val_accuracy: 0.8700\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0682 - accuracy: 0.9825 - val_loss: 0.4002 - val_accuracy: 0.8900\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.0703 - accuracy: 0.9825 - val_loss: 0.4376 - val_accuracy: 0.8700\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0699 - accuracy: 0.9775 - val_loss: 0.5135 - val_accuracy: 0.8800\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0623 - accuracy: 0.9875 - val_loss: 0.4512 - val_accuracy: 0.8800\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0512 - accuracy: 0.9900 - val_loss: 0.4034 - val_accuracy: 0.8700\n",
      "Epoch 134/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0650 - accuracy: 0.9800 - val_loss: 0.4239 - val_accuracy: 0.8800\n",
      "Epoch 135/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.0537 - accuracy: 0.9875 - val_loss: 0.4302 - val_accuracy: 0.8800\n",
      "Epoch 136/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0605 - accuracy: 0.9850 - val_loss: 0.4199 - val_accuracy: 0.8900\n",
      "Epoch 137/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0644 - accuracy: 0.9850 - val_loss: 0.4075 - val_accuracy: 0.8600\n",
      "Epoch 138/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0493 - accuracy: 0.9875 - val_loss: 0.4416 - val_accuracy: 0.8700\n",
      "Epoch 139/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0528 - accuracy: 0.9875 - val_loss: 0.4299 - val_accuracy: 0.8900\n",
      "Epoch 140/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0529 - accuracy: 0.9900 - val_loss: 0.4549 - val_accuracy: 0.8600\n",
      "Epoch 141/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0571 - accuracy: 0.9875 - val_loss: 0.4244 - val_accuracy: 0.8800\n",
      "Epoch 142/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0429 - accuracy: 0.9850 - val_loss: 0.4159 - val_accuracy: 0.8700\n",
      "Epoch 143/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0485 - accuracy: 0.9875 - val_loss: 0.4307 - val_accuracy: 0.8800\n",
      "Epoch 144/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0424 - accuracy: 0.9900 - val_loss: 0.4203 - val_accuracy: 0.8700\n",
      "Epoch 145/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0407 - accuracy: 0.9900 - val_loss: 0.4348 - val_accuracy: 0.8900\n",
      "Epoch 146/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0371 - accuracy: 0.9900 - val_loss: 0.4607 - val_accuracy: 0.8800\n",
      "Epoch 147/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0418 - accuracy: 0.9900 - val_loss: 0.4608 - val_accuracy: 0.8800\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.4700158633646901\n",
      "F1 Micro: 0.8974038317242761\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5035311469543076\n",
      "F1 Micro: 0.9355209844429995\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 285us/step - loss: 1.9210 - accuracy: 0.4675 - val_loss: 1.8821 - val_accuracy: 0.4600\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 1.7564 - accuracy: 0.5550 - val_loss: 1.7610 - val_accuracy: 0.5200\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.6499 - accuracy: 0.6050 - val_loss: 1.6817 - val_accuracy: 0.5400\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 1.5747 - accuracy: 0.6175 - val_loss: 1.6160 - val_accuracy: 0.5700\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 1.5118 - accuracy: 0.6400 - val_loss: 1.5522 - val_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.4522 - accuracy: 0.6625 - val_loss: 1.4964 - val_accuracy: 0.6200\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.3969 - accuracy: 0.6875 - val_loss: 1.4372 - val_accuracy: 0.6400\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.3414 - accuracy: 0.7000 - val_loss: 1.3818 - val_accuracy: 0.6600\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.2854 - accuracy: 0.7100 - val_loss: 1.3286 - val_accuracy: 0.6800\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.2303 - accuracy: 0.7350 - val_loss: 1.2726 - val_accuracy: 0.7100\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.1741 - accuracy: 0.7500 - val_loss: 1.2174 - val_accuracy: 0.7100\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.1177 - accuracy: 0.7700 - val_loss: 1.1612 - val_accuracy: 0.7100\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.0618 - accuracy: 0.7900 - val_loss: 1.1076 - val_accuracy: 0.7300\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 1.0046 - accuracy: 0.8025 - val_loss: 1.0551 - val_accuracy: 0.7600\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.9501 - accuracy: 0.8175 - val_loss: 1.0012 - val_accuracy: 0.7700\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.8939 - accuracy: 0.8325 - val_loss: 0.9554 - val_accuracy: 0.7700\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.8431 - accuracy: 0.8525 - val_loss: 0.9067 - val_accuracy: 0.8100\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.7890 - accuracy: 0.8725 - val_loss: 0.8667 - val_accuracy: 0.8100\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.7405 - accuracy: 0.8775 - val_loss: 0.8241 - val_accuracy: 0.8200\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.6946 - accuracy: 0.8900 - val_loss: 0.7819 - val_accuracy: 0.8200\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.6523 - accuracy: 0.8975 - val_loss: 0.7450 - val_accuracy: 0.8200\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.6110 - accuracy: 0.9050 - val_loss: 0.7117 - val_accuracy: 0.8300\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.5729 - accuracy: 0.9075 - val_loss: 0.6817 - val_accuracy: 0.8300\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.5362 - accuracy: 0.9100 - val_loss: 0.6527 - val_accuracy: 0.8300\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.5032 - accuracy: 0.9175 - val_loss: 0.6238 - val_accuracy: 0.8500\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.4723 - accuracy: 0.9250 - val_loss: 0.5942 - val_accuracy: 0.8600\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.4418 - accuracy: 0.9325 - val_loss: 0.5695 - val_accuracy: 0.8700\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.4149 - accuracy: 0.9400 - val_loss: 0.5487 - val_accuracy: 0.8700\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.3893 - accuracy: 0.9425 - val_loss: 0.5235 - val_accuracy: 0.8700\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.3676 - accuracy: 0.9425 - val_loss: 0.5011 - val_accuracy: 0.8700\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.3443 - accuracy: 0.9475 - val_loss: 0.4873 - val_accuracy: 0.8700\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.3246 - accuracy: 0.9475 - val_loss: 0.4713 - val_accuracy: 0.8800\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.3065 - accuracy: 0.9475 - val_loss: 0.4505 - val_accuracy: 0.8900\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.2892 - accuracy: 0.9525 - val_loss: 0.4377 - val_accuracy: 0.8900\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2733 - accuracy: 0.9550 - val_loss: 0.4248 - val_accuracy: 0.8900\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2590 - accuracy: 0.9575 - val_loss: 0.4143 - val_accuracy: 0.9000\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2458 - accuracy: 0.9575 - val_loss: 0.4025 - val_accuracy: 0.9000\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2332 - accuracy: 0.9625 - val_loss: 0.3921 - val_accuracy: 0.9100\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2222 - accuracy: 0.9625 - val_loss: 0.3837 - val_accuracy: 0.9100\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.2116 - accuracy: 0.9650 - val_loss: 0.3756 - val_accuracy: 0.9100\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2021 - accuracy: 0.9700 - val_loss: 0.3669 - val_accuracy: 0.9100\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1926 - accuracy: 0.9700 - val_loss: 0.3600 - val_accuracy: 0.9200\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1849 - accuracy: 0.9725 - val_loss: 0.3553 - val_accuracy: 0.9200\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1762 - accuracy: 0.9775 - val_loss: 0.3495 - val_accuracy: 0.9200\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1694 - accuracy: 0.9750 - val_loss: 0.3434 - val_accuracy: 0.9200\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.1626 - accuracy: 0.9775 - val_loss: 0.3389 - val_accuracy: 0.9100\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1561 - accuracy: 0.9825 - val_loss: 0.3352 - val_accuracy: 0.9200\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1503 - accuracy: 0.9825 - val_loss: 0.3320 - val_accuracy: 0.9100\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1444 - accuracy: 0.9825 - val_loss: 0.3284 - val_accuracy: 0.9200\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.1394 - accuracy: 0.9825 - val_loss: 0.3251 - val_accuracy: 0.9200\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.1347 - accuracy: 0.9850 - val_loss: 0.3230 - val_accuracy: 0.9100\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.1298 - accuracy: 0.9850 - val_loss: 0.3208 - val_accuracy: 0.9200\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1254 - accuracy: 0.9850 - val_loss: 0.3184 - val_accuracy: 0.9200\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1213 - accuracy: 0.9850 - val_loss: 0.3168 - val_accuracy: 0.9200\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1176 - accuracy: 0.9875 - val_loss: 0.3142 - val_accuracy: 0.9200\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1142 - accuracy: 0.9875 - val_loss: 0.3130 - val_accuracy: 0.9200\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.1105 - accuracy: 0.9875 - val_loss: 0.3126 - val_accuracy: 0.9200\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1074 - accuracy: 0.9875 - val_loss: 0.3111 - val_accuracy: 0.9200\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.1041 - accuracy: 0.9875 - val_loss: 0.3102 - val_accuracy: 0.9200\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1014 - accuracy: 0.9875 - val_loss: 0.3090 - val_accuracy: 0.9200\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0982 - accuracy: 0.9900 - val_loss: 0.3068 - val_accuracy: 0.9200\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.0954 - accuracy: 0.9900 - val_loss: 0.3065 - val_accuracy: 0.9200\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0929 - accuracy: 0.9925 - val_loss: 0.3056 - val_accuracy: 0.9200\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0904 - accuracy: 0.9925 - val_loss: 0.3045 - val_accuracy: 0.9200\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0879 - accuracy: 0.9925 - val_loss: 0.3044 - val_accuracy: 0.9200\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0856 - accuracy: 0.9925 - val_loss: 0.3027 - val_accuracy: 0.9200\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0834 - accuracy: 0.9925 - val_loss: 0.3023 - val_accuracy: 0.9200\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0816 - accuracy: 0.9925 - val_loss: 0.3019 - val_accuracy: 0.9200\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0792 - accuracy: 0.9925 - val_loss: 0.3019 - val_accuracy: 0.9200\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0773 - accuracy: 0.9925 - val_loss: 0.3036 - val_accuracy: 0.9200\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0755 - accuracy: 0.9925 - val_loss: 0.3029 - val_accuracy: 0.9200\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0738 - accuracy: 0.9925 - val_loss: 0.3024 - val_accuracy: 0.9200\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0719 - accuracy: 0.9925 - val_loss: 0.3017 - val_accuracy: 0.9200\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0704 - accuracy: 0.9925 - val_loss: 0.3030 - val_accuracy: 0.9200\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0686 - accuracy: 0.9950 - val_loss: 0.3041 - val_accuracy: 0.9200\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0674 - accuracy: 0.9950 - val_loss: 0.3035 - val_accuracy: 0.9200\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0655 - accuracy: 0.9950 - val_loss: 0.3034 - val_accuracy: 0.9200\n",
      "Epoch 78/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 82us/step - loss: 0.0643 - accuracy: 0.9950 - val_loss: 0.3033 - val_accuracy: 0.9200\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0629 - accuracy: 0.9950 - val_loss: 0.3029 - val_accuracy: 0.9200\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0614 - accuracy: 0.9950 - val_loss: 0.3031 - val_accuracy: 0.9200\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0602 - accuracy: 0.9950 - val_loss: 0.3022 - val_accuracy: 0.9200\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0589 - accuracy: 0.9950 - val_loss: 0.3027 - val_accuracy: 0.9200\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0576 - accuracy: 0.9950 - val_loss: 0.3032 - val_accuracy: 0.9200\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.0564 - accuracy: 0.9975 - val_loss: 0.3029 - val_accuracy: 0.9200\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0552 - accuracy: 0.9975 - val_loss: 0.3025 - val_accuracy: 0.9200\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0541 - accuracy: 0.9975 - val_loss: 0.3037 - val_accuracy: 0.9200\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0530 - accuracy: 0.9975 - val_loss: 0.3037 - val_accuracy: 0.9200\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0519 - accuracy: 0.9975 - val_loss: 0.3032 - val_accuracy: 0.9200\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0508 - accuracy: 0.9975 - val_loss: 0.3035 - val_accuracy: 0.9200\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0497 - accuracy: 0.9975 - val_loss: 0.3036 - val_accuracy: 0.9200\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0488 - accuracy: 0.9975 - val_loss: 0.3036 - val_accuracy: 0.9200\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9200\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9200\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5629896377792193\n",
      "F1 Micro: 0.9420710355177588\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 763us/step - loss: 1.9334 - accuracy: 0.3625 - val_loss: 1.4896 - val_accuracy: 0.7300\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.8626 - accuracy: 0.8400 - val_loss: 0.8192 - val_accuracy: 0.7900\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 233us/step - loss: 0.5759 - accuracy: 0.8475 - val_loss: 0.7534 - val_accuracy: 0.7900\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.4631 - accuracy: 0.8775 - val_loss: 0.6079 - val_accuracy: 0.8300\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.4162 - accuracy: 0.8900 - val_loss: 0.5759 - val_accuracy: 0.8300\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3856 - accuracy: 0.8925 - val_loss: 0.5527 - val_accuracy: 0.8300\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3611 - accuracy: 0.9075 - val_loss: 0.5261 - val_accuracy: 0.8300\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3423 - accuracy: 0.9175 - val_loss: 0.5107 - val_accuracy: 0.8400\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.3265 - accuracy: 0.9200 - val_loss: 0.5047 - val_accuracy: 0.8300\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.3088 - accuracy: 0.9275 - val_loss: 0.4838 - val_accuracy: 0.8600\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2984 - accuracy: 0.9325 - val_loss: 0.4773 - val_accuracy: 0.8400\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 233us/step - loss: 0.2850 - accuracy: 0.9300 - val_loss: 0.4686 - val_accuracy: 0.8400\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 236us/step - loss: 0.2709 - accuracy: 0.9375 - val_loss: 0.4554 - val_accuracy: 0.8700\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 240us/step - loss: 0.2622 - accuracy: 0.9375 - val_loss: 0.4521 - val_accuracy: 0.8700\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.2514 - accuracy: 0.9400 - val_loss: 0.4442 - val_accuracy: 0.8900\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.2412 - accuracy: 0.9375 - val_loss: 0.4360 - val_accuracy: 0.8900\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 236us/step - loss: 0.2328 - accuracy: 0.9400 - val_loss: 0.4304 - val_accuracy: 0.8900\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.2254 - accuracy: 0.9375 - val_loss: 0.4273 - val_accuracy: 0.8900\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 236us/step - loss: 0.2164 - accuracy: 0.9425 - val_loss: 0.4216 - val_accuracy: 0.8800\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2087 - accuracy: 0.9425 - val_loss: 0.4246 - val_accuracy: 0.8800\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2014 - accuracy: 0.9450 - val_loss: 0.4157 - val_accuracy: 0.8800\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1966 - accuracy: 0.9425 - val_loss: 0.4127 - val_accuracy: 0.8800\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.1897 - accuracy: 0.9475 - val_loss: 0.4086 - val_accuracy: 0.8800\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 235us/step - loss: 0.1837 - accuracy: 0.9500 - val_loss: 0.4160 - val_accuracy: 0.8800\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1779 - accuracy: 0.9475 - val_loss: 0.4045 - val_accuracy: 0.8900\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1731 - accuracy: 0.9500 - val_loss: 0.4050 - val_accuracy: 0.8900\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 235us/step - loss: 0.1684 - accuracy: 0.9525 - val_loss: 0.4024 - val_accuracy: 0.8900\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1644 - accuracy: 0.9600 - val_loss: 0.4081 - val_accuracy: 0.8800\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1609 - accuracy: 0.9475 - val_loss: 0.3954 - val_accuracy: 0.8900\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.1555 - accuracy: 0.9575 - val_loss: 0.4087 - val_accuracy: 0.8900\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.1504 - accuracy: 0.9525 - val_loss: 0.3998 - val_accuracy: 0.8900\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.1453 - accuracy: 0.9575 - val_loss: 0.3964 - val_accuracy: 0.8900\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.1397 - accuracy: 0.9700 - val_loss: 0.4045 - val_accuracy: 0.8900\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1417 - accuracy: 0.9600 - val_loss: 0.3795 - val_accuracy: 0.9000\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.1369 - accuracy: 0.9650 - val_loss: 0.3993 - val_accuracy: 0.8900\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.1287 - accuracy: 0.9700 - val_loss: 0.3837 - val_accuracy: 0.8900\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1269 - accuracy: 0.9675 - val_loss: 0.3899 - val_accuracy: 0.8900\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1219 - accuracy: 0.9700 - val_loss: 0.3932 - val_accuracy: 0.8900\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1190 - accuracy: 0.9725 - val_loss: 0.3917 - val_accuracy: 0.8900\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1166 - accuracy: 0.9675 - val_loss: 0.3809 - val_accuracy: 0.8900\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1152 - accuracy: 0.9675 - val_loss: 0.4044 - val_accuracy: 0.8900\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1113 - accuracy: 0.9675 - val_loss: 0.3818 - val_accuracy: 0.8900\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.1084 - accuracy: 0.9775 - val_loss: 0.4031 - val_accuracy: 0.8800\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1082 - accuracy: 0.9750 - val_loss: 0.3731 - val_accuracy: 0.9200\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1036 - accuracy: 0.9775 - val_loss: 0.4090 - val_accuracy: 0.8800\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1010 - accuracy: 0.9750 - val_loss: 0.3737 - val_accuracy: 0.9100\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0988 - accuracy: 0.9725 - val_loss: 0.3869 - val_accuracy: 0.8900\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0939 - accuracy: 0.9750 - val_loss: 0.3845 - val_accuracy: 0.8900\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0933 - accuracy: 0.9775 - val_loss: 0.3696 - val_accuracy: 0.9100\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0906 - accuracy: 0.9775 - val_loss: 0.3992 - val_accuracy: 0.8900\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0890 - accuracy: 0.9750 - val_loss: 0.3898 - val_accuracy: 0.8900\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0849 - accuracy: 0.9775 - val_loss: 0.3864 - val_accuracy: 0.8900\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0825 - accuracy: 0.9775 - val_loss: 0.3793 - val_accuracy: 0.9000\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0817 - accuracy: 0.9750 - val_loss: 0.3737 - val_accuracy: 0.9100\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0782 - accuracy: 0.9825 - val_loss: 0.3845 - val_accuracy: 0.8900\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0772 - accuracy: 0.9825 - val_loss: 0.4005 - val_accuracy: 0.8900\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0748 - accuracy: 0.9775 - val_loss: 0.3661 - val_accuracy: 0.9200\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.0738 - accuracy: 0.9825 - val_loss: 0.3844 - val_accuracy: 0.9000\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0701 - accuracy: 0.9900 - val_loss: 0.3933 - val_accuracy: 0.8900\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0753 - accuracy: 0.9750 - val_loss: 0.3602 - val_accuracy: 0.9200\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0697 - accuracy: 0.9800 - val_loss: 0.3763 - val_accuracy: 0.9100\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0646 - accuracy: 0.9900 - val_loss: 0.3742 - val_accuracy: 0.9100\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0621 - accuracy: 0.9900 - val_loss: 0.3823 - val_accuracy: 0.9000\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0601 - accuracy: 0.9875 - val_loss: 0.3793 - val_accuracy: 0.9000\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 235us/step - loss: 0.0603 - accuracy: 0.9900 - val_loss: 0.3633 - val_accuracy: 0.9200\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0582 - accuracy: 0.9850 - val_loss: 0.4068 - val_accuracy: 0.8900\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0564 - accuracy: 0.9900 - val_loss: 0.3652 - val_accuracy: 0.9100\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0560 - accuracy: 0.9875 - val_loss: 0.3644 - val_accuracy: 0.9100\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0533 - accuracy: 0.9900 - val_loss: 0.3645 - val_accuracy: 0.9100\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0506 - accuracy: 0.9875 - val_loss: 0.3793 - val_accuracy: 0.9000\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0480 - accuracy: 0.9900 - val_loss: 0.3908 - val_accuracy: 0.8900\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0476 - accuracy: 0.9900 - val_loss: 0.3756 - val_accuracy: 0.9100\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0446 - accuracy: 0.9900 - val_loss: 0.4099 - val_accuracy: 0.8900\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.98 - 0s 224us/step - loss: 0.0462 - accuracy: 0.9900 - val_loss: 0.3546 - val_accuracy: 0.9200\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0459 - accuracy: 0.9900 - val_loss: 0.3975 - val_accuracy: 0.8900\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0472 - accuracy: 0.9925 - val_loss: 0.3788 - val_accuracy: 0.9100\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0416 - accuracy: 0.9925 - val_loss: 0.3903 - val_accuracy: 0.9000\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0397 - accuracy: 0.9925 - val_loss: 0.3899 - val_accuracy: 0.9000\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0373 - accuracy: 0.9950 - val_loss: 0.3677 - val_accuracy: 0.9100\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.0361 - accuracy: 0.9975 - val_loss: 0.4075 - val_accuracy: 0.8900\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0356 - accuracy: 0.9975 - val_loss: 0.3702 - val_accuracy: 0.9100\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9100\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9100\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0315 - accuracy: 0.9975 - val_loss: 0.3802 - val_accuracy: 0.9100\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9100\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.8900\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.9100\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.9100\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 233us/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.9100\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.9100\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.9100\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9000\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9000\n",
      "Epoch 94/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 229us/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9100\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5307489729699173\n",
      "F1 Micro: 0.9354209394227402\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5181284377944733\n",
      "F1 Micro: 0.9361212545645541\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5491677734503746\n",
      "F1 Micro: 0.9408233705167325\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 2 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 262us/step - loss: 0.8946 - accuracy: 0.8390 - val_loss: 0.6158 - val_accuracy: 0.8590\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.6497 - accuracy: 0.8453 - val_loss: 0.5438 - val_accuracy: 0.8590\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.5500 - accuracy: 0.8480 - val_loss: 0.4463 - val_accuracy: 0.8880\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.4400 - accuracy: 0.8873 - val_loss: 0.3608 - val_accuracy: 0.9070\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.3759 - accuracy: 0.9062 - val_loss: 0.3019 - val_accuracy: 0.9280\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.3340 - accuracy: 0.9130 - val_loss: 0.3022 - val_accuracy: 0.9220\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.3249 - accuracy: 0.9168 - val_loss: 0.2591 - val_accuracy: 0.9300\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.2964 - accuracy: 0.9202 - val_loss: 0.2667 - val_accuracy: 0.9270\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.2646 - accuracy: 0.9247 - val_loss: 0.2286 - val_accuracy: 0.9380\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.2661 - accuracy: 0.9295 - val_loss: 0.2280 - val_accuracy: 0.9360\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.2384 - accuracy: 0.9348 - val_loss: 0.1945 - val_accuracy: 0.9440\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.2217 - accuracy: 0.9392 - val_loss: 0.2239 - val_accuracy: 0.9350\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.2102 - accuracy: 0.9383 - val_loss: 0.1801 - val_accuracy: 0.9470\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1940 - accuracy: 0.9460 - val_loss: 0.1754 - val_accuracy: 0.9450\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1923 - accuracy: 0.9440 - val_loss: 0.1748 - val_accuracy: 0.9480\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1741 - accuracy: 0.9513 - val_loss: 0.1624 - val_accuracy: 0.9480\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.1673 - accuracy: 0.9507 - val_loss: 0.1815 - val_accuracy: 0.9430\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1568 - accuracy: 0.9523 - val_loss: 0.1389 - val_accuracy: 0.9570\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1512 - accuracy: 0.9538 - val_loss: 0.1481 - val_accuracy: 0.9510\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1454 - accuracy: 0.9557 - val_loss: 0.1420 - val_accuracy: 0.9540\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1432 - accuracy: 0.9578 - val_loss: 0.1594 - val_accuracy: 0.9560\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.1419 - accuracy: 0.9563 - val_loss: 0.1399 - val_accuracy: 0.9510\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.1352 - accuracy: 0.9610 - val_loss: 0.2358 - val_accuracy: 0.9300\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1318 - accuracy: 0.9592 - val_loss: 0.1432 - val_accuracy: 0.9520\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1163 - accuracy: 0.9655 - val_loss: 0.1420 - val_accuracy: 0.9490\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1149 - accuracy: 0.9647 - val_loss: 0.1438 - val_accuracy: 0.9530\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.1098 - accuracy: 0.9638 - val_loss: 0.1247 - val_accuracy: 0.9570\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1206 - accuracy: 0.9625 - val_loss: 0.1423 - val_accuracy: 0.9550\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1009 - accuracy: 0.9700 - val_loss: 0.1387 - val_accuracy: 0.9590\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1029 - accuracy: 0.9670 - val_loss: 0.1467 - val_accuracy: 0.9590\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0947 - accuracy: 0.9707 - val_loss: 0.1258 - val_accuracy: 0.9540\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0950 - accuracy: 0.9705 - val_loss: 0.1320 - val_accuracy: 0.9550\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0833 - accuracy: 0.9725 - val_loss: 0.1268 - val_accuracy: 0.9600\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0889 - accuracy: 0.9707 - val_loss: 0.1331 - val_accuracy: 0.9560\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0826 - accuracy: 0.9718 - val_loss: 0.1332 - val_accuracy: 0.9550\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0748 - accuracy: 0.9765 - val_loss: 0.1328 - val_accuracy: 0.9580\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0767 - accuracy: 0.9737 - val_loss: 0.1392 - val_accuracy: 0.9550\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0718 - accuracy: 0.9785 - val_loss: 0.1367 - val_accuracy: 0.9600\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0642 - accuracy: 0.9787 - val_loss: 0.1387 - val_accuracy: 0.9600\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0649 - accuracy: 0.9803 - val_loss: 0.1720 - val_accuracy: 0.9500\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0615 - accuracy: 0.9795 - val_loss: 0.1496 - val_accuracy: 0.9570\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0558 - accuracy: 0.9818 - val_loss: 0.1411 - val_accuracy: 0.9610\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0520 - accuracy: 0.9812 - val_loss: 0.1604 - val_accuracy: 0.9500\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0718 - accuracy: 0.9747 - val_loss: 0.1316 - val_accuracy: 0.9620\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0473 - accuracy: 0.9840 - val_loss: 0.1578 - val_accuracy: 0.9530\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0462 - accuracy: 0.9845 - val_loss: 0.1409 - val_accuracy: 0.9600\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0384 - accuracy: 0.9883 - val_loss: 0.1581 - val_accuracy: 0.9580\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5756163349763255\n",
      "F1 Micro: 0.9567\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7455358702675441\n",
      "F1 Micro: 0.958\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 89us/step - loss: 1.6652 - accuracy: 0.5715 - val_loss: 1.3363 - val_accuracy: 0.6830\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 1.0161 - accuracy: 0.7980 - val_loss: 0.7769 - val_accuracy: 0.8710\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.5809 - accuracy: 0.9025 - val_loss: 0.4706 - val_accuracy: 0.9220\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.3672 - accuracy: 0.9333 - val_loss: 0.3269 - val_accuracy: 0.9340\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.2685 - accuracy: 0.9452 - val_loss: 0.2577 - val_accuracy: 0.9470\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.2181 - accuracy: 0.9510 - val_loss: 0.2225 - val_accuracy: 0.9500\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1892 - accuracy: 0.9555 - val_loss: 0.2037 - val_accuracy: 0.9490\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1714 - accuracy: 0.9567 - val_loss: 0.1907 - val_accuracy: 0.9510\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1592 - accuracy: 0.9572 - val_loss: 0.1830 - val_accuracy: 0.9510\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1502 - accuracy: 0.9572 - val_loss: 0.1764 - val_accuracy: 0.9530\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1427 - accuracy: 0.9585 - val_loss: 0.1721 - val_accuracy: 0.9530\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1366 - accuracy: 0.9605 - val_loss: 0.1697 - val_accuracy: 0.9540\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.1307 - accuracy: 0.9600 - val_loss: 0.1645 - val_accuracy: 0.9570\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.1271 - accuracy: 0.9620 - val_loss: 0.1630 - val_accuracy: 0.9560\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.1227 - accuracy: 0.9615 - val_loss: 0.1624 - val_accuracy: 0.9570\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1199 - accuracy: 0.9638 - val_loss: 0.1596 - val_accuracy: 0.9570\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1161 - accuracy: 0.9645 - val_loss: 0.1584 - val_accuracy: 0.9580\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1131 - accuracy: 0.9650 - val_loss: 0.1557 - val_accuracy: 0.9580\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.1104 - accuracy: 0.9657 - val_loss: 0.1564 - val_accuracy: 0.9580\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1075 - accuracy: 0.9675 - val_loss: 0.1537 - val_accuracy: 0.9570\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.1054 - accuracy: 0.9682 - val_loss: 0.1552 - val_accuracy: 0.9570\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.1027 - accuracy: 0.9693 - val_loss: 0.1532 - val_accuracy: 0.9570\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1004 - accuracy: 0.9693 - val_loss: 0.1516 - val_accuracy: 0.9590\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0986 - accuracy: 0.9700 - val_loss: 0.1519 - val_accuracy: 0.9570\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0966 - accuracy: 0.9707 - val_loss: 0.1508 - val_accuracy: 0.9580\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0950 - accuracy: 0.9715 - val_loss: 0.1497 - val_accuracy: 0.9560\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0927 - accuracy: 0.9725 - val_loss: 0.1510 - val_accuracy: 0.9590\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0913 - accuracy: 0.9720 - val_loss: 0.1497 - val_accuracy: 0.9550\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0896 - accuracy: 0.9728 - val_loss: 0.1512 - val_accuracy: 0.9580\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0889 - accuracy: 0.9730 - val_loss: 0.1481 - val_accuracy: 0.9590\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0861 - accuracy: 0.9760 - val_loss: 0.1520 - val_accuracy: 0.9590\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0853 - accuracy: 0.9743 - val_loss: 0.1482 - val_accuracy: 0.9590\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0830 - accuracy: 0.9755 - val_loss: 0.1525 - val_accuracy: 0.9580\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0828 - accuracy: 0.9760 - val_loss: 0.1462 - val_accuracy: 0.9590\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0812 - accuracy: 0.9760 - val_loss: 0.1473 - val_accuracy: 0.9570\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0795 - accuracy: 0.9778 - val_loss: 0.1468 - val_accuracy: 0.9590\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0779 - accuracy: 0.9762 - val_loss: 0.1471 - val_accuracy: 0.9590\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0769 - accuracy: 0.9780 - val_loss: 0.1486 - val_accuracy: 0.9590\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0757 - accuracy: 0.9780 - val_loss: 0.1514 - val_accuracy: 0.9570\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0749 - accuracy: 0.9783 - val_loss: 0.1462 - val_accuracy: 0.9590\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0739 - accuracy: 0.9787 - val_loss: 0.1486 - val_accuracy: 0.9590\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0727 - accuracy: 0.9790 - val_loss: 0.1472 - val_accuracy: 0.9590\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0713 - accuracy: 0.9795 - val_loss: 0.1508 - val_accuracy: 0.9590\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0704 - accuracy: 0.9795 - val_loss: 0.1461 - val_accuracy: 0.9600\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0693 - accuracy: 0.9808 - val_loss: 0.1459 - val_accuracy: 0.9590\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0683 - accuracy: 0.9815 - val_loss: 0.1472 - val_accuracy: 0.9600\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0679 - accuracy: 0.9805 - val_loss: 0.1455 - val_accuracy: 0.9600\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0668 - accuracy: 0.9812 - val_loss: 0.1453 - val_accuracy: 0.9600\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.1446 - val_accuracy: 0.9600\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0644 - accuracy: 0.9810 - val_loss: 0.1453 - val_accuracy: 0.9590\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0641 - accuracy: 0.9830 - val_loss: 0.1449 - val_accuracy: 0.9600\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0628 - accuracy: 0.9818 - val_loss: 0.1456 - val_accuracy: 0.9590\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0620 - accuracy: 0.9833 - val_loss: 0.1454 - val_accuracy: 0.9610\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0606 - accuracy: 0.9827 - val_loss: 0.1447 - val_accuracy: 0.9600\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0598 - accuracy: 0.9847 - val_loss: 0.1475 - val_accuracy: 0.9590\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0595 - accuracy: 0.9858 - val_loss: 0.1467 - val_accuracy: 0.9600\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0583 - accuracy: 0.9852 - val_loss: 0.1456 - val_accuracy: 0.9610\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0573 - accuracy: 0.9845 - val_loss: 0.1449 - val_accuracy: 0.9600\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0568 - accuracy: 0.9860 - val_loss: 0.1444 - val_accuracy: 0.9600\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0561 - accuracy: 0.9852 - val_loss: 0.1453 - val_accuracy: 0.9610\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0553 - accuracy: 0.9862 - val_loss: 0.1482 - val_accuracy: 0.9580\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0544 - accuracy: 0.9875 - val_loss: 0.1472 - val_accuracy: 0.9600\n",
      "Epoch 63/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0537 - accuracy: 0.9872 - val_loss: 0.1453 - val_accuracy: 0.9600\n",
      "Epoch 64/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0531 - accuracy: 0.9860 - val_loss: 0.1467 - val_accuracy: 0.9590\n",
      "Epoch 65/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0521 - accuracy: 0.9885 - val_loss: 0.1469 - val_accuracy: 0.9610\n",
      "Epoch 66/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0513 - accuracy: 0.9885 - val_loss: 0.1484 - val_accuracy: 0.9600\n",
      "Epoch 67/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0508 - accuracy: 0.9885 - val_loss: 0.1448 - val_accuracy: 0.9610\n",
      "Epoch 68/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0500 - accuracy: 0.9877 - val_loss: 0.1471 - val_accuracy: 0.9580\n",
      "Epoch 69/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0494 - accuracy: 0.9885 - val_loss: 0.1493 - val_accuracy: 0.9580\n",
      "Epoch 70/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0493 - accuracy: 0.9880 - val_loss: 0.1477 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0480 - accuracy: 0.9890 - val_loss: 0.1523 - val_accuracy: 0.9600\n",
      "Epoch 72/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0474 - accuracy: 0.9890 - val_loss: 0.1465 - val_accuracy: 0.9620\n",
      "Epoch 73/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0465 - accuracy: 0.9885 - val_loss: 0.1473 - val_accuracy: 0.9620\n",
      "Epoch 74/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0459 - accuracy: 0.9895 - val_loss: 0.1497 - val_accuracy: 0.9590\n",
      "Epoch 75/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0450 - accuracy: 0.9900 - val_loss: 0.1464 - val_accuracy: 0.9620\n",
      "Epoch 76/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0448 - accuracy: 0.9890 - val_loss: 0.1489 - val_accuracy: 0.9590\n",
      "Epoch 77/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0442 - accuracy: 0.9905 - val_loss: 0.1484 - val_accuracy: 0.9590\n",
      "Epoch 78/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0433 - accuracy: 0.9905 - val_loss: 0.1510 - val_accuracy: 0.9580\n",
      "Epoch 79/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0423 - accuracy: 0.9900 - val_loss: 0.1470 - val_accuracy: 0.9610\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6396664868953947\n",
      "F1 Micro: 0.9579000000000001\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 263us/step - loss: 0.7104 - accuracy: 0.8127 - val_loss: 0.3351 - val_accuracy: 0.9180\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.3286 - accuracy: 0.9137 - val_loss: 0.2746 - val_accuracy: 0.9360\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.2704 - accuracy: 0.9320 - val_loss: 0.2416 - val_accuracy: 0.9410\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.2350 - accuracy: 0.9388 - val_loss: 0.2451 - val_accuracy: 0.9410\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 212us/step - loss: 0.2090 - accuracy: 0.9420 - val_loss: 0.1980 - val_accuracy: 0.9490\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 214us/step - loss: 0.1900 - accuracy: 0.9463 - val_loss: 0.2029 - val_accuracy: 0.9470\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 217us/step - loss: 0.1761 - accuracy: 0.9485 - val_loss: 0.1833 - val_accuracy: 0.9490\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 218us/step - loss: 0.1660 - accuracy: 0.9495 - val_loss: 0.1752 - val_accuracy: 0.9480\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.1550 - accuracy: 0.9513 - val_loss: 0.1715 - val_accuracy: 0.9500\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.1474 - accuracy: 0.9550 - val_loss: 0.1648 - val_accuracy: 0.9480\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.1398 - accuracy: 0.9565 - val_loss: 0.1725 - val_accuracy: 0.9490\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1361 - accuracy: 0.9555 - val_loss: 0.1636 - val_accuracy: 0.9520\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.1290 - accuracy: 0.9588 - val_loss: 0.1554 - val_accuracy: 0.9510\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.1236 - accuracy: 0.9610 - val_loss: 0.1533 - val_accuracy: 0.9530\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1220 - accuracy: 0.9613 - val_loss: 0.1528 - val_accuracy: 0.9520\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1168 - accuracy: 0.9643 - val_loss: 0.1496 - val_accuracy: 0.9540\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.1138 - accuracy: 0.9657 - val_loss: 0.1595 - val_accuracy: 0.9510\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.1112 - accuracy: 0.9647 - val_loss: 0.1517 - val_accuracy: 0.9510\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.1060 - accuracy: 0.9675 - val_loss: 0.1489 - val_accuracy: 0.9540\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.1030 - accuracy: 0.9678 - val_loss: 0.1591 - val_accuracy: 0.9500\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0988 - accuracy: 0.9675 - val_loss: 0.1480 - val_accuracy: 0.9520\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.0968 - accuracy: 0.9690 - val_loss: 0.1412 - val_accuracy: 0.9540\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0911 - accuracy: 0.9697 - val_loss: 0.1534 - val_accuracy: 0.9550\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0900 - accuracy: 0.9700 - val_loss: 0.1481 - val_accuracy: 0.9550\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.0852 - accuracy: 0.9705 - val_loss: 0.1429 - val_accuracy: 0.9540\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.0807 - accuracy: 0.9730 - val_loss: 0.1464 - val_accuracy: 0.9540\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0782 - accuracy: 0.9745 - val_loss: 0.1448 - val_accuracy: 0.9520\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0757 - accuracy: 0.9747 - val_loss: 0.1409 - val_accuracy: 0.9610\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0702 - accuracy: 0.9765 - val_loss: 0.1468 - val_accuracy: 0.9540\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0653 - accuracy: 0.9795 - val_loss: 0.1396 - val_accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 214us/step - loss: 0.0636 - accuracy: 0.9790 - val_loss: 0.1737 - val_accuracy: 0.9460\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 215us/step - loss: 0.0633 - accuracy: 0.9812 - val_loss: 0.1484 - val_accuracy: 0.9540\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 217us/step - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.1428 - val_accuracy: 0.9590\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0540 - accuracy: 0.9837 - val_loss: 0.1505 - val_accuracy: 0.9580\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0496 - accuracy: 0.9872 - val_loss: 0.1587 - val_accuracy: 0.9480\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0438 - accuracy: 0.9880 - val_loss: 0.1526 - val_accuracy: 0.9540\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0404 - accuracy: 0.9900 - val_loss: 0.1464 - val_accuracy: 0.9550\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0404 - accuracy: 0.9883 - val_loss: 0.1672 - val_accuracy: 0.9560\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.0350 - accuracy: 0.9902 - val_loss: 0.1527 - val_accuracy: 0.9570\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0284 - accuracy: 0.9940 - val_loss: 0.1715 - val_accuracy: 0.9460\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0272 - accuracy: 0.9942 - val_loss: 0.1559 - val_accuracy: 0.9570\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0237 - accuracy: 0.9948 - val_loss: 0.1599 - val_accuracy: 0.9570\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0222 - accuracy: 0.9960 - val_loss: 0.1616 - val_accuracy: 0.9560\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0195 - accuracy: 0.9970 - val_loss: 0.1698 - val_accuracy: 0.9570\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.0184 - accuracy: 0.9970 - val_loss: 0.1618 - val_accuracy: 0.9550\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0157 - accuracy: 0.9973 - val_loss: 0.1747 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 212us/step - loss: 0.0135 - accuracy: 0.9990 - val_loss: 0.1699 - val_accuracy: 0.9560\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 213us/step - loss: 0.0124 - accuracy: 0.9985 - val_loss: 0.1720 - val_accuracy: 0.9530\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 218us/step - loss: 0.0116 - accuracy: 0.9992 - val_loss: 0.1742 - val_accuracy: 0.9580\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 218us/step - loss: 0.0092 - accuracy: 0.9998 - val_loss: 0.1743 - val_accuracy: 0.9550\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6455291486338213\n",
      "F1 Micro: 0.9599\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.751630988320221\n",
      "F1 Micro: 0.9568\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6874038081995384\n",
      "F1 Micro: 0.9593\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 2 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.4105 - accuracy: 0.8999 - val_loss: 0.2024 - val_accuracy: 0.9426\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.1771 - accuracy: 0.9477 - val_loss: 0.1463 - val_accuracy: 0.9555\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.1392 - accuracy: 0.9576 - val_loss: 0.1244 - val_accuracy: 0.9621\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.1256 - accuracy: 0.9610 - val_loss: 0.1275 - val_accuracy: 0.9612\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.1144 - accuracy: 0.9636 - val_loss: 0.1169 - val_accuracy: 0.9629\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.1064 - accuracy: 0.9661 - val_loss: 0.1033 - val_accuracy: 0.9669\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.1004 - accuracy: 0.9678 - val_loss: 0.1072 - val_accuracy: 0.9667\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0953 - accuracy: 0.9689 - val_loss: 0.0951 - val_accuracy: 0.9702\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0903 - accuracy: 0.9710 - val_loss: 0.0925 - val_accuracy: 0.9693\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0856 - accuracy: 0.9723 - val_loss: 0.0909 - val_accuracy: 0.9712\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0799 - accuracy: 0.9741 - val_loss: 0.0918 - val_accuracy: 0.9708\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0756 - accuracy: 0.9756 - val_loss: 0.0880 - val_accuracy: 0.9697\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0717 - accuracy: 0.9761 - val_loss: 0.1026 - val_accuracy: 0.9666\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0692 - accuracy: 0.9764 - val_loss: 0.0977 - val_accuracy: 0.9657\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0646 - accuracy: 0.9780 - val_loss: 0.0877 - val_accuracy: 0.9704\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0596 - accuracy: 0.9797 - val_loss: 0.0866 - val_accuracy: 0.9718\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0564 - accuracy: 0.9805 - val_loss: 0.0951 - val_accuracy: 0.9696\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0522 - accuracy: 0.9821 - val_loss: 0.0958 - val_accuracy: 0.9673\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0488 - accuracy: 0.9830 - val_loss: 0.1038 - val_accuracy: 0.9693\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0441 - accuracy: 0.9851 - val_loss: 0.0892 - val_accuracy: 0.9723\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0399 - accuracy: 0.9865 - val_loss: 0.0867 - val_accuracy: 0.9735\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0368 - accuracy: 0.9872 - val_loss: 0.0888 - val_accuracy: 0.9735\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0318 - accuracy: 0.9892 - val_loss: 0.1078 - val_accuracy: 0.9667\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0278 - accuracy: 0.9901 - val_loss: 0.0963 - val_accuracy: 0.9728\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.1002 - val_accuracy: 0.9729\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.1166 - val_accuracy: 0.9687\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.1016 - val_accuracy: 0.9750\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.1165 - val_accuracy: 0.9716\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.1044 - val_accuracy: 0.9724\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.1454 - val_accuracy: 0.9674\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.1278 - val_accuracy: 0.9711\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.1196 - val_accuracy: 0.9720\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.1240 - val_accuracy: 0.9723\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.1312 - val_accuracy: 0.9744\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1399 - val_accuracy: 0.9669\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.1323 - val_accuracy: 0.9743\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8249339610963689\n",
      "F1 Micro: 0.9703\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7939475438648189\n",
      "F1 Micro: 0.9669\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.5127 - accuracy: 0.8827 - val_loss: 0.1563 - val_accuracy: 0.9568\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1418 - accuracy: 0.9589 - val_loss: 0.1314 - val_accuracy: 0.9606\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1247 - accuracy: 0.9627 - val_loss: 0.1215 - val_accuracy: 0.9621\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1160 - accuracy: 0.9647 - val_loss: 0.1162 - val_accuracy: 0.9630\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1107 - accuracy: 0.9661 - val_loss: 0.1146 - val_accuracy: 0.9631\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1059 - accuracy: 0.9675 - val_loss: 0.1104 - val_accuracy: 0.9641\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1028 - accuracy: 0.9683 - val_loss: 0.1106 - val_accuracy: 0.9647\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0995 - accuracy: 0.9689 - val_loss: 0.1096 - val_accuracy: 0.9659\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0970 - accuracy: 0.9696 - val_loss: 0.1063 - val_accuracy: 0.9662\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0950 - accuracy: 0.9708 - val_loss: 0.1055 - val_accuracy: 0.9659\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0930 - accuracy: 0.9712 - val_loss: 0.1049 - val_accuracy: 0.9668\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0909 - accuracy: 0.9713 - val_loss: 0.1049 - val_accuracy: 0.9658\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0895 - accuracy: 0.9722 - val_loss: 0.1037 - val_accuracy: 0.9661\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0879 - accuracy: 0.9726 - val_loss: 0.1016 - val_accuracy: 0.9675\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0861 - accuracy: 0.9737 - val_loss: 0.1017 - val_accuracy: 0.9661\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0848 - accuracy: 0.9738 - val_loss: 0.1017 - val_accuracy: 0.9673\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0835 - accuracy: 0.9740 - val_loss: 0.1014 - val_accuracy: 0.9676\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0823 - accuracy: 0.9749 - val_loss: 0.1003 - val_accuracy: 0.9668\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0812 - accuracy: 0.9751 - val_loss: 0.1012 - val_accuracy: 0.9671\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0800 - accuracy: 0.9757 - val_loss: 0.0994 - val_accuracy: 0.9684\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0793 - accuracy: 0.9753 - val_loss: 0.0994 - val_accuracy: 0.9673\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0777 - accuracy: 0.9766 - val_loss: 0.0997 - val_accuracy: 0.9667\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0769 - accuracy: 0.9764 - val_loss: 0.1004 - val_accuracy: 0.9674\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0762 - accuracy: 0.9766 - val_loss: 0.0987 - val_accuracy: 0.9685\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0752 - accuracy: 0.9770 - val_loss: 0.0978 - val_accuracy: 0.9683\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0743 - accuracy: 0.9773 - val_loss: 0.0988 - val_accuracy: 0.9683\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0728 - accuracy: 0.9779 - val_loss: 0.0987 - val_accuracy: 0.9675\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0725 - accuracy: 0.9784 - val_loss: 0.0980 - val_accuracy: 0.9682\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0716 - accuracy: 0.9782 - val_loss: 0.0967 - val_accuracy: 0.9686\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0706 - accuracy: 0.9789 - val_loss: 0.0973 - val_accuracy: 0.9684\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0697 - accuracy: 0.9789 - val_loss: 0.0986 - val_accuracy: 0.9676\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0690 - accuracy: 0.9791 - val_loss: 0.0968 - val_accuracy: 0.9680\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0685 - accuracy: 0.9789 - val_loss: 0.0967 - val_accuracy: 0.9683\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0672 - accuracy: 0.9798 - val_loss: 0.0970 - val_accuracy: 0.9688\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0668 - accuracy: 0.9798 - val_loss: 0.0971 - val_accuracy: 0.9687\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0658 - accuracy: 0.9801 - val_loss: 0.0963 - val_accuracy: 0.9676\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0652 - accuracy: 0.9803 - val_loss: 0.0968 - val_accuracy: 0.9681\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0642 - accuracy: 0.9808 - val_loss: 0.0979 - val_accuracy: 0.9679\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0638 - accuracy: 0.9811 - val_loss: 0.0969 - val_accuracy: 0.9682\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0631 - accuracy: 0.9811 - val_loss: 0.0964 - val_accuracy: 0.9692\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0623 - accuracy: 0.9818 - val_loss: 0.0979 - val_accuracy: 0.9681\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0615 - accuracy: 0.9816 - val_loss: 0.0969 - val_accuracy: 0.9694\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 67us/step - loss: 0.0610 - accuracy: 0.9819 - val_loss: 0.0957 - val_accuracy: 0.9693\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0600 - accuracy: 0.9819 - val_loss: 0.0963 - val_accuracy: 0.9682\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0593 - accuracy: 0.9816 - val_loss: 0.0981 - val_accuracy: 0.9676\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0588 - accuracy: 0.9823 - val_loss: 0.0998 - val_accuracy: 0.9683\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0581 - accuracy: 0.9826 - val_loss: 0.0965 - val_accuracy: 0.9678\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0572 - accuracy: 0.9833 - val_loss: 0.0985 - val_accuracy: 0.9696\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0569 - accuracy: 0.9829 - val_loss: 0.0966 - val_accuracy: 0.9680\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0564 - accuracy: 0.9834 - val_loss: 0.0963 - val_accuracy: 0.9690\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0557 - accuracy: 0.9836 - val_loss: 0.0964 - val_accuracy: 0.9688\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0547 - accuracy: 0.9834 - val_loss: 0.0976 - val_accuracy: 0.9680\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0544 - accuracy: 0.9837 - val_loss: 0.0963 - val_accuracy: 0.9688\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0538 - accuracy: 0.9840 - val_loss: 0.0978 - val_accuracy: 0.9688\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0531 - accuracy: 0.9843 - val_loss: 0.0976 - val_accuracy: 0.9685\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0524 - accuracy: 0.9848 - val_loss: 0.0975 - val_accuracy: 0.9678\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0517 - accuracy: 0.9847 - val_loss: 0.0978 - val_accuracy: 0.9690\n",
      "Epoch 58/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0511 - accuracy: 0.9850 - val_loss: 0.0973 - val_accuracy: 0.9683\n",
      "Epoch 59/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0504 - accuracy: 0.9850 - val_loss: 0.0974 - val_accuracy: 0.9694\n",
      "Epoch 60/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0499 - accuracy: 0.9858 - val_loss: 0.0982 - val_accuracy: 0.9686\n",
      "Epoch 61/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0496 - accuracy: 0.9851 - val_loss: 0.0988 - val_accuracy: 0.9694\n",
      "Epoch 62/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0488 - accuracy: 0.9853 - val_loss: 0.0988 - val_accuracy: 0.9681\n",
      "Epoch 63/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0482 - accuracy: 0.9858 - val_loss: 0.0981 - val_accuracy: 0.9697\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8099773755098616\n",
      "F1 Micro: 0.9695\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 9s 215us/step - loss: 0.2687 - accuracy: 0.9257 - val_loss: 0.1611 - val_accuracy: 0.9522\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.1444 - accuracy: 0.9556 - val_loss: 0.1402 - val_accuracy: 0.9602\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.1232 - accuracy: 0.9623 - val_loss: 0.1199 - val_accuracy: 0.9630\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.1124 - accuracy: 0.9647 - val_loss: 0.1153 - val_accuracy: 0.9647\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.1046 - accuracy: 0.9672 - val_loss: 0.1133 - val_accuracy: 0.9633\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0991 - accuracy: 0.9692 - val_loss: 0.1078 - val_accuracy: 0.9653\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0943 - accuracy: 0.9707 - val_loss: 0.1037 - val_accuracy: 0.9658\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0899 - accuracy: 0.9721 - val_loss: 0.0990 - val_accuracy: 0.9671\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0850 - accuracy: 0.9730 - val_loss: 0.1051 - val_accuracy: 0.9675\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0798 - accuracy: 0.9748 - val_loss: 0.0953 - val_accuracy: 0.9696\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0745 - accuracy: 0.9764 - val_loss: 0.0926 - val_accuracy: 0.9699\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.0680 - accuracy: 0.9786 - val_loss: 0.0937 - val_accuracy: 0.9697\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0615 - accuracy: 0.9801 - val_loss: 0.0912 - val_accuracy: 0.9700\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0554 - accuracy: 0.9820 - val_loss: 0.0926 - val_accuracy: 0.9692\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0475 - accuracy: 0.9850 - val_loss: 0.0935 - val_accuracy: 0.9702\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0394 - accuracy: 0.9878 - val_loss: 0.1037 - val_accuracy: 0.9653\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0322 - accuracy: 0.9900 - val_loss: 0.1020 - val_accuracy: 0.9687\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 0.1165 - val_accuracy: 0.9626\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 0.1133 - val_accuracy: 0.9678\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 0.1159 - val_accuracy: 0.9688\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.1258 - val_accuracy: 0.9683\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.1307 - val_accuracy: 0.9700\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.1371 - val_accuracy: 0.9714\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.1610 - val_accuracy: 0.9717\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.1449 - val_accuracy: 0.9700\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1376 - val_accuracy: 0.9711\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.1511 - val_accuracy: 0.9700\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.1651 - val_accuracy: 0.9712\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1842 - val_accuracy: 0.9703\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.1679 - val_accuracy: 0.9698\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.1781 - val_accuracy: 0.9637\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.1652 - val_accuracy: 0.9696\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.1751 - val_accuracy: 0.9681\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8322070533699797\n",
      "F1 Micro: 0.9715\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8048491221004509\n",
      "F1 Micro: 0.9661\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8443051923687686\n",
      "F1 Micro: 0.9739\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 2 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.2328 - accuracy: 0.9368 - val_loss: 0.1253 - val_accuracy: 0.9617\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.1166 - accuracy: 0.9631 - val_loss: 0.1008 - val_accuracy: 0.9681\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0991 - accuracy: 0.9678 - val_loss: 0.0931 - val_accuracy: 0.9693\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0898 - accuracy: 0.9703 - val_loss: 0.0920 - val_accuracy: 0.9697\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0813 - accuracy: 0.9729 - val_loss: 0.0944 - val_accuracy: 0.9701\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0745 - accuracy: 0.9750 - val_loss: 0.0751 - val_accuracy: 0.9751\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0679 - accuracy: 0.9772 - val_loss: 0.0697 - val_accuracy: 0.9766\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0623 - accuracy: 0.9787 - val_loss: 0.0695 - val_accuracy: 0.9761\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 29s 223us/step - loss: 0.0581 - accuracy: 0.9795 - val_loss: 0.0680 - val_accuracy: 0.9771\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 28s 213us/step - loss: 0.0533 - accuracy: 0.9815 - val_loss: 0.0665 - val_accuracy: 0.9769\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0506 - accuracy: 0.9823 - val_loss: 0.0667 - val_accuracy: 0.9761\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0462 - accuracy: 0.9838 - val_loss: 0.0700 - val_accuracy: 0.9764\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0429 - accuracy: 0.9848 - val_loss: 0.0644 - val_accuracy: 0.9774\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0395 - accuracy: 0.9859 - val_loss: 0.0658 - val_accuracy: 0.9779\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0355 - accuracy: 0.9871 - val_loss: 0.0676 - val_accuracy: 0.9766\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0316 - accuracy: 0.9884 - val_loss: 0.0748 - val_accuracy: 0.9763\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0279 - accuracy: 0.9900 - val_loss: 0.0713 - val_accuracy: 0.9779\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.0725 - val_accuracy: 0.9778\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.0800 - val_accuracy: 0.9779\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.0828 - val_accuracy: 0.9781\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.0880 - val_accuracy: 0.9783\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 29s 219us/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0996 - val_accuracy: 0.9766\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 28s 215us/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0884 - val_accuracy: 0.9775\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.1076 - val_accuracy: 0.9749\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 28s 214us/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.1091 - val_accuracy: 0.9778\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 28s 211us/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.1193 - val_accuracy: 0.9729\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.1105 - val_accuracy: 0.9785\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.1008 - val_accuracy: 0.9782\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1111 - val_accuracy: 0.9768\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.1129 - val_accuracy: 0.9780\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.1115 - val_accuracy: 0.9777\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.1207 - val_accuracy: 0.9768\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.1323 - val_accuracy: 0.9737\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8861719271805271\n",
      "F1 Micro: 0.9752\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8443760785221669\n",
      "F1 Micro: 0.9713\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.2599 - accuracy: 0.9331 - val_loss: 0.1197 - val_accuracy: 0.9637\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.1133 - accuracy: 0.9650 - val_loss: 0.1067 - val_accuracy: 0.9669\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.1035 - accuracy: 0.9674 - val_loss: 0.0999 - val_accuracy: 0.9693\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0978 - accuracy: 0.9691 - val_loss: 0.0958 - val_accuracy: 0.9703\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0937 - accuracy: 0.9706 - val_loss: 0.0958 - val_accuracy: 0.9700\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0906 - accuracy: 0.9713 - val_loss: 0.0912 - val_accuracy: 0.9712\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0883 - accuracy: 0.9718 - val_loss: 0.0905 - val_accuracy: 0.9718\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0860 - accuracy: 0.9726 - val_loss: 0.0894 - val_accuracy: 0.9712\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0841 - accuracy: 0.9729 - val_loss: 0.0872 - val_accuracy: 0.9719\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0823 - accuracy: 0.9738 - val_loss: 0.0884 - val_accuracy: 0.9708\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0809 - accuracy: 0.9738 - val_loss: 0.0845 - val_accuracy: 0.9727\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0794 - accuracy: 0.9747 - val_loss: 0.0842 - val_accuracy: 0.9725\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0781 - accuracy: 0.9746 - val_loss: 0.0843 - val_accuracy: 0.9733\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0770 - accuracy: 0.9752 - val_loss: 0.0827 - val_accuracy: 0.9737\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0759 - accuracy: 0.9754 - val_loss: 0.0826 - val_accuracy: 0.9733\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0749 - accuracy: 0.9758 - val_loss: 0.0822 - val_accuracy: 0.9733\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0739 - accuracy: 0.9760 - val_loss: 0.0819 - val_accuracy: 0.9734\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0731 - accuracy: 0.9763 - val_loss: 0.0808 - val_accuracy: 0.9735\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0721 - accuracy: 0.9768 - val_loss: 0.0820 - val_accuracy: 0.9735\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0714 - accuracy: 0.9771 - val_loss: 0.0815 - val_accuracy: 0.9739\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0706 - accuracy: 0.9773 - val_loss: 0.0802 - val_accuracy: 0.9739\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0697 - accuracy: 0.9775 - val_loss: 0.0792 - val_accuracy: 0.9739\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0689 - accuracy: 0.9778 - val_loss: 0.0824 - val_accuracy: 0.9728\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0683 - accuracy: 0.9779 - val_loss: 0.0796 - val_accuracy: 0.9740\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0676 - accuracy: 0.9782 - val_loss: 0.0794 - val_accuracy: 0.9743\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0668 - accuracy: 0.9784 - val_loss: 0.0809 - val_accuracy: 0.9736\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0661 - accuracy: 0.9787 - val_loss: 0.0820 - val_accuracy: 0.9732\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0654 - accuracy: 0.9789 - val_loss: 0.0792 - val_accuracy: 0.9743\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0648 - accuracy: 0.9793 - val_loss: 0.0798 - val_accuracy: 0.9745\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0641 - accuracy: 0.9792 - val_loss: 0.0799 - val_accuracy: 0.9737\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0636 - accuracy: 0.9796 - val_loss: 0.0789 - val_accuracy: 0.9744\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0628 - accuracy: 0.9797 - val_loss: 0.0789 - val_accuracy: 0.9746\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0623 - accuracy: 0.9799 - val_loss: 0.0793 - val_accuracy: 0.9742\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0617 - accuracy: 0.9803 - val_loss: 0.0807 - val_accuracy: 0.9739\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0612 - accuracy: 0.9802 - val_loss: 0.0797 - val_accuracy: 0.9744\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0605 - accuracy: 0.9803 - val_loss: 0.0818 - val_accuracy: 0.9738\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0599 - accuracy: 0.9807 - val_loss: 0.0801 - val_accuracy: 0.9744\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0594 - accuracy: 0.9805 - val_loss: 0.0802 - val_accuracy: 0.9736\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0587 - accuracy: 0.9811 - val_loss: 0.0787 - val_accuracy: 0.9750\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0581 - accuracy: 0.9813 - val_loss: 0.0798 - val_accuracy: 0.9750\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0577 - accuracy: 0.9814 - val_loss: 0.0793 - val_accuracy: 0.9748\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0572 - accuracy: 0.9816 - val_loss: 0.0789 - val_accuracy: 0.9746\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0565 - accuracy: 0.9816 - val_loss: 0.0803 - val_accuracy: 0.9736\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0561 - accuracy: 0.9820 - val_loss: 0.0803 - val_accuracy: 0.9745\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0555 - accuracy: 0.9822 - val_loss: 0.0825 - val_accuracy: 0.9731\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0550 - accuracy: 0.9823 - val_loss: 0.0796 - val_accuracy: 0.9752\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0544 - accuracy: 0.9824 - val_loss: 0.0804 - val_accuracy: 0.9748\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0539 - accuracy: 0.9828 - val_loss: 0.0785 - val_accuracy: 0.9755\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0533 - accuracy: 0.9828 - val_loss: 0.0797 - val_accuracy: 0.9753\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0528 - accuracy: 0.9831 - val_loss: 0.0801 - val_accuracy: 0.9745\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0524 - accuracy: 0.9831 - val_loss: 0.0799 - val_accuracy: 0.9745\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 0.0805 - val_accuracy: 0.9746\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0513 - accuracy: 0.9838 - val_loss: 0.0802 - val_accuracy: 0.9745\n",
      "Epoch 54/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0507 - accuracy: 0.9836 - val_loss: 0.0806 - val_accuracy: 0.9747\n",
      "Epoch 55/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0503 - accuracy: 0.9841 - val_loss: 0.0807 - val_accuracy: 0.9740\n",
      "Epoch 56/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0499 - accuracy: 0.9839 - val_loss: 0.0818 - val_accuracy: 0.9738\n",
      "Epoch 57/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.0824 - val_accuracy: 0.9738\n",
      "Epoch 58/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0490 - accuracy: 0.9843 - val_loss: 0.0826 - val_accuracy: 0.9740\n",
      "Epoch 59/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0482 - accuracy: 0.9846 - val_loss: 0.0809 - val_accuracy: 0.9743\n",
      "Epoch 60/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0477 - accuracy: 0.9849 - val_loss: 0.0814 - val_accuracy: 0.9744\n",
      "Epoch 61/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0473 - accuracy: 0.9850 - val_loss: 0.0817 - val_accuracy: 0.9747\n",
      "Epoch 62/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0467 - accuracy: 0.9851 - val_loss: 0.0825 - val_accuracy: 0.9743\n",
      "Epoch 63/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0463 - accuracy: 0.9850 - val_loss: 0.0829 - val_accuracy: 0.9739\n",
      "Epoch 64/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0460 - accuracy: 0.9852 - val_loss: 0.0820 - val_accuracy: 0.9744\n",
      "Epoch 65/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0452 - accuracy: 0.9856 - val_loss: 0.0832 - val_accuracy: 0.9750\n",
      "Epoch 66/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0450 - accuracy: 0.9857 - val_loss: 0.0830 - val_accuracy: 0.9742\n",
      "Epoch 67/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0443 - accuracy: 0.9859 - val_loss: 0.0828 - val_accuracy: 0.9747\n",
      "Epoch 68/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0439 - accuracy: 0.9860 - val_loss: 0.0838 - val_accuracy: 0.9742\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8562167425128672\n",
      "F1 Micro: 0.9739\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.1694 - accuracy: 0.9508 - val_loss: 0.1181 - val_accuracy: 0.9637\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.1076 - accuracy: 0.9665 - val_loss: 0.1023 - val_accuracy: 0.9685\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0966 - accuracy: 0.9692 - val_loss: 0.0901 - val_accuracy: 0.9708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0873 - accuracy: 0.9719 - val_loss: 0.0844 - val_accuracy: 0.9725\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0795 - accuracy: 0.9741 - val_loss: 0.0832 - val_accuracy: 0.9737\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0738 - accuracy: 0.9757 - val_loss: 0.0763 - val_accuracy: 0.9750\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0680 - accuracy: 0.9776 - val_loss: 0.0754 - val_accuracy: 0.9750\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0625 - accuracy: 0.9793 - val_loss: 0.0722 - val_accuracy: 0.9760\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0572 - accuracy: 0.9809 - val_loss: 0.0691 - val_accuracy: 0.9766\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0517 - accuracy: 0.9825 - val_loss: 0.0714 - val_accuracy: 0.9757\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0460 - accuracy: 0.9844 - val_loss: 0.0708 - val_accuracy: 0.9770\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0390 - accuracy: 0.9869 - val_loss: 0.0722 - val_accuracy: 0.9772\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0321 - accuracy: 0.9889 - val_loss: 0.0774 - val_accuracy: 0.9756\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.0784 - val_accuracy: 0.9761\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.0852 - val_accuracy: 0.9756\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.1086 - val_accuracy: 0.9760\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.1007 - val_accuracy: 0.9755\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 27s 210us/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.1061 - val_accuracy: 0.9727\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.1265 - val_accuracy: 0.9753\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1153 - val_accuracy: 0.9749\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1203 - val_accuracy: 0.9749\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1287 - val_accuracy: 0.9751\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1307 - val_accuracy: 0.9764\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1478 - val_accuracy: 0.9758\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 27s 211us/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1346 - val_accuracy: 0.9755\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1342 - val_accuracy: 0.9756\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.1343 - val_accuracy: 0.9762\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.1412 - val_accuracy: 0.9763\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1475 - val_accuracy: 0.9753\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8613695848495699\n",
      "F1 Micro: 0.9741\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8525141776777284\n",
      "F1 Micro: 0.9718\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8929998539793362\n",
      "F1 Micro: 0.9779\n",
      "\n",
      "\n",
      " 57.95866916974386 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 3 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 3 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.9755 - accuracy: 0.6875 - val_loss: 1.5540 - val_accuracy: 0.8600\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 236us/step - loss: 1.2209 - accuracy: 0.8200 - val_loss: 0.7398 - val_accuracy: 0.8600\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.8753 - accuracy: 0.8200 - val_loss: 0.7408 - val_accuracy: 0.8600\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.8367 - accuracy: 0.8200 - val_loss: 0.7512 - val_accuracy: 0.8600\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.8090 - accuracy: 0.8200 - val_loss: 0.7403 - val_accuracy: 0.8600\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.7942 - accuracy: 0.8200 - val_loss: 0.7260 - val_accuracy: 0.8600\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.7800 - accuracy: 0.8200 - val_loss: 0.7332 - val_accuracy: 0.8600\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.7731 - accuracy: 0.8200 - val_loss: 0.7151 - val_accuracy: 0.8600\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.7613 - accuracy: 0.8200 - val_loss: 0.7145 - val_accuracy: 0.8600\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.7532 - accuracy: 0.8200 - val_loss: 0.6871 - val_accuracy: 0.8600\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.7434 - accuracy: 0.8200 - val_loss: 0.6943 - val_accuracy: 0.8600\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.7359 - accuracy: 0.8200 - val_loss: 0.6846 - val_accuracy: 0.8600\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.7308 - accuracy: 0.8200 - val_loss: 0.6841 - val_accuracy: 0.8600\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.7206 - accuracy: 0.8200 - val_loss: 0.6631 - val_accuracy: 0.8600\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.7126 - accuracy: 0.8200 - val_loss: 0.6692 - val_accuracy: 0.8600\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.7047 - accuracy: 0.8200 - val_loss: 0.6522 - val_accuracy: 0.8600\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.6959 - accuracy: 0.8200 - val_loss: 0.6588 - val_accuracy: 0.8600\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6863 - accuracy: 0.8200 - val_loss: 0.6485 - val_accuracy: 0.8600\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6764 - accuracy: 0.8200 - val_loss: 0.6422 - val_accuracy: 0.8600\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6672 - accuracy: 0.8200 - val_loss: 0.6623 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.6629 - accuracy: 0.8200 - val_loss: 0.6514 - val_accuracy: 0.8600\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6498 - accuracy: 0.8200 - val_loss: 0.6913 - val_accuracy: 0.8600\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6631 - accuracy: 0.8200 - val_loss: 0.6363 - val_accuracy: 0.8600\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.6305 - accuracy: 0.8175 - val_loss: 0.6305 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6193 - accuracy: 0.8175 - val_loss: 0.6854 - val_accuracy: 0.8500\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 233us/step - loss: 0.6347 - accuracy: 0.8200 - val_loss: 0.6810 - val_accuracy: 0.8500\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6252 - accuracy: 0.8250 - val_loss: 0.6567 - val_accuracy: 0.8500\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.5955 - accuracy: 0.8225 - val_loss: 0.6259 - val_accuracy: 0.8500\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.5800 - accuracy: 0.8250 - val_loss: 0.6496 - val_accuracy: 0.8500\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.5926 - accuracy: 0.8325 - val_loss: 0.5988 - val_accuracy: 0.8600\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.5602 - accuracy: 0.8400 - val_loss: 0.6057 - val_accuracy: 0.8600\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.5537 - accuracy: 0.8400 - val_loss: 0.6194 - val_accuracy: 0.8500\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.5435 - accuracy: 0.8475 - val_loss: 0.6263 - val_accuracy: 0.8500\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.5106 - accuracy: 0.8575 - val_loss: 0.5820 - val_accuracy: 0.8700\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.4934 - accuracy: 0.8650 - val_loss: 0.5781 - val_accuracy: 0.8600\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.4909 - accuracy: 0.8650 - val_loss: 0.5989 - val_accuracy: 0.8600\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.5005 - accuracy: 0.8575 - val_loss: 0.5627 - val_accuracy: 0.8700\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.4575 - accuracy: 0.8675 - val_loss: 0.5538 - val_accuracy: 0.8700\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.4454 - accuracy: 0.8750 - val_loss: 0.5500 - val_accuracy: 0.8700\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.4358 - accuracy: 0.8750 - val_loss: 0.5615 - val_accuracy: 0.8700\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.4288 - accuracy: 0.8800 - val_loss: 0.5569 - val_accuracy: 0.8700\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.4356 - accuracy: 0.8725 - val_loss: 0.5429 - val_accuracy: 0.8700\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.4166 - accuracy: 0.8825 - val_loss: 0.5257 - val_accuracy: 0.8700\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.4100 - accuracy: 0.8825 - val_loss: 0.5222 - val_accuracy: 0.8700\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.4024 - accuracy: 0.8725 - val_loss: 0.4993 - val_accuracy: 0.8800\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3994 - accuracy: 0.8900 - val_loss: 0.5275 - val_accuracy: 0.8600\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.4086 - accuracy: 0.8950 - val_loss: 0.5423 - val_accuracy: 0.8500\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.4019 - accuracy: 0.8950 - val_loss: 0.6127 - val_accuracy: 0.8400\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.4032 - accuracy: 0.8875 - val_loss: 0.4930 - val_accuracy: 0.8600\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3532 - accuracy: 0.8900 - val_loss: 0.4663 - val_accuracy: 0.8800\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.3585 - accuracy: 0.8925 - val_loss: 0.4688 - val_accuracy: 0.8800\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3420 - accuracy: 0.8925 - val_loss: 0.4542 - val_accuracy: 0.8800\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3374 - accuracy: 0.9000 - val_loss: 0.4459 - val_accuracy: 0.8800\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3210 - accuracy: 0.9000 - val_loss: 0.4398 - val_accuracy: 0.8800\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3168 - accuracy: 0.9025 - val_loss: 0.4294 - val_accuracy: 0.8800\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3028 - accuracy: 0.9075 - val_loss: 0.5161 - val_accuracy: 0.8400\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3146 - accuracy: 0.9050 - val_loss: 0.4405 - val_accuracy: 0.8800\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3337 - accuracy: 0.9100 - val_loss: 0.4943 - val_accuracy: 0.8700\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3272 - accuracy: 0.9000 - val_loss: 0.4151 - val_accuracy: 0.8800\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3538 - accuracy: 0.9075 - val_loss: 0.4750 - val_accuracy: 0.8400\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3047 - accuracy: 0.9125 - val_loss: 0.4284 - val_accuracy: 0.8700\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2817 - accuracy: 0.9200 - val_loss: 0.4072 - val_accuracy: 0.8800\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.2741 - accuracy: 0.9100 - val_loss: 0.4044 - val_accuracy: 0.8800\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2660 - accuracy: 0.9225 - val_loss: 0.4015 - val_accuracy: 0.8900\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2581 - accuracy: 0.9125 - val_loss: 0.4889 - val_accuracy: 0.8400\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2797 - accuracy: 0.9175 - val_loss: 0.4032 - val_accuracy: 0.8900\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2451 - accuracy: 0.9300 - val_loss: 0.3957 - val_accuracy: 0.8700\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2396 - accuracy: 0.9325 - val_loss: 0.3814 - val_accuracy: 0.8900\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.2376 - accuracy: 0.9175 - val_loss: 0.3808 - val_accuracy: 0.9000\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2318 - accuracy: 0.9200 - val_loss: 0.4322 - val_accuracy: 0.8800\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2341 - accuracy: 0.9250 - val_loss: 0.3886 - val_accuracy: 0.8900\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2273 - accuracy: 0.9275 - val_loss: 0.3929 - val_accuracy: 0.8800\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2215 - accuracy: 0.9425 - val_loss: 0.3655 - val_accuracy: 0.8800\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2029 - accuracy: 0.9300 - val_loss: 0.3722 - val_accuracy: 0.8900\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1940 - accuracy: 0.9450 - val_loss: 0.3614 - val_accuracy: 0.8900\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1934 - accuracy: 0.9450 - val_loss: 0.3745 - val_accuracy: 0.8900\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1844 - accuracy: 0.9500 - val_loss: 0.3671 - val_accuracy: 0.9000\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1953 - accuracy: 0.9400 - val_loss: 0.3653 - val_accuracy: 0.9000\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2090 - accuracy: 0.9425 - val_loss: 0.3646 - val_accuracy: 0.8900\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1667 - accuracy: 0.9525 - val_loss: 0.3544 - val_accuracy: 0.8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1683 - accuracy: 0.9525 - val_loss: 0.4023 - val_accuracy: 0.8900\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1632 - accuracy: 0.9550 - val_loss: 0.3612 - val_accuracy: 0.8900\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1511 - accuracy: 0.9675 - val_loss: 0.3542 - val_accuracy: 0.9000\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1460 - accuracy: 0.9625 - val_loss: 0.3547 - val_accuracy: 0.9000\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1453 - accuracy: 0.9625 - val_loss: 0.3871 - val_accuracy: 0.9000\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1717 - accuracy: 0.9525 - val_loss: 0.3694 - val_accuracy: 0.9000\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1336 - accuracy: 0.9625 - val_loss: 0.3590 - val_accuracy: 0.8800\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1326 - accuracy: 0.9700 - val_loss: 0.3512 - val_accuracy: 0.9000\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1333 - accuracy: 0.9675 - val_loss: 0.3921 - val_accuracy: 0.8900\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.1326 - accuracy: 0.9600 - val_loss: 0.3732 - val_accuracy: 0.9000\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.1331 - accuracy: 0.9675 - val_loss: 0.3618 - val_accuracy: 0.9000\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.1274 - accuracy: 0.9675 - val_loss: 0.3448 - val_accuracy: 0.9000\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1181 - accuracy: 0.9725 - val_loss: 0.3871 - val_accuracy: 0.9100\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1155 - accuracy: 0.9700 - val_loss: 0.4075 - val_accuracy: 0.9000\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1362 - accuracy: 0.9525 - val_loss: 0.3526 - val_accuracy: 0.8800\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1109 - accuracy: 0.9725 - val_loss: 0.4043 - val_accuracy: 0.9000\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1076 - accuracy: 0.9650 - val_loss: 0.4030 - val_accuracy: 0.8900\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1174 - accuracy: 0.9700 - val_loss: 0.4984 - val_accuracy: 0.8500\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1762 - accuracy: 0.9350 - val_loss: 0.4029 - val_accuracy: 0.9100\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1170 - accuracy: 0.9650 - val_loss: 0.3634 - val_accuracy: 0.9000\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0943 - accuracy: 0.9725 - val_loss: 0.3433 - val_accuracy: 0.9100\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0884 - accuracy: 0.9825 - val_loss: 0.3479 - val_accuracy: 0.8800\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0968 - accuracy: 0.9700 - val_loss: 0.3656 - val_accuracy: 0.9000\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1175 - accuracy: 0.9575 - val_loss: 0.3693 - val_accuracy: 0.8900\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0785 - accuracy: 0.9850 - val_loss: 0.3423 - val_accuracy: 0.9000\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0739 - accuracy: 0.9850 - val_loss: 0.3665 - val_accuracy: 0.9100\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1142 - accuracy: 0.9725 - val_loss: 0.3670 - val_accuracy: 0.9000\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0948 - accuracy: 0.9750 - val_loss: 0.3605 - val_accuracy: 0.9000\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0933 - accuracy: 0.9675 - val_loss: 0.3400 - val_accuracy: 0.9000\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0706 - accuracy: 0.9850 - val_loss: 0.3510 - val_accuracy: 0.9000\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0695 - accuracy: 0.9825 - val_loss: 0.3482 - val_accuracy: 0.9000\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0633 - accuracy: 0.9875 - val_loss: 0.3483 - val_accuracy: 0.9000\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0594 - accuracy: 0.9900 - val_loss: 0.3684 - val_accuracy: 0.9000\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0588 - accuracy: 0.9850 - val_loss: 0.3616 - val_accuracy: 0.9000\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0643 - accuracy: 0.9875 - val_loss: 0.3559 - val_accuracy: 0.8900\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0543 - accuracy: 0.9925 - val_loss: 0.3548 - val_accuracy: 0.9000\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0521 - accuracy: 0.9900 - val_loss: 0.3590 - val_accuracy: 0.9000\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0552 - accuracy: 0.9900 - val_loss: 0.3533 - val_accuracy: 0.8900\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0510 - accuracy: 0.9900 - val_loss: 0.3678 - val_accuracy: 0.9000\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0456 - accuracy: 0.9950 - val_loss: 0.3685 - val_accuracy: 0.9000\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0499 - accuracy: 0.9900 - val_loss: 0.3504 - val_accuracy: 0.8900\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0422 - accuracy: 0.9950 - val_loss: 0.3529 - val_accuracy: 0.8900\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0407 - accuracy: 0.9975 - val_loss: 0.3520 - val_accuracy: 0.8900\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0401 - accuracy: 0.9925 - val_loss: 0.3557 - val_accuracy: 0.9000\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0390 - accuracy: 0.9950 - val_loss: 0.3943 - val_accuracy: 0.9000\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0427 - accuracy: 0.9950 - val_loss: 0.3781 - val_accuracy: 0.9000\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0376 - accuracy: 0.9975 - val_loss: 0.3687 - val_accuracy: 0.8900\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0360 - accuracy: 0.9950 - val_loss: 0.3702 - val_accuracy: 0.8900\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.8900\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.4541070170540927\n",
      "F1 Micro: 0.9297183732679705\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5446447833658519\n",
      "F1 Micro: 0.9476264318943526\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 309us/step - loss: 2.1248 - accuracy: 0.1950 - val_loss: 2.0014 - val_accuracy: 0.3700\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 1.9063 - accuracy: 0.4800 - val_loss: 1.8286 - val_accuracy: 0.4800\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.7499 - accuracy: 0.5575 - val_loss: 1.7126 - val_accuracy: 0.5100\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.6383 - accuracy: 0.6000 - val_loss: 1.6411 - val_accuracy: 0.5300\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.5561 - accuracy: 0.6250 - val_loss: 1.5848 - val_accuracy: 0.5600\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.4864 - accuracy: 0.6550 - val_loss: 1.5323 - val_accuracy: 0.5800\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.4234 - accuracy: 0.6725 - val_loss: 1.4794 - val_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 1.3629 - accuracy: 0.7000 - val_loss: 1.4242 - val_accuracy: 0.6300\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.3019 - accuracy: 0.7075 - val_loss: 1.3739 - val_accuracy: 0.6300\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.2449 - accuracy: 0.7325 - val_loss: 1.3201 - val_accuracy: 0.6400\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.1867 - accuracy: 0.7475 - val_loss: 1.2650 - val_accuracy: 0.6500\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.1299 - accuracy: 0.7750 - val_loss: 1.2062 - val_accuracy: 0.6700\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.0743 - accuracy: 0.8075 - val_loss: 1.1472 - val_accuracy: 0.7200\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.0206 - accuracy: 0.8125 - val_loss: 1.0917 - val_accuracy: 0.7500\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.9693 - accuracy: 0.8250 - val_loss: 1.0430 - val_accuracy: 0.7600\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.9201 - accuracy: 0.8275 - val_loss: 0.9911 - val_accuracy: 0.7700\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.8731 - accuracy: 0.8350 - val_loss: 0.9407 - val_accuracy: 0.7800\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.8282 - accuracy: 0.8550 - val_loss: 0.8931 - val_accuracy: 0.7900\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.7857 - accuracy: 0.8675 - val_loss: 0.8550 - val_accuracy: 0.7900\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.7448 - accuracy: 0.8725 - val_loss: 0.8138 - val_accuracy: 0.8200\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.7058 - accuracy: 0.8850 - val_loss: 0.7766 - val_accuracy: 0.8300\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.6702 - accuracy: 0.8900 - val_loss: 0.7409 - val_accuracy: 0.8400\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.6352 - accuracy: 0.8975 - val_loss: 0.7090 - val_accuracy: 0.8400\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.6030 - accuracy: 0.9075 - val_loss: 0.6794 - val_accuracy: 0.8400\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.5722 - accuracy: 0.9100 - val_loss: 0.6521 - val_accuracy: 0.8400\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.5435 - accuracy: 0.9150 - val_loss: 0.6229 - val_accuracy: 0.8400\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.5157 - accuracy: 0.9175 - val_loss: 0.6015 - val_accuracy: 0.8400\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.4902 - accuracy: 0.9175 - val_loss: 0.5747 - val_accuracy: 0.8600\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.4650 - accuracy: 0.9175 - val_loss: 0.5561 - val_accuracy: 0.8500\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.4423 - accuracy: 0.9200 - val_loss: 0.5340 - val_accuracy: 0.8600\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.4210 - accuracy: 0.9250 - val_loss: 0.5168 - val_accuracy: 0.8600\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.4004 - accuracy: 0.9300 - val_loss: 0.4981 - val_accuracy: 0.8900\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.3815 - accuracy: 0.9300 - val_loss: 0.4804 - val_accuracy: 0.9000\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.3639 - accuracy: 0.9300 - val_loss: 0.4647 - val_accuracy: 0.9000\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.3475 - accuracy: 0.9350 - val_loss: 0.4486 - val_accuracy: 0.9100\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.3317 - accuracy: 0.9375 - val_loss: 0.4368 - val_accuracy: 0.9100\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.3173 - accuracy: 0.9425 - val_loss: 0.4233 - val_accuracy: 0.9100\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.3033 - accuracy: 0.9425 - val_loss: 0.4112 - val_accuracy: 0.9100\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2908 - accuracy: 0.9425 - val_loss: 0.3981 - val_accuracy: 0.9100\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2790 - accuracy: 0.9450 - val_loss: 0.3863 - val_accuracy: 0.9100\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2684 - accuracy: 0.9475 - val_loss: 0.3767 - val_accuracy: 0.9100\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.2572 - accuracy: 0.9475 - val_loss: 0.3712 - val_accuracy: 0.9100\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2473 - accuracy: 0.9475 - val_loss: 0.3613 - val_accuracy: 0.9200\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2387 - accuracy: 0.9500 - val_loss: 0.3508 - val_accuracy: 0.9200\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2297 - accuracy: 0.9550 - val_loss: 0.3452 - val_accuracy: 0.9200\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.2214 - accuracy: 0.9550 - val_loss: 0.3386 - val_accuracy: 0.9200\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2148 - accuracy: 0.9550 - val_loss: 0.3358 - val_accuracy: 0.9200\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2073 - accuracy: 0.9550 - val_loss: 0.3228 - val_accuracy: 0.9200\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2003 - accuracy: 0.9550 - val_loss: 0.3183 - val_accuracy: 0.9200\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1939 - accuracy: 0.9550 - val_loss: 0.3157 - val_accuracy: 0.9200\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.1877 - accuracy: 0.9550 - val_loss: 0.3103 - val_accuracy: 0.9200\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1820 - accuracy: 0.9575 - val_loss: 0.2989 - val_accuracy: 0.9300\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1763 - accuracy: 0.9575 - val_loss: 0.2980 - val_accuracy: 0.9200\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1712 - accuracy: 0.9575 - val_loss: 0.2950 - val_accuracy: 0.9200\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1661 - accuracy: 0.9625 - val_loss: 0.2906 - val_accuracy: 0.9200\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1618 - accuracy: 0.9675 - val_loss: 0.2825 - val_accuracy: 0.9300\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1573 - accuracy: 0.9725 - val_loss: 0.2806 - val_accuracy: 0.9300\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1529 - accuracy: 0.9725 - val_loss: 0.2804 - val_accuracy: 0.9300\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1490 - accuracy: 0.9725 - val_loss: 0.2773 - val_accuracy: 0.9300\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1453 - accuracy: 0.9725 - val_loss: 0.2738 - val_accuracy: 0.9300\n",
      "Epoch 61/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 80us/step - loss: 0.1418 - accuracy: 0.9750 - val_loss: 0.2697 - val_accuracy: 0.9300\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1383 - accuracy: 0.9750 - val_loss: 0.2687 - val_accuracy: 0.9300\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1349 - accuracy: 0.9750 - val_loss: 0.2650 - val_accuracy: 0.9300\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1317 - accuracy: 0.9750 - val_loss: 0.2654 - val_accuracy: 0.9300\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1286 - accuracy: 0.9750 - val_loss: 0.2607 - val_accuracy: 0.9400\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1257 - accuracy: 0.9775 - val_loss: 0.2568 - val_accuracy: 0.9400\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1225 - accuracy: 0.9775 - val_loss: 0.2585 - val_accuracy: 0.9400\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.1202 - accuracy: 0.9775 - val_loss: 0.2597 - val_accuracy: 0.9300\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.1173 - accuracy: 0.9775 - val_loss: 0.2525 - val_accuracy: 0.9400\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1147 - accuracy: 0.9825 - val_loss: 0.2479 - val_accuracy: 0.9400\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1124 - accuracy: 0.9825 - val_loss: 0.2493 - val_accuracy: 0.9400\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1098 - accuracy: 0.9825 - val_loss: 0.2477 - val_accuracy: 0.9400\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1078 - accuracy: 0.9825 - val_loss: 0.2481 - val_accuracy: 0.9400\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1051 - accuracy: 0.9850 - val_loss: 0.2449 - val_accuracy: 0.9400\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1031 - accuracy: 0.9825 - val_loss: 0.2403 - val_accuracy: 0.9400\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 71us/step - loss: 0.1009 - accuracy: 0.9850 - val_loss: 0.2407 - val_accuracy: 0.9400\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0987 - accuracy: 0.9875 - val_loss: 0.2402 - val_accuracy: 0.9400\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0967 - accuracy: 0.9875 - val_loss: 0.2414 - val_accuracy: 0.9400\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0946 - accuracy: 0.9875 - val_loss: 0.2386 - val_accuracy: 0.9400\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0930 - accuracy: 0.9875 - val_loss: 0.2383 - val_accuracy: 0.9400\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0911 - accuracy: 0.9875 - val_loss: 0.2363 - val_accuracy: 0.9400\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0894 - accuracy: 0.9875 - val_loss: 0.2383 - val_accuracy: 0.9400\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0874 - accuracy: 0.9875 - val_loss: 0.2378 - val_accuracy: 0.9400\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0856 - accuracy: 0.9875 - val_loss: 0.2316 - val_accuracy: 0.9400\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0840 - accuracy: 0.9875 - val_loss: 0.2293 - val_accuracy: 0.9400\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0824 - accuracy: 0.9875 - val_loss: 0.2321 - val_accuracy: 0.9400\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0812 - accuracy: 0.9900 - val_loss: 0.2271 - val_accuracy: 0.9400\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0792 - accuracy: 0.9900 - val_loss: 0.2290 - val_accuracy: 0.9400\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0775 - accuracy: 0.9900 - val_loss: 0.2288 - val_accuracy: 0.9400\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0762 - accuracy: 0.9900 - val_loss: 0.2286 - val_accuracy: 0.9500\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0747 - accuracy: 0.9900 - val_loss: 0.2249 - val_accuracy: 0.9500\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0734 - accuracy: 0.9900 - val_loss: 0.2262 - val_accuracy: 0.9500\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0719 - accuracy: 0.9900 - val_loss: 0.2252 - val_accuracy: 0.9500\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0705 - accuracy: 0.9900 - val_loss: 0.2249 - val_accuracy: 0.9500\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0694 - accuracy: 0.9900 - val_loss: 0.2219 - val_accuracy: 0.9500\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0680 - accuracy: 0.9925 - val_loss: 0.2238 - val_accuracy: 0.9500\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0667 - accuracy: 0.9925 - val_loss: 0.2228 - val_accuracy: 0.9500\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0655 - accuracy: 0.9925 - val_loss: 0.2218 - val_accuracy: 0.9500\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0644 - accuracy: 0.9925 - val_loss: 0.2213 - val_accuracy: 0.9500\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0632 - accuracy: 0.9925 - val_loss: 0.2211 - val_accuracy: 0.9500\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0618 - accuracy: 0.9925 - val_loss: 0.2213 - val_accuracy: 0.9500\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0607 - accuracy: 0.9925 - val_loss: 0.2213 - val_accuracy: 0.9500\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0596 - accuracy: 0.9950 - val_loss: 0.2187 - val_accuracy: 0.9500\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0586 - accuracy: 0.9925 - val_loss: 0.2178 - val_accuracy: 0.9500\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0575 - accuracy: 0.9950 - val_loss: 0.2185 - val_accuracy: 0.9500\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0564 - accuracy: 0.9950 - val_loss: 0.2183 - val_accuracy: 0.9500\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0554 - accuracy: 0.9950 - val_loss: 0.2176 - val_accuracy: 0.9400\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0544 - accuracy: 0.9950 - val_loss: 0.2176 - val_accuracy: 0.9400\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0534 - accuracy: 0.9950 - val_loss: 0.2151 - val_accuracy: 0.9500\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0527 - accuracy: 0.9950 - val_loss: 0.2179 - val_accuracy: 0.9400\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0515 - accuracy: 0.9950 - val_loss: 0.2173 - val_accuracy: 0.9400\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0506 - accuracy: 0.9950 - val_loss: 0.2156 - val_accuracy: 0.9400\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0497 - accuracy: 0.9950 - val_loss: 0.2164 - val_accuracy: 0.9500\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0488 - accuracy: 0.9950 - val_loss: 0.2153 - val_accuracy: 0.9400\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0481 - accuracy: 0.9950 - val_loss: 0.2153 - val_accuracy: 0.9400\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0472 - accuracy: 0.9950 - val_loss: 0.2126 - val_accuracy: 0.9500\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 82us/step - loss: 0.0463 - accuracy: 0.9950 - val_loss: 0.2148 - val_accuracy: 0.9500\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0455 - accuracy: 0.9950 - val_loss: 0.2141 - val_accuracy: 0.9600\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0447 - accuracy: 0.9950 - val_loss: 0.2156 - val_accuracy: 0.9600\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0439 - accuracy: 0.9950 - val_loss: 0.2160 - val_accuracy: 0.9600\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0431 - accuracy: 0.9950 - val_loss: 0.2135 - val_accuracy: 0.9600\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0425 - accuracy: 0.9950 - val_loss: 0.2131 - val_accuracy: 0.9600\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0416 - accuracy: 0.9975 - val_loss: 0.2125 - val_accuracy: 0.9600\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0409 - accuracy: 0.9975 - val_loss: 0.2134 - val_accuracy: 0.9600\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0403 - accuracy: 0.9975 - val_loss: 0.2118 - val_accuracy: 0.9600\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0396 - accuracy: 0.9975 - val_loss: 0.2147 - val_accuracy: 0.9600\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.0389 - accuracy: 0.9975 - val_loss: 0.2128 - val_accuracy: 0.9600\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0382 - accuracy: 0.9975 - val_loss: 0.2124 - val_accuracy: 0.9600\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0376 - accuracy: 0.9975 - val_loss: 0.2104 - val_accuracy: 0.9600\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0370 - accuracy: 0.9975 - val_loss: 0.2135 - val_accuracy: 0.9600\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0365 - accuracy: 0.9975 - val_loss: 0.2140 - val_accuracy: 0.9600\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0358 - accuracy: 0.9975 - val_loss: 0.2089 - val_accuracy: 0.9600\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9600\n",
      "Epoch 134/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0346 - accuracy: 0.9975 - val_loss: 0.2100 - val_accuracy: 0.9600\n",
      "Epoch 135/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9600\n",
      "Epoch 136/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9600\n",
      "Epoch 137/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9600\n",
      "Epoch 138/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9600\n",
      "Epoch 139/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9600\n",
      "Epoch 140/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9600\n",
      "Epoch 141/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9600\n",
      "Epoch 142/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9600\n",
      "Epoch 143/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9600\n",
      "Epoch 144/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9600\n",
      "Epoch 145/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9600\n",
      "Epoch 146/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9600\n",
      "Epoch 147/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9600\n",
      "Epoch 148/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9600\n",
      "Epoch 149/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9600\n",
      "Epoch 150/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9600\n",
      "Epoch 151/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9600\n",
      "Epoch 152/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9600\n",
      "Epoch 153/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9600\n",
      "Epoch 154/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9600\n",
      "Epoch 155/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9600\n",
      "Epoch 156/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9600\n",
      "Epoch 157/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9600\n",
      "Epoch 158/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9600\n",
      "Epoch 159/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9600\n",
      "Epoch 160/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9600\n",
      "Epoch 161/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9600\n",
      "Epoch 162/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9600\n",
      "Epoch 163/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9600\n",
      "Epoch 164/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9600\n",
      "Epoch 165/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9600\n",
      "Epoch 166/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9600\n",
      "Epoch 167/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9600\n",
      "Epoch 168/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9600\n",
      "Epoch 169/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9600\n",
      "Epoch 170/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9600\n",
      "Epoch 171/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9600\n",
      "Epoch 172/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9600\n",
      "Epoch 174/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9600\n",
      "Epoch 175/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9600\n",
      "Epoch 176/1000\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9600\n",
      "Epoch 177/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9600\n",
      "Epoch 178/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9600\n",
      "Epoch 179/1000\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9600\n",
      "Epoch 180/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9600\n",
      "Epoch 181/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9600\n",
      "Epoch 182/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9600\n",
      "Epoch 183/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9600\n",
      "Epoch 184/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9600\n",
      "Epoch 185/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9600\n",
      "Epoch 186/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9600\n",
      "Epoch 187/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9600\n",
      "Epoch 188/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9600\n",
      "Epoch 189/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9600\n",
      "Epoch 190/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9600\n",
      "Epoch 191/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9600\n",
      "Epoch 192/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9600\n",
      "Epoch 193/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9600\n",
      "Epoch 194/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9600\n",
      "Epoch 195/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9600\n",
      "Epoch 196/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9600\n",
      "Epoch 197/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9600\n",
      "Epoch 198/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9600\n",
      "Epoch 199/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9600\n",
      "Epoch 200/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9600\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5969064342668755\n",
      "F1 Micro: 0.9500275123805713\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 845us/step - loss: 1.9074 - accuracy: 0.4325 - val_loss: 1.5865 - val_accuracy: 0.6200\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 1.1737 - accuracy: 0.7950 - val_loss: 0.6668 - val_accuracy: 0.8700\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.5538 - accuracy: 0.8450 - val_loss: 0.5206 - val_accuracy: 0.8600\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5179 - accuracy: 0.8475 - val_loss: 0.4943 - val_accuracy: 0.8700\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 233us/step - loss: 0.4620 - accuracy: 0.8700 - val_loss: 0.4856 - val_accuracy: 0.8700\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.4396 - accuracy: 0.8825 - val_loss: 0.4524 - val_accuracy: 0.8700\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.4219 - accuracy: 0.8900 - val_loss: 0.4376 - val_accuracy: 0.8800\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.4068 - accuracy: 0.8875 - val_loss: 0.4246 - val_accuracy: 0.8800\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.3903 - accuracy: 0.8950 - val_loss: 0.4233 - val_accuracy: 0.8800\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3782 - accuracy: 0.9000 - val_loss: 0.4055 - val_accuracy: 0.8800\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3671 - accuracy: 0.9075 - val_loss: 0.3979 - val_accuracy: 0.8800\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.3535 - accuracy: 0.9075 - val_loss: 0.3918 - val_accuracy: 0.8800\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.3487 - accuracy: 0.9050 - val_loss: 0.3796 - val_accuracy: 0.8800\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3364 - accuracy: 0.9175 - val_loss: 0.3721 - val_accuracy: 0.8800\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3250 - accuracy: 0.9175 - val_loss: 0.3634 - val_accuracy: 0.8900\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 236us/step - loss: 0.3176 - accuracy: 0.9200 - val_loss: 0.3571 - val_accuracy: 0.9000\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 238us/step - loss: 0.3109 - accuracy: 0.9225 - val_loss: 0.3506 - val_accuracy: 0.9100\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3095 - accuracy: 0.9225 - val_loss: 0.3445 - val_accuracy: 0.9200\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 236us/step - loss: 0.2968 - accuracy: 0.9225 - val_loss: 0.3373 - val_accuracy: 0.9200\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2862 - accuracy: 0.9275 - val_loss: 0.3331 - val_accuracy: 0.9400\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2801 - accuracy: 0.9275 - val_loss: 0.3245 - val_accuracy: 0.9400\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2741 - accuracy: 0.9300 - val_loss: 0.3194 - val_accuracy: 0.9500\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2669 - accuracy: 0.9300 - val_loss: 0.3151 - val_accuracy: 0.9500\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.2610 - accuracy: 0.9325 - val_loss: 0.3117 - val_accuracy: 0.9500\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2544 - accuracy: 0.9325 - val_loss: 0.3049 - val_accuracy: 0.9500\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2480 - accuracy: 0.9300 - val_loss: 0.3007 - val_accuracy: 0.9500\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.2432 - accuracy: 0.9350 - val_loss: 0.2967 - val_accuracy: 0.9500\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.2375 - accuracy: 0.9350 - val_loss: 0.2915 - val_accuracy: 0.9500\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2313 - accuracy: 0.9350 - val_loss: 0.2883 - val_accuracy: 0.9500\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.2289 - accuracy: 0.9350 - val_loss: 0.2877 - val_accuracy: 0.9500\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2241 - accuracy: 0.9400 - val_loss: 0.2842 - val_accuracy: 0.9500\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.2185 - accuracy: 0.9425 - val_loss: 0.2765 - val_accuracy: 0.9500\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.2159 - accuracy: 0.9375 - val_loss: 0.2740 - val_accuracy: 0.9500\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2117 - accuracy: 0.9425 - val_loss: 0.2730 - val_accuracy: 0.9500\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.2033 - accuracy: 0.9425 - val_loss: 0.2690 - val_accuracy: 0.9500\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1979 - accuracy: 0.9450 - val_loss: 0.2664 - val_accuracy: 0.9500\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1945 - accuracy: 0.9450 - val_loss: 0.2611 - val_accuracy: 0.9500\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1896 - accuracy: 0.9400 - val_loss: 0.2591 - val_accuracy: 0.9500\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1844 - accuracy: 0.9450 - val_loss: 0.2582 - val_accuracy: 0.9500\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1846 - accuracy: 0.9450 - val_loss: 0.2561 - val_accuracy: 0.9500\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 233us/step - loss: 0.1791 - accuracy: 0.9450 - val_loss: 0.2525 - val_accuracy: 0.9500\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1781 - accuracy: 0.9425 - val_loss: 0.2520 - val_accuracy: 0.9500\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1716 - accuracy: 0.9525 - val_loss: 0.2450 - val_accuracy: 0.9500\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1684 - accuracy: 0.9475 - val_loss: 0.2449 - val_accuracy: 0.9500\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.1610 - accuracy: 0.9525 - val_loss: 0.2443 - val_accuracy: 0.9500\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1596 - accuracy: 0.9550 - val_loss: 0.2401 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1561 - accuracy: 0.9575 - val_loss: 0.2365 - val_accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1514 - accuracy: 0.9575 - val_loss: 0.2370 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1484 - accuracy: 0.9575 - val_loss: 0.2351 - val_accuracy: 0.9500\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1440 - accuracy: 0.9575 - val_loss: 0.2315 - val_accuracy: 0.9500\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.1411 - accuracy: 0.9600 - val_loss: 0.2318 - val_accuracy: 0.9500\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 233us/step - loss: 0.1379 - accuracy: 0.9575 - val_loss: 0.2318 - val_accuracy: 0.9500\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.1349 - accuracy: 0.9650 - val_loss: 0.2265 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1320 - accuracy: 0.9625 - val_loss: 0.2256 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1311 - accuracy: 0.9650 - val_loss: 0.2237 - val_accuracy: 0.9500\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1309 - accuracy: 0.9625 - val_loss: 0.2344 - val_accuracy: 0.9600\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.1264 - accuracy: 0.9725 - val_loss: 0.2255 - val_accuracy: 0.9500\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1296 - accuracy: 0.9575 - val_loss: 0.2225 - val_accuracy: 0.9600\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1208 - accuracy: 0.9650 - val_loss: 0.2240 - val_accuracy: 0.9600\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1158 - accuracy: 0.9700 - val_loss: 0.2156 - val_accuracy: 0.9500\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1169 - accuracy: 0.9650 - val_loss: 0.2179 - val_accuracy: 0.9600\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1093 - accuracy: 0.9675 - val_loss: 0.2157 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1060 - accuracy: 0.9700 - val_loss: 0.2230 - val_accuracy: 0.9600\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1064 - accuracy: 0.9800 - val_loss: 0.2161 - val_accuracy: 0.9400\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1046 - accuracy: 0.9700 - val_loss: 0.2194 - val_accuracy: 0.9600\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1004 - accuracy: 0.9725 - val_loss: 0.2111 - val_accuracy: 0.9500\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1003 - accuracy: 0.9750 - val_loss: 0.2152 - val_accuracy: 0.9500\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0932 - accuracy: 0.9825 - val_loss: 0.2102 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0974 - accuracy: 0.9725 - val_loss: 0.2093 - val_accuracy: 0.9600\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0878 - accuracy: 0.9775 - val_loss: 0.2079 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0883 - accuracy: 0.9775 - val_loss: 0.2167 - val_accuracy: 0.9600\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0856 - accuracy: 0.9775 - val_loss: 0.2093 - val_accuracy: 0.9600\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0827 - accuracy: 0.9875 - val_loss: 0.2054 - val_accuracy: 0.9600\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0845 - accuracy: 0.9825 - val_loss: 0.2168 - val_accuracy: 0.9600\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0822 - accuracy: 0.9850 - val_loss: 0.2063 - val_accuracy: 0.9600\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0829 - accuracy: 0.9775 - val_loss: 0.2107 - val_accuracy: 0.9500\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.0775 - accuracy: 0.9850 - val_loss: 0.2092 - val_accuracy: 0.9600\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0729 - accuracy: 0.9900 - val_loss: 0.2035 - val_accuracy: 0.9600\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0709 - accuracy: 0.9900 - val_loss: 0.2040 - val_accuracy: 0.9600\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0667 - accuracy: 0.9900 - val_loss: 0.2032 - val_accuracy: 0.9600\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0663 - accuracy: 0.9850 - val_loss: 0.2031 - val_accuracy: 0.9600\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0687 - accuracy: 0.9825 - val_loss: 0.2058 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.0665 - accuracy: 0.9900 - val_loss: 0.2052 - val_accuracy: 0.9600\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.0630 - accuracy: 0.9900 - val_loss: 0.2056 - val_accuracy: 0.9600\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0597 - accuracy: 0.9925 - val_loss: 0.2043 - val_accuracy: 0.9600\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0571 - accuracy: 0.9950 - val_loss: 0.2013 - val_accuracy: 0.9600\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0543 - accuracy: 0.9950 - val_loss: 0.2008 - val_accuracy: 0.9600\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0536 - accuracy: 0.9950 - val_loss: 0.2028 - val_accuracy: 0.9600\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0508 - accuracy: 0.9950 - val_loss: 0.2005 - val_accuracy: 0.9600\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0491 - accuracy: 0.9950 - val_loss: 0.2048 - val_accuracy: 0.9600\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.0471 - accuracy: 0.9950 - val_loss: 0.2021 - val_accuracy: 0.9600\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0472 - accuracy: 0.9950 - val_loss: 0.1986 - val_accuracy: 0.9600\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0439 - accuracy: 0.9950 - val_loss: 0.2004 - val_accuracy: 0.9600\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0443 - accuracy: 0.9950 - val_loss: 0.2006 - val_accuracy: 0.9600\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.0415 - accuracy: 0.9950 - val_loss: 0.1996 - val_accuracy: 0.9600\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0410 - accuracy: 0.9950 - val_loss: 0.2008 - val_accuracy: 0.9600\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0387 - accuracy: 0.9950 - val_loss: 0.1977 - val_accuracy: 0.9600\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0367 - accuracy: 0.9950 - val_loss: 0.2005 - val_accuracy: 0.9600\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0352 - accuracy: 0.9950 - val_loss: 0.2022 - val_accuracy: 0.9600\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0401 - accuracy: 0.9950 - val_loss: 0.2004 - val_accuracy: 0.9600\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0381 - accuracy: 0.9925 - val_loss: 0.2054 - val_accuracy: 0.9600\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0328 - accuracy: 0.9950 - val_loss: 0.2006 - val_accuracy: 0.9600\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.0318 - accuracy: 0.9975 - val_loss: 0.2037 - val_accuracy: 0.9600\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0295 - accuracy: 0.9975 - val_loss: 0.1998 - val_accuracy: 0.9600\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0295 - accuracy: 0.9950 - val_loss: 0.1946 - val_accuracy: 0.9500\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9600\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9600\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0289 - accuracy: 0.9975 - val_loss: 0.1978 - val_accuracy: 0.9600\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0256 - accuracy: 0.9975 - val_loss: 0.2002 - val_accuracy: 0.9600\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9600\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9600\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0268 - accuracy: 0.9975 - val_loss: 0.1963 - val_accuracy: 0.9600\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0246 - accuracy: 0.9975 - val_loss: 0.1942 - val_accuracy: 0.9600\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9600\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9600\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9500\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9600\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9600\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9500\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9600\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9600\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9600\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9600\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9500\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9400\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9500\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9600\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9500\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9500\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9500\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9500\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9600\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5549445671739395\n",
      "F1 Micro: 0.9474263418538342\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6318040918228065\n",
      "F1 Micro: 0.9528287729478265\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6616180693117695\n",
      "F1 Micro: 0.9527287279275675\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 3 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 266us/step - loss: 0.8945 - accuracy: 0.8307 - val_loss: 0.6356 - val_accuracy: 0.8590\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.6800 - accuracy: 0.8428 - val_loss: 0.5997 - val_accuracy: 0.8590\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.6017 - accuracy: 0.8435 - val_loss: 0.5021 - val_accuracy: 0.8600\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.4632 - accuracy: 0.8745 - val_loss: 0.3618 - val_accuracy: 0.9120\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.3758 - accuracy: 0.9028 - val_loss: 0.3505 - val_accuracy: 0.9110\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.3620 - accuracy: 0.9047 - val_loss: 0.3013 - val_accuracy: 0.9190\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.3184 - accuracy: 0.9130 - val_loss: 0.2888 - val_accuracy: 0.9120\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.2974 - accuracy: 0.9160 - val_loss: 0.2734 - val_accuracy: 0.9230\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.2748 - accuracy: 0.9220 - val_loss: 0.2419 - val_accuracy: 0.9320\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.2622 - accuracy: 0.9262 - val_loss: 0.2269 - val_accuracy: 0.9330\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.2297 - accuracy: 0.9333 - val_loss: 0.2199 - val_accuracy: 0.9290\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.2160 - accuracy: 0.9365 - val_loss: 0.2317 - val_accuracy: 0.9340\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.2146 - accuracy: 0.9377 - val_loss: 0.1957 - val_accuracy: 0.9440\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1919 - accuracy: 0.9448 - val_loss: 0.1713 - val_accuracy: 0.9440\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.1837 - accuracy: 0.9450 - val_loss: 0.1832 - val_accuracy: 0.9440\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.1729 - accuracy: 0.9510 - val_loss: 0.1714 - val_accuracy: 0.9480\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1637 - accuracy: 0.9528 - val_loss: 0.1530 - val_accuracy: 0.9540\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1569 - accuracy: 0.9538 - val_loss: 0.1687 - val_accuracy: 0.9460\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1514 - accuracy: 0.9538 - val_loss: 0.1582 - val_accuracy: 0.9490\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1402 - accuracy: 0.9570 - val_loss: 0.1502 - val_accuracy: 0.9560\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.1382 - accuracy: 0.9590 - val_loss: 0.1943 - val_accuracy: 0.9430\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1377 - accuracy: 0.9565 - val_loss: 0.1436 - val_accuracy: 0.9570\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.1338 - accuracy: 0.9595 - val_loss: 0.1466 - val_accuracy: 0.9530\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1241 - accuracy: 0.9610 - val_loss: 0.1472 - val_accuracy: 0.9560\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1295 - accuracy: 0.9588 - val_loss: 0.1428 - val_accuracy: 0.9580\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1249 - accuracy: 0.9607 - val_loss: 0.1493 - val_accuracy: 0.9510\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1141 - accuracy: 0.9613 - val_loss: 0.1880 - val_accuracy: 0.9510\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1053 - accuracy: 0.9660 - val_loss: 0.1266 - val_accuracy: 0.9590\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1024 - accuracy: 0.9670 - val_loss: 0.1451 - val_accuracy: 0.9540\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1068 - accuracy: 0.9660 - val_loss: 0.1386 - val_accuracy: 0.9560\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1005 - accuracy: 0.9695 - val_loss: 0.1821 - val_accuracy: 0.9530\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0939 - accuracy: 0.9730 - val_loss: 0.1316 - val_accuracy: 0.9600\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0901 - accuracy: 0.9718 - val_loss: 0.1410 - val_accuracy: 0.9570\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0843 - accuracy: 0.9725 - val_loss: 0.1274 - val_accuracy: 0.9550\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0882 - accuracy: 0.9722 - val_loss: 0.1258 - val_accuracy: 0.9580\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0913 - accuracy: 0.9693 - val_loss: 0.1848 - val_accuracy: 0.9490\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0774 - accuracy: 0.9745 - val_loss: 0.1513 - val_accuracy: 0.9570\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0712 - accuracy: 0.9768 - val_loss: 0.1284 - val_accuracy: 0.9640\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0761 - accuracy: 0.9753 - val_loss: 0.1414 - val_accuracy: 0.9590\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0634 - accuracy: 0.9790 - val_loss: 0.1266 - val_accuracy: 0.9550\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0712 - accuracy: 0.9760 - val_loss: 0.1845 - val_accuracy: 0.9450\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0677 - accuracy: 0.9783 - val_loss: 0.1299 - val_accuracy: 0.9620\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0615 - accuracy: 0.9815 - val_loss: 0.1269 - val_accuracy: 0.9580\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0530 - accuracy: 0.9825 - val_loss: 0.1306 - val_accuracy: 0.9630\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0514 - accuracy: 0.9840 - val_loss: 0.1665 - val_accuracy: 0.9520\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0525 - accuracy: 0.9845 - val_loss: 0.1389 - val_accuracy: 0.9560\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0482 - accuracy: 0.9840 - val_loss: 0.1346 - val_accuracy: 0.9570\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0390 - accuracy: 0.9898 - val_loss: 0.2100 - val_accuracy: 0.9530\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0457 - accuracy: 0.9833 - val_loss: 0.1323 - val_accuracy: 0.9590\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0493 - accuracy: 0.9833 - val_loss: 0.1667 - val_accuracy: 0.9560\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0329 - accuracy: 0.9902 - val_loss: 0.1379 - val_accuracy: 0.9590\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0317 - accuracy: 0.9900 - val_loss: 0.1442 - val_accuracy: 0.9560\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0267 - accuracy: 0.9940 - val_loss: 0.1420 - val_accuracy: 0.9570\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.1597 - val_accuracy: 0.9520\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0347 - accuracy: 0.9902 - val_loss: 0.1590 - val_accuracy: 0.9560\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7033587195795097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Micro: 0.9607\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6842743628679948\n",
      "F1 Micro: 0.9595\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 95us/step - loss: 1.7085 - accuracy: 0.5282 - val_loss: 1.3366 - val_accuracy: 0.6750\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 1.1537 - accuracy: 0.7505 - val_loss: 0.8728 - val_accuracy: 0.8440\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.6948 - accuracy: 0.8827 - val_loss: 0.5117 - val_accuracy: 0.9120\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.4237 - accuracy: 0.9197 - val_loss: 0.3377 - val_accuracy: 0.9360\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.2961 - accuracy: 0.9405 - val_loss: 0.2520 - val_accuracy: 0.9440\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.2367 - accuracy: 0.9433 - val_loss: 0.2139 - val_accuracy: 0.9460\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.2070 - accuracy: 0.9470 - val_loss: 0.1949 - val_accuracy: 0.9470\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1884 - accuracy: 0.9507 - val_loss: 0.1813 - val_accuracy: 0.9500\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1760 - accuracy: 0.9525 - val_loss: 0.1726 - val_accuracy: 0.9510\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1669 - accuracy: 0.9540 - val_loss: 0.1634 - val_accuracy: 0.9520\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1591 - accuracy: 0.9540 - val_loss: 0.1583 - val_accuracy: 0.9530\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1534 - accuracy: 0.9557 - val_loss: 0.1538 - val_accuracy: 0.9560\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1478 - accuracy: 0.9567 - val_loss: 0.1504 - val_accuracy: 0.9580\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1433 - accuracy: 0.9578 - val_loss: 0.1470 - val_accuracy: 0.9580\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1389 - accuracy: 0.9572 - val_loss: 0.1448 - val_accuracy: 0.9580\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1354 - accuracy: 0.9595 - val_loss: 0.1426 - val_accuracy: 0.9610\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1315 - accuracy: 0.9590 - val_loss: 0.1419 - val_accuracy: 0.9580\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1277 - accuracy: 0.9615 - val_loss: 0.1397 - val_accuracy: 0.9600\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1264 - accuracy: 0.9630 - val_loss: 0.1384 - val_accuracy: 0.9600\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1224 - accuracy: 0.9640 - val_loss: 0.1384 - val_accuracy: 0.9600\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1204 - accuracy: 0.9640 - val_loss: 0.1367 - val_accuracy: 0.9610\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1169 - accuracy: 0.9660 - val_loss: 0.1366 - val_accuracy: 0.9610\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.1149 - accuracy: 0.9670 - val_loss: 0.1348 - val_accuracy: 0.9600\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1142 - accuracy: 0.9663 - val_loss: 0.1370 - val_accuracy: 0.9590\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.1105 - accuracy: 0.9682 - val_loss: 0.1349 - val_accuracy: 0.9580\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1088 - accuracy: 0.9688 - val_loss: 0.1352 - val_accuracy: 0.9590\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1068 - accuracy: 0.9690 - val_loss: 0.1334 - val_accuracy: 0.9580\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1046 - accuracy: 0.9700 - val_loss: 0.1334 - val_accuracy: 0.9590\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1036 - accuracy: 0.9703 - val_loss: 0.1323 - val_accuracy: 0.9560\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1016 - accuracy: 0.9712 - val_loss: 0.1337 - val_accuracy: 0.9550\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1000 - accuracy: 0.9725 - val_loss: 0.1324 - val_accuracy: 0.9570\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0986 - accuracy: 0.9735 - val_loss: 0.1343 - val_accuracy: 0.9560\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0969 - accuracy: 0.9737 - val_loss: 0.1306 - val_accuracy: 0.9570\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0954 - accuracy: 0.9743 - val_loss: 0.1322 - val_accuracy: 0.9580\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0940 - accuracy: 0.9743 - val_loss: 0.1315 - val_accuracy: 0.9570\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0923 - accuracy: 0.9758 - val_loss: 0.1346 - val_accuracy: 0.9570\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0920 - accuracy: 0.9750 - val_loss: 0.1307 - val_accuracy: 0.9570\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0904 - accuracy: 0.9768 - val_loss: 0.1308 - val_accuracy: 0.9570\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0889 - accuracy: 0.9758 - val_loss: 0.1312 - val_accuracy: 0.9570\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0878 - accuracy: 0.9787 - val_loss: 0.1300 - val_accuracy: 0.9590\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0871 - accuracy: 0.9770 - val_loss: 0.1322 - val_accuracy: 0.9560\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0859 - accuracy: 0.9775 - val_loss: 0.1318 - val_accuracy: 0.9560\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0847 - accuracy: 0.9780 - val_loss: 0.1292 - val_accuracy: 0.9590\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0835 - accuracy: 0.9780 - val_loss: 0.1301 - val_accuracy: 0.9580\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0825 - accuracy: 0.9785 - val_loss: 0.1314 - val_accuracy: 0.9560\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0812 - accuracy: 0.9780 - val_loss: 0.1308 - val_accuracy: 0.9580\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0805 - accuracy: 0.9790 - val_loss: 0.1319 - val_accuracy: 0.9560\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0797 - accuracy: 0.9793 - val_loss: 0.1328 - val_accuracy: 0.9540\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0777 - accuracy: 0.9803 - val_loss: 0.1306 - val_accuracy: 0.9590\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0768 - accuracy: 0.9800 - val_loss: 0.1323 - val_accuracy: 0.9550\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0775 - accuracy: 0.9790 - val_loss: 0.1304 - val_accuracy: 0.9590\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0757 - accuracy: 0.9812 - val_loss: 0.1363 - val_accuracy: 0.9510\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0748 - accuracy: 0.9808 - val_loss: 0.1316 - val_accuracy: 0.9570\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0735 - accuracy: 0.9815 - val_loss: 0.1323 - val_accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0726 - accuracy: 0.9808 - val_loss: 0.1339 - val_accuracy: 0.9550\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0722 - accuracy: 0.9805 - val_loss: 0.1328 - val_accuracy: 0.9560\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0710 - accuracy: 0.9812 - val_loss: 0.1326 - val_accuracy: 0.9570\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0700 - accuracy: 0.9812 - val_loss: 0.1345 - val_accuracy: 0.9540\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0695 - accuracy: 0.9812 - val_loss: 0.1342 - val_accuracy: 0.9540\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.98 - 0s 71us/step - loss: 0.0681 - accuracy: 0.9827 - val_loss: 0.1341 - val_accuracy: 0.9520\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0672 - accuracy: 0.9827 - val_loss: 0.1350 - val_accuracy: 0.9550\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0669 - accuracy: 0.9822 - val_loss: 0.1374 - val_accuracy: 0.9520\n",
      "Epoch 63/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0656 - accuracy: 0.9827 - val_loss: 0.1352 - val_accuracy: 0.9540\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.769637127038968\n",
      "F1 Micro: 0.9635\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 257us/step - loss: 0.6405 - accuracy: 0.8450 - val_loss: 0.3586 - val_accuracy: 0.9080\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.3386 - accuracy: 0.9087 - val_loss: 0.2849 - val_accuracy: 0.9270\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.2743 - accuracy: 0.9260 - val_loss: 0.2487 - val_accuracy: 0.9380\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.2361 - accuracy: 0.9335 - val_loss: 0.2263 - val_accuracy: 0.9440\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.2139 - accuracy: 0.9405 - val_loss: 0.2056 - val_accuracy: 0.9450\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1956 - accuracy: 0.9433 - val_loss: 0.1939 - val_accuracy: 0.9470\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1829 - accuracy: 0.9473 - val_loss: 0.1987 - val_accuracy: 0.9440\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.1754 - accuracy: 0.9503 - val_loss: 0.1791 - val_accuracy: 0.9450\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1645 - accuracy: 0.9520 - val_loss: 0.1765 - val_accuracy: 0.9500\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1580 - accuracy: 0.9538 - val_loss: 0.1662 - val_accuracy: 0.9460\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1494 - accuracy: 0.9553 - val_loss: 0.1637 - val_accuracy: 0.9480\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1466 - accuracy: 0.9557 - val_loss: 0.1599 - val_accuracy: 0.9510\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.1436 - accuracy: 0.9585 - val_loss: 0.1640 - val_accuracy: 0.9510\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1349 - accuracy: 0.9588 - val_loss: 0.1558 - val_accuracy: 0.9540\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1324 - accuracy: 0.9597 - val_loss: 0.1540 - val_accuracy: 0.9550\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1267 - accuracy: 0.9628 - val_loss: 0.1560 - val_accuracy: 0.9560\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1203 - accuracy: 0.9628 - val_loss: 0.1455 - val_accuracy: 0.9570\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1163 - accuracy: 0.9663 - val_loss: 0.1485 - val_accuracy: 0.9560\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1107 - accuracy: 0.9675 - val_loss: 0.1495 - val_accuracy: 0.9590\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1085 - accuracy: 0.9680 - val_loss: 0.1436 - val_accuracy: 0.9570\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1036 - accuracy: 0.9695 - val_loss: 0.1391 - val_accuracy: 0.9580\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0981 - accuracy: 0.9720 - val_loss: 0.1500 - val_accuracy: 0.9560\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1013 - accuracy: 0.9695 - val_loss: 0.1393 - val_accuracy: 0.9590\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0972 - accuracy: 0.9707 - val_loss: 0.1488 - val_accuracy: 0.9570\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0874 - accuracy: 0.9747 - val_loss: 0.1345 - val_accuracy: 0.9610\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0839 - accuracy: 0.9747 - val_loss: 0.1334 - val_accuracy: 0.9590\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0773 - accuracy: 0.9772 - val_loss: 0.1313 - val_accuracy: 0.9590\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.0722 - accuracy: 0.9797 - val_loss: 0.1317 - val_accuracy: 0.9530\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0652 - accuracy: 0.9820 - val_loss: 0.1378 - val_accuracy: 0.9530\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 211us/step - loss: 0.0598 - accuracy: 0.9827 - val_loss: 0.1274 - val_accuracy: 0.9520\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0561 - accuracy: 0.9840 - val_loss: 0.1511 - val_accuracy: 0.9570\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0508 - accuracy: 0.9847 - val_loss: 0.1279 - val_accuracy: 0.9620\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0425 - accuracy: 0.9900 - val_loss: 0.1268 - val_accuracy: 0.9630\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0368 - accuracy: 0.9908 - val_loss: 0.1278 - val_accuracy: 0.9610\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0344 - accuracy: 0.9933 - val_loss: 0.1198 - val_accuracy: 0.9630\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.0310 - accuracy: 0.9937 - val_loss: 0.1270 - val_accuracy: 0.9590\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.0254 - accuracy: 0.9958 - val_loss: 0.1255 - val_accuracy: 0.9630\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.0228 - accuracy: 0.9970 - val_loss: 0.1306 - val_accuracy: 0.9650\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.0233 - accuracy: 0.9958 - val_loss: 0.1359 - val_accuracy: 0.9630\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0177 - accuracy: 0.9977 - val_loss: 0.1335 - val_accuracy: 0.9630\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0154 - accuracy: 0.9987 - val_loss: 0.1268 - val_accuracy: 0.9630\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0130 - accuracy: 0.9992 - val_loss: 0.1452 - val_accuracy: 0.9580\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0108 - accuracy: 0.9998 - val_loss: 0.1366 - val_accuracy: 0.9620\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0103 - accuracy: 0.9998 - val_loss: 0.1387 - val_accuracy: 0.9630\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9620\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0082 - accuracy: 0.9998 - val_loss: 0.1815 - val_accuracy: 0.9590\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9650\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9600\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9630\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9640\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9650\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9650\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9630\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9620\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9630\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.756893903593168\n",
      "F1 Micro: 0.9632\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.723122349507866\n",
      "F1 Micro: 0.9611\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7725600380138505\n",
      "F1 Micro: 0.966\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 3 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.4131 - accuracy: 0.9000 - val_loss: 0.2196 - val_accuracy: 0.9389\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.1854 - accuracy: 0.9467 - val_loss: 0.1578 - val_accuracy: 0.9527\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.1445 - accuracy: 0.9557 - val_loss: 0.1502 - val_accuracy: 0.9534\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1272 - accuracy: 0.9614 - val_loss: 0.1207 - val_accuracy: 0.9628\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1166 - accuracy: 0.9641 - val_loss: 0.1108 - val_accuracy: 0.9655\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1087 - accuracy: 0.9662 - val_loss: 0.1100 - val_accuracy: 0.9640\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1001 - accuracy: 0.9683 - val_loss: 0.1165 - val_accuracy: 0.9626\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0955 - accuracy: 0.9697 - val_loss: 0.0983 - val_accuracy: 0.9673\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0894 - accuracy: 0.9717 - val_loss: 0.1069 - val_accuracy: 0.9657\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0836 - accuracy: 0.9737 - val_loss: 0.1032 - val_accuracy: 0.9673\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0818 - accuracy: 0.9736 - val_loss: 0.0982 - val_accuracy: 0.9669\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0759 - accuracy: 0.9750 - val_loss: 0.1082 - val_accuracy: 0.9628\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0731 - accuracy: 0.9756 - val_loss: 0.0976 - val_accuracy: 0.9703\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0680 - accuracy: 0.9777 - val_loss: 0.0872 - val_accuracy: 0.9709\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0638 - accuracy: 0.9791 - val_loss: 0.0870 - val_accuracy: 0.9711\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0600 - accuracy: 0.9801 - val_loss: 0.1039 - val_accuracy: 0.9642\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0553 - accuracy: 0.9809 - val_loss: 0.0896 - val_accuracy: 0.9679\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0505 - accuracy: 0.9826 - val_loss: 0.0896 - val_accuracy: 0.9713\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0464 - accuracy: 0.9839 - val_loss: 0.1044 - val_accuracy: 0.9691\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0441 - accuracy: 0.9854 - val_loss: 0.0899 - val_accuracy: 0.9701\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0368 - accuracy: 0.9875 - val_loss: 0.0919 - val_accuracy: 0.9684\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0323 - accuracy: 0.9895 - val_loss: 0.0979 - val_accuracy: 0.9708\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0288 - accuracy: 0.9903 - val_loss: 0.1582 - val_accuracy: 0.9661\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.1100 - val_accuracy: 0.9693\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.1177 - val_accuracy: 0.9699\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.1197 - val_accuracy: 0.9705\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.1596 - val_accuracy: 0.9690\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.1273 - val_accuracy: 0.9710\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1151 - val_accuracy: 0.9723\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.1681 - val_accuracy: 0.9686\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.1661 - val_accuracy: 0.9587\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.1426 - val_accuracy: 0.9679\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.1383 - val_accuracy: 0.9697\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1493 - val_accuracy: 0.9707\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.1735 - val_accuracy: 0.9697\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8203644634574906\n",
      "F1 Micro: 0.9746\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.819648864237233\n",
      "F1 Micro: 0.9701\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.5126 - accuracy: 0.8823 - val_loss: 0.1633 - val_accuracy: 0.9520\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1436 - accuracy: 0.9575 - val_loss: 0.1369 - val_accuracy: 0.9570\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1269 - accuracy: 0.9615 - val_loss: 0.1259 - val_accuracy: 0.9593\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1183 - accuracy: 0.9633 - val_loss: 0.1202 - val_accuracy: 0.9623\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.1125 - accuracy: 0.9649 - val_loss: 0.1165 - val_accuracy: 0.9638\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.1080 - accuracy: 0.9659 - val_loss: 0.1130 - val_accuracy: 0.9642\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1043 - accuracy: 0.9672 - val_loss: 0.1113 - val_accuracy: 0.9644\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.1011 - accuracy: 0.9680 - val_loss: 0.1072 - val_accuracy: 0.9664\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0986 - accuracy: 0.9688 - val_loss: 0.1117 - val_accuracy: 0.9642\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0961 - accuracy: 0.9693 - val_loss: 0.1034 - val_accuracy: 0.9670\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0939 - accuracy: 0.9702 - val_loss: 0.1025 - val_accuracy: 0.9668\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0919 - accuracy: 0.9705 - val_loss: 0.1029 - val_accuracy: 0.9682\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0904 - accuracy: 0.9716 - val_loss: 0.1011 - val_accuracy: 0.9683\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0887 - accuracy: 0.9715 - val_loss: 0.1012 - val_accuracy: 0.9676\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0873 - accuracy: 0.9724 - val_loss: 0.1007 - val_accuracy: 0.9675\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0861 - accuracy: 0.9725 - val_loss: 0.0983 - val_accuracy: 0.9679\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0847 - accuracy: 0.9727 - val_loss: 0.0987 - val_accuracy: 0.9670\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0835 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9688\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0819 - accuracy: 0.9741 - val_loss: 0.0978 - val_accuracy: 0.9684\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0811 - accuracy: 0.9740 - val_loss: 0.0971 - val_accuracy: 0.9692\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0801 - accuracy: 0.9745 - val_loss: 0.0958 - val_accuracy: 0.9688\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0789 - accuracy: 0.9750 - val_loss: 0.0976 - val_accuracy: 0.9683\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0780 - accuracy: 0.9752 - val_loss: 0.0970 - val_accuracy: 0.9691\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0771 - accuracy: 0.9758 - val_loss: 0.0959 - val_accuracy: 0.9682\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0759 - accuracy: 0.9757 - val_loss: 0.0955 - val_accuracy: 0.9691\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0750 - accuracy: 0.9761 - val_loss: 0.0962 - val_accuracy: 0.9690\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0741 - accuracy: 0.9773 - val_loss: 0.0951 - val_accuracy: 0.9689\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0731 - accuracy: 0.9768 - val_loss: 0.0953 - val_accuracy: 0.9678\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0725 - accuracy: 0.9772 - val_loss: 0.0953 - val_accuracy: 0.9683\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0716 - accuracy: 0.9771 - val_loss: 0.0955 - val_accuracy: 0.9695\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0709 - accuracy: 0.9775 - val_loss: 0.0961 - val_accuracy: 0.9677\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0699 - accuracy: 0.9777 - val_loss: 0.0960 - val_accuracy: 0.9691\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0690 - accuracy: 0.9780 - val_loss: 0.0945 - val_accuracy: 0.9680\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0685 - accuracy: 0.9786 - val_loss: 0.0948 - val_accuracy: 0.9688\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0677 - accuracy: 0.9787 - val_loss: 0.0946 - val_accuracy: 0.9696\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0668 - accuracy: 0.9790 - val_loss: 0.0938 - val_accuracy: 0.9701\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0663 - accuracy: 0.9793 - val_loss: 0.0953 - val_accuracy: 0.9688\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0653 - accuracy: 0.9799 - val_loss: 0.0962 - val_accuracy: 0.9683\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0647 - accuracy: 0.9796 - val_loss: 0.0950 - val_accuracy: 0.9693\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0643 - accuracy: 0.9794 - val_loss: 0.0948 - val_accuracy: 0.9693\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0633 - accuracy: 0.9798 - val_loss: 0.0949 - val_accuracy: 0.9687\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0624 - accuracy: 0.9803 - val_loss: 0.0946 - val_accuracy: 0.9689\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0619 - accuracy: 0.9808 - val_loss: 0.0954 - val_accuracy: 0.9685\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0612 - accuracy: 0.9812 - val_loss: 0.0955 - val_accuracy: 0.9685\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0608 - accuracy: 0.9808 - val_loss: 0.0960 - val_accuracy: 0.9685\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0599 - accuracy: 0.9813 - val_loss: 0.0950 - val_accuracy: 0.9685\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0593 - accuracy: 0.9814 - val_loss: 0.0946 - val_accuracy: 0.9694\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0587 - accuracy: 0.9815 - val_loss: 0.0963 - val_accuracy: 0.9688\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0579 - accuracy: 0.9819 - val_loss: 0.0966 - val_accuracy: 0.9686\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0574 - accuracy: 0.9815 - val_loss: 0.0952 - val_accuracy: 0.9689\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0564 - accuracy: 0.9827 - val_loss: 0.0951 - val_accuracy: 0.9685\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0560 - accuracy: 0.9822 - val_loss: 0.0966 - val_accuracy: 0.9688\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0555 - accuracy: 0.9831 - val_loss: 0.0963 - val_accuracy: 0.9684\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0550 - accuracy: 0.9828 - val_loss: 0.0952 - val_accuracy: 0.9691\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0541 - accuracy: 0.9833 - val_loss: 0.0955 - val_accuracy: 0.9690\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0538 - accuracy: 0.9835 - val_loss: 0.0967 - val_accuracy: 0.9683\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8563708433960371\n",
      "F1 Micro: 0.9734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.2576 - accuracy: 0.9298 - val_loss: 0.1661 - val_accuracy: 0.9517\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.1429 - accuracy: 0.9566 - val_loss: 0.1311 - val_accuracy: 0.9593\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.1222 - accuracy: 0.9628 - val_loss: 0.1181 - val_accuracy: 0.9631\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.1115 - accuracy: 0.9656 - val_loss: 0.1095 - val_accuracy: 0.9652\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.1039 - accuracy: 0.9668 - val_loss: 0.1063 - val_accuracy: 0.9656\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0988 - accuracy: 0.9688 - val_loss: 0.1072 - val_accuracy: 0.9643\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.0927 - accuracy: 0.9705 - val_loss: 0.0966 - val_accuracy: 0.9673\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0875 - accuracy: 0.9719 - val_loss: 0.0945 - val_accuracy: 0.9684\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0823 - accuracy: 0.9733 - val_loss: 0.0950 - val_accuracy: 0.9681\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0775 - accuracy: 0.9746 - val_loss: 0.0892 - val_accuracy: 0.9709\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0725 - accuracy: 0.9764 - val_loss: 0.0893 - val_accuracy: 0.9712\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0679 - accuracy: 0.9770 - val_loss: 0.0909 - val_accuracy: 0.9696\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0628 - accuracy: 0.9792 - val_loss: 0.0923 - val_accuracy: 0.9706\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0582 - accuracy: 0.9808 - val_loss: 0.0876 - val_accuracy: 0.9719\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0510 - accuracy: 0.9838 - val_loss: 0.0869 - val_accuracy: 0.9719\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.0453 - accuracy: 0.9854 - val_loss: 0.0913 - val_accuracy: 0.9707\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.0397 - accuracy: 0.9870 - val_loss: 0.0916 - val_accuracy: 0.9705\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0331 - accuracy: 0.9894 - val_loss: 0.0979 - val_accuracy: 0.9696\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.1017 - val_accuracy: 0.9712\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 0.1256 - val_accuracy: 0.9701\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.1140 - val_accuracy: 0.9708\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.1219 - val_accuracy: 0.9703\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.1417 - val_accuracy: 0.9703\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.1357 - val_accuracy: 0.9696\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1725 - val_accuracy: 0.9692\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.1195 - val_accuracy: 0.9717\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.1398 - val_accuracy: 0.9707\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1442 - val_accuracy: 0.9687\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.1643 - val_accuracy: 0.9711\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1582 - val_accuracy: 0.9717\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.1573 - val_accuracy: 0.9656\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.1631 - val_accuracy: 0.9709\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 5.6903e-04 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9707\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1523 - val_accuracy: 0.9694\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1603 - val_accuracy: 0.9702\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8565044146116948\n",
      "F1 Micro: 0.9744\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8178014969854631\n",
      "F1 Micro: 0.968\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8772577970956021\n",
      "F1 Micro: 0.9778\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 3 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.2481 - accuracy: 0.9338 - val_loss: 0.1476 - val_accuracy: 0.9553\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.1201 - accuracy: 0.9625 - val_loss: 0.1007 - val_accuracy: 0.9679\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.1015 - accuracy: 0.9679 - val_loss: 0.1029 - val_accuracy: 0.9691\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0903 - accuracy: 0.9707 - val_loss: 0.0827 - val_accuracy: 0.9732\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0810 - accuracy: 0.9734 - val_loss: 0.0897 - val_accuracy: 0.9690\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 25s 196us/step - loss: 0.0734 - accuracy: 0.9752 - val_loss: 0.0806 - val_accuracy: 0.9726\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0681 - accuracy: 0.9770 - val_loss: 0.0736 - val_accuracy: 0.9744\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0630 - accuracy: 0.9783 - val_loss: 0.0654 - val_accuracy: 0.9780\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0580 - accuracy: 0.9799 - val_loss: 0.0718 - val_accuracy: 0.9757\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.0723 - val_accuracy: 0.9752\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0500 - accuracy: 0.9825 - val_loss: 0.0708 - val_accuracy: 0.9759\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0464 - accuracy: 0.9833 - val_loss: 0.0710 - val_accuracy: 0.9755\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0423 - accuracy: 0.9846 - val_loss: 0.0716 - val_accuracy: 0.9773\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0387 - accuracy: 0.9860 - val_loss: 0.0707 - val_accuracy: 0.9774\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0349 - accuracy: 0.9877 - val_loss: 0.0713 - val_accuracy: 0.9766\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0306 - accuracy: 0.9889 - val_loss: 0.0690 - val_accuracy: 0.9780\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0265 - accuracy: 0.9905 - val_loss: 0.0790 - val_accuracy: 0.9766\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.0762 - val_accuracy: 0.9773\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0200 - accuracy: 0.9929 - val_loss: 0.0832 - val_accuracy: 0.9763\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 0.1006 - val_accuracy: 0.9771\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 0.0962 - val_accuracy: 0.9768\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.1019 - val_accuracy: 0.9766\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.1091 - val_accuracy: 0.9771\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.1133 - val_accuracy: 0.9770\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.1040 - val_accuracy: 0.9774\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.1141 - val_accuracy: 0.9765\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.1151 - val_accuracy: 0.9779\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1229 - val_accuracy: 0.9768\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8814560524719678\n",
      "F1 Micro: 0.9793\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8406538824192702\n",
      "F1 Micro: 0.9725\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.2529 - accuracy: 0.9360 - val_loss: 0.1200 - val_accuracy: 0.9631\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.1139 - accuracy: 0.9648 - val_loss: 0.1069 - val_accuracy: 0.9668\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.1044 - accuracy: 0.9671 - val_loss: 0.1012 - val_accuracy: 0.9682\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0990 - accuracy: 0.9689 - val_loss: 0.0976 - val_accuracy: 0.9701\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0951 - accuracy: 0.9699 - val_loss: 0.0950 - val_accuracy: 0.9706\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0920 - accuracy: 0.9709 - val_loss: 0.0925 - val_accuracy: 0.9715\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0896 - accuracy: 0.9712 - val_loss: 0.0919 - val_accuracy: 0.9712\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0874 - accuracy: 0.9723 - val_loss: 0.0899 - val_accuracy: 0.9720\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0855 - accuracy: 0.9724 - val_loss: 0.0902 - val_accuracy: 0.9713\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0838 - accuracy: 0.9733 - val_loss: 0.0887 - val_accuracy: 0.9721\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0822 - accuracy: 0.9738 - val_loss: 0.0874 - val_accuracy: 0.9730\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0807 - accuracy: 0.9742 - val_loss: 0.0875 - val_accuracy: 0.9716\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0796 - accuracy: 0.9745 - val_loss: 0.0869 - val_accuracy: 0.9721\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0785 - accuracy: 0.9747 - val_loss: 0.0860 - val_accuracy: 0.9732\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0773 - accuracy: 0.9751 - val_loss: 0.0841 - val_accuracy: 0.9737\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0763 - accuracy: 0.9754 - val_loss: 0.0838 - val_accuracy: 0.9729\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0752 - accuracy: 0.9757 - val_loss: 0.0839 - val_accuracy: 0.9731\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0742 - accuracy: 0.9761 - val_loss: 0.0840 - val_accuracy: 0.9729\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0734 - accuracy: 0.9762 - val_loss: 0.0829 - val_accuracy: 0.9732\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0725 - accuracy: 0.9763 - val_loss: 0.0821 - val_accuracy: 0.9733\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0716 - accuracy: 0.9767 - val_loss: 0.0828 - val_accuracy: 0.9729\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0707 - accuracy: 0.9771 - val_loss: 0.0825 - val_accuracy: 0.9730\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0698 - accuracy: 0.9774 - val_loss: 0.0819 - val_accuracy: 0.9736\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0692 - accuracy: 0.9776 - val_loss: 0.0810 - val_accuracy: 0.9742\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0684 - accuracy: 0.9780 - val_loss: 0.0835 - val_accuracy: 0.9734\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0677 - accuracy: 0.9780 - val_loss: 0.0826 - val_accuracy: 0.9728\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0669 - accuracy: 0.9782 - val_loss: 0.0823 - val_accuracy: 0.9737\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0662 - accuracy: 0.9785 - val_loss: 0.0811 - val_accuracy: 0.9738\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0655 - accuracy: 0.9789 - val_loss: 0.0823 - val_accuracy: 0.9735\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0649 - accuracy: 0.9791 - val_loss: 0.0810 - val_accuracy: 0.9740\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0641 - accuracy: 0.9792 - val_loss: 0.0811 - val_accuracy: 0.9741\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0634 - accuracy: 0.9797 - val_loss: 0.0822 - val_accuracy: 0.9738\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0628 - accuracy: 0.9795 - val_loss: 0.0816 - val_accuracy: 0.9743\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0625 - accuracy: 0.9798 - val_loss: 0.0812 - val_accuracy: 0.9744\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0617 - accuracy: 0.9804 - val_loss: 0.0825 - val_accuracy: 0.9743\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0611 - accuracy: 0.9804 - val_loss: 0.0809 - val_accuracy: 0.9736\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0603 - accuracy: 0.9806 - val_loss: 0.0815 - val_accuracy: 0.9745\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0598 - accuracy: 0.9808 - val_loss: 0.0812 - val_accuracy: 0.9748\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0593 - accuracy: 0.9806 - val_loss: 0.0827 - val_accuracy: 0.9736\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0587 - accuracy: 0.9813 - val_loss: 0.0815 - val_accuracy: 0.9744\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0581 - accuracy: 0.9815 - val_loss: 0.0804 - val_accuracy: 0.9748\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0577 - accuracy: 0.9816 - val_loss: 0.0811 - val_accuracy: 0.9744\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0570 - accuracy: 0.9817 - val_loss: 0.0820 - val_accuracy: 0.9745\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0565 - accuracy: 0.9819 - val_loss: 0.0829 - val_accuracy: 0.9741\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0560 - accuracy: 0.9818 - val_loss: 0.0827 - val_accuracy: 0.9736\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0553 - accuracy: 0.9823 - val_loss: 0.0825 - val_accuracy: 0.9740\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0546 - accuracy: 0.9825 - val_loss: 0.0831 - val_accuracy: 0.9735\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0542 - accuracy: 0.9824 - val_loss: 0.0845 - val_accuracy: 0.9735\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0537 - accuracy: 0.9830 - val_loss: 0.0831 - val_accuracy: 0.9739\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0533 - accuracy: 0.9828 - val_loss: 0.0840 - val_accuracy: 0.9734\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0525 - accuracy: 0.9831 - val_loss: 0.0832 - val_accuracy: 0.9742\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0521 - accuracy: 0.9830 - val_loss: 0.0840 - val_accuracy: 0.9743\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0515 - accuracy: 0.9834 - val_loss: 0.0834 - val_accuracy: 0.9744\n",
      "Epoch 54/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0512 - accuracy: 0.9836 - val_loss: 0.0827 - val_accuracy: 0.9739\n",
      "Epoch 55/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0506 - accuracy: 0.9839 - val_loss: 0.0851 - val_accuracy: 0.9736\n",
      "Epoch 56/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0500 - accuracy: 0.9839 - val_loss: 0.0843 - val_accuracy: 0.9737\n",
      "Epoch 57/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0496 - accuracy: 0.9842 - val_loss: 0.0841 - val_accuracy: 0.9735\n",
      "Epoch 58/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0491 - accuracy: 0.9841 - val_loss: 0.0841 - val_accuracy: 0.9737\n",
      "Epoch 59/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0486 - accuracy: 0.9844 - val_loss: 0.0849 - val_accuracy: 0.9732\n",
      "Epoch 60/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0481 - accuracy: 0.9848 - val_loss: 0.0847 - val_accuracy: 0.9738\n",
      "Epoch 61/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0476 - accuracy: 0.9848 - val_loss: 0.0862 - val_accuracy: 0.9727\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8906656447859552\n",
      "F1 Micro: 0.9775\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.1729 - accuracy: 0.9499 - val_loss: 0.1149 - val_accuracy: 0.9641\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.1095 - accuracy: 0.9656 - val_loss: 0.1056 - val_accuracy: 0.9665\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0972 - accuracy: 0.9692 - val_loss: 0.0940 - val_accuracy: 0.9690\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0852 - accuracy: 0.9722 - val_loss: 0.0918 - val_accuracy: 0.9711\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0768 - accuracy: 0.9750 - val_loss: 0.0803 - val_accuracy: 0.9732\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0700 - accuracy: 0.9767 - val_loss: 0.0760 - val_accuracy: 0.9741\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 27s 203us/step - loss: 0.0640 - accuracy: 0.9788 - val_loss: 0.0740 - val_accuracy: 0.9749\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0584 - accuracy: 0.9803 - val_loss: 0.0675 - val_accuracy: 0.9777\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0524 - accuracy: 0.9825 - val_loss: 0.0711 - val_accuracy: 0.9758\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0465 - accuracy: 0.9841 - val_loss: 0.0754 - val_accuracy: 0.9764\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0400 - accuracy: 0.9862 - val_loss: 0.0715 - val_accuracy: 0.9774\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0333 - accuracy: 0.9889 - val_loss: 0.0784 - val_accuracy: 0.9770\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.0850 - val_accuracy: 0.9763\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.0782 - val_accuracy: 0.9772\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.1007 - val_accuracy: 0.9767\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.1003 - val_accuracy: 0.9766\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.1123 - val_accuracy: 0.9773\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 27s 203us/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1018 - val_accuracy: 0.9768\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1100 - val_accuracy: 0.9741\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1130 - val_accuracy: 0.9774\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.1200 - val_accuracy: 0.9754\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.1297 - val_accuracy: 0.9743\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.1340 - val_accuracy: 0.9772\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.1258 - val_accuracy: 0.9764\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1282 - val_accuracy: 0.9762\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1335 - val_accuracy: 0.9759\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1450 - val_accuracy: 0.9769\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1425 - val_accuracy: 0.9724\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8836082212290406\n",
      "F1 Micro: 0.9787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.845446967931106\n",
      "F1 Micro: 0.9712\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.9109677123333252\n",
      "F1 Micro: 0.9817\n",
      "\n",
      "\n",
      " 53.53215571641922 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 4 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 4 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 2.0216 - accuracy: 0.6950 - val_loss: 1.6689 - val_accuracy: 0.8700\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 1.2353 - accuracy: 0.8375 - val_loss: 0.7247 - val_accuracy: 0.8700\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.8114 - accuracy: 0.8375 - val_loss: 0.7187 - val_accuracy: 0.8700\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.7674 - accuracy: 0.8375 - val_loss: 0.7239 - val_accuracy: 0.8700\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.7455 - accuracy: 0.8375 - val_loss: 0.7193 - val_accuracy: 0.8700\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.7301 - accuracy: 0.8375 - val_loss: 0.7104 - val_accuracy: 0.8700\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.7223 - accuracy: 0.8375 - val_loss: 0.7150 - val_accuracy: 0.8700\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.7165 - accuracy: 0.8375 - val_loss: 0.7180 - val_accuracy: 0.8700\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.7109 - accuracy: 0.8375 - val_loss: 0.7065 - val_accuracy: 0.8700\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.7026 - accuracy: 0.8375 - val_loss: 0.7076 - val_accuracy: 0.8700\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.7037 - accuracy: 0.8375 - val_loss: 0.7003 - val_accuracy: 0.8700\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6994 - accuracy: 0.8375 - val_loss: 0.6940 - val_accuracy: 0.8700\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.6935 - accuracy: 0.8375 - val_loss: 0.6994 - val_accuracy: 0.8700\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.6891 - accuracy: 0.8375 - val_loss: 0.6897 - val_accuracy: 0.8700\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.6890 - accuracy: 0.8375 - val_loss: 0.6888 - val_accuracy: 0.8700\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6903 - accuracy: 0.8375 - val_loss: 0.6843 - val_accuracy: 0.8700\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6773 - accuracy: 0.8375 - val_loss: 0.6767 - val_accuracy: 0.8700\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6730 - accuracy: 0.8375 - val_loss: 0.6718 - val_accuracy: 0.8700\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.6703 - accuracy: 0.8375 - val_loss: 0.6617 - val_accuracy: 0.8700\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6641 - accuracy: 0.8375 - val_loss: 0.6577 - val_accuracy: 0.8700\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.6521 - accuracy: 0.8375 - val_loss: 0.6458 - val_accuracy: 0.8700\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.6416 - accuracy: 0.8375 - val_loss: 0.6419 - val_accuracy: 0.8700\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.6349 - accuracy: 0.8375 - val_loss: 0.6258 - val_accuracy: 0.8700\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6178 - accuracy: 0.8375 - val_loss: 0.6072 - val_accuracy: 0.8700\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6251 - accuracy: 0.8350 - val_loss: 0.6024 - val_accuracy: 0.8700\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.5862 - accuracy: 0.8350 - val_loss: 0.5792 - val_accuracy: 0.8700\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.5788 - accuracy: 0.8375 - val_loss: 0.5714 - val_accuracy: 0.8700\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.5670 - accuracy: 0.8375 - val_loss: 0.5646 - val_accuracy: 0.8700\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.5766 - accuracy: 0.8475 - val_loss: 0.5463 - val_accuracy: 0.8600\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.5443 - accuracy: 0.8400 - val_loss: 0.5437 - val_accuracy: 0.8600\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.5143 - accuracy: 0.8450 - val_loss: 0.5292 - val_accuracy: 0.8700\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.5037 - accuracy: 0.8550 - val_loss: 0.5354 - val_accuracy: 0.8700\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.4901 - accuracy: 0.8575 - val_loss: 0.5452 - val_accuracy: 0.8800\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.4892 - accuracy: 0.8675 - val_loss: 0.5222 - val_accuracy: 0.8800\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.4573 - accuracy: 0.8825 - val_loss: 0.5137 - val_accuracy: 0.8800\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.4515 - accuracy: 0.8875 - val_loss: 0.5094 - val_accuracy: 0.8800\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.4453 - accuracy: 0.8900 - val_loss: 0.5089 - val_accuracy: 0.8800\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.4645 - accuracy: 0.8775 - val_loss: 0.5081 - val_accuracy: 0.8800\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.4259 - accuracy: 0.8825 - val_loss: 0.5005 - val_accuracy: 0.8800\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.4058 - accuracy: 0.9000 - val_loss: 0.4945 - val_accuracy: 0.8800\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.4006 - accuracy: 0.9025 - val_loss: 0.4981 - val_accuracy: 0.8800\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.4009 - accuracy: 0.8975 - val_loss: 0.4958 - val_accuracy: 0.8800\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.3797 - accuracy: 0.9075 - val_loss: 0.4899 - val_accuracy: 0.8800\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.3783 - accuracy: 0.9000 - val_loss: 0.4804 - val_accuracy: 0.8800\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.3706 - accuracy: 0.9075 - val_loss: 0.5008 - val_accuracy: 0.8800\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.3663 - accuracy: 0.9000 - val_loss: 0.4885 - val_accuracy: 0.8800\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.3899 - accuracy: 0.9050 - val_loss: 0.4730 - val_accuracy: 0.8800\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.4480 - accuracy: 0.8850 - val_loss: 0.4644 - val_accuracy: 0.8800\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.3574 - accuracy: 0.9025 - val_loss: 0.4713 - val_accuracy: 0.8800\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.3507 - accuracy: 0.9075 - val_loss: 0.4571 - val_accuracy: 0.8800\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.3437 - accuracy: 0.9050 - val_loss: 0.4519 - val_accuracy: 0.8800\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3342 - accuracy: 0.9150 - val_loss: 0.4525 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.3276 - accuracy: 0.9100 - val_loss: 0.4501 - val_accuracy: 0.8800\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.3334 - accuracy: 0.9025 - val_loss: 0.4449 - val_accuracy: 0.8800\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.3259 - accuracy: 0.9125 - val_loss: 0.4464 - val_accuracy: 0.8800\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.3163 - accuracy: 0.9075 - val_loss: 0.4397 - val_accuracy: 0.8800\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.3344 - accuracy: 0.9125 - val_loss: 0.4323 - val_accuracy: 0.8800\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.3104 - accuracy: 0.9075 - val_loss: 0.4275 - val_accuracy: 0.8800\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.3059 - accuracy: 0.9200 - val_loss: 0.4292 - val_accuracy: 0.8800\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.3186 - accuracy: 0.9075 - val_loss: 0.4276 - val_accuracy: 0.8800\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.3048 - accuracy: 0.9075 - val_loss: 0.4197 - val_accuracy: 0.8800\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.3035 - accuracy: 0.9100 - val_loss: 0.4222 - val_accuracy: 0.8800\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.3054 - accuracy: 0.9150 - val_loss: 0.4090 - val_accuracy: 0.8800\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.2852 - accuracy: 0.9175 - val_loss: 0.4147 - val_accuracy: 0.8900\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2879 - accuracy: 0.9225 - val_loss: 0.4043 - val_accuracy: 0.8900\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2742 - accuracy: 0.9225 - val_loss: 0.4049 - val_accuracy: 0.9000\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2755 - accuracy: 0.9225 - val_loss: 0.4020 - val_accuracy: 0.8900\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.3005 - accuracy: 0.9225 - val_loss: 0.4012 - val_accuracy: 0.8900\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.3086 - accuracy: 0.9225 - val_loss: 0.4029 - val_accuracy: 0.8900\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.2692 - accuracy: 0.9225 - val_loss: 0.4574 - val_accuracy: 0.8700\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.2913 - accuracy: 0.9200 - val_loss: 0.3895 - val_accuracy: 0.8900\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2600 - accuracy: 0.9300 - val_loss: 0.3889 - val_accuracy: 0.8900\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2603 - accuracy: 0.9275 - val_loss: 0.3857 - val_accuracy: 0.8900\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2457 - accuracy: 0.9375 - val_loss: 0.3906 - val_accuracy: 0.8900\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2474 - accuracy: 0.9325 - val_loss: 0.3871 - val_accuracy: 0.8900\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2379 - accuracy: 0.9300 - val_loss: 0.3854 - val_accuracy: 0.8800\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2559 - accuracy: 0.9275 - val_loss: 0.3803 - val_accuracy: 0.8800\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2481 - accuracy: 0.9275 - val_loss: 0.3862 - val_accuracy: 0.9000\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2407 - accuracy: 0.9275 - val_loss: 0.3723 - val_accuracy: 0.8800\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.2293 - accuracy: 0.9425 - val_loss: 0.3729 - val_accuracy: 0.8900\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.2448 - accuracy: 0.9400 - val_loss: 0.4042 - val_accuracy: 0.9100\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.2196 - accuracy: 0.9425 - val_loss: 0.3621 - val_accuracy: 0.8900\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.2118 - accuracy: 0.9375 - val_loss: 0.3667 - val_accuracy: 0.8900\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.2308 - accuracy: 0.9175 - val_loss: 0.4006 - val_accuracy: 0.9100\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.2133 - accuracy: 0.9300 - val_loss: 0.3719 - val_accuracy: 0.9100\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2271 - accuracy: 0.9350 - val_loss: 0.3816 - val_accuracy: 0.8900\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.2145 - accuracy: 0.9325 - val_loss: 0.3630 - val_accuracy: 0.8900\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1962 - accuracy: 0.9450 - val_loss: 0.3645 - val_accuracy: 0.8900\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1992 - accuracy: 0.9400 - val_loss: 0.3607 - val_accuracy: 0.9000\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.1775 - accuracy: 0.9475 - val_loss: 0.4052 - val_accuracy: 0.9100\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1882 - accuracy: 0.9475 - val_loss: 0.3478 - val_accuracy: 0.8900\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1794 - accuracy: 0.9450 - val_loss: 0.3489 - val_accuracy: 0.9000\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.94 - 0s 209us/step - loss: 0.1775 - accuracy: 0.9500 - val_loss: 0.3778 - val_accuracy: 0.9100\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.2147 - accuracy: 0.9275 - val_loss: 0.3667 - val_accuracy: 0.8900\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1700 - accuracy: 0.9525 - val_loss: 0.3454 - val_accuracy: 0.9200\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1687 - accuracy: 0.9550 - val_loss: 0.3524 - val_accuracy: 0.8900\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1634 - accuracy: 0.9575 - val_loss: 0.3348 - val_accuracy: 0.9200\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.1557 - accuracy: 0.9525 - val_loss: 0.3425 - val_accuracy: 0.8900\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1543 - accuracy: 0.9575 - val_loss: 0.3355 - val_accuracy: 0.9100\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1646 - accuracy: 0.9550 - val_loss: 0.3385 - val_accuracy: 0.9200\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1444 - accuracy: 0.9575 - val_loss: 0.3558 - val_accuracy: 0.9200\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.1502 - accuracy: 0.9525 - val_loss: 0.3544 - val_accuracy: 0.9100\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.1350 - accuracy: 0.9650 - val_loss: 0.3343 - val_accuracy: 0.9200\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1376 - accuracy: 0.9475 - val_loss: 0.3579 - val_accuracy: 0.9200\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1384 - accuracy: 0.9550 - val_loss: 0.3354 - val_accuracy: 0.9200\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 208us/step - loss: 0.1360 - accuracy: 0.9625 - val_loss: 0.3760 - val_accuracy: 0.9200\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.1353 - accuracy: 0.9550 - val_loss: 0.3456 - val_accuracy: 0.9200\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1189 - accuracy: 0.9650 - val_loss: 0.3436 - val_accuracy: 0.9000\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.1222 - accuracy: 0.9600 - val_loss: 0.3300 - val_accuracy: 0.9100\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1141 - accuracy: 0.9675 - val_loss: 0.3332 - val_accuracy: 0.9100\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.1221 - accuracy: 0.9625 - val_loss: 0.3713 - val_accuracy: 0.8800\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1418 - accuracy: 0.9600 - val_loss: 0.3358 - val_accuracy: 0.9100\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.1215 - accuracy: 0.9600 - val_loss: 0.3344 - val_accuracy: 0.9100\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.1129 - accuracy: 0.9675 - val_loss: 0.3296 - val_accuracy: 0.9100\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.1022 - accuracy: 0.9700 - val_loss: 0.3392 - val_accuracy: 0.9100\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1026 - accuracy: 0.9650 - val_loss: 0.3318 - val_accuracy: 0.9300\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0950 - accuracy: 0.9750 - val_loss: 0.3402 - val_accuracy: 0.9000\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.0887 - accuracy: 0.9700 - val_loss: 0.3444 - val_accuracy: 0.9200\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0876 - accuracy: 0.9750 - val_loss: 0.3544 - val_accuracy: 0.9200\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0961 - accuracy: 0.9600 - val_loss: 0.3567 - val_accuracy: 0.9200\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.0845 - accuracy: 0.9800 - val_loss: 0.3690 - val_accuracy: 0.9200\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.0868 - accuracy: 0.9775 - val_loss: 0.3558 - val_accuracy: 0.9200\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.0837 - accuracy: 0.9700 - val_loss: 0.3362 - val_accuracy: 0.9100\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0785 - accuracy: 0.9825 - val_loss: 0.3321 - val_accuracy: 0.9100\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0705 - accuracy: 0.9875 - val_loss: 0.3402 - val_accuracy: 0.9100\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.0684 - accuracy: 0.9850 - val_loss: 0.3596 - val_accuracy: 0.9300\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0693 - accuracy: 0.9850 - val_loss: 0.3746 - val_accuracy: 0.9200\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0706 - accuracy: 0.9875 - val_loss: 0.3623 - val_accuracy: 0.9200\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0679 - accuracy: 0.9825 - val_loss: 0.3473 - val_accuracy: 0.9300\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.0875 - accuracy: 0.9775 - val_loss: 0.3541 - val_accuracy: 0.9100\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0806 - accuracy: 0.9800 - val_loss: 0.3365 - val_accuracy: 0.9100\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0673 - accuracy: 0.9825 - val_loss: 0.3360 - val_accuracy: 0.9100\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0567 - accuracy: 0.9925 - val_loss: 0.3394 - val_accuracy: 0.9100\n",
      "Epoch 134/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0523 - accuracy: 0.9875 - val_loss: 0.3492 - val_accuracy: 0.9100\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5372830662500958\n",
      "F1 Micro: 0.9254164373968286\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6453745268142836\n",
      "F1 Micro: 0.9461999999999999\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 289us/step - loss: 2.3746 - accuracy: 0.0300 - val_loss: 2.1545 - val_accuracy: 0.2000\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 89us/step - loss: 2.1199 - accuracy: 0.3050 - val_loss: 1.8932 - val_accuracy: 0.5200\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.9317 - accuracy: 0.4625 - val_loss: 1.7080 - val_accuracy: 0.5800\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.7967 - accuracy: 0.5250 - val_loss: 1.5890 - val_accuracy: 0.6300\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.6944 - accuracy: 0.5550 - val_loss: 1.5064 - val_accuracy: 0.6300\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.6075 - accuracy: 0.6125 - val_loss: 1.4399 - val_accuracy: 0.6500\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.5340 - accuracy: 0.6325 - val_loss: 1.3800 - val_accuracy: 0.6700\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.4638 - accuracy: 0.6600 - val_loss: 1.3224 - val_accuracy: 0.6700\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.3935 - accuracy: 0.6800 - val_loss: 1.2650 - val_accuracy: 0.6700\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.3265 - accuracy: 0.6950 - val_loss: 1.2087 - val_accuracy: 0.6900\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.2587 - accuracy: 0.7200 - val_loss: 1.1533 - val_accuracy: 0.7100\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.1929 - accuracy: 0.7375 - val_loss: 1.0977 - val_accuracy: 0.7100\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.1278 - accuracy: 0.7525 - val_loss: 1.0403 - val_accuracy: 0.7500\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.0636 - accuracy: 0.7800 - val_loss: 0.9817 - val_accuracy: 0.7800\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.0008 - accuracy: 0.8025 - val_loss: 0.9278 - val_accuracy: 0.7900\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.9409 - accuracy: 0.8225 - val_loss: 0.8763 - val_accuracy: 0.8300\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.8838 - accuracy: 0.8425 - val_loss: 0.8269 - val_accuracy: 0.8300\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.8288 - accuracy: 0.8600 - val_loss: 0.7803 - val_accuracy: 0.8500\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.7776 - accuracy: 0.8725 - val_loss: 0.7380 - val_accuracy: 0.8500\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.7295 - accuracy: 0.8800 - val_loss: 0.6976 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.6830 - accuracy: 0.8875 - val_loss: 0.6608 - val_accuracy: 0.8600\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.6404 - accuracy: 0.8900 - val_loss: 0.6266 - val_accuracy: 0.8800\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.6019 - accuracy: 0.8950 - val_loss: 0.5969 - val_accuracy: 0.8800\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.5654 - accuracy: 0.9075 - val_loss: 0.5661 - val_accuracy: 0.8800\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.5309 - accuracy: 0.9075 - val_loss: 0.5408 - val_accuracy: 0.8800\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.4995 - accuracy: 0.9150 - val_loss: 0.5180 - val_accuracy: 0.8900\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 80us/step - loss: 0.4712 - accuracy: 0.9175 - val_loss: 0.4966 - val_accuracy: 0.8900\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.4444 - accuracy: 0.9175 - val_loss: 0.4782 - val_accuracy: 0.8900\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.4202 - accuracy: 0.9250 - val_loss: 0.4603 - val_accuracy: 0.8900\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.3962 - accuracy: 0.9250 - val_loss: 0.4445 - val_accuracy: 0.8800\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.3756 - accuracy: 0.9250 - val_loss: 0.4330 - val_accuracy: 0.8800\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.3564 - accuracy: 0.9250 - val_loss: 0.4185 - val_accuracy: 0.8900\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.3370 - accuracy: 0.9275 - val_loss: 0.4081 - val_accuracy: 0.8900\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.3210 - accuracy: 0.9350 - val_loss: 0.3982 - val_accuracy: 0.8900\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.3057 - accuracy: 0.9400 - val_loss: 0.3885 - val_accuracy: 0.8900\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.2910 - accuracy: 0.9475 - val_loss: 0.3805 - val_accuracy: 0.8900\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2792 - accuracy: 0.9500 - val_loss: 0.3724 - val_accuracy: 0.8900\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2654 - accuracy: 0.9500 - val_loss: 0.3658 - val_accuracy: 0.8900\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.2542 - accuracy: 0.9575 - val_loss: 0.3595 - val_accuracy: 0.9000\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.2446 - accuracy: 0.9575 - val_loss: 0.3538 - val_accuracy: 0.9000\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2335 - accuracy: 0.9625 - val_loss: 0.3484 - val_accuracy: 0.9000\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.2250 - accuracy: 0.9650 - val_loss: 0.3441 - val_accuracy: 0.9000\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2161 - accuracy: 0.9650 - val_loss: 0.3407 - val_accuracy: 0.9000\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2088 - accuracy: 0.9675 - val_loss: 0.3366 - val_accuracy: 0.9000\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2019 - accuracy: 0.9675 - val_loss: 0.3337 - val_accuracy: 0.9000\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1942 - accuracy: 0.9675 - val_loss: 0.3296 - val_accuracy: 0.9000\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.1873 - accuracy: 0.9650 - val_loss: 0.3281 - val_accuracy: 0.9000\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1808 - accuracy: 0.9625 - val_loss: 0.3265 - val_accuracy: 0.9000\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1752 - accuracy: 0.9675 - val_loss: 0.3231 - val_accuracy: 0.9000\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.1692 - accuracy: 0.9750 - val_loss: 0.3200 - val_accuracy: 0.9000\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1637 - accuracy: 0.9775 - val_loss: 0.3176 - val_accuracy: 0.9000\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1587 - accuracy: 0.9775 - val_loss: 0.3154 - val_accuracy: 0.9000\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.1538 - accuracy: 0.9750 - val_loss: 0.3137 - val_accuracy: 0.9000\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1492 - accuracy: 0.9775 - val_loss: 0.3119 - val_accuracy: 0.9000\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1448 - accuracy: 0.9775 - val_loss: 0.3099 - val_accuracy: 0.9000\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1408 - accuracy: 0.9800 - val_loss: 0.3096 - val_accuracy: 0.9000\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1366 - accuracy: 0.9800 - val_loss: 0.3092 - val_accuracy: 0.9000\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1325 - accuracy: 0.9800 - val_loss: 0.3071 - val_accuracy: 0.9000\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1289 - accuracy: 0.9825 - val_loss: 0.3061 - val_accuracy: 0.9000\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1253 - accuracy: 0.9825 - val_loss: 0.3050 - val_accuracy: 0.9000\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.1219 - accuracy: 0.9800 - val_loss: 0.3036 - val_accuracy: 0.9000\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.1184 - accuracy: 0.9825 - val_loss: 0.3035 - val_accuracy: 0.9000\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1155 - accuracy: 0.9825 - val_loss: 0.3040 - val_accuracy: 0.9000\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1126 - accuracy: 0.9825 - val_loss: 0.3022 - val_accuracy: 0.9000\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1097 - accuracy: 0.9800 - val_loss: 0.3009 - val_accuracy: 0.9000\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.1068 - accuracy: 0.9825 - val_loss: 0.3007 - val_accuracy: 0.9000\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1043 - accuracy: 0.9850 - val_loss: 0.2999 - val_accuracy: 0.9000\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.1016 - accuracy: 0.9850 - val_loss: 0.3004 - val_accuracy: 0.9000\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0992 - accuracy: 0.9850 - val_loss: 0.3001 - val_accuracy: 0.9000\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0968 - accuracy: 0.9850 - val_loss: 0.2996 - val_accuracy: 0.9000\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0944 - accuracy: 0.9850 - val_loss: 0.2987 - val_accuracy: 0.9000\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0925 - accuracy: 0.9850 - val_loss: 0.2989 - val_accuracy: 0.9000\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0902 - accuracy: 0.9900 - val_loss: 0.2978 - val_accuracy: 0.9000\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0880 - accuracy: 0.9900 - val_loss: 0.2982 - val_accuracy: 0.9000\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0863 - accuracy: 0.9900 - val_loss: 0.2983 - val_accuracy: 0.9000\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0843 - accuracy: 0.9900 - val_loss: 0.2965 - val_accuracy: 0.9000\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0823 - accuracy: 0.9900 - val_loss: 0.2948 - val_accuracy: 0.9000\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0806 - accuracy: 0.9900 - val_loss: 0.2954 - val_accuracy: 0.9000\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0788 - accuracy: 0.9900 - val_loss: 0.2948 - val_accuracy: 0.9000\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0771 - accuracy: 0.9900 - val_loss: 0.2936 - val_accuracy: 0.9000\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0755 - accuracy: 0.9900 - val_loss: 0.2948 - val_accuracy: 0.9000\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0740 - accuracy: 0.9900 - val_loss: 0.2937 - val_accuracy: 0.9000\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0723 - accuracy: 0.9925 - val_loss: 0.2937 - val_accuracy: 0.9000\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0709 - accuracy: 0.9950 - val_loss: 0.2933 - val_accuracy: 0.9000\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0695 - accuracy: 0.9950 - val_loss: 0.2935 - val_accuracy: 0.9000\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9000\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9000\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9000\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9000\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9000\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9000\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9000\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9000\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9000\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9000\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9000\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.9100\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9000\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9100\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9100\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9100\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9100\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9100\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9100\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9100\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9100\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9100\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.9100\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9100\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9100\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9100\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9100\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9100\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9100\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9100\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9100\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9100\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.9100\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9100\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9100\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9100\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5052690040171397\n",
      "F1 Micro: 0.9374218398279225\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 752us/step - loss: 2.0671 - accuracy: 0.3200 - val_loss: 1.5734 - val_accuracy: 0.8000\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 1.1029 - accuracy: 0.8175 - val_loss: 0.5229 - val_accuracy: 0.8800\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.5596 - accuracy: 0.8550 - val_loss: 0.4416 - val_accuracy: 0.8700\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.4808 - accuracy: 0.8675 - val_loss: 0.4266 - val_accuracy: 0.9000\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.4260 - accuracy: 0.8875 - val_loss: 0.4291 - val_accuracy: 0.9000\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3999 - accuracy: 0.8975 - val_loss: 0.4123 - val_accuracy: 0.9000\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.3766 - accuracy: 0.9025 - val_loss: 0.4046 - val_accuracy: 0.9000\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3581 - accuracy: 0.9100 - val_loss: 0.4052 - val_accuracy: 0.9000\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3468 - accuracy: 0.9125 - val_loss: 0.4015 - val_accuracy: 0.9000\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.3318 - accuracy: 0.9150 - val_loss: 0.3934 - val_accuracy: 0.9000\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.3191 - accuracy: 0.9150 - val_loss: 0.3889 - val_accuracy: 0.9100\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.3087 - accuracy: 0.9225 - val_loss: 0.3827 - val_accuracy: 0.9100\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.3003 - accuracy: 0.9175 - val_loss: 0.3786 - val_accuracy: 0.9100\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2884 - accuracy: 0.9250 - val_loss: 0.3778 - val_accuracy: 0.9000\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.2807 - accuracy: 0.9225 - val_loss: 0.3706 - val_accuracy: 0.9200\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 227us/step - loss: 0.2723 - accuracy: 0.9250 - val_loss: 0.3631 - val_accuracy: 0.9300\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.2653 - accuracy: 0.9275 - val_loss: 0.3610 - val_accuracy: 0.9300\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.2578 - accuracy: 0.9275 - val_loss: 0.3537 - val_accuracy: 0.9300\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2510 - accuracy: 0.9275 - val_loss: 0.3519 - val_accuracy: 0.9300\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.2458 - accuracy: 0.9350 - val_loss: 0.3477 - val_accuracy: 0.9300\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.2401 - accuracy: 0.9350 - val_loss: 0.3441 - val_accuracy: 0.9300\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2319 - accuracy: 0.9325 - val_loss: 0.3411 - val_accuracy: 0.9300\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2249 - accuracy: 0.9400 - val_loss: 0.3358 - val_accuracy: 0.9300\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2206 - accuracy: 0.9400 - val_loss: 0.3314 - val_accuracy: 0.9300\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2137 - accuracy: 0.9400 - val_loss: 0.3283 - val_accuracy: 0.9300\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.2112 - accuracy: 0.9400 - val_loss: 0.3261 - val_accuracy: 0.9300\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2024 - accuracy: 0.9400 - val_loss: 0.3239 - val_accuracy: 0.9300\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1975 - accuracy: 0.9425 - val_loss: 0.3172 - val_accuracy: 0.9300\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1937 - accuracy: 0.9425 - val_loss: 0.3196 - val_accuracy: 0.9300\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.1905 - accuracy: 0.9425 - val_loss: 0.3131 - val_accuracy: 0.9300\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1834 - accuracy: 0.9450 - val_loss: 0.3082 - val_accuracy: 0.9300\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1796 - accuracy: 0.9425 - val_loss: 0.3075 - val_accuracy: 0.9300\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1743 - accuracy: 0.9425 - val_loss: 0.3105 - val_accuracy: 0.9300\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1715 - accuracy: 0.9500 - val_loss: 0.3021 - val_accuracy: 0.9300\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1671 - accuracy: 0.9450 - val_loss: 0.3011 - val_accuracy: 0.9300\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1616 - accuracy: 0.9475 - val_loss: 0.3025 - val_accuracy: 0.9300\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1578 - accuracy: 0.9475 - val_loss: 0.2965 - val_accuracy: 0.9300\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.1590 - accuracy: 0.9550 - val_loss: 0.2925 - val_accuracy: 0.9300\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1590 - accuracy: 0.9450 - val_loss: 0.2932 - val_accuracy: 0.9300\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1505 - accuracy: 0.9575 - val_loss: 0.2904 - val_accuracy: 0.9300\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1433 - accuracy: 0.9550 - val_loss: 0.2902 - val_accuracy: 0.9300\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1434 - accuracy: 0.9575 - val_loss: 0.2894 - val_accuracy: 0.9300\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1378 - accuracy: 0.9550 - val_loss: 0.2848 - val_accuracy: 0.9300\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1316 - accuracy: 0.9550 - val_loss: 0.2868 - val_accuracy: 0.9300\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1308 - accuracy: 0.9600 - val_loss: 0.2851 - val_accuracy: 0.9300\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1269 - accuracy: 0.9650 - val_loss: 0.2819 - val_accuracy: 0.9300\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1224 - accuracy: 0.9625 - val_loss: 0.2814 - val_accuracy: 0.9300\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1208 - accuracy: 0.9700 - val_loss: 0.2811 - val_accuracy: 0.9300\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1200 - accuracy: 0.9600 - val_loss: 0.2818 - val_accuracy: 0.9300\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1149 - accuracy: 0.9650 - val_loss: 0.2797 - val_accuracy: 0.9300\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1086 - accuracy: 0.9700 - val_loss: 0.2808 - val_accuracy: 0.9300\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1070 - accuracy: 0.9725 - val_loss: 0.2799 - val_accuracy: 0.9300\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1064 - accuracy: 0.9650 - val_loss: 0.2762 - val_accuracy: 0.9300\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1004 - accuracy: 0.9700 - val_loss: 0.2731 - val_accuracy: 0.9300\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0981 - accuracy: 0.9750 - val_loss: 0.2751 - val_accuracy: 0.9300\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0958 - accuracy: 0.9775 - val_loss: 0.2753 - val_accuracy: 0.9300\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0920 - accuracy: 0.9725 - val_loss: 0.2715 - val_accuracy: 0.9300\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0968 - accuracy: 0.9800 - val_loss: 0.2735 - val_accuracy: 0.9300\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0883 - accuracy: 0.9775 - val_loss: 0.2752 - val_accuracy: 0.9300\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0838 - accuracy: 0.9825 - val_loss: 0.2721 - val_accuracy: 0.9300\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0830 - accuracy: 0.9800 - val_loss: 0.2736 - val_accuracy: 0.9300\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0809 - accuracy: 0.9850 - val_loss: 0.2722 - val_accuracy: 0.9300\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0786 - accuracy: 0.9825 - val_loss: 0.2720 - val_accuracy: 0.9300\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0749 - accuracy: 0.9875 - val_loss: 0.2729 - val_accuracy: 0.9300\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0730 - accuracy: 0.9900 - val_loss: 0.2703 - val_accuracy: 0.9300\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0710 - accuracy: 0.9900 - val_loss: 0.2699 - val_accuracy: 0.9300\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0686 - accuracy: 0.9875 - val_loss: 0.2697 - val_accuracy: 0.9300\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0670 - accuracy: 0.9900 - val_loss: 0.2708 - val_accuracy: 0.9300\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0657 - accuracy: 0.9900 - val_loss: 0.2699 - val_accuracy: 0.9300\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0625 - accuracy: 0.9925 - val_loss: 0.2671 - val_accuracy: 0.9300\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0659 - accuracy: 0.9850 - val_loss: 0.2693 - val_accuracy: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0584 - accuracy: 0.9925 - val_loss: 0.2702 - val_accuracy: 0.9300\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0587 - accuracy: 0.9875 - val_loss: 0.2674 - val_accuracy: 0.9300\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0548 - accuracy: 0.9925 - val_loss: 0.2679 - val_accuracy: 0.9300\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0527 - accuracy: 0.9925 - val_loss: 0.2687 - val_accuracy: 0.9300\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0526 - accuracy: 0.9925 - val_loss: 0.2686 - val_accuracy: 0.9300\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0521 - accuracy: 0.9975 - val_loss: 0.2719 - val_accuracy: 0.9300\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0495 - accuracy: 0.9925 - val_loss: 0.2720 - val_accuracy: 0.9300\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0473 - accuracy: 0.9950 - val_loss: 0.2714 - val_accuracy: 0.9300\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0457 - accuracy: 0.9950 - val_loss: 0.2684 - val_accuracy: 0.9300\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0448 - accuracy: 0.9975 - val_loss: 0.2767 - val_accuracy: 0.9300\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0473 - accuracy: 0.9950 - val_loss: 0.2702 - val_accuracy: 0.9300\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0447 - accuracy: 0.9925 - val_loss: 0.2697 - val_accuracy: 0.9300\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0404 - accuracy: 0.9950 - val_loss: 0.2688 - val_accuracy: 0.9300\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0377 - accuracy: 0.9975 - val_loss: 0.2674 - val_accuracy: 0.9300\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0356 - accuracy: 0.9975 - val_loss: 0.2729 - val_accuracy: 0.9300\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0367 - accuracy: 0.9975 - val_loss: 0.2703 - val_accuracy: 0.9300\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0357 - accuracy: 0.9975 - val_loss: 0.2735 - val_accuracy: 0.9300\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0330 - accuracy: 0.9975 - val_loss: 0.2708 - val_accuracy: 0.9300\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0322 - accuracy: 0.9975 - val_loss: 0.2721 - val_accuracy: 0.9300\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5140040958120851\n",
      "F1 Micro: 0.9407233254964734\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6783552971395811\n",
      "F1 Micro: 0.9477000000000001\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5132830028633417\n",
      "F1 Micro: 0.9415\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 4 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 255us/step - loss: 0.8959 - accuracy: 0.8347 - val_loss: 0.6793 - val_accuracy: 0.8470\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.6641 - accuracy: 0.8478 - val_loss: 0.6387 - val_accuracy: 0.8470\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.6221 - accuracy: 0.8478 - val_loss: 0.5692 - val_accuracy: 0.8470\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.5162 - accuracy: 0.8655 - val_loss: 0.4584 - val_accuracy: 0.8980\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.4118 - accuracy: 0.9000 - val_loss: 0.4317 - val_accuracy: 0.8890\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.3544 - accuracy: 0.9090 - val_loss: 0.3508 - val_accuracy: 0.9090\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.3162 - accuracy: 0.9158 - val_loss: 0.2920 - val_accuracy: 0.9140\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.2736 - accuracy: 0.9250 - val_loss: 0.2576 - val_accuracy: 0.9270\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.2421 - accuracy: 0.9315 - val_loss: 0.2558 - val_accuracy: 0.9290\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.2290 - accuracy: 0.9370 - val_loss: 0.2291 - val_accuracy: 0.9340\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.2122 - accuracy: 0.9367 - val_loss: 0.2099 - val_accuracy: 0.9400\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1974 - accuracy: 0.9410 - val_loss: 0.2401 - val_accuracy: 0.9350\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1954 - accuracy: 0.9425 - val_loss: 0.1970 - val_accuracy: 0.9450\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1832 - accuracy: 0.9460 - val_loss: 0.1781 - val_accuracy: 0.9470\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1736 - accuracy: 0.9482 - val_loss: 0.1815 - val_accuracy: 0.9490\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.1676 - accuracy: 0.9485 - val_loss: 0.1761 - val_accuracy: 0.9490\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1557 - accuracy: 0.9523 - val_loss: 0.1701 - val_accuracy: 0.9500\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1614 - accuracy: 0.9507 - val_loss: 0.1784 - val_accuracy: 0.9460\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1462 - accuracy: 0.9555 - val_loss: 0.1712 - val_accuracy: 0.9500\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1371 - accuracy: 0.9585 - val_loss: 0.1757 - val_accuracy: 0.9450\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1436 - accuracy: 0.9560 - val_loss: 0.1803 - val_accuracy: 0.9430\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.1318 - accuracy: 0.9580 - val_loss: 0.1599 - val_accuracy: 0.9560\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1255 - accuracy: 0.9622 - val_loss: 0.1680 - val_accuracy: 0.9470\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1257 - accuracy: 0.9617 - val_loss: 0.1627 - val_accuracy: 0.9450\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1199 - accuracy: 0.9605 - val_loss: 0.1762 - val_accuracy: 0.9490\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1180 - accuracy: 0.9613 - val_loss: 0.1786 - val_accuracy: 0.9500\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1169 - accuracy: 0.9600 - val_loss: 0.1517 - val_accuracy: 0.9560\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1055 - accuracy: 0.9670 - val_loss: 0.1552 - val_accuracy: 0.9510\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0965 - accuracy: 0.9685 - val_loss: 0.1574 - val_accuracy: 0.9480\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1046 - accuracy: 0.9643 - val_loss: 0.1616 - val_accuracy: 0.9460\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0979 - accuracy: 0.9675 - val_loss: 0.1486 - val_accuracy: 0.9540\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0892 - accuracy: 0.9712 - val_loss: 0.1527 - val_accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0869 - accuracy: 0.9722 - val_loss: 0.1451 - val_accuracy: 0.9560\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0829 - accuracy: 0.9725 - val_loss: 0.1651 - val_accuracy: 0.9520\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1041 - accuracy: 0.9653 - val_loss: 0.1486 - val_accuracy: 0.9540\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0787 - accuracy: 0.9760 - val_loss: 0.1444 - val_accuracy: 0.9600\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0732 - accuracy: 0.9762 - val_loss: 0.1571 - val_accuracy: 0.9560\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0712 - accuracy: 0.9770 - val_loss: 0.1502 - val_accuracy: 0.9540\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0739 - accuracy: 0.9750 - val_loss: 0.1692 - val_accuracy: 0.9420\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0763 - accuracy: 0.9737 - val_loss: 0.1602 - val_accuracy: 0.9580\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0604 - accuracy: 0.9797 - val_loss: 0.1512 - val_accuracy: 0.9550\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0580 - accuracy: 0.9812 - val_loss: 0.1700 - val_accuracy: 0.9580\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0589 - accuracy: 0.9812 - val_loss: 0.1809 - val_accuracy: 0.9550\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0561 - accuracy: 0.9818 - val_loss: 0.1788 - val_accuracy: 0.9500\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0570 - accuracy: 0.9803 - val_loss: 0.1645 - val_accuracy: 0.9510\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0536 - accuracy: 0.9818 - val_loss: 0.1609 - val_accuracy: 0.9540\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0451 - accuracy: 0.9868 - val_loss: 0.1645 - val_accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0396 - accuracy: 0.9893 - val_loss: 0.1629 - val_accuracy: 0.9560\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0498 - accuracy: 0.9833 - val_loss: 0.1761 - val_accuracy: 0.9540\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0413 - accuracy: 0.9877 - val_loss: 0.1636 - val_accuracy: 0.9530\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0318 - accuracy: 0.9898 - val_loss: 0.1702 - val_accuracy: 0.9590\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.1894 - val_accuracy: 0.9470\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0337 - accuracy: 0.9893 - val_loss: 0.1776 - val_accuracy: 0.9550\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0363 - accuracy: 0.9870 - val_loss: 0.1918 - val_accuracy: 0.9510\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 0.1806 - val_accuracy: 0.9540\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0258 - accuracy: 0.9930 - val_loss: 0.2010 - val_accuracy: 0.9540\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7183388519193866\n",
      "F1 Micro: 0.9578\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7400360507361863\n",
      "F1 Micro: 0.9572\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 92us/step - loss: 1.6709 - accuracy: 0.5675 - val_loss: 1.3866 - val_accuracy: 0.6730\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 1.0770 - accuracy: 0.7815 - val_loss: 0.8930 - val_accuracy: 0.8260\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.6471 - accuracy: 0.8882 - val_loss: 0.5429 - val_accuracy: 0.9080\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.4013 - accuracy: 0.9237 - val_loss: 0.3557 - val_accuracy: 0.9350\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.2847 - accuracy: 0.9367 - val_loss: 0.2699 - val_accuracy: 0.9440\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.2275 - accuracy: 0.9450 - val_loss: 0.2296 - val_accuracy: 0.9450\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.1970 - accuracy: 0.9495 - val_loss: 0.2070 - val_accuracy: 0.9510\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1777 - accuracy: 0.9548 - val_loss: 0.1947 - val_accuracy: 0.9500\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1650 - accuracy: 0.9550 - val_loss: 0.1863 - val_accuracy: 0.9540\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1553 - accuracy: 0.9563 - val_loss: 0.1786 - val_accuracy: 0.9510\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.1483 - accuracy: 0.9588 - val_loss: 0.1740 - val_accuracy: 0.9530\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1422 - accuracy: 0.9585 - val_loss: 0.1713 - val_accuracy: 0.9510\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1366 - accuracy: 0.9597 - val_loss: 0.1680 - val_accuracy: 0.9520\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1320 - accuracy: 0.9600 - val_loss: 0.1670 - val_accuracy: 0.9510\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1292 - accuracy: 0.9600 - val_loss: 0.1650 - val_accuracy: 0.9500\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 79us/step - loss: 0.1246 - accuracy: 0.9615 - val_loss: 0.1631 - val_accuracy: 0.9500\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1222 - accuracy: 0.9615 - val_loss: 0.1613 - val_accuracy: 0.9490\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1187 - accuracy: 0.9628 - val_loss: 0.1599 - val_accuracy: 0.9500\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1159 - accuracy: 0.9632 - val_loss: 0.1585 - val_accuracy: 0.9480\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1129 - accuracy: 0.9630 - val_loss: 0.1580 - val_accuracy: 0.9510\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1110 - accuracy: 0.9657 - val_loss: 0.1569 - val_accuracy: 0.9530\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1090 - accuracy: 0.9663 - val_loss: 0.1572 - val_accuracy: 0.9510\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1075 - accuracy: 0.9665 - val_loss: 0.1565 - val_accuracy: 0.9530\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1046 - accuracy: 0.9665 - val_loss: 0.1555 - val_accuracy: 0.9540\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1027 - accuracy: 0.9682 - val_loss: 0.1551 - val_accuracy: 0.9540\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1012 - accuracy: 0.9685 - val_loss: 0.1537 - val_accuracy: 0.9520\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0994 - accuracy: 0.9695 - val_loss: 0.1544 - val_accuracy: 0.9530\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0974 - accuracy: 0.9700 - val_loss: 0.1540 - val_accuracy: 0.9530\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0965 - accuracy: 0.9710 - val_loss: 0.1566 - val_accuracy: 0.9520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0949 - accuracy: 0.9715 - val_loss: 0.1524 - val_accuracy: 0.9540\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0929 - accuracy: 0.9712 - val_loss: 0.1534 - val_accuracy: 0.9510\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0922 - accuracy: 0.9730 - val_loss: 0.1555 - val_accuracy: 0.9540\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0902 - accuracy: 0.9732 - val_loss: 0.1547 - val_accuracy: 0.9540\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0892 - accuracy: 0.9740 - val_loss: 0.1519 - val_accuracy: 0.9510\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0874 - accuracy: 0.9737 - val_loss: 0.1523 - val_accuracy: 0.9540\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0862 - accuracy: 0.9737 - val_loss: 0.1533 - val_accuracy: 0.9510\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0850 - accuracy: 0.9745 - val_loss: 0.1535 - val_accuracy: 0.9520\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0837 - accuracy: 0.9765 - val_loss: 0.1537 - val_accuracy: 0.9540\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0827 - accuracy: 0.9755 - val_loss: 0.1531 - val_accuracy: 0.9520\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0818 - accuracy: 0.9768 - val_loss: 0.1538 - val_accuracy: 0.9510\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0802 - accuracy: 0.9768 - val_loss: 0.1522 - val_accuracy: 0.9520\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0791 - accuracy: 0.9760 - val_loss: 0.1536 - val_accuracy: 0.9510\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0785 - accuracy: 0.9755 - val_loss: 0.1524 - val_accuracy: 0.9510\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0769 - accuracy: 0.9787 - val_loss: 0.1542 - val_accuracy: 0.9520\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0760 - accuracy: 0.9768 - val_loss: 0.1554 - val_accuracy: 0.9500\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0753 - accuracy: 0.9783 - val_loss: 0.1541 - val_accuracy: 0.9510\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0736 - accuracy: 0.9793 - val_loss: 0.1551 - val_accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0728 - accuracy: 0.9785 - val_loss: 0.1551 - val_accuracy: 0.9510\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0721 - accuracy: 0.9800 - val_loss: 0.1547 - val_accuracy: 0.9520\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0714 - accuracy: 0.9795 - val_loss: 0.1536 - val_accuracy: 0.9530\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0703 - accuracy: 0.9797 - val_loss: 0.1538 - val_accuracy: 0.9540\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0690 - accuracy: 0.9812 - val_loss: 0.1550 - val_accuracy: 0.9520\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0683 - accuracy: 0.9808 - val_loss: 0.1543 - val_accuracy: 0.9540\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0680 - accuracy: 0.9827 - val_loss: 0.1547 - val_accuracy: 0.9530\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7423567115155532\n",
      "F1 Micro: 0.9563\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 257us/step - loss: 0.6210 - accuracy: 0.8420 - val_loss: 0.3703 - val_accuracy: 0.9090\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.3143 - accuracy: 0.9175 - val_loss: 0.2985 - val_accuracy: 0.9200\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.2612 - accuracy: 0.9315 - val_loss: 0.2630 - val_accuracy: 0.9260\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.2299 - accuracy: 0.9375 - val_loss: 0.2360 - val_accuracy: 0.9320\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.2073 - accuracy: 0.9435 - val_loss: 0.2145 - val_accuracy: 0.9420\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.1896 - accuracy: 0.9473 - val_loss: 0.2077 - val_accuracy: 0.9400\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.1795 - accuracy: 0.9492 - val_loss: 0.1966 - val_accuracy: 0.9440\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1699 - accuracy: 0.9510 - val_loss: 0.1827 - val_accuracy: 0.9510\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1599 - accuracy: 0.9550 - val_loss: 0.1784 - val_accuracy: 0.9520\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1530 - accuracy: 0.9560 - val_loss: 0.1749 - val_accuracy: 0.9510\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1491 - accuracy: 0.9567 - val_loss: 0.1697 - val_accuracy: 0.9510\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1424 - accuracy: 0.9597 - val_loss: 0.1640 - val_accuracy: 0.9520\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.1376 - accuracy: 0.9605 - val_loss: 0.1589 - val_accuracy: 0.9510\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.1315 - accuracy: 0.9600 - val_loss: 0.1604 - val_accuracy: 0.9500\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1291 - accuracy: 0.9632 - val_loss: 0.1581 - val_accuracy: 0.9510\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1249 - accuracy: 0.9638 - val_loss: 0.1598 - val_accuracy: 0.9540\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1223 - accuracy: 0.9647 - val_loss: 0.1568 - val_accuracy: 0.9530\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1183 - accuracy: 0.9647 - val_loss: 0.1529 - val_accuracy: 0.9550\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1143 - accuracy: 0.9660 - val_loss: 0.1475 - val_accuracy: 0.9550\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1109 - accuracy: 0.9660 - val_loss: 0.1513 - val_accuracy: 0.9560\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1128 - accuracy: 0.9647 - val_loss: 0.1469 - val_accuracy: 0.9580\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1057 - accuracy: 0.9682 - val_loss: 0.1481 - val_accuracy: 0.9560\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1011 - accuracy: 0.9690 - val_loss: 0.1536 - val_accuracy: 0.9540\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1011 - accuracy: 0.9700 - val_loss: 0.1435 - val_accuracy: 0.9550\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0992 - accuracy: 0.9703 - val_loss: 0.1394 - val_accuracy: 0.9570\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0932 - accuracy: 0.9730 - val_loss: 0.1412 - val_accuracy: 0.9580\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0929 - accuracy: 0.9725 - val_loss: 0.1397 - val_accuracy: 0.9610\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0860 - accuracy: 0.9750 - val_loss: 0.1407 - val_accuracy: 0.9620\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0843 - accuracy: 0.9730 - val_loss: 0.1433 - val_accuracy: 0.9530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0811 - accuracy: 0.9753 - val_loss: 0.1412 - val_accuracy: 0.9620\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0757 - accuracy: 0.9778 - val_loss: 0.1451 - val_accuracy: 0.9620\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0721 - accuracy: 0.9785 - val_loss: 0.1405 - val_accuracy: 0.9610\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0665 - accuracy: 0.9800 - val_loss: 0.1427 - val_accuracy: 0.9630\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0613 - accuracy: 0.9820 - val_loss: 0.1718 - val_accuracy: 0.9610\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0606 - accuracy: 0.9822 - val_loss: 0.1444 - val_accuracy: 0.9630\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0521 - accuracy: 0.9862 - val_loss: 0.1464 - val_accuracy: 0.9570\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0468 - accuracy: 0.9885 - val_loss: 0.1637 - val_accuracy: 0.9580\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0414 - accuracy: 0.9893 - val_loss: 0.1491 - val_accuracy: 0.9570\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0392 - accuracy: 0.9898 - val_loss: 0.2124 - val_accuracy: 0.9520\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0347 - accuracy: 0.9920 - val_loss: 0.1618 - val_accuracy: 0.9600\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0317 - accuracy: 0.9927 - val_loss: 0.1615 - val_accuracy: 0.9620\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0264 - accuracy: 0.9948 - val_loss: 0.1571 - val_accuracy: 0.9590\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0231 - accuracy: 0.9955 - val_loss: 0.1595 - val_accuracy: 0.9630\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0223 - accuracy: 0.9958 - val_loss: 0.1650 - val_accuracy: 0.9660\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0187 - accuracy: 0.9973 - val_loss: 0.1858 - val_accuracy: 0.9600\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.729433757167905\n",
      "F1 Micro: 0.9582\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7538671317401531\n",
      "F1 Micro: 0.9569\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7726025765525989\n",
      "F1 Micro: 0.9612\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 4 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.4318 - accuracy: 0.8955 - val_loss: 0.2441 - val_accuracy: 0.9345\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.1874 - accuracy: 0.9464 - val_loss: 0.1727 - val_accuracy: 0.9463\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.1386 - accuracy: 0.9574 - val_loss: 0.1463 - val_accuracy: 0.9522\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.1223 - accuracy: 0.9617 - val_loss: 0.1258 - val_accuracy: 0.9581\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.1116 - accuracy: 0.9656 - val_loss: 0.1137 - val_accuracy: 0.9626\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.1043 - accuracy: 0.9676 - val_loss: 0.1180 - val_accuracy: 0.9618\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0984 - accuracy: 0.9694 - val_loss: 0.1079 - val_accuracy: 0.9632\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0922 - accuracy: 0.9707 - val_loss: 0.1127 - val_accuracy: 0.9636\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0856 - accuracy: 0.9719 - val_loss: 0.1144 - val_accuracy: 0.9641\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0805 - accuracy: 0.9741 - val_loss: 0.1127 - val_accuracy: 0.9629\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0772 - accuracy: 0.9748 - val_loss: 0.1083 - val_accuracy: 0.9638\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0710 - accuracy: 0.9757 - val_loss: 0.1049 - val_accuracy: 0.9649\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0673 - accuracy: 0.9773 - val_loss: 0.1119 - val_accuracy: 0.9647\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0627 - accuracy: 0.9787 - val_loss: 0.1010 - val_accuracy: 0.9654\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0575 - accuracy: 0.9808 - val_loss: 0.0989 - val_accuracy: 0.9666\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0520 - accuracy: 0.9826 - val_loss: 0.1011 - val_accuracy: 0.9657\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0480 - accuracy: 0.9836 - val_loss: 0.0972 - val_accuracy: 0.9695\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0417 - accuracy: 0.9861 - val_loss: 0.0961 - val_accuracy: 0.9694\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0363 - accuracy: 0.9875 - val_loss: 0.0974 - val_accuracy: 0.9697\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0327 - accuracy: 0.9887 - val_loss: 0.1001 - val_accuracy: 0.9690\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 0.1083 - val_accuracy: 0.9660\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.1127 - val_accuracy: 0.9688\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.1293 - val_accuracy: 0.9690\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.1186 - val_accuracy: 0.9677\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.1329 - val_accuracy: 0.9707\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.1498 - val_accuracy: 0.9690\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.1292 - val_accuracy: 0.9684\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.1484 - val_accuracy: 0.9667\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.1716 - val_accuracy: 0.9664\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1509 - val_accuracy: 0.9656\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.1343 - val_accuracy: 0.9696\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.1947 - val_accuracy: 0.9590\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.2331 - val_accuracy: 0.9641\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1509 - val_accuracy: 0.9703\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1608 - val_accuracy: 0.9664\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.1486 - val_accuracy: 0.9711\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.1369 - val_accuracy: 0.9703\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.1530 - val_accuracy: 0.9699\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8286644317337637\n",
      "F1 Micro: 0.9727\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8049513665087576\n",
      "F1 Micro: 0.9643\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.5061 - accuracy: 0.8863 - val_loss: 0.1680 - val_accuracy: 0.9522\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1462 - accuracy: 0.9587 - val_loss: 0.1394 - val_accuracy: 0.9564\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1278 - accuracy: 0.9624 - val_loss: 0.1298 - val_accuracy: 0.9585\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1185 - accuracy: 0.9642 - val_loss: 0.1240 - val_accuracy: 0.9594\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.1121 - accuracy: 0.9659 - val_loss: 0.1204 - val_accuracy: 0.9619\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1078 - accuracy: 0.9671 - val_loss: 0.1174 - val_accuracy: 0.9618\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1036 - accuracy: 0.9687 - val_loss: 0.1142 - val_accuracy: 0.9629\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1005 - accuracy: 0.9689 - val_loss: 0.1104 - val_accuracy: 0.9640\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0976 - accuracy: 0.9701 - val_loss: 0.1111 - val_accuracy: 0.9631\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0953 - accuracy: 0.9701 - val_loss: 0.1084 - val_accuracy: 0.9644\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0931 - accuracy: 0.9712 - val_loss: 0.1067 - val_accuracy: 0.9654\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0916 - accuracy: 0.9717 - val_loss: 0.1042 - val_accuracy: 0.9648\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0897 - accuracy: 0.9721 - val_loss: 0.1079 - val_accuracy: 0.9635\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0883 - accuracy: 0.9726 - val_loss: 0.1038 - val_accuracy: 0.9655\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0868 - accuracy: 0.9737 - val_loss: 0.1031 - val_accuracy: 0.9655\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0856 - accuracy: 0.9732 - val_loss: 0.1021 - val_accuracy: 0.9667\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0841 - accuracy: 0.9746 - val_loss: 0.1010 - val_accuracy: 0.9661\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0828 - accuracy: 0.9749 - val_loss: 0.1024 - val_accuracy: 0.9666\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0816 - accuracy: 0.9749 - val_loss: 0.1003 - val_accuracy: 0.9667\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0807 - accuracy: 0.9747 - val_loss: 0.1011 - val_accuracy: 0.9672\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0797 - accuracy: 0.9753 - val_loss: 0.1006 - val_accuracy: 0.9670\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0785 - accuracy: 0.9758 - val_loss: 0.1000 - val_accuracy: 0.9672\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0773 - accuracy: 0.9765 - val_loss: 0.0995 - val_accuracy: 0.9666\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0766 - accuracy: 0.9765 - val_loss: 0.1000 - val_accuracy: 0.9669\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0755 - accuracy: 0.9765 - val_loss: 0.0999 - val_accuracy: 0.9677\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0745 - accuracy: 0.9768 - val_loss: 0.1016 - val_accuracy: 0.9662\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0737 - accuracy: 0.9774 - val_loss: 0.0989 - val_accuracy: 0.9673\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0728 - accuracy: 0.9776 - val_loss: 0.0987 - val_accuracy: 0.9675\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0717 - accuracy: 0.9783 - val_loss: 0.1005 - val_accuracy: 0.9668\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0710 - accuracy: 0.9782 - val_loss: 0.0983 - val_accuracy: 0.9670\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0701 - accuracy: 0.9784 - val_loss: 0.0983 - val_accuracy: 0.9676\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0697 - accuracy: 0.9786 - val_loss: 0.0980 - val_accuracy: 0.9673\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0687 - accuracy: 0.9787 - val_loss: 0.0976 - val_accuracy: 0.9672\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0678 - accuracy: 0.9795 - val_loss: 0.0974 - val_accuracy: 0.9677\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0670 - accuracy: 0.9794 - val_loss: 0.0980 - val_accuracy: 0.9686\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0662 - accuracy: 0.9797 - val_loss: 0.0985 - val_accuracy: 0.9663\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0659 - accuracy: 0.9802 - val_loss: 0.0979 - val_accuracy: 0.9676\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0651 - accuracy: 0.9804 - val_loss: 0.0989 - val_accuracy: 0.9689\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0645 - accuracy: 0.9806 - val_loss: 0.0971 - val_accuracy: 0.9677\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0635 - accuracy: 0.9809 - val_loss: 0.0973 - val_accuracy: 0.9672\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0630 - accuracy: 0.9812 - val_loss: 0.0975 - val_accuracy: 0.9684\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0621 - accuracy: 0.9813 - val_loss: 0.0984 - val_accuracy: 0.9684\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0617 - accuracy: 0.9815 - val_loss: 0.0985 - val_accuracy: 0.9686\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0609 - accuracy: 0.9815 - val_loss: 0.0977 - val_accuracy: 0.9676\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0602 - accuracy: 0.9820 - val_loss: 0.0983 - val_accuracy: 0.9665\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0595 - accuracy: 0.9821 - val_loss: 0.0978 - val_accuracy: 0.9685\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0588 - accuracy: 0.9827 - val_loss: 0.0980 - val_accuracy: 0.9688\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0584 - accuracy: 0.9822 - val_loss: 0.0981 - val_accuracy: 0.9678\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0575 - accuracy: 0.9823 - val_loss: 0.0996 - val_accuracy: 0.9688\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0570 - accuracy: 0.9832 - val_loss: 0.0980 - val_accuracy: 0.9664\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0565 - accuracy: 0.9832 - val_loss: 0.0982 - val_accuracy: 0.9682\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0556 - accuracy: 0.9829 - val_loss: 0.0981 - val_accuracy: 0.9683\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0553 - accuracy: 0.9833 - val_loss: 0.0975 - val_accuracy: 0.9683\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0544 - accuracy: 0.9833 - val_loss: 0.0982 - val_accuracy: 0.9682\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0539 - accuracy: 0.9837 - val_loss: 0.0990 - val_accuracy: 0.9678\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0533 - accuracy: 0.9838 - val_loss: 0.0998 - val_accuracy: 0.9685\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0527 - accuracy: 0.9846 - val_loss: 0.1000 - val_accuracy: 0.9685\n",
      "Epoch 58/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0520 - accuracy: 0.9843 - val_loss: 0.0998 - val_accuracy: 0.9675\n",
      "Epoch 59/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0514 - accuracy: 0.9849 - val_loss: 0.0992 - val_accuracy: 0.9683\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8337990770622952\n",
      "F1 Micro: 0.9687\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.2422 - accuracy: 0.9342 - val_loss: 0.1613 - val_accuracy: 0.9536\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.1401 - accuracy: 0.9585 - val_loss: 0.1371 - val_accuracy: 0.9574\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.1214 - accuracy: 0.9631 - val_loss: 0.1206 - val_accuracy: 0.9617\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.1104 - accuracy: 0.9661 - val_loss: 0.1178 - val_accuracy: 0.9628\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.1035 - accuracy: 0.9679 - val_loss: 0.1120 - val_accuracy: 0.9639\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0963 - accuracy: 0.9703 - val_loss: 0.1075 - val_accuracy: 0.9659\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0903 - accuracy: 0.9715 - val_loss: 0.0996 - val_accuracy: 0.9664\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0837 - accuracy: 0.9740 - val_loss: 0.1009 - val_accuracy: 0.9669\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0786 - accuracy: 0.9753 - val_loss: 0.1014 - val_accuracy: 0.9676\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0729 - accuracy: 0.9766 - val_loss: 0.1083 - val_accuracy: 0.9635\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0680 - accuracy: 0.9776 - val_loss: 0.0932 - val_accuracy: 0.9697\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0625 - accuracy: 0.9797 - val_loss: 0.0912 - val_accuracy: 0.9710\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0569 - accuracy: 0.9815 - val_loss: 0.0903 - val_accuracy: 0.9710\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0505 - accuracy: 0.9838 - val_loss: 0.0947 - val_accuracy: 0.9700\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0443 - accuracy: 0.9857 - val_loss: 0.0941 - val_accuracy: 0.9704\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0371 - accuracy: 0.9876 - val_loss: 0.1055 - val_accuracy: 0.9706\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0297 - accuracy: 0.9905 - val_loss: 0.1087 - val_accuracy: 0.9686\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.1113 - val_accuracy: 0.9701\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.1416 - val_accuracy: 0.9687\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0147 - accuracy: 0.9959 - val_loss: 0.1222 - val_accuracy: 0.9695\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.1378 - val_accuracy: 0.9694\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.1366 - val_accuracy: 0.9700\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.1445 - val_accuracy: 0.9690\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.1556 - val_accuracy: 0.9708\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.1554 - val_accuracy: 0.9705\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.1613 - val_accuracy: 0.9679\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.1666 - val_accuracy: 0.9697\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.1668 - val_accuracy: 0.9707\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.1646 - val_accuracy: 0.9697\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.1735 - val_accuracy: 0.9687\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.1852 - val_accuracy: 0.9698\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 7.3153e-04 - accuracy: 0.9999 - val_loss: 0.1908 - val_accuracy: 0.9700\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 2.5750e-04 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9702\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8651727213605941\n",
      "F1 Micro: 0.9739\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8203768407952049\n",
      "F1 Micro: 0.9664\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8601045200433892\n",
      "F1 Micro: 0.9747\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 4 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.2308 - accuracy: 0.9374 - val_loss: 0.1194 - val_accuracy: 0.9644\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.1174 - accuracy: 0.9632 - val_loss: 0.0986 - val_accuracy: 0.9674\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0995 - accuracy: 0.9678 - val_loss: 0.0839 - val_accuracy: 0.9727\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0894 - accuracy: 0.9707 - val_loss: 0.0921 - val_accuracy: 0.9689\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0807 - accuracy: 0.9731 - val_loss: 0.0756 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0728 - accuracy: 0.9752 - val_loss: 0.0736 - val_accuracy: 0.9747\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0659 - accuracy: 0.9772 - val_loss: 0.0764 - val_accuracy: 0.9743\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 25s 196us/step - loss: 0.0610 - accuracy: 0.9789 - val_loss: 0.0693 - val_accuracy: 0.9768\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0566 - accuracy: 0.9802 - val_loss: 0.0638 - val_accuracy: 0.9772\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0521 - accuracy: 0.9815 - val_loss: 0.0649 - val_accuracy: 0.9781\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0479 - accuracy: 0.9824 - val_loss: 0.0608 - val_accuracy: 0.9787\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0445 - accuracy: 0.9839 - val_loss: 0.0661 - val_accuracy: 0.9769\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0407 - accuracy: 0.9851 - val_loss: 0.0685 - val_accuracy: 0.9770\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0370 - accuracy: 0.9865 - val_loss: 0.0745 - val_accuracy: 0.9751\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0328 - accuracy: 0.9881 - val_loss: 0.0711 - val_accuracy: 0.9770\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0287 - accuracy: 0.9894 - val_loss: 0.0781 - val_accuracy: 0.9772\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0252 - accuracy: 0.9908 - val_loss: 0.0766 - val_accuracy: 0.9780\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.0909 - val_accuracy: 0.9737\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0179 - accuracy: 0.9938 - val_loss: 0.0802 - val_accuracy: 0.9781\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.0861 - val_accuracy: 0.9781\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0930 - val_accuracy: 0.9761\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.1052 - val_accuracy: 0.9770\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.1112 - val_accuracy: 0.9767\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.1024 - val_accuracy: 0.9779\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.1082 - val_accuracy: 0.9759\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1141 - val_accuracy: 0.9754\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.1146 - val_accuracy: 0.9751\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.1290 - val_accuracy: 0.9766\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.1232 - val_accuracy: 0.9774\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.1158 - val_accuracy: 0.9774\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.1190 - val_accuracy: 0.9777\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8896830167074862\n",
      "F1 Micro: 0.9794\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.841263348610311\n",
      "F1 Micro: 0.9693\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.2418 - accuracy: 0.9385 - val_loss: 0.1224 - val_accuracy: 0.9615\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.1138 - accuracy: 0.9652 - val_loss: 0.1118 - val_accuracy: 0.9657\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.1041 - accuracy: 0.9674 - val_loss: 0.1036 - val_accuracy: 0.9675\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0982 - accuracy: 0.9695 - val_loss: 0.0980 - val_accuracy: 0.9695\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0944 - accuracy: 0.9704 - val_loss: 0.0970 - val_accuracy: 0.9688\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0912 - accuracy: 0.9710 - val_loss: 0.0939 - val_accuracy: 0.9702\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0890 - accuracy: 0.9721 - val_loss: 0.0934 - val_accuracy: 0.9702\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0870 - accuracy: 0.9725 - val_loss: 0.0910 - val_accuracy: 0.9709\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0850 - accuracy: 0.9729 - val_loss: 0.0900 - val_accuracy: 0.9714\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0834 - accuracy: 0.9735 - val_loss: 0.0886 - val_accuracy: 0.9721\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0819 - accuracy: 0.9741 - val_loss: 0.0882 - val_accuracy: 0.9722\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0803 - accuracy: 0.9743 - val_loss: 0.0881 - val_accuracy: 0.9719\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0790 - accuracy: 0.9749 - val_loss: 0.0871 - val_accuracy: 0.9720\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0777 - accuracy: 0.9751 - val_loss: 0.0863 - val_accuracy: 0.9720\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0766 - accuracy: 0.9754 - val_loss: 0.0851 - val_accuracy: 0.9720\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0758 - accuracy: 0.9759 - val_loss: 0.0857 - val_accuracy: 0.9717\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0748 - accuracy: 0.9758 - val_loss: 0.0840 - val_accuracy: 0.9725\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0738 - accuracy: 0.9764 - val_loss: 0.0849 - val_accuracy: 0.9725\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0728 - accuracy: 0.9767 - val_loss: 0.0843 - val_accuracy: 0.9727\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0720 - accuracy: 0.9771 - val_loss: 0.0832 - val_accuracy: 0.9725\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0712 - accuracy: 0.9773 - val_loss: 0.0841 - val_accuracy: 0.9730\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0704 - accuracy: 0.9775 - val_loss: 0.0837 - val_accuracy: 0.9724\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0696 - accuracy: 0.9778 - val_loss: 0.0828 - val_accuracy: 0.9726\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0688 - accuracy: 0.9781 - val_loss: 0.0824 - val_accuracy: 0.9729\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0681 - accuracy: 0.9781 - val_loss: 0.0826 - val_accuracy: 0.9732\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0675 - accuracy: 0.9785 - val_loss: 0.0829 - val_accuracy: 0.9732\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0667 - accuracy: 0.9787 - val_loss: 0.0829 - val_accuracy: 0.9726\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0661 - accuracy: 0.9789 - val_loss: 0.0820 - val_accuracy: 0.9738\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0654 - accuracy: 0.9791 - val_loss: 0.0824 - val_accuracy: 0.9729\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0648 - accuracy: 0.9792 - val_loss: 0.0816 - val_accuracy: 0.9732\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0641 - accuracy: 0.9795 - val_loss: 0.0823 - val_accuracy: 0.9729\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0634 - accuracy: 0.9798 - val_loss: 0.0823 - val_accuracy: 0.9727\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0629 - accuracy: 0.9799 - val_loss: 0.0854 - val_accuracy: 0.9721\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0624 - accuracy: 0.9799 - val_loss: 0.0815 - val_accuracy: 0.9733\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0617 - accuracy: 0.9804 - val_loss: 0.0819 - val_accuracy: 0.9733\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0610 - accuracy: 0.9805 - val_loss: 0.0820 - val_accuracy: 0.9731\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0604 - accuracy: 0.9809 - val_loss: 0.0825 - val_accuracy: 0.9729\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0598 - accuracy: 0.9808 - val_loss: 0.0814 - val_accuracy: 0.9734\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0595 - accuracy: 0.9810 - val_loss: 0.0816 - val_accuracy: 0.9731\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0588 - accuracy: 0.9813 - val_loss: 0.0813 - val_accuracy: 0.9734\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0583 - accuracy: 0.9813 - val_loss: 0.0827 - val_accuracy: 0.9731\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.0828 - val_accuracy: 0.9735\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0571 - accuracy: 0.9818 - val_loss: 0.0817 - val_accuracy: 0.9732\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0567 - accuracy: 0.9820 - val_loss: 0.0818 - val_accuracy: 0.9734\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0561 - accuracy: 0.9823 - val_loss: 0.0817 - val_accuracy: 0.9732\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0554 - accuracy: 0.9825 - val_loss: 0.0823 - val_accuracy: 0.9732\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0550 - accuracy: 0.9825 - val_loss: 0.0822 - val_accuracy: 0.9725\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0546 - accuracy: 0.9825 - val_loss: 0.0830 - val_accuracy: 0.9727\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0539 - accuracy: 0.9828 - val_loss: 0.0828 - val_accuracy: 0.9735\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0534 - accuracy: 0.9829 - val_loss: 0.0838 - val_accuracy: 0.9728\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0528 - accuracy: 0.9835 - val_loss: 0.0835 - val_accuracy: 0.9739\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0525 - accuracy: 0.9831 - val_loss: 0.0826 - val_accuracy: 0.9729\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.0836 - val_accuracy: 0.9732\n",
      "Epoch 54/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0515 - accuracy: 0.9839 - val_loss: 0.0842 - val_accuracy: 0.9735\n",
      "Epoch 55/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0509 - accuracy: 0.9839 - val_loss: 0.0840 - val_accuracy: 0.9732\n",
      "Epoch 56/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0503 - accuracy: 0.9841 - val_loss: 0.0849 - val_accuracy: 0.9723\n",
      "Epoch 57/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0498 - accuracy: 0.9841 - val_loss: 0.0842 - val_accuracy: 0.9730\n",
      "Epoch 58/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0493 - accuracy: 0.9844 - val_loss: 0.0841 - val_accuracy: 0.9733\n",
      "Epoch 59/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0488 - accuracy: 0.9845 - val_loss: 0.0845 - val_accuracy: 0.9731\n",
      "Epoch 60/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0483 - accuracy: 0.9849 - val_loss: 0.0856 - val_accuracy: 0.9727\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8698662011878915\n",
      "F1 Micro: 0.9721\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.1748 - accuracy: 0.9493 - val_loss: 0.1116 - val_accuracy: 0.9652\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.1003 - accuracy: 0.9680 - val_loss: 0.0920 - val_accuracy: 0.9706\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0860 - accuracy: 0.9719 - val_loss: 0.0853 - val_accuracy: 0.9730\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0782 - accuracy: 0.9744 - val_loss: 0.0764 - val_accuracy: 0.9746\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0722 - accuracy: 0.9761 - val_loss: 0.0784 - val_accuracy: 0.9746\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0674 - accuracy: 0.9776 - val_loss: 0.0699 - val_accuracy: 0.9766\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0626 - accuracy: 0.9792 - val_loss: 0.0711 - val_accuracy: 0.9755\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0575 - accuracy: 0.9808 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0525 - accuracy: 0.9822 - val_loss: 0.0673 - val_accuracy: 0.9776\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0474 - accuracy: 0.9840 - val_loss: 0.0827 - val_accuracy: 0.9747\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0420 - accuracy: 0.9858 - val_loss: 0.0674 - val_accuracy: 0.9769\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0356 - accuracy: 0.9877 - val_loss: 0.0702 - val_accuracy: 0.9765\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0298 - accuracy: 0.9901 - val_loss: 0.0733 - val_accuracy: 0.9768\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.0766 - val_accuracy: 0.9774\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0859 - val_accuracy: 0.9770\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.0899 - val_accuracy: 0.9769\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.1202 - val_accuracy: 0.9693\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.1033 - val_accuracy: 0.9767\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.1057 - val_accuracy: 0.9775\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.1120 - val_accuracy: 0.9759\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.1154 - val_accuracy: 0.9761\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1162 - val_accuracy: 0.9763\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.1198 - val_accuracy: 0.9768\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.1264 - val_accuracy: 0.9774\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1263 - val_accuracy: 0.9759\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1396 - val_accuracy: 0.9764\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1492 - val_accuracy: 0.9768\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1439 - val_accuracy: 0.9755\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1365 - val_accuracy: 0.9739\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8780890086574168\n",
      "F1 Micro: 0.9773999999999999\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8437136007201609\n",
      "F1 Micro: 0.9683\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.9031601305313823\n",
      "F1 Micro: 0.98\n",
      "\n",
      "\n",
      " 55.2724681297938 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 5 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 5 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 2, 3, 4, 5, 6, 8]\n",
      "label_list [0, 2, 3, 4, 5, 6, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 813us/step - loss: 1.9789 - accuracy: 0.7900 - val_loss: 1.6556 - val_accuracy: 0.8100\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 1.1324 - accuracy: 0.8600 - val_loss: 0.9335 - val_accuracy: 0.8100\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.7728 - accuracy: 0.8600 - val_loss: 1.0017 - val_accuracy: 0.8100\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.7216 - accuracy: 0.8600 - val_loss: 0.8519 - val_accuracy: 0.8100\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.6785 - accuracy: 0.8600 - val_loss: 0.8226 - val_accuracy: 0.8100\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.6639 - accuracy: 0.8600 - val_loss: 0.8136 - val_accuracy: 0.8100\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.6421 - accuracy: 0.8600 - val_loss: 0.7834 - val_accuracy: 0.8100\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.6377 - accuracy: 0.8600 - val_loss: 0.7784 - val_accuracy: 0.8100\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6250 - accuracy: 0.8600 - val_loss: 0.7811 - val_accuracy: 0.8100\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.6210 - accuracy: 0.8600 - val_loss: 0.7657 - val_accuracy: 0.8100\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6163 - accuracy: 0.8600 - val_loss: 0.7578 - val_accuracy: 0.8100\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6143 - accuracy: 0.8600 - val_loss: 0.7589 - val_accuracy: 0.8100\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.6144 - accuracy: 0.8600 - val_loss: 0.7547 - val_accuracy: 0.8100\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6086 - accuracy: 0.8600 - val_loss: 0.7607 - val_accuracy: 0.8100\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.6046 - accuracy: 0.8600 - val_loss: 0.7442 - val_accuracy: 0.8100\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6006 - accuracy: 0.8600 - val_loss: 0.7511 - val_accuracy: 0.8100\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.5947 - accuracy: 0.8600 - val_loss: 0.7417 - val_accuracy: 0.8100\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.5881 - accuracy: 0.8600 - val_loss: 0.7293 - val_accuracy: 0.8100\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.5823 - accuracy: 0.8600 - val_loss: 0.7401 - val_accuracy: 0.8100\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.5894 - accuracy: 0.8600 - val_loss: 0.7151 - val_accuracy: 0.8100\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.5698 - accuracy: 0.8600 - val_loss: 0.7372 - val_accuracy: 0.8100\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.5667 - accuracy: 0.8600 - val_loss: 0.6995 - val_accuracy: 0.8100\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.5501 - accuracy: 0.8600 - val_loss: 0.7079 - val_accuracy: 0.8100\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.5469 - accuracy: 0.8600 - val_loss: 0.6722 - val_accuracy: 0.8100\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.5324 - accuracy: 0.8600 - val_loss: 0.6723 - val_accuracy: 0.8100\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.5481 - accuracy: 0.8600 - val_loss: 0.7288 - val_accuracy: 0.8100\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.5134 - accuracy: 0.8600 - val_loss: 0.6780 - val_accuracy: 0.8100\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.5014 - accuracy: 0.8600 - val_loss: 0.6727 - val_accuracy: 0.8100\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.4795 - accuracy: 0.8625 - val_loss: 0.6474 - val_accuracy: 0.8100\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.4705 - accuracy: 0.8675 - val_loss: 0.6667 - val_accuracy: 0.8100\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.4654 - accuracy: 0.8675 - val_loss: 0.6124 - val_accuracy: 0.8100\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.4474 - accuracy: 0.8725 - val_loss: 0.5825 - val_accuracy: 0.8200\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.4327 - accuracy: 0.8850 - val_loss: 0.5828 - val_accuracy: 0.8400\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.4524 - accuracy: 0.8875 - val_loss: 0.5560 - val_accuracy: 0.8200\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.4122 - accuracy: 0.8875 - val_loss: 0.5416 - val_accuracy: 0.8400\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.4047 - accuracy: 0.9025 - val_loss: 0.5246 - val_accuracy: 0.8500\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.4050 - accuracy: 0.9000 - val_loss: 0.5646 - val_accuracy: 0.8200\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.3653 - accuracy: 0.9000 - val_loss: 0.5262 - val_accuracy: 0.8400\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.3488 - accuracy: 0.9075 - val_loss: 0.5239 - val_accuracy: 0.8400\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.3431 - accuracy: 0.9100 - val_loss: 0.5649 - val_accuracy: 0.8300\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3377 - accuracy: 0.9125 - val_loss: 0.4867 - val_accuracy: 0.8600\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.3314 - accuracy: 0.9125 - val_loss: 0.4818 - val_accuracy: 0.8700\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.3289 - accuracy: 0.9200 - val_loss: 0.4700 - val_accuracy: 0.8700\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.3227 - accuracy: 0.9150 - val_loss: 0.4618 - val_accuracy: 0.8700\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.3151 - accuracy: 0.9200 - val_loss: 0.4565 - val_accuracy: 0.8700\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.3047 - accuracy: 0.9125 - val_loss: 0.4607 - val_accuracy: 0.8700\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.3034 - accuracy: 0.9175 - val_loss: 0.4432 - val_accuracy: 0.8600\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2882 - accuracy: 0.9175 - val_loss: 0.4607 - val_accuracy: 0.8600\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2830 - accuracy: 0.9150 - val_loss: 0.4687 - val_accuracy: 0.8600\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.2828 - accuracy: 0.9150 - val_loss: 0.4469 - val_accuracy: 0.8900\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.2892 - accuracy: 0.9125 - val_loss: 0.4581 - val_accuracy: 0.8400\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.2639 - accuracy: 0.9200 - val_loss: 0.4373 - val_accuracy: 0.8700\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2702 - accuracy: 0.9250 - val_loss: 0.4303 - val_accuracy: 0.8700\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2593 - accuracy: 0.9275 - val_loss: 0.4722 - val_accuracy: 0.8500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.2670 - accuracy: 0.9200 - val_loss: 0.4197 - val_accuracy: 0.8800\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2474 - accuracy: 0.9225 - val_loss: 0.4211 - val_accuracy: 0.8600\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.2380 - accuracy: 0.9225 - val_loss: 0.4110 - val_accuracy: 0.8800\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2392 - accuracy: 0.9250 - val_loss: 0.4168 - val_accuracy: 0.8700\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.2611 - accuracy: 0.9250 - val_loss: 0.4198 - val_accuracy: 0.8600\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2373 - accuracy: 0.9225 - val_loss: 0.4247 - val_accuracy: 0.8800\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.2380 - accuracy: 0.9250 - val_loss: 0.4109 - val_accuracy: 0.8800\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2170 - accuracy: 0.9325 - val_loss: 0.4033 - val_accuracy: 0.8900\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2240 - accuracy: 0.9250 - val_loss: 0.4743 - val_accuracy: 0.8600\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2242 - accuracy: 0.9250 - val_loss: 0.4219 - val_accuracy: 0.8900\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2071 - accuracy: 0.9350 - val_loss: 0.4512 - val_accuracy: 0.8500\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.2204 - accuracy: 0.9350 - val_loss: 0.4645 - val_accuracy: 0.8700\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2167 - accuracy: 0.9375 - val_loss: 0.3975 - val_accuracy: 0.8800\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.1844 - accuracy: 0.9375 - val_loss: 0.3870 - val_accuracy: 0.8900\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.1827 - accuracy: 0.9350 - val_loss: 0.3926 - val_accuracy: 0.8800\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1829 - accuracy: 0.9450 - val_loss: 0.3807 - val_accuracy: 0.8700\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1749 - accuracy: 0.9425 - val_loss: 0.3748 - val_accuracy: 0.8800\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 233us/step - loss: 0.1708 - accuracy: 0.9525 - val_loss: 0.3802 - val_accuracy: 0.8900\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1834 - accuracy: 0.9400 - val_loss: 0.4003 - val_accuracy: 0.9000\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1762 - accuracy: 0.9375 - val_loss: 0.3826 - val_accuracy: 0.8900\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1636 - accuracy: 0.9500 - val_loss: 0.3810 - val_accuracy: 0.8700\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.1503 - accuracy: 0.9550 - val_loss: 0.3707 - val_accuracy: 0.8900\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1471 - accuracy: 0.9550 - val_loss: 0.3695 - val_accuracy: 0.8900\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1463 - accuracy: 0.9525 - val_loss: 0.3607 - val_accuracy: 0.8700\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1501 - accuracy: 0.9575 - val_loss: 0.3799 - val_accuracy: 0.8800\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1416 - accuracy: 0.9600 - val_loss: 0.3706 - val_accuracy: 0.8800\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1534 - accuracy: 0.9500 - val_loss: 0.3788 - val_accuracy: 0.9000\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1367 - accuracy: 0.9575 - val_loss: 0.4399 - val_accuracy: 0.8800\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1500 - accuracy: 0.9575 - val_loss: 0.3594 - val_accuracy: 0.8900\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1678 - accuracy: 0.9400 - val_loss: 0.3726 - val_accuracy: 0.9000\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1548 - accuracy: 0.9425 - val_loss: 0.3659 - val_accuracy: 0.9000\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1881 - accuracy: 0.9450 - val_loss: 0.3851 - val_accuracy: 0.8600\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.1713 - accuracy: 0.9500 - val_loss: 0.3591 - val_accuracy: 0.8600\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1397 - accuracy: 0.9625 - val_loss: 0.3590 - val_accuracy: 0.8900\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.1243 - accuracy: 0.9675 - val_loss: 0.3992 - val_accuracy: 0.8800\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1289 - accuracy: 0.9625 - val_loss: 0.3588 - val_accuracy: 0.9000\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.1222 - accuracy: 0.9625 - val_loss: 0.3978 - val_accuracy: 0.9000\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1476 - accuracy: 0.9550 - val_loss: 0.3914 - val_accuracy: 0.8600\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1403 - accuracy: 0.9600 - val_loss: 0.3333 - val_accuracy: 0.9100\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.1149 - accuracy: 0.9650 - val_loss: 0.3587 - val_accuracy: 0.8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1097 - accuracy: 0.9675 - val_loss: 0.3343 - val_accuracy: 0.8900\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.1137 - accuracy: 0.9675 - val_loss: 0.3431 - val_accuracy: 0.8600\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.1212 - accuracy: 0.9725 - val_loss: 0.3611 - val_accuracy: 0.8800\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.1329 - accuracy: 0.9650 - val_loss: 0.3519 - val_accuracy: 0.8800\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.1186 - accuracy: 0.9650 - val_loss: 0.3239 - val_accuracy: 0.8800\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1247 - accuracy: 0.9650 - val_loss: 0.3191 - val_accuracy: 0.8800\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1155 - accuracy: 0.9700 - val_loss: 0.3236 - val_accuracy: 0.9000\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1093 - accuracy: 0.9650 - val_loss: 0.3768 - val_accuracy: 0.8900\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.0938 - accuracy: 0.9700 - val_loss: 0.3384 - val_accuracy: 0.9000\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0823 - accuracy: 0.9825 - val_loss: 0.3071 - val_accuracy: 0.8800\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0886 - accuracy: 0.9775 - val_loss: 0.3092 - val_accuracy: 0.9000\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0874 - accuracy: 0.9750 - val_loss: 0.3127 - val_accuracy: 0.8800\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0801 - accuracy: 0.9750 - val_loss: 0.3104 - val_accuracy: 0.8900\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0765 - accuracy: 0.9825 - val_loss: 0.3024 - val_accuracy: 0.9000\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0774 - accuracy: 0.9800 - val_loss: 0.3029 - val_accuracy: 0.8700\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0920 - accuracy: 0.9750 - val_loss: 0.3069 - val_accuracy: 0.9000\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0760 - accuracy: 0.9725 - val_loss: 0.3143 - val_accuracy: 0.9000\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0782 - accuracy: 0.9725 - val_loss: 0.3435 - val_accuracy: 0.8900\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0832 - accuracy: 0.9800 - val_loss: 0.3757 - val_accuracy: 0.9000\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0844 - accuracy: 0.9750 - val_loss: 0.4109 - val_accuracy: 0.9100\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1184 - accuracy: 0.9550 - val_loss: 0.4576 - val_accuracy: 0.8800\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1315 - accuracy: 0.9550 - val_loss: 0.5803 - val_accuracy: 0.8800\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.1592 - accuracy: 0.9475 - val_loss: 0.4198 - val_accuracy: 0.9100\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0940 - accuracy: 0.9725 - val_loss: 0.3928 - val_accuracy: 0.8800\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.0787 - accuracy: 0.9750 - val_loss: 0.3102 - val_accuracy: 0.9000\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0658 - accuracy: 0.9825 - val_loss: 0.3069 - val_accuracy: 0.9000\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0582 - accuracy: 0.9900 - val_loss: 0.2909 - val_accuracy: 0.8900\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0530 - accuracy: 0.9875 - val_loss: 0.2871 - val_accuracy: 0.9100\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.0499 - accuracy: 0.9875 - val_loss: 0.2948 - val_accuracy: 0.9100\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0493 - accuracy: 0.9875 - val_loss: 0.2983 - val_accuracy: 0.9100\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0477 - accuracy: 0.9950 - val_loss: 0.3097 - val_accuracy: 0.9100\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.0509 - accuracy: 0.9900 - val_loss: 0.2912 - val_accuracy: 0.9000\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0517 - accuracy: 0.9850 - val_loss: 0.3077 - val_accuracy: 0.9100\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0509 - accuracy: 0.9900 - val_loss: 0.2938 - val_accuracy: 0.9100\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0508 - accuracy: 0.9850 - val_loss: 0.2930 - val_accuracy: 0.9000\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0451 - accuracy: 0.9925 - val_loss: 0.2885 - val_accuracy: 0.9100\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0446 - accuracy: 0.9925 - val_loss: 0.2974 - val_accuracy: 0.9100\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.0397 - accuracy: 0.9925 - val_loss: 0.3248 - val_accuracy: 0.9100\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0457 - accuracy: 0.9875 - val_loss: 0.3177 - val_accuracy: 0.9100\n",
      "Epoch 134/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0388 - accuracy: 0.9925 - val_loss: 0.2834 - val_accuracy: 0.9100\n",
      "Epoch 135/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0383 - accuracy: 0.9950 - val_loss: 0.2714 - val_accuracy: 0.9000\n",
      "Epoch 136/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0355 - accuracy: 0.9950 - val_loss: 0.2720 - val_accuracy: 0.9100\n",
      "Epoch 137/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0335 - accuracy: 0.9925 - val_loss: 0.2938 - val_accuracy: 0.9100\n",
      "Epoch 138/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0338 - accuracy: 0.9950 - val_loss: 0.2858 - val_accuracy: 0.9200\n",
      "Epoch 139/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0331 - accuracy: 0.9950 - val_loss: 0.2718 - val_accuracy: 0.9100\n",
      "Epoch 140/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0344 - accuracy: 0.9975 - val_loss: 0.2774 - val_accuracy: 0.9000\n",
      "Epoch 141/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0336 - accuracy: 0.9925 - val_loss: 0.2798 - val_accuracy: 0.9100\n",
      "Epoch 142/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.0327 - accuracy: 0.9925 - val_loss: 0.2710 - val_accuracy: 0.9100\n",
      "Epoch 143/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0324 - accuracy: 0.9975 - val_loss: 0.2675 - val_accuracy: 0.9200\n",
      "Epoch 144/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0300 - accuracy: 0.9975 - val_loss: 0.2861 - val_accuracy: 0.9100\n",
      "Epoch 145/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0257 - accuracy: 0.9975 - val_loss: 0.2720 - val_accuracy: 0.9300\n",
      "Epoch 146/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0275 - accuracy: 0.9975 - val_loss: 0.2663 - val_accuracy: 0.9200\n",
      "Epoch 147/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.0306 - accuracy: 0.9925 - val_loss: 0.2936 - val_accuracy: 0.9100\n",
      "Epoch 148/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0282 - accuracy: 0.9975 - val_loss: 0.2832 - val_accuracy: 0.9000\n",
      "Epoch 149/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0240 - accuracy: 0.9975 - val_loss: 0.2761 - val_accuracy: 0.9100\n",
      "Epoch 150/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0225 - accuracy: 0.9975 - val_loss: 0.2664 - val_accuracy: 0.9300\n",
      "Epoch 151/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0230 - accuracy: 0.9975 - val_loss: 0.2768 - val_accuracy: 0.9100\n",
      "Epoch 152/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0221 - accuracy: 0.9950 - val_loss: 0.2834 - val_accuracy: 0.9100\n",
      "Epoch 153/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0247 - accuracy: 0.9925 - val_loss: 0.2815 - val_accuracy: 0.9100\n",
      "Epoch 154/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0214 - accuracy: 0.9975 - val_loss: 0.3012 - val_accuracy: 0.9100\n",
      "Epoch 155/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0214 - accuracy: 0.9975 - val_loss: 0.2677 - val_accuracy: 0.9100\n",
      "Epoch 156/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0202 - accuracy: 0.9975 - val_loss: 0.2743 - val_accuracy: 0.9100\n",
      "Epoch 157/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.0200 - accuracy: 0.9975 - val_loss: 0.2698 - val_accuracy: 0.9200\n",
      "Epoch 158/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.0206 - accuracy: 0.9950 - val_loss: 0.2728 - val_accuracy: 0.9100\n",
      "Epoch 159/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0187 - accuracy: 0.9975 - val_loss: 0.2888 - val_accuracy: 0.9100\n",
      "Epoch 160/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0168 - accuracy: 0.9975 - val_loss: 0.2700 - val_accuracy: 0.9200\n",
      "Epoch 161/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0164 - accuracy: 0.9975 - val_loss: 0.2717 - val_accuracy: 0.9200\n",
      "Epoch 162/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0187 - accuracy: 0.9975 - val_loss: 0.2814 - val_accuracy: 0.9200\n",
      "Epoch 163/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.9100\n",
      "Epoch 164/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0199 - accuracy: 0.9975 - val_loss: 0.3665 - val_accuracy: 0.9200\n",
      "Epoch 165/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0263 - accuracy: 0.9950 - val_loss: 0.3878 - val_accuracy: 0.9100\n",
      "Epoch 166/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.3272 - val_accuracy: 0.9100\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5758209147552017\n",
      "F1 Micro: 0.9320106217746381\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6246659563888246\n",
      "F1 Micro: 0.9452377373615912\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 297us/step - loss: 2.2401 - accuracy: 0.0700 - val_loss: 2.1539 - val_accuracy: 0.1000\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 90us/step - loss: 2.0269 - accuracy: 0.2700 - val_loss: 1.9919 - val_accuracy: 0.4300\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 74us/step - loss: 1.8662 - accuracy: 0.4925 - val_loss: 1.8827 - val_accuracy: 0.4900\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.7529 - accuracy: 0.5575 - val_loss: 1.8071 - val_accuracy: 0.5100\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.6680 - accuracy: 0.5900 - val_loss: 1.7457 - val_accuracy: 0.5300\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.5975 - accuracy: 0.6200 - val_loss: 1.6877 - val_accuracy: 0.5500\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.5292 - accuracy: 0.6500 - val_loss: 1.6336 - val_accuracy: 0.5700\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.4646 - accuracy: 0.6725 - val_loss: 1.5770 - val_accuracy: 0.5800\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.3987 - accuracy: 0.6900 - val_loss: 1.5222 - val_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.3342 - accuracy: 0.7175 - val_loss: 1.4656 - val_accuracy: 0.6300\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.2682 - accuracy: 0.7400 - val_loss: 1.4113 - val_accuracy: 0.6600\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 1.2041 - accuracy: 0.7725 - val_loss: 1.3535 - val_accuracy: 0.6800\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 1.1390 - accuracy: 0.7925 - val_loss: 1.2978 - val_accuracy: 0.7000\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.0767 - accuracy: 0.8050 - val_loss: 1.2450 - val_accuracy: 0.7100\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.0176 - accuracy: 0.8100 - val_loss: 1.1899 - val_accuracy: 0.7200\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.9580 - accuracy: 0.8375 - val_loss: 1.1372 - val_accuracy: 0.7300\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.9001 - accuracy: 0.8475 - val_loss: 1.0932 - val_accuracy: 0.7500\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.8482 - accuracy: 0.8600 - val_loss: 1.0396 - val_accuracy: 0.7900\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.7960 - accuracy: 0.8700 - val_loss: 0.9967 - val_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.7495 - accuracy: 0.8750 - val_loss: 0.9497 - val_accuracy: 0.8100\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.7043 - accuracy: 0.8900 - val_loss: 0.9088 - val_accuracy: 0.8300\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 71us/step - loss: 0.6620 - accuracy: 0.8975 - val_loss: 0.8798 - val_accuracy: 0.8300\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.6244 - accuracy: 0.9050 - val_loss: 0.8423 - val_accuracy: 0.8400\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.5868 - accuracy: 0.9075 - val_loss: 0.8120 - val_accuracy: 0.8500\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.5536 - accuracy: 0.9125 - val_loss: 0.7735 - val_accuracy: 0.8700\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.5212 - accuracy: 0.9150 - val_loss: 0.7465 - val_accuracy: 0.8900\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.4919 - accuracy: 0.9200 - val_loss: 0.7229 - val_accuracy: 0.8900\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.4648 - accuracy: 0.9250 - val_loss: 0.6960 - val_accuracy: 0.8900\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.4397 - accuracy: 0.9300 - val_loss: 0.6714 - val_accuracy: 0.8900\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.4178 - accuracy: 0.9425 - val_loss: 0.6433 - val_accuracy: 0.9000\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.3956 - accuracy: 0.9475 - val_loss: 0.6309 - val_accuracy: 0.9100\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.3751 - accuracy: 0.9500 - val_loss: 0.6110 - val_accuracy: 0.9100\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.3558 - accuracy: 0.9575 - val_loss: 0.5909 - val_accuracy: 0.9100\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.3388 - accuracy: 0.9625 - val_loss: 0.5761 - val_accuracy: 0.9100\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.3225 - accuracy: 0.9625 - val_loss: 0.5632 - val_accuracy: 0.9100\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.3076 - accuracy: 0.9650 - val_loss: 0.5452 - val_accuracy: 0.9100\n",
      "Epoch 37/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 82us/step - loss: 0.2939 - accuracy: 0.9650 - val_loss: 0.5325 - val_accuracy: 0.9200\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2811 - accuracy: 0.9675 - val_loss: 0.5201 - val_accuracy: 0.9200\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2698 - accuracy: 0.9675 - val_loss: 0.5091 - val_accuracy: 0.9200\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.2583 - accuracy: 0.9675 - val_loss: 0.4983 - val_accuracy: 0.9200\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2483 - accuracy: 0.9700 - val_loss: 0.4874 - val_accuracy: 0.9200\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2383 - accuracy: 0.9700 - val_loss: 0.4774 - val_accuracy: 0.9200\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.2298 - accuracy: 0.9700 - val_loss: 0.4737 - val_accuracy: 0.9200\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2210 - accuracy: 0.9700 - val_loss: 0.4612 - val_accuracy: 0.9200\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2137 - accuracy: 0.9700 - val_loss: 0.4553 - val_accuracy: 0.9200\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2068 - accuracy: 0.9700 - val_loss: 0.4399 - val_accuracy: 0.9200\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.1985 - accuracy: 0.9700 - val_loss: 0.4359 - val_accuracy: 0.9200\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1921 - accuracy: 0.9725 - val_loss: 0.4298 - val_accuracy: 0.9200\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1856 - accuracy: 0.9725 - val_loss: 0.4228 - val_accuracy: 0.9200\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1793 - accuracy: 0.9725 - val_loss: 0.4107 - val_accuracy: 0.9200\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1743 - accuracy: 0.9725 - val_loss: 0.4049 - val_accuracy: 0.9200\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.1685 - accuracy: 0.9725 - val_loss: 0.4021 - val_accuracy: 0.9200\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1635 - accuracy: 0.9725 - val_loss: 0.3968 - val_accuracy: 0.9200\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1585 - accuracy: 0.9750 - val_loss: 0.3968 - val_accuracy: 0.9200\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.1543 - accuracy: 0.9750 - val_loss: 0.3907 - val_accuracy: 0.9200\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.1495 - accuracy: 0.9750 - val_loss: 0.3820 - val_accuracy: 0.9200\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1463 - accuracy: 0.9750 - val_loss: 0.3722 - val_accuracy: 0.9200\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.1416 - accuracy: 0.9750 - val_loss: 0.3680 - val_accuracy: 0.9200\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1370 - accuracy: 0.9750 - val_loss: 0.3707 - val_accuracy: 0.9200\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1338 - accuracy: 0.9750 - val_loss: 0.3654 - val_accuracy: 0.9200\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 86us/step - loss: 0.1302 - accuracy: 0.9750 - val_loss: 0.3619 - val_accuracy: 0.9200\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1265 - accuracy: 0.9750 - val_loss: 0.3547 - val_accuracy: 0.9200\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1231 - accuracy: 0.9750 - val_loss: 0.3486 - val_accuracy: 0.9300\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.1204 - accuracy: 0.9750 - val_loss: 0.3417 - val_accuracy: 0.9300\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1168 - accuracy: 0.9750 - val_loss: 0.3408 - val_accuracy: 0.9300\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1139 - accuracy: 0.9775 - val_loss: 0.3398 - val_accuracy: 0.9300\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1111 - accuracy: 0.9775 - val_loss: 0.3354 - val_accuracy: 0.9300\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1086 - accuracy: 0.9775 - val_loss: 0.3301 - val_accuracy: 0.9300\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1057 - accuracy: 0.9800 - val_loss: 0.3286 - val_accuracy: 0.9300\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.1035 - accuracy: 0.9800 - val_loss: 0.3264 - val_accuracy: 0.9300\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1012 - accuracy: 0.9825 - val_loss: 0.3202 - val_accuracy: 0.9300\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0988 - accuracy: 0.9800 - val_loss: 0.3166 - val_accuracy: 0.9300\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0969 - accuracy: 0.9825 - val_loss: 0.3171 - val_accuracy: 0.9300\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0949 - accuracy: 0.9825 - val_loss: 0.3062 - val_accuracy: 0.9300\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0926 - accuracy: 0.9850 - val_loss: 0.3056 - val_accuracy: 0.9300\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0902 - accuracy: 0.9850 - val_loss: 0.3063 - val_accuracy: 0.9300\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0885 - accuracy: 0.9850 - val_loss: 0.3030 - val_accuracy: 0.9300\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0866 - accuracy: 0.9850 - val_loss: 0.3021 - val_accuracy: 0.9300\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.0849 - accuracy: 0.9875 - val_loss: 0.2989 - val_accuracy: 0.9300\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.0832 - accuracy: 0.9875 - val_loss: 0.2900 - val_accuracy: 0.9300\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0816 - accuracy: 0.9875 - val_loss: 0.2895 - val_accuracy: 0.9300\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0800 - accuracy: 0.9875 - val_loss: 0.2886 - val_accuracy: 0.9300\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.0788 - accuracy: 0.9875 - val_loss: 0.2918 - val_accuracy: 0.9300\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0774 - accuracy: 0.9875 - val_loss: 0.2833 - val_accuracy: 0.9300\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0755 - accuracy: 0.9875 - val_loss: 0.2833 - val_accuracy: 0.9300\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0743 - accuracy: 0.9875 - val_loss: 0.2781 - val_accuracy: 0.9300\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0727 - accuracy: 0.9875 - val_loss: 0.2803 - val_accuracy: 0.9300\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0715 - accuracy: 0.9875 - val_loss: 0.2782 - val_accuracy: 0.9300\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0702 - accuracy: 0.9875 - val_loss: 0.2758 - val_accuracy: 0.9300\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0689 - accuracy: 0.9875 - val_loss: 0.2717 - val_accuracy: 0.9300\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0677 - accuracy: 0.9875 - val_loss: 0.2721 - val_accuracy: 0.9300\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0667 - accuracy: 0.9875 - val_loss: 0.2684 - val_accuracy: 0.9300\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0655 - accuracy: 0.9875 - val_loss: 0.2713 - val_accuracy: 0.9300\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0645 - accuracy: 0.9900 - val_loss: 0.2637 - val_accuracy: 0.9300\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0631 - accuracy: 0.9900 - val_loss: 0.2652 - val_accuracy: 0.9300\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0622 - accuracy: 0.9900 - val_loss: 0.2626 - val_accuracy: 0.9300\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0613 - accuracy: 0.9900 - val_loss: 0.2662 - val_accuracy: 0.9300\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0601 - accuracy: 0.9900 - val_loss: 0.2589 - val_accuracy: 0.9300\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0592 - accuracy: 0.9900 - val_loss: 0.2584 - val_accuracy: 0.9300\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0581 - accuracy: 0.9900 - val_loss: 0.2559 - val_accuracy: 0.9300\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0570 - accuracy: 0.9900 - val_loss: 0.2541 - val_accuracy: 0.9300\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0563 - accuracy: 0.9900 - val_loss: 0.2554 - val_accuracy: 0.9300\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0554 - accuracy: 0.9900 - val_loss: 0.2527 - val_accuracy: 0.9300\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0544 - accuracy: 0.9900 - val_loss: 0.2525 - val_accuracy: 0.9300\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.0536 - accuracy: 0.9925 - val_loss: 0.2484 - val_accuracy: 0.9300\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0527 - accuracy: 0.9925 - val_loss: 0.2498 - val_accuracy: 0.9300\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0523 - accuracy: 0.9925 - val_loss: 0.2459 - val_accuracy: 0.9300\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0512 - accuracy: 0.9925 - val_loss: 0.2483 - val_accuracy: 0.9400\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0503 - accuracy: 0.9925 - val_loss: 0.2476 - val_accuracy: 0.9400\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0494 - accuracy: 0.9925 - val_loss: 0.2438 - val_accuracy: 0.9400\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0487 - accuracy: 0.9925 - val_loss: 0.2424 - val_accuracy: 0.9500\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0481 - accuracy: 0.9925 - val_loss: 0.2431 - val_accuracy: 0.9500\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0474 - accuracy: 0.9925 - val_loss: 0.2423 - val_accuracy: 0.9500\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0466 - accuracy: 0.9925 - val_loss: 0.2420 - val_accuracy: 0.9500\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0464 - accuracy: 0.9925 - val_loss: 0.2452 - val_accuracy: 0.9500\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0453 - accuracy: 0.9925 - val_loss: 0.2410 - val_accuracy: 0.9500\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0449 - accuracy: 0.9925 - val_loss: 0.2357 - val_accuracy: 0.9600\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0440 - accuracy: 0.9950 - val_loss: 0.2364 - val_accuracy: 0.9500\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0435 - accuracy: 0.9950 - val_loss: 0.2390 - val_accuracy: 0.9500\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0429 - accuracy: 0.9975 - val_loss: 0.2353 - val_accuracy: 0.9600\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0422 - accuracy: 0.9975 - val_loss: 0.2346 - val_accuracy: 0.9600\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 92us/step - loss: 0.0414 - accuracy: 0.9975 - val_loss: 0.2344 - val_accuracy: 0.9600\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0408 - accuracy: 0.9975 - val_loss: 0.2343 - val_accuracy: 0.9600\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0403 - accuracy: 0.9975 - val_loss: 0.2333 - val_accuracy: 0.9600\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0397 - accuracy: 0.9975 - val_loss: 0.2327 - val_accuracy: 0.9600\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0392 - accuracy: 0.9975 - val_loss: 0.2315 - val_accuracy: 0.9600\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0386 - accuracy: 0.9975 - val_loss: 0.2292 - val_accuracy: 0.9700\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0380 - accuracy: 0.9975 - val_loss: 0.2295 - val_accuracy: 0.9600\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0375 - accuracy: 0.9975 - val_loss: 0.2295 - val_accuracy: 0.9700\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0371 - accuracy: 0.9975 - val_loss: 0.2288 - val_accuracy: 0.9700\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0365 - accuracy: 0.9975 - val_loss: 0.2287 - val_accuracy: 0.9600\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0359 - accuracy: 0.9975 - val_loss: 0.2288 - val_accuracy: 0.9700\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0356 - accuracy: 0.9975 - val_loss: 0.2265 - val_accuracy: 0.9700\n",
      "Epoch 134/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0350 - accuracy: 0.9975 - val_loss: 0.2274 - val_accuracy: 0.9700\n",
      "Epoch 135/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0347 - accuracy: 0.9975 - val_loss: 0.2255 - val_accuracy: 0.9700\n",
      "Epoch 136/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0340 - accuracy: 0.9975 - val_loss: 0.2249 - val_accuracy: 0.9700\n",
      "Epoch 137/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0336 - accuracy: 0.9975 - val_loss: 0.2245 - val_accuracy: 0.9700\n",
      "Epoch 138/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0333 - accuracy: 0.9975 - val_loss: 0.2271 - val_accuracy: 0.9700\n",
      "Epoch 139/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0329 - accuracy: 0.9975 - val_loss: 0.2233 - val_accuracy: 0.9700\n",
      "Epoch 140/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0323 - accuracy: 0.9975 - val_loss: 0.2233 - val_accuracy: 0.9700\n",
      "Epoch 141/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0318 - accuracy: 0.9975 - val_loss: 0.2220 - val_accuracy: 0.9700\n",
      "Epoch 142/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0313 - accuracy: 0.9975 - val_loss: 0.2214 - val_accuracy: 0.9700\n",
      "Epoch 143/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0310 - accuracy: 0.9975 - val_loss: 0.2219 - val_accuracy: 0.9700\n",
      "Epoch 144/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0305 - accuracy: 0.9975 - val_loss: 0.2205 - val_accuracy: 0.9700\n",
      "Epoch 145/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0302 - accuracy: 0.9975 - val_loss: 0.2199 - val_accuracy: 0.9700\n",
      "Epoch 146/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0298 - accuracy: 0.9975 - val_loss: 0.2196 - val_accuracy: 0.9700\n",
      "Epoch 147/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0293 - accuracy: 0.9975 - val_loss: 0.2200 - val_accuracy: 0.9700\n",
      "Epoch 148/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0289 - accuracy: 0.9975 - val_loss: 0.2189 - val_accuracy: 0.9700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0286 - accuracy: 0.9975 - val_loss: 0.2197 - val_accuracy: 0.9700\n",
      "Epoch 150/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0283 - accuracy: 0.9975 - val_loss: 0.2185 - val_accuracy: 0.9700\n",
      "Epoch 151/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0279 - accuracy: 0.9975 - val_loss: 0.2191 - val_accuracy: 0.9700\n",
      "Epoch 152/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0275 - accuracy: 0.9975 - val_loss: 0.2168 - val_accuracy: 0.9700\n",
      "Epoch 153/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0271 - accuracy: 0.9975 - val_loss: 0.2169 - val_accuracy: 0.9700\n",
      "Epoch 154/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0267 - accuracy: 0.9975 - val_loss: 0.2178 - val_accuracy: 0.9700\n",
      "Epoch 155/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0264 - accuracy: 0.9975 - val_loss: 0.2171 - val_accuracy: 0.9700\n",
      "Epoch 156/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0262 - accuracy: 0.9975 - val_loss: 0.2182 - val_accuracy: 0.9700\n",
      "Epoch 157/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0257 - accuracy: 0.9975 - val_loss: 0.2160 - val_accuracy: 0.9700\n",
      "Epoch 158/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0254 - accuracy: 0.9975 - val_loss: 0.2154 - val_accuracy: 0.9700\n",
      "Epoch 159/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0252 - accuracy: 0.9975 - val_loss: 0.2161 - val_accuracy: 0.9600\n",
      "Epoch 160/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0261 - accuracy: 0.9975 - val_loss: 0.2105 - val_accuracy: 0.9700\n",
      "Epoch 161/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0247 - accuracy: 0.9975 - val_loss: 0.2122 - val_accuracy: 0.9700\n",
      "Epoch 162/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0241 - accuracy: 0.9975 - val_loss: 0.2166 - val_accuracy: 0.9600\n",
      "Epoch 163/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0239 - accuracy: 0.9975 - val_loss: 0.2148 - val_accuracy: 0.9600\n",
      "Epoch 164/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0235 - accuracy: 0.9975 - val_loss: 0.2140 - val_accuracy: 0.9600\n",
      "Epoch 165/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0232 - accuracy: 0.9975 - val_loss: 0.2134 - val_accuracy: 0.9600\n",
      "Epoch 166/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0230 - accuracy: 0.9975 - val_loss: 0.2123 - val_accuracy: 0.9600\n",
      "Epoch 167/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0226 - accuracy: 0.9975 - val_loss: 0.2125 - val_accuracy: 0.9600\n",
      "Epoch 168/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0224 - accuracy: 0.9975 - val_loss: 0.2144 - val_accuracy: 0.9600\n",
      "Epoch 169/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0221 - accuracy: 0.9975 - val_loss: 0.2130 - val_accuracy: 0.9600\n",
      "Epoch 170/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0217 - accuracy: 0.9975 - val_loss: 0.2125 - val_accuracy: 0.9600\n",
      "Epoch 171/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0215 - accuracy: 0.9975 - val_loss: 0.2117 - val_accuracy: 0.9600\n",
      "Epoch 172/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0213 - accuracy: 0.9975 - val_loss: 0.2112 - val_accuracy: 0.9600\n",
      "Epoch 173/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0209 - accuracy: 0.9975 - val_loss: 0.2119 - val_accuracy: 0.9600\n",
      "Epoch 174/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0211 - accuracy: 0.9975 - val_loss: 0.2145 - val_accuracy: 0.9600\n",
      "Epoch 175/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0210 - accuracy: 0.9975 - val_loss: 0.2082 - val_accuracy: 0.9600\n",
      "Epoch 176/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0203 - accuracy: 0.9975 - val_loss: 0.2093 - val_accuracy: 0.9600\n",
      "Epoch 177/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0198 - accuracy: 0.9975 - val_loss: 0.2110 - val_accuracy: 0.9600\n",
      "Epoch 178/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0197 - accuracy: 0.9975 - val_loss: 0.2118 - val_accuracy: 0.9600\n",
      "Epoch 179/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0194 - accuracy: 0.9975 - val_loss: 0.2112 - val_accuracy: 0.9600\n",
      "Epoch 180/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0193 - accuracy: 0.9975 - val_loss: 0.2123 - val_accuracy: 0.9600\n",
      "Epoch 181/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0189 - accuracy: 0.9975 - val_loss: 0.2107 - val_accuracy: 0.9600\n",
      "Epoch 182/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0187 - accuracy: 0.9975 - val_loss: 0.2105 - val_accuracy: 0.9600\n",
      "Epoch 183/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0187 - accuracy: 0.9975 - val_loss: 0.2101 - val_accuracy: 0.9600\n",
      "Epoch 184/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0182 - accuracy: 0.9975 - val_loss: 0.2113 - val_accuracy: 0.9600\n",
      "Epoch 185/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0182 - accuracy: 0.9975 - val_loss: 0.2131 - val_accuracy: 0.9600\n",
      "Epoch 186/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0181 - accuracy: 0.9975 - val_loss: 0.2106 - val_accuracy: 0.9600\n",
      "Epoch 187/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0177 - accuracy: 0.9975 - val_loss: 0.2121 - val_accuracy: 0.9600\n",
      "Epoch 188/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0176 - accuracy: 0.9975 - val_loss: 0.2096 - val_accuracy: 0.9600\n",
      "Epoch 189/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.0172 - accuracy: 0.9975 - val_loss: 0.2111 - val_accuracy: 0.9600\n",
      "Epoch 190/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0170 - accuracy: 0.9975 - val_loss: 0.2110 - val_accuracy: 0.9600\n",
      "Epoch 191/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0169 - accuracy: 0.9975 - val_loss: 0.2104 - val_accuracy: 0.9600\n",
      "Epoch 192/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0166 - accuracy: 0.9975 - val_loss: 0.2102 - val_accuracy: 0.9600\n",
      "Epoch 193/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0164 - accuracy: 0.9975 - val_loss: 0.2105 - val_accuracy: 0.9600\n",
      "Epoch 194/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0165 - accuracy: 0.9975 - val_loss: 0.2124 - val_accuracy: 0.9600\n",
      "Epoch 195/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0160 - accuracy: 0.9975 - val_loss: 0.2099 - val_accuracy: 0.9600\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.619618924697879\n",
      "F1 Micro: 0.9409760497043792\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 776us/step - loss: 2.0731 - accuracy: 0.2450 - val_loss: 1.7045 - val_accuracy: 0.6100\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 1.1802 - accuracy: 0.8500 - val_loss: 0.7372 - val_accuracy: 0.8200\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.5234 - accuracy: 0.8625 - val_loss: 0.7209 - val_accuracy: 0.8100\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.4942 - accuracy: 0.8650 - val_loss: 0.6118 - val_accuracy: 0.8100\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.4254 - accuracy: 0.8800 - val_loss: 0.5493 - val_accuracy: 0.8300\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 233us/step - loss: 0.4007 - accuracy: 0.8975 - val_loss: 0.5255 - val_accuracy: 0.8400\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.3780 - accuracy: 0.8975 - val_loss: 0.5139 - val_accuracy: 0.8400\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.3594 - accuracy: 0.9000 - val_loss: 0.4874 - val_accuracy: 0.8500\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.3413 - accuracy: 0.9050 - val_loss: 0.4785 - val_accuracy: 0.8500\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.3273 - accuracy: 0.9025 - val_loss: 0.4665 - val_accuracy: 0.8500\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3146 - accuracy: 0.9125 - val_loss: 0.4522 - val_accuracy: 0.8500\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.3048 - accuracy: 0.9200 - val_loss: 0.4419 - val_accuracy: 0.8500\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2939 - accuracy: 0.9200 - val_loss: 0.4373 - val_accuracy: 0.8500\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2845 - accuracy: 0.9200 - val_loss: 0.4219 - val_accuracy: 0.8700\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2749 - accuracy: 0.9225 - val_loss: 0.4152 - val_accuracy: 0.8700\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2663 - accuracy: 0.9250 - val_loss: 0.4061 - val_accuracy: 0.8600\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2578 - accuracy: 0.9300 - val_loss: 0.3950 - val_accuracy: 0.8700\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2516 - accuracy: 0.9350 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.2434 - accuracy: 0.9350 - val_loss: 0.3839 - val_accuracy: 0.8700\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.2388 - accuracy: 0.9350 - val_loss: 0.3774 - val_accuracy: 0.8700\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.2304 - accuracy: 0.9400 - val_loss: 0.3669 - val_accuracy: 0.8700\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2247 - accuracy: 0.9375 - val_loss: 0.3688 - val_accuracy: 0.8700\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2190 - accuracy: 0.9375 - val_loss: 0.3570 - val_accuracy: 0.8700\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2148 - accuracy: 0.9425 - val_loss: 0.3452 - val_accuracy: 0.9000\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2083 - accuracy: 0.9450 - val_loss: 0.3509 - val_accuracy: 0.8700\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2026 - accuracy: 0.9475 - val_loss: 0.3369 - val_accuracy: 0.9000\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1966 - accuracy: 0.9475 - val_loss: 0.3371 - val_accuracy: 0.9000\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1938 - accuracy: 0.9475 - val_loss: 0.3280 - val_accuracy: 0.9000\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1878 - accuracy: 0.9525 - val_loss: 0.3222 - val_accuracy: 0.9100\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1841 - accuracy: 0.9550 - val_loss: 0.3222 - val_accuracy: 0.9000\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1784 - accuracy: 0.9525 - val_loss: 0.3139 - val_accuracy: 0.9000\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1742 - accuracy: 0.9600 - val_loss: 0.3099 - val_accuracy: 0.9000\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1700 - accuracy: 0.9550 - val_loss: 0.3055 - val_accuracy: 0.9000\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1672 - accuracy: 0.9550 - val_loss: 0.3007 - val_accuracy: 0.9100\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1648 - accuracy: 0.9575 - val_loss: 0.2950 - val_accuracy: 0.9100\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1642 - accuracy: 0.9500 - val_loss: 0.2927 - val_accuracy: 0.9100\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1566 - accuracy: 0.9600 - val_loss: 0.2888 - val_accuracy: 0.9100\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1513 - accuracy: 0.9575 - val_loss: 0.2876 - val_accuracy: 0.9100\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1487 - accuracy: 0.9575 - val_loss: 0.2777 - val_accuracy: 0.9100\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1492 - accuracy: 0.9625 - val_loss: 0.2828 - val_accuracy: 0.9100\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1427 - accuracy: 0.9575 - val_loss: 0.2734 - val_accuracy: 0.9100\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1391 - accuracy: 0.9650 - val_loss: 0.2786 - val_accuracy: 0.9100\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1370 - accuracy: 0.9650 - val_loss: 0.2725 - val_accuracy: 0.9100\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1332 - accuracy: 0.9700 - val_loss: 0.2672 - val_accuracy: 0.9200\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1311 - accuracy: 0.9750 - val_loss: 0.2665 - val_accuracy: 0.9200\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1290 - accuracy: 0.9725 - val_loss: 0.2621 - val_accuracy: 0.9100\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1278 - accuracy: 0.9700 - val_loss: 0.2570 - val_accuracy: 0.9200\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1231 - accuracy: 0.9700 - val_loss: 0.2619 - val_accuracy: 0.9100\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1205 - accuracy: 0.9775 - val_loss: 0.2525 - val_accuracy: 0.9000\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1181 - accuracy: 0.9775 - val_loss: 0.2540 - val_accuracy: 0.9100\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1170 - accuracy: 0.9725 - val_loss: 0.2409 - val_accuracy: 0.9200\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1190 - accuracy: 0.9775 - val_loss: 0.2588 - val_accuracy: 0.9100\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1119 - accuracy: 0.9750 - val_loss: 0.2362 - val_accuracy: 0.9200\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1106 - accuracy: 0.9825 - val_loss: 0.2505 - val_accuracy: 0.9100\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1168 - accuracy: 0.9725 - val_loss: 0.2321 - val_accuracy: 0.9300\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1071 - accuracy: 0.9800 - val_loss: 0.2404 - val_accuracy: 0.9100\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1029 - accuracy: 0.9825 - val_loss: 0.2370 - val_accuracy: 0.9200\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1015 - accuracy: 0.9825 - val_loss: 0.2325 - val_accuracy: 0.9000\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0993 - accuracy: 0.9825 - val_loss: 0.2368 - val_accuracy: 0.9100\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0974 - accuracy: 0.9800 - val_loss: 0.2325 - val_accuracy: 0.9200\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0949 - accuracy: 0.9850 - val_loss: 0.2374 - val_accuracy: 0.9100\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0969 - accuracy: 0.9825 - val_loss: 0.2307 - val_accuracy: 0.9200\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0985 - accuracy: 0.9825 - val_loss: 0.2502 - val_accuracy: 0.9100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0904 - accuracy: 0.9800 - val_loss: 0.2204 - val_accuracy: 0.9200\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0886 - accuracy: 0.9850 - val_loss: 0.2313 - val_accuracy: 0.9200\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0860 - accuracy: 0.9850 - val_loss: 0.2318 - val_accuracy: 0.9300\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0850 - accuracy: 0.9850 - val_loss: 0.2521 - val_accuracy: 0.9100\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0847 - accuracy: 0.9800 - val_loss: 0.2121 - val_accuracy: 0.9400\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0823 - accuracy: 0.9850 - val_loss: 0.2233 - val_accuracy: 0.9300\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0787 - accuracy: 0.9875 - val_loss: 0.2370 - val_accuracy: 0.9200\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0771 - accuracy: 0.9850 - val_loss: 0.2109 - val_accuracy: 0.9200\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0740 - accuracy: 0.9875 - val_loss: 0.2388 - val_accuracy: 0.9200\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0760 - accuracy: 0.9825 - val_loss: 0.1995 - val_accuracy: 0.9300\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0781 - accuracy: 0.9900 - val_loss: 0.2586 - val_accuracy: 0.9200\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0694 - accuracy: 0.9875 - val_loss: 0.1976 - val_accuracy: 0.9500\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0674 - accuracy: 0.9875 - val_loss: 0.2459 - val_accuracy: 0.9100\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0673 - accuracy: 0.9900 - val_loss: 0.2058 - val_accuracy: 0.9200\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0646 - accuracy: 0.9900 - val_loss: 0.2091 - val_accuracy: 0.9300\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0625 - accuracy: 0.9900 - val_loss: 0.1998 - val_accuracy: 0.9300\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0639 - accuracy: 0.9925 - val_loss: 0.2716 - val_accuracy: 0.9200\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0617 - accuracy: 0.9850 - val_loss: 0.1879 - val_accuracy: 0.9400\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0565 - accuracy: 0.9925 - val_loss: 0.2312 - val_accuracy: 0.9200\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0559 - accuracy: 0.9900 - val_loss: 0.2012 - val_accuracy: 0.9200\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0548 - accuracy: 0.9900 - val_loss: 0.1986 - val_accuracy: 0.9300\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0525 - accuracy: 0.9925 - val_loss: 0.2043 - val_accuracy: 0.9200\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0501 - accuracy: 0.9900 - val_loss: 0.2086 - val_accuracy: 0.9200\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0511 - accuracy: 0.9925 - val_loss: 0.1773 - val_accuracy: 0.9300\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0508 - accuracy: 0.9875 - val_loss: 0.1765 - val_accuracy: 0.9300\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0459 - accuracy: 0.9950 - val_loss: 0.2754 - val_accuracy: 0.9200\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0529 - accuracy: 0.9925 - val_loss: 0.1826 - val_accuracy: 0.9300\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0457 - accuracy: 0.9900 - val_loss: 0.1821 - val_accuracy: 0.9300\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.0400 - accuracy: 0.9925 - val_loss: 0.2000 - val_accuracy: 0.9200\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0377 - accuracy: 0.9925 - val_loss: 0.1990 - val_accuracy: 0.9200\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0383 - accuracy: 0.9925 - val_loss: 0.1724 - val_accuracy: 0.9300\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0379 - accuracy: 0.9950 - val_loss: 0.1910 - val_accuracy: 0.9200\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0338 - accuracy: 0.9950 - val_loss: 0.2155 - val_accuracy: 0.9200\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0320 - accuracy: 0.9925 - val_loss: 0.1737 - val_accuracy: 0.9300\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 0.1625 - val_accuracy: 0.9500\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0347 - accuracy: 0.9975 - val_loss: 0.1812 - val_accuracy: 0.9400\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0292 - accuracy: 0.9975 - val_loss: 0.2025 - val_accuracy: 0.9200\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0271 - accuracy: 0.9950 - val_loss: 0.1816 - val_accuracy: 0.9400\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0257 - accuracy: 0.9950 - val_loss: 0.2131 - val_accuracy: 0.9200\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9300\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9400\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0208 - accuracy: 0.9975 - val_loss: 0.1614 - val_accuracy: 0.9400\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9300\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9300\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9400\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9300\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9300\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9500\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9400\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9400\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9400\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9500\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9300\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9400\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9400\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9300\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9400\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9400\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9400\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9300\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9600\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9300\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9300\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9400\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9500\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9300\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9500\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9500\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9300\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9300\n",
      "Epoch 134/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9500\n",
      "Epoch 135/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9500\n",
      "Epoch 136/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9300\n",
      "Epoch 137/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9300\n",
      "Epoch 138/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9500\n",
      "Epoch 139/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9300\n",
      "Epoch 140/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9300\n",
      "Epoch 141/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9400\n",
      "Epoch 142/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9400\n",
      "Epoch 143/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9300\n",
      "Epoch 144/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6263603199830984\n",
      "F1 Micro: 0.9401272608848139\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6414850187599914\n",
      "F1 Micro: 0.949045543363896\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6344196331272908\n",
      "F1 Micro: 0.9463399969938372\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 5 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 257us/step - loss: 0.8877 - accuracy: 0.8405 - val_loss: 0.6248 - val_accuracy: 0.8630\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.6321 - accuracy: 0.8515 - val_loss: 0.5769 - val_accuracy: 0.8630\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.5782 - accuracy: 0.8515 - val_loss: 0.5277 - val_accuracy: 0.8620\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.5131 - accuracy: 0.8540 - val_loss: 0.4580 - val_accuracy: 0.8760\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.4382 - accuracy: 0.8827 - val_loss: 0.3985 - val_accuracy: 0.8990\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.3743 - accuracy: 0.8988 - val_loss: 0.3530 - val_accuracy: 0.9080\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.3499 - accuracy: 0.9068 - val_loss: 0.3381 - val_accuracy: 0.9090\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.3229 - accuracy: 0.9118 - val_loss: 0.3794 - val_accuracy: 0.9080\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.2998 - accuracy: 0.9190 - val_loss: 0.2893 - val_accuracy: 0.9220\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.2792 - accuracy: 0.9212 - val_loss: 0.2927 - val_accuracy: 0.9200\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.2614 - accuracy: 0.9240 - val_loss: 0.2562 - val_accuracy: 0.9290\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.2335 - accuracy: 0.9312 - val_loss: 0.2634 - val_accuracy: 0.9310\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.2196 - accuracy: 0.9375 - val_loss: 0.2294 - val_accuracy: 0.9370\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.2145 - accuracy: 0.9365 - val_loss: 0.2622 - val_accuracy: 0.9290\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1928 - accuracy: 0.9470 - val_loss: 0.2875 - val_accuracy: 0.9350\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1819 - accuracy: 0.9482 - val_loss: 0.2082 - val_accuracy: 0.9350\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1701 - accuracy: 0.9510 - val_loss: 0.2125 - val_accuracy: 0.9390\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1580 - accuracy: 0.9553 - val_loss: 0.1958 - val_accuracy: 0.9500\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1529 - accuracy: 0.9542 - val_loss: 0.1809 - val_accuracy: 0.9470\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1522 - accuracy: 0.9565 - val_loss: 0.1834 - val_accuracy: 0.9510\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1411 - accuracy: 0.9592 - val_loss: 0.1748 - val_accuracy: 0.9520\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1258 - accuracy: 0.9617 - val_loss: 0.1881 - val_accuracy: 0.9490\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.1281 - accuracy: 0.9635 - val_loss: 0.2021 - val_accuracy: 0.9370\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.1186 - accuracy: 0.9647 - val_loss: 0.1776 - val_accuracy: 0.9530\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1183 - accuracy: 0.9640 - val_loss: 0.1612 - val_accuracy: 0.9540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.1093 - accuracy: 0.9690 - val_loss: 0.1932 - val_accuracy: 0.9460\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0989 - accuracy: 0.9695 - val_loss: 0.1698 - val_accuracy: 0.9530\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0951 - accuracy: 0.9710 - val_loss: 0.1649 - val_accuracy: 0.9540\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0973 - accuracy: 0.9703 - val_loss: 0.1786 - val_accuracy: 0.9510\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0917 - accuracy: 0.9735 - val_loss: 0.1878 - val_accuracy: 0.9570\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1049 - accuracy: 0.9720 - val_loss: 0.1551 - val_accuracy: 0.9570\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0776 - accuracy: 0.9745 - val_loss: 0.1674 - val_accuracy: 0.9570\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0848 - accuracy: 0.9707 - val_loss: 0.1664 - val_accuracy: 0.9570\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.0662 - accuracy: 0.9780 - val_loss: 0.1609 - val_accuracy: 0.9580\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0635 - accuracy: 0.9812 - val_loss: 0.1674 - val_accuracy: 0.9570\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0598 - accuracy: 0.9808 - val_loss: 0.1767 - val_accuracy: 0.9530\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0579 - accuracy: 0.9825 - val_loss: 0.1796 - val_accuracy: 0.9510\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0548 - accuracy: 0.9843 - val_loss: 0.1762 - val_accuracy: 0.9550\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0452 - accuracy: 0.9865 - val_loss: 0.1743 - val_accuracy: 0.9570\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0451 - accuracy: 0.9870 - val_loss: 0.1783 - val_accuracy: 0.9550\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0391 - accuracy: 0.9870 - val_loss: 0.2120 - val_accuracy: 0.9460\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0532 - accuracy: 0.9862 - val_loss: 0.1745 - val_accuracy: 0.9560\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0328 - accuracy: 0.9918 - val_loss: 0.1801 - val_accuracy: 0.9560\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0289 - accuracy: 0.9923 - val_loss: 0.1761 - val_accuracy: 0.9580\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0250 - accuracy: 0.9948 - val_loss: 0.1931 - val_accuracy: 0.9580\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0600 - accuracy: 0.9822 - val_loss: 0.1788 - val_accuracy: 0.9540\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0282 - accuracy: 0.9920 - val_loss: 0.1805 - val_accuracy: 0.9580\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.1850 - val_accuracy: 0.9570\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0184 - accuracy: 0.9960 - val_loss: 0.1937 - val_accuracy: 0.9590\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0159 - accuracy: 0.9965 - val_loss: 0.2061 - val_accuracy: 0.9600\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.2109 - val_accuracy: 0.9570\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6235900320583478\n",
      "F1 Micro: 0.9584\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6897066055407347\n",
      "F1 Micro: 0.9579000000000001\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 88us/step - loss: 1.6684 - accuracy: 0.5527 - val_loss: 1.2864 - val_accuracy: 0.7100\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 1.0926 - accuracy: 0.7722 - val_loss: 0.8159 - val_accuracy: 0.8340\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.6590 - accuracy: 0.8825 - val_loss: 0.4904 - val_accuracy: 0.9120\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.3998 - accuracy: 0.9273 - val_loss: 0.3224 - val_accuracy: 0.9330\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.2739 - accuracy: 0.9445 - val_loss: 0.2453 - val_accuracy: 0.9430\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.2151 - accuracy: 0.9488 - val_loss: 0.2116 - val_accuracy: 0.9480\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1854 - accuracy: 0.9538 - val_loss: 0.1894 - val_accuracy: 0.9530\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1675 - accuracy: 0.9550 - val_loss: 0.1731 - val_accuracy: 0.9540\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.1555 - accuracy: 0.9563 - val_loss: 0.1637 - val_accuracy: 0.9530\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1473 - accuracy: 0.9575 - val_loss: 0.1610 - val_accuracy: 0.9530\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 80us/step - loss: 0.1407 - accuracy: 0.9605 - val_loss: 0.1536 - val_accuracy: 0.9530\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1359 - accuracy: 0.9597 - val_loss: 0.1531 - val_accuracy: 0.9530\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1310 - accuracy: 0.9605 - val_loss: 0.1478 - val_accuracy: 0.9530\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.1270 - accuracy: 0.9610 - val_loss: 0.1439 - val_accuracy: 0.9530\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1231 - accuracy: 0.9620 - val_loss: 0.1477 - val_accuracy: 0.9530\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.1197 - accuracy: 0.9625 - val_loss: 0.1438 - val_accuracy: 0.9540\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.1169 - accuracy: 0.9630 - val_loss: 0.1407 - val_accuracy: 0.9560\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 79us/step - loss: 0.1142 - accuracy: 0.9643 - val_loss: 0.1391 - val_accuracy: 0.9540\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1117 - accuracy: 0.9647 - val_loss: 0.1452 - val_accuracy: 0.9530\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1096 - accuracy: 0.9655 - val_loss: 0.1373 - val_accuracy: 0.9550\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1078 - accuracy: 0.9657 - val_loss: 0.1439 - val_accuracy: 0.9530\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1053 - accuracy: 0.9678 - val_loss: 0.1373 - val_accuracy: 0.9550\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1024 - accuracy: 0.9697 - val_loss: 0.1350 - val_accuracy: 0.9540\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1015 - accuracy: 0.9693 - val_loss: 0.1371 - val_accuracy: 0.9550\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0994 - accuracy: 0.9697 - val_loss: 0.1348 - val_accuracy: 0.9540\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0972 - accuracy: 0.9688 - val_loss: 0.1342 - val_accuracy: 0.9560\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 80us/step - loss: 0.0963 - accuracy: 0.9690 - val_loss: 0.1332 - val_accuracy: 0.9560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0948 - accuracy: 0.9710 - val_loss: 0.1338 - val_accuracy: 0.9560\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0923 - accuracy: 0.9720 - val_loss: 0.1338 - val_accuracy: 0.9540\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0910 - accuracy: 0.9732 - val_loss: 0.1327 - val_accuracy: 0.9560\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 79us/step - loss: 0.0896 - accuracy: 0.9722 - val_loss: 0.1332 - val_accuracy: 0.9540\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0885 - accuracy: 0.9735 - val_loss: 0.1331 - val_accuracy: 0.9540\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0866 - accuracy: 0.9740 - val_loss: 0.1339 - val_accuracy: 0.9540\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0853 - accuracy: 0.9737 - val_loss: 0.1341 - val_accuracy: 0.9520\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0845 - accuracy: 0.9730 - val_loss: 0.1331 - val_accuracy: 0.9530\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0831 - accuracy: 0.9735 - val_loss: 0.1326 - val_accuracy: 0.9520\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0812 - accuracy: 0.9747 - val_loss: 0.1325 - val_accuracy: 0.9540\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0786 - accuracy: 0.9758 - val_loss: 0.1371 - val_accuracy: 0.9570\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0793 - accuracy: 0.9743 - val_loss: 0.1331 - val_accuracy: 0.9540\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0774 - accuracy: 0.9760 - val_loss: 0.1324 - val_accuracy: 0.9560\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 79us/step - loss: 0.0764 - accuracy: 0.9758 - val_loss: 0.1369 - val_accuracy: 0.9550\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0753 - accuracy: 0.9760 - val_loss: 0.1339 - val_accuracy: 0.9570\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0741 - accuracy: 0.9762 - val_loss: 0.1330 - val_accuracy: 0.9580\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 79us/step - loss: 0.0727 - accuracy: 0.9768 - val_loss: 0.1375 - val_accuracy: 0.9540\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0721 - accuracy: 0.9790 - val_loss: 0.1327 - val_accuracy: 0.9570\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0708 - accuracy: 0.9787 - val_loss: 0.1329 - val_accuracy: 0.9550\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 79us/step - loss: 0.0690 - accuracy: 0.9797 - val_loss: 0.1339 - val_accuracy: 0.9550\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0687 - accuracy: 0.9785 - val_loss: 0.1343 - val_accuracy: 0.9550\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0678 - accuracy: 0.9795 - val_loss: 0.1341 - val_accuracy: 0.9560\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0669 - accuracy: 0.9793 - val_loss: 0.1360 - val_accuracy: 0.9560\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0657 - accuracy: 0.9808 - val_loss: 0.1355 - val_accuracy: 0.9560\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0642 - accuracy: 0.9797 - val_loss: 0.1354 - val_accuracy: 0.9550\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0634 - accuracy: 0.9815 - val_loss: 0.1349 - val_accuracy: 0.9550\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0626 - accuracy: 0.9820 - val_loss: 0.1359 - val_accuracy: 0.9560\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0607 - accuracy: 0.9825 - val_loss: 0.1375 - val_accuracy: 0.9560\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0608 - accuracy: 0.9818 - val_loss: 0.1362 - val_accuracy: 0.9560\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0597 - accuracy: 0.9830 - val_loss: 0.1365 - val_accuracy: 0.9540\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0592 - accuracy: 0.9830 - val_loss: 0.1374 - val_accuracy: 0.9550\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0577 - accuracy: 0.9847 - val_loss: 0.1372 - val_accuracy: 0.9520\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0573 - accuracy: 0.9830 - val_loss: 0.1388 - val_accuracy: 0.9540\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7111484962164388\n",
      "F1 Micro: 0.9577000000000001\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 265us/step - loss: 0.6661 - accuracy: 0.8227 - val_loss: 0.3517 - val_accuracy: 0.8980\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.3112 - accuracy: 0.9103 - val_loss: 0.2803 - val_accuracy: 0.9260\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.2585 - accuracy: 0.9287 - val_loss: 0.2389 - val_accuracy: 0.9380\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.2253 - accuracy: 0.9367 - val_loss: 0.2230 - val_accuracy: 0.9360\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.2026 - accuracy: 0.9435 - val_loss: 0.1967 - val_accuracy: 0.9450\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1872 - accuracy: 0.9467 - val_loss: 0.1903 - val_accuracy: 0.9460\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1744 - accuracy: 0.9488 - val_loss: 0.1792 - val_accuracy: 0.9490\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.1636 - accuracy: 0.9540 - val_loss: 0.1738 - val_accuracy: 0.9520\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.1555 - accuracy: 0.9538 - val_loss: 0.1641 - val_accuracy: 0.9570\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.1489 - accuracy: 0.9565 - val_loss: 0.1581 - val_accuracy: 0.9570\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1401 - accuracy: 0.9555 - val_loss: 0.1585 - val_accuracy: 0.9540\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1359 - accuracy: 0.9588 - val_loss: 0.1550 - val_accuracy: 0.9550\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1309 - accuracy: 0.9578 - val_loss: 0.1698 - val_accuracy: 0.9460\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1269 - accuracy: 0.9595 - val_loss: 0.1494 - val_accuracy: 0.9580\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1218 - accuracy: 0.9615 - val_loss: 0.1462 - val_accuracy: 0.9550\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.1162 - accuracy: 0.9615 - val_loss: 0.1497 - val_accuracy: 0.9570\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1154 - accuracy: 0.9607 - val_loss: 0.1469 - val_accuracy: 0.9580\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1088 - accuracy: 0.9645 - val_loss: 0.1449 - val_accuracy: 0.9560\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.1088 - accuracy: 0.9655 - val_loss: 0.1479 - val_accuracy: 0.9560\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1023 - accuracy: 0.9663 - val_loss: 0.1473 - val_accuracy: 0.9550\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0997 - accuracy: 0.9680 - val_loss: 0.1503 - val_accuracy: 0.9540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0956 - accuracy: 0.9680 - val_loss: 0.1450 - val_accuracy: 0.9570\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0953 - accuracy: 0.9682 - val_loss: 0.1448 - val_accuracy: 0.9570\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0907 - accuracy: 0.9678 - val_loss: 0.1441 - val_accuracy: 0.9540\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0936 - accuracy: 0.9678 - val_loss: 0.1463 - val_accuracy: 0.9560\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0857 - accuracy: 0.9705 - val_loss: 0.1431 - val_accuracy: 0.9570\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0841 - accuracy: 0.9718 - val_loss: 0.1424 - val_accuracy: 0.9570\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0833 - accuracy: 0.9737 - val_loss: 0.1436 - val_accuracy: 0.9530\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0794 - accuracy: 0.9745 - val_loss: 0.1404 - val_accuracy: 0.9590\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0766 - accuracy: 0.9755 - val_loss: 0.1403 - val_accuracy: 0.9560\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0783 - accuracy: 0.9732 - val_loss: 0.1443 - val_accuracy: 0.9600\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0704 - accuracy: 0.9780 - val_loss: 0.1391 - val_accuracy: 0.9550\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0684 - accuracy: 0.9772 - val_loss: 0.1507 - val_accuracy: 0.9590\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.0672 - accuracy: 0.9795 - val_loss: 0.1395 - val_accuracy: 0.9560\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0629 - accuracy: 0.9785 - val_loss: 0.1466 - val_accuracy: 0.9560\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0647 - accuracy: 0.9778 - val_loss: 0.1422 - val_accuracy: 0.9570\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0580 - accuracy: 0.9827 - val_loss: 0.1474 - val_accuracy: 0.9580\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0522 - accuracy: 0.9840 - val_loss: 0.1426 - val_accuracy: 0.9570\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0486 - accuracy: 0.9858 - val_loss: 0.1473 - val_accuracy: 0.9600\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0447 - accuracy: 0.9875 - val_loss: 0.1549 - val_accuracy: 0.9610\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0414 - accuracy: 0.9890 - val_loss: 0.1741 - val_accuracy: 0.9590\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0421 - accuracy: 0.9880 - val_loss: 0.1465 - val_accuracy: 0.9570\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0331 - accuracy: 0.9923 - val_loss: 0.1464 - val_accuracy: 0.9590\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0308 - accuracy: 0.9923 - val_loss: 0.1394 - val_accuracy: 0.9570\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0276 - accuracy: 0.9950 - val_loss: 0.1583 - val_accuracy: 0.9610\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0240 - accuracy: 0.9952 - val_loss: 0.1541 - val_accuracy: 0.9580\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0228 - accuracy: 0.9960 - val_loss: 0.1511 - val_accuracy: 0.9570\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0206 - accuracy: 0.9952 - val_loss: 0.1627 - val_accuracy: 0.9580\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0189 - accuracy: 0.9970 - val_loss: 0.1728 - val_accuracy: 0.9610\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0180 - accuracy: 0.9970 - val_loss: 0.1592 - val_accuracy: 0.9570\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0166 - accuracy: 0.9975 - val_loss: 0.1580 - val_accuracy: 0.9590\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0144 - accuracy: 0.9975 - val_loss: 0.1716 - val_accuracy: 0.9590\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.698557356495271\n",
      "F1 Micro: 0.9601\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7177017057379005\n",
      "F1 Micro: 0.9602\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7464201358524098\n",
      "F1 Micro: 0.9643\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 5 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.4125 - accuracy: 0.8988 - val_loss: 0.1954 - val_accuracy: 0.9468\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.1808 - accuracy: 0.9470 - val_loss: 0.1594 - val_accuracy: 0.9513\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.1432 - accuracy: 0.9559 - val_loss: 0.1420 - val_accuracy: 0.9585\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1272 - accuracy: 0.9606 - val_loss: 0.1260 - val_accuracy: 0.9609\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.1161 - accuracy: 0.9629 - val_loss: 0.1071 - val_accuracy: 0.9680\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.1075 - accuracy: 0.9657 - val_loss: 0.1039 - val_accuracy: 0.9677\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.1003 - accuracy: 0.9683 - val_loss: 0.1078 - val_accuracy: 0.9667\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0933 - accuracy: 0.9698 - val_loss: 0.0971 - val_accuracy: 0.9701\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0880 - accuracy: 0.9714 - val_loss: 0.0964 - val_accuracy: 0.9704\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0844 - accuracy: 0.9722 - val_loss: 0.0910 - val_accuracy: 0.9712\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0786 - accuracy: 0.9744 - val_loss: 0.0891 - val_accuracy: 0.9720\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0744 - accuracy: 0.9753 - val_loss: 0.1148 - val_accuracy: 0.9680\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0718 - accuracy: 0.9764 - val_loss: 0.0942 - val_accuracy: 0.9703\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0663 - accuracy: 0.9780 - val_loss: 0.0991 - val_accuracy: 0.9685\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0602 - accuracy: 0.9803 - val_loss: 0.1112 - val_accuracy: 0.9641\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0569 - accuracy: 0.9808 - val_loss: 0.0858 - val_accuracy: 0.9730\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0513 - accuracy: 0.9833 - val_loss: 0.0881 - val_accuracy: 0.9735\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0485 - accuracy: 0.9834 - val_loss: 0.0883 - val_accuracy: 0.9744\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0428 - accuracy: 0.9851 - val_loss: 0.1005 - val_accuracy: 0.9729\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0377 - accuracy: 0.9875 - val_loss: 0.1166 - val_accuracy: 0.9718\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0344 - accuracy: 0.9881 - val_loss: 0.0944 - val_accuracy: 0.9717\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 0.0921 - val_accuracy: 0.9735\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0264 - accuracy: 0.9911 - val_loss: 0.1301 - val_accuracy: 0.9706\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 0.1008 - val_accuracy: 0.9749\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.1085 - val_accuracy: 0.9730\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.1127 - val_accuracy: 0.9719\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.1338 - val_accuracy: 0.9668\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.1230 - val_accuracy: 0.9733\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.1239 - val_accuracy: 0.9725\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.1323 - val_accuracy: 0.9740\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.1279 - val_accuracy: 0.9718\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.1297 - val_accuracy: 0.9712\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.1250 - val_accuracy: 0.9735\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.1499 - val_accuracy: 0.9731\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.1438 - val_accuracy: 0.9740\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.1369 - val_accuracy: 0.9760\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8074546461418293\n",
      "F1 Micro: 0.9717000000000001\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8058098862088086\n",
      "F1 Micro: 0.967\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.5229 - accuracy: 0.8771 - val_loss: 0.1584 - val_accuracy: 0.9567\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.1483 - accuracy: 0.9568 - val_loss: 0.1282 - val_accuracy: 0.9608\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.1298 - accuracy: 0.9613 - val_loss: 0.1161 - val_accuracy: 0.9642\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1205 - accuracy: 0.9635 - val_loss: 0.1094 - val_accuracy: 0.9662\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1144 - accuracy: 0.9652 - val_loss: 0.1056 - val_accuracy: 0.9668\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1092 - accuracy: 0.9668 - val_loss: 0.1031 - val_accuracy: 0.9673\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1059 - accuracy: 0.9679 - val_loss: 0.1005 - val_accuracy: 0.9691\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1029 - accuracy: 0.9685 - val_loss: 0.1001 - val_accuracy: 0.9686\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1004 - accuracy: 0.9693 - val_loss: 0.0977 - val_accuracy: 0.9692\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0976 - accuracy: 0.9702 - val_loss: 0.0961 - val_accuracy: 0.9700\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0959 - accuracy: 0.9707 - val_loss: 0.0953 - val_accuracy: 0.9706\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0936 - accuracy: 0.9710 - val_loss: 0.0939 - val_accuracy: 0.9713\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0921 - accuracy: 0.9718 - val_loss: 0.0953 - val_accuracy: 0.9704\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0904 - accuracy: 0.9729 - val_loss: 0.0928 - val_accuracy: 0.9713\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0889 - accuracy: 0.9725 - val_loss: 0.0921 - val_accuracy: 0.9718\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0871 - accuracy: 0.9736 - val_loss: 0.0916 - val_accuracy: 0.9717\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0860 - accuracy: 0.9739 - val_loss: 0.0903 - val_accuracy: 0.9715\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0848 - accuracy: 0.9740 - val_loss: 0.0907 - val_accuracy: 0.9716\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0835 - accuracy: 0.9740 - val_loss: 0.0896 - val_accuracy: 0.9720\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0824 - accuracy: 0.9747 - val_loss: 0.0932 - val_accuracy: 0.9707\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0813 - accuracy: 0.9754 - val_loss: 0.0884 - val_accuracy: 0.9710\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0801 - accuracy: 0.9754 - val_loss: 0.0884 - val_accuracy: 0.9713\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0793 - accuracy: 0.9759 - val_loss: 0.0871 - val_accuracy: 0.9722\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0780 - accuracy: 0.9764 - val_loss: 0.0878 - val_accuracy: 0.9719\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0773 - accuracy: 0.9767 - val_loss: 0.0872 - val_accuracy: 0.9721\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0759 - accuracy: 0.9768 - val_loss: 0.0870 - val_accuracy: 0.9717\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0752 - accuracy: 0.9777 - val_loss: 0.0860 - val_accuracy: 0.9727\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0746 - accuracy: 0.9778 - val_loss: 0.0860 - val_accuracy: 0.9726\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0737 - accuracy: 0.9775 - val_loss: 0.0863 - val_accuracy: 0.9719\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0726 - accuracy: 0.9783 - val_loss: 0.0857 - val_accuracy: 0.9733\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0718 - accuracy: 0.9789 - val_loss: 0.0848 - val_accuracy: 0.9726\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0713 - accuracy: 0.9786 - val_loss: 0.0866 - val_accuracy: 0.9717\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0704 - accuracy: 0.9790 - val_loss: 0.0853 - val_accuracy: 0.9731\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0695 - accuracy: 0.9797 - val_loss: 0.0865 - val_accuracy: 0.9716\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0686 - accuracy: 0.9798 - val_loss: 0.0863 - val_accuracy: 0.9718\n",
      "Epoch 36/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0681 - accuracy: 0.9797 - val_loss: 0.0854 - val_accuracy: 0.9717\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0672 - accuracy: 0.9802 - val_loss: 0.0843 - val_accuracy: 0.9726\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0664 - accuracy: 0.9804 - val_loss: 0.0845 - val_accuracy: 0.9725\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0658 - accuracy: 0.9801 - val_loss: 0.0841 - val_accuracy: 0.9726\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0648 - accuracy: 0.9808 - val_loss: 0.0846 - val_accuracy: 0.9716\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0641 - accuracy: 0.9814 - val_loss: 0.0836 - val_accuracy: 0.9714\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0633 - accuracy: 0.9812 - val_loss: 0.0840 - val_accuracy: 0.9725\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0629 - accuracy: 0.9811 - val_loss: 0.0848 - val_accuracy: 0.9721\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0623 - accuracy: 0.9813 - val_loss: 0.0854 - val_accuracy: 0.9719\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0616 - accuracy: 0.9816 - val_loss: 0.0845 - val_accuracy: 0.9718\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0609 - accuracy: 0.9819 - val_loss: 0.0855 - val_accuracy: 0.9719\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0601 - accuracy: 0.9825 - val_loss: 0.0855 - val_accuracy: 0.9712\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0596 - accuracy: 0.9829 - val_loss: 0.0838 - val_accuracy: 0.9715\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0587 - accuracy: 0.9828 - val_loss: 0.0839 - val_accuracy: 0.9716\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0581 - accuracy: 0.9825 - val_loss: 0.0849 - val_accuracy: 0.9713\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0579 - accuracy: 0.9828 - val_loss: 0.0885 - val_accuracy: 0.9708\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0570 - accuracy: 0.9832 - val_loss: 0.0852 - val_accuracy: 0.9721\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0561 - accuracy: 0.9837 - val_loss: 0.0853 - val_accuracy: 0.9717\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0557 - accuracy: 0.9838 - val_loss: 0.0853 - val_accuracy: 0.9717\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0551 - accuracy: 0.9842 - val_loss: 0.0846 - val_accuracy: 0.9719\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0546 - accuracy: 0.9840 - val_loss: 0.0871 - val_accuracy: 0.9719\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0541 - accuracy: 0.9841 - val_loss: 0.0856 - val_accuracy: 0.9718\n",
      "Epoch 58/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0532 - accuracy: 0.9841 - val_loss: 0.0864 - val_accuracy: 0.9705\n",
      "Epoch 59/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0528 - accuracy: 0.9846 - val_loss: 0.0858 - val_accuracy: 0.9716\n",
      "Epoch 60/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0518 - accuracy: 0.9851 - val_loss: 0.0851 - val_accuracy: 0.9713\n",
      "Epoch 61/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0515 - accuracy: 0.9852 - val_loss: 0.0849 - val_accuracy: 0.9715\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8361509888917131\n",
      "F1 Micro: 0.9689\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.2588 - accuracy: 0.9300 - val_loss: 0.1526 - val_accuracy: 0.9564\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.1448 - accuracy: 0.9568 - val_loss: 0.1218 - val_accuracy: 0.9620\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.1242 - accuracy: 0.9617 - val_loss: 0.1114 - val_accuracy: 0.9664\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.1132 - accuracy: 0.9655 - val_loss: 0.1030 - val_accuracy: 0.9686\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.1059 - accuracy: 0.9674 - val_loss: 0.1006 - val_accuracy: 0.9683\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.1010 - accuracy: 0.9686 - val_loss: 0.1001 - val_accuracy: 0.9690\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0967 - accuracy: 0.9701 - val_loss: 0.0927 - val_accuracy: 0.9704\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0912 - accuracy: 0.9714 - val_loss: 0.0932 - val_accuracy: 0.9703\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.0874 - accuracy: 0.9727 - val_loss: 0.0900 - val_accuracy: 0.9705\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0825 - accuracy: 0.9746 - val_loss: 0.1026 - val_accuracy: 0.9675\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0761 - accuracy: 0.9758 - val_loss: 0.1039 - val_accuracy: 0.9660\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0709 - accuracy: 0.9774 - val_loss: 0.0872 - val_accuracy: 0.9725\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0643 - accuracy: 0.9801 - val_loss: 0.0892 - val_accuracy: 0.9713\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0580 - accuracy: 0.9822 - val_loss: 0.0884 - val_accuracy: 0.9722\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0518 - accuracy: 0.9834 - val_loss: 0.0852 - val_accuracy: 0.9738\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0447 - accuracy: 0.9865 - val_loss: 0.0895 - val_accuracy: 0.9727\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0371 - accuracy: 0.9882 - val_loss: 0.1046 - val_accuracy: 0.9724\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.1100 - val_accuracy: 0.9679\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0254 - accuracy: 0.9922 - val_loss: 0.1102 - val_accuracy: 0.9711\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.1129 - val_accuracy: 0.9686\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 210us/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.1186 - val_accuracy: 0.9705\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.1482 - val_accuracy: 0.9710\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.1315 - val_accuracy: 0.9702\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.1402 - val_accuracy: 0.9655\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1437 - val_accuracy: 0.9704\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 208us/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1423 - val_accuracy: 0.9691\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.1388 - val_accuracy: 0.9696\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.1514 - val_accuracy: 0.9723\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1602 - val_accuracy: 0.9664\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.1499 - val_accuracy: 0.9689\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1571 - val_accuracy: 0.9723\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.1795 - val_accuracy: 0.9641\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.1642 - val_accuracy: 0.9707\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1568 - val_accuracy: 0.9728\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 8.4162e-04 - accuracy: 0.9999 - val_loss: 0.1687 - val_accuracy: 0.9721\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8428325489338186\n",
      "F1 Micro: 0.9697\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8238636273685755\n",
      "F1 Micro: 0.9676\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8525980406952871\n",
      "F1 Micro: 0.9741\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 5 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.2566 - accuracy: 0.9322 - val_loss: 0.1364 - val_accuracy: 0.9561\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 25s 191us/step - loss: 0.1195 - accuracy: 0.9624 - val_loss: 0.1086 - val_accuracy: 0.9643\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 25s 191us/step - loss: 0.1010 - accuracy: 0.9675 - val_loss: 0.0943 - val_accuracy: 0.9693\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0903 - accuracy: 0.9707 - val_loss: 0.0898 - val_accuracy: 0.9709\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0826 - accuracy: 0.9725 - val_loss: 0.0861 - val_accuracy: 0.9719\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0764 - accuracy: 0.9746 - val_loss: 0.0803 - val_accuracy: 0.9727\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0699 - accuracy: 0.9766 - val_loss: 0.0722 - val_accuracy: 0.9752\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 25s 191us/step - loss: 0.0650 - accuracy: 0.9777 - val_loss: 0.0693 - val_accuracy: 0.9761\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0618 - accuracy: 0.9788 - val_loss: 0.0780 - val_accuracy: 0.9724\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0568 - accuracy: 0.9806 - val_loss: 0.0668 - val_accuracy: 0.9773\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0540 - accuracy: 0.9814 - val_loss: 0.0705 - val_accuracy: 0.9759\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0506 - accuracy: 0.9821 - val_loss: 0.0648 - val_accuracy: 0.9780\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0475 - accuracy: 0.9834 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0443 - accuracy: 0.9840 - val_loss: 0.0688 - val_accuracy: 0.9778\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0420 - accuracy: 0.9853 - val_loss: 0.0649 - val_accuracy: 0.9772\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0392 - accuracy: 0.9861 - val_loss: 0.0655 - val_accuracy: 0.9784\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0357 - accuracy: 0.9871 - val_loss: 0.0669 - val_accuracy: 0.9778\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0325 - accuracy: 0.9886 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0298 - accuracy: 0.9893 - val_loss: 0.0720 - val_accuracy: 0.9772\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0261 - accuracy: 0.9906 - val_loss: 0.0752 - val_accuracy: 0.9765\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 0.0813 - val_accuracy: 0.9764\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0202 - accuracy: 0.9927 - val_loss: 0.0752 - val_accuracy: 0.9782\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 0.0797 - val_accuracy: 0.9779\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.0816 - val_accuracy: 0.9774\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 0.0870 - val_accuracy: 0.9780\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0841 - val_accuracy: 0.9770\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0994 - val_accuracy: 0.9768\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0972 - val_accuracy: 0.9773\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.1057 - val_accuracy: 0.9757\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.1062 - val_accuracy: 0.9760\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1027 - val_accuracy: 0.9769\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1184 - val_accuracy: 0.9747\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8658266774447547\n",
      "F1 Micro: 0.9782\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8227745286516066\n",
      "F1 Micro: 0.9682\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.2520 - accuracy: 0.9344 - val_loss: 0.1227 - val_accuracy: 0.9627\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.1142 - accuracy: 0.9645 - val_loss: 0.1087 - val_accuracy: 0.9664\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.1041 - accuracy: 0.9675 - val_loss: 0.1029 - val_accuracy: 0.9683\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0986 - accuracy: 0.9690 - val_loss: 0.0976 - val_accuracy: 0.9695\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0945 - accuracy: 0.9704 - val_loss: 0.0974 - val_accuracy: 0.9690\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0913 - accuracy: 0.9711 - val_loss: 0.0939 - val_accuracy: 0.9704\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0890 - accuracy: 0.9718 - val_loss: 0.0907 - val_accuracy: 0.9714\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0869 - accuracy: 0.9724 - val_loss: 0.0891 - val_accuracy: 0.9717\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0850 - accuracy: 0.9729 - val_loss: 0.0903 - val_accuracy: 0.9713\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0832 - accuracy: 0.9734 - val_loss: 0.0875 - val_accuracy: 0.9719\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0818 - accuracy: 0.9742 - val_loss: 0.0856 - val_accuracy: 0.9725\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0805 - accuracy: 0.9743 - val_loss: 0.0858 - val_accuracy: 0.9720\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0791 - accuracy: 0.9745 - val_loss: 0.0862 - val_accuracy: 0.9718\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0779 - accuracy: 0.9748 - val_loss: 0.0844 - val_accuracy: 0.9722\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0769 - accuracy: 0.9752 - val_loss: 0.0830 - val_accuracy: 0.9727\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0759 - accuracy: 0.9754 - val_loss: 0.0830 - val_accuracy: 0.9732\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0750 - accuracy: 0.9757 - val_loss: 0.0824 - val_accuracy: 0.9729\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0742 - accuracy: 0.9758 - val_loss: 0.0831 - val_accuracy: 0.9734\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0731 - accuracy: 0.9763 - val_loss: 0.0824 - val_accuracy: 0.9726\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0723 - accuracy: 0.9766 - val_loss: 0.0822 - val_accuracy: 0.9730\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0714 - accuracy: 0.9765 - val_loss: 0.0812 - val_accuracy: 0.9732\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0704 - accuracy: 0.9770 - val_loss: 0.0836 - val_accuracy: 0.9730\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0698 - accuracy: 0.9774 - val_loss: 0.0812 - val_accuracy: 0.9733\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0689 - accuracy: 0.9775 - val_loss: 0.0821 - val_accuracy: 0.9732\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0683 - accuracy: 0.9778 - val_loss: 0.0823 - val_accuracy: 0.9730\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0675 - accuracy: 0.9781 - val_loss: 0.0814 - val_accuracy: 0.9728\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0670 - accuracy: 0.9782 - val_loss: 0.0801 - val_accuracy: 0.9737\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0662 - accuracy: 0.9787 - val_loss: 0.0806 - val_accuracy: 0.9738\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0655 - accuracy: 0.9787 - val_loss: 0.0815 - val_accuracy: 0.9733\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0649 - accuracy: 0.9790 - val_loss: 0.0814 - val_accuracy: 0.9733\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0641 - accuracy: 0.9794 - val_loss: 0.0822 - val_accuracy: 0.9729\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0636 - accuracy: 0.9794 - val_loss: 0.0795 - val_accuracy: 0.9740\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0629 - accuracy: 0.9797 - val_loss: 0.0812 - val_accuracy: 0.9734\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0623 - accuracy: 0.9797 - val_loss: 0.0813 - val_accuracy: 0.9732\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0617 - accuracy: 0.9799 - val_loss: 0.0818 - val_accuracy: 0.9727\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0610 - accuracy: 0.9802 - val_loss: 0.0798 - val_accuracy: 0.9734\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0604 - accuracy: 0.9801 - val_loss: 0.0799 - val_accuracy: 0.9733\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0600 - accuracy: 0.9804 - val_loss: 0.0807 - val_accuracy: 0.9729\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0593 - accuracy: 0.9807 - val_loss: 0.0805 - val_accuracy: 0.9733\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0586 - accuracy: 0.9809 - val_loss: 0.0808 - val_accuracy: 0.9733\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0582 - accuracy: 0.9810 - val_loss: 0.0808 - val_accuracy: 0.9730\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0575 - accuracy: 0.9815 - val_loss: 0.0820 - val_accuracy: 0.9733\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0571 - accuracy: 0.9811 - val_loss: 0.0813 - val_accuracy: 0.9736\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0563 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9731\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0559 - accuracy: 0.9818 - val_loss: 0.0809 - val_accuracy: 0.9738\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0553 - accuracy: 0.9821 - val_loss: 0.0806 - val_accuracy: 0.9731\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0546 - accuracy: 0.9820 - val_loss: 0.0813 - val_accuracy: 0.9734\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0542 - accuracy: 0.9825 - val_loss: 0.0821 - val_accuracy: 0.9735\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0536 - accuracy: 0.9828 - val_loss: 0.0814 - val_accuracy: 0.9729\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0531 - accuracy: 0.9829 - val_loss: 0.0815 - val_accuracy: 0.9736\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0526 - accuracy: 0.9830 - val_loss: 0.0821 - val_accuracy: 0.9735\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0520 - accuracy: 0.9829 - val_loss: 0.0845 - val_accuracy: 0.9735\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8412807257553838\n",
      "F1 Micro: 0.9716\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.1696 - accuracy: 0.9506 - val_loss: 0.1136 - val_accuracy: 0.9644\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.1085 - accuracy: 0.9660 - val_loss: 0.0987 - val_accuracy: 0.9694\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0971 - accuracy: 0.9693 - val_loss: 0.0905 - val_accuracy: 0.9716\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0882 - accuracy: 0.9718 - val_loss: 0.0842 - val_accuracy: 0.9730\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0806 - accuracy: 0.9740 - val_loss: 0.0833 - val_accuracy: 0.9733\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0747 - accuracy: 0.9759 - val_loss: 0.0764 - val_accuracy: 0.9759\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0685 - accuracy: 0.9777 - val_loss: 0.0760 - val_accuracy: 0.9742\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0632 - accuracy: 0.9789 - val_loss: 0.0714 - val_accuracy: 0.9767\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0574 - accuracy: 0.9807 - val_loss: 0.0699 - val_accuracy: 0.9769\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0512 - accuracy: 0.9830 - val_loss: 0.0794 - val_accuracy: 0.9730\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 0.0730 - val_accuracy: 0.9756\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0391 - accuracy: 0.9865 - val_loss: 0.0793 - val_accuracy: 0.9769\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0324 - accuracy: 0.9892 - val_loss: 0.0752 - val_accuracy: 0.9767\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0260 - accuracy: 0.9911 - val_loss: 0.1001 - val_accuracy: 0.9696\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.0810 - val_accuracy: 0.9770\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.0997 - val_accuracy: 0.9761\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0976 - val_accuracy: 0.9760\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.1060 - val_accuracy: 0.9764\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1345 - val_accuracy: 0.9751\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1228 - val_accuracy: 0.9720\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1221 - val_accuracy: 0.9745\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.1284 - val_accuracy: 0.9763\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 27s 208us/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1256 - val_accuracy: 0.9744\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1239 - val_accuracy: 0.9774\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1237 - val_accuracy: 0.9766\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1416 - val_accuracy: 0.9757\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.1371 - val_accuracy: 0.9759\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1325 - val_accuracy: 0.9772\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1381 - val_accuracy: 0.9764\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8416359846448143\n",
      "F1 Micro: 0.9728\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8294992401342506\n",
      "F1 Micro: 0.9669\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8802849631670981\n",
      "F1 Micro: 0.9788\n",
      "\n",
      "\n",
      " 54.951136096318564 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 6 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 6 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 788us/step - loss: 1.8312 - accuracy: 0.8375 - val_loss: 1.3793 - val_accuracy: 0.8200\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.8561 - accuracy: 0.8925 - val_loss: 0.9807 - val_accuracy: 0.8200\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.6152 - accuracy: 0.8925 - val_loss: 0.9653 - val_accuracy: 0.8200\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.5805 - accuracy: 0.8925 - val_loss: 0.8650 - val_accuracy: 0.8200\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.5484 - accuracy: 0.8925 - val_loss: 0.8613 - val_accuracy: 0.8200\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.5424 - accuracy: 0.8925 - val_loss: 0.8554 - val_accuracy: 0.8200\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.5335 - accuracy: 0.8925 - val_loss: 0.8441 - val_accuracy: 0.8200\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.5291 - accuracy: 0.8925 - val_loss: 0.8285 - val_accuracy: 0.8200\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.5230 - accuracy: 0.8925 - val_loss: 0.8183 - val_accuracy: 0.8200\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.5206 - accuracy: 0.8925 - val_loss: 0.8027 - val_accuracy: 0.8200\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.5172 - accuracy: 0.8925 - val_loss: 0.7919 - val_accuracy: 0.8200\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.5135 - accuracy: 0.8925 - val_loss: 0.7838 - val_accuracy: 0.8200\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.5156 - accuracy: 0.8925 - val_loss: 0.7951 - val_accuracy: 0.8200\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.5075 - accuracy: 0.8925 - val_loss: 0.7823 - val_accuracy: 0.8200\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.5003 - accuracy: 0.8925 - val_loss: 0.7675 - val_accuracy: 0.8200\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.5001 - accuracy: 0.8925 - val_loss: 0.7880 - val_accuracy: 0.8200\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.4975 - accuracy: 0.8925 - val_loss: 0.7532 - val_accuracy: 0.8200\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.4903 - accuracy: 0.8925 - val_loss: 0.7783 - val_accuracy: 0.8200\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.4820 - accuracy: 0.8925 - val_loss: 0.7251 - val_accuracy: 0.8200\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.4778 - accuracy: 0.8925 - val_loss: 0.7424 - val_accuracy: 0.8200\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.4707 - accuracy: 0.8925 - val_loss: 0.7100 - val_accuracy: 0.8200\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 257us/step - loss: 0.4563 - accuracy: 0.8925 - val_loss: 0.6976 - val_accuracy: 0.8200\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.4486 - accuracy: 0.8925 - val_loss: 0.6737 - val_accuracy: 0.8200\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.4454 - accuracy: 0.8925 - val_loss: 0.6619 - val_accuracy: 0.8300\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.4370 - accuracy: 0.8925 - val_loss: 0.6510 - val_accuracy: 0.8300\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.4094 - accuracy: 0.8925 - val_loss: 0.6325 - val_accuracy: 0.8300\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.4003 - accuracy: 0.8950 - val_loss: 0.6076 - val_accuracy: 0.8600\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.4075 - accuracy: 0.9050 - val_loss: 0.5945 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.4213 - accuracy: 0.9050 - val_loss: 0.6049 - val_accuracy: 0.8400\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.3712 - accuracy: 0.9050 - val_loss: 0.5585 - val_accuracy: 0.8700\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3578 - accuracy: 0.9100 - val_loss: 0.5799 - val_accuracy: 0.8400\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.3425 - accuracy: 0.9100 - val_loss: 0.5457 - val_accuracy: 0.8700\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3276 - accuracy: 0.9175 - val_loss: 0.5551 - val_accuracy: 0.8700\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3218 - accuracy: 0.9175 - val_loss: 0.5247 - val_accuracy: 0.8800\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.3199 - accuracy: 0.9225 - val_loss: 0.5176 - val_accuracy: 0.8900\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3027 - accuracy: 0.9225 - val_loss: 0.5013 - val_accuracy: 0.9000\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3132 - accuracy: 0.9250 - val_loss: 0.5593 - val_accuracy: 0.8700\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3270 - accuracy: 0.9175 - val_loss: 0.5307 - val_accuracy: 0.8700\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2825 - accuracy: 0.9225 - val_loss: 0.5086 - val_accuracy: 0.8900\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.2736 - accuracy: 0.9275 - val_loss: 0.4994 - val_accuracy: 0.8900\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.2679 - accuracy: 0.9250 - val_loss: 0.4819 - val_accuracy: 0.9000\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3074 - accuracy: 0.9150 - val_loss: 0.5030 - val_accuracy: 0.8900\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.3194 - accuracy: 0.9225 - val_loss: 0.4931 - val_accuracy: 0.9000\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2829 - accuracy: 0.9175 - val_loss: 0.4779 - val_accuracy: 0.9000\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2686 - accuracy: 0.9225 - val_loss: 0.4582 - val_accuracy: 0.9000\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.2639 - accuracy: 0.9300 - val_loss: 0.4650 - val_accuracy: 0.9000\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2508 - accuracy: 0.9350 - val_loss: 0.4734 - val_accuracy: 0.9000\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2359 - accuracy: 0.9350 - val_loss: 0.4541 - val_accuracy: 0.9000\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2541 - accuracy: 0.9250 - val_loss: 0.4666 - val_accuracy: 0.9000\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2590 - accuracy: 0.9325 - val_loss: 0.4878 - val_accuracy: 0.8900\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2322 - accuracy: 0.9425 - val_loss: 0.4669 - val_accuracy: 0.9000\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2292 - accuracy: 0.9325 - val_loss: 0.4751 - val_accuracy: 0.8900\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 252us/step - loss: 0.2220 - accuracy: 0.9350 - val_loss: 0.4333 - val_accuracy: 0.9000\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.2089 - accuracy: 0.9400 - val_loss: 0.4723 - val_accuracy: 0.9000\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.2022 - accuracy: 0.9450 - val_loss: 0.4293 - val_accuracy: 0.9100\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.2044 - accuracy: 0.9425 - val_loss: 0.4368 - val_accuracy: 0.9100\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.2012 - accuracy: 0.9475 - val_loss: 0.4359 - val_accuracy: 0.9000\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1994 - accuracy: 0.9375 - val_loss: 0.4218 - val_accuracy: 0.9100\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2041 - accuracy: 0.9350 - val_loss: 0.4148 - val_accuracy: 0.9300\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.2230 - accuracy: 0.9425 - val_loss: 0.4155 - val_accuracy: 0.9100\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1981 - accuracy: 0.9450 - val_loss: 0.4164 - val_accuracy: 0.9200\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1872 - accuracy: 0.9500 - val_loss: 0.4249 - val_accuracy: 0.9200\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1779 - accuracy: 0.9475 - val_loss: 0.4167 - val_accuracy: 0.9200\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1772 - accuracy: 0.9525 - val_loss: 0.3995 - val_accuracy: 0.9200\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1654 - accuracy: 0.9525 - val_loss: 0.4044 - val_accuracy: 0.9300\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.1678 - accuracy: 0.9500 - val_loss: 0.4174 - val_accuracy: 0.9300\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1792 - accuracy: 0.9475 - val_loss: 0.4059 - val_accuracy: 0.9200\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.1498 - accuracy: 0.9550 - val_loss: 0.4077 - val_accuracy: 0.9200\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1602 - accuracy: 0.9525 - val_loss: 0.4064 - val_accuracy: 0.9200\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1598 - accuracy: 0.9550 - val_loss: 0.4307 - val_accuracy: 0.9200\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1537 - accuracy: 0.9625 - val_loss: 0.4031 - val_accuracy: 0.9200\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1610 - accuracy: 0.9675 - val_loss: 0.4574 - val_accuracy: 0.9200\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1983 - accuracy: 0.9550 - val_loss: 0.4436 - val_accuracy: 0.9200\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.1797 - accuracy: 0.9475 - val_loss: 0.4039 - val_accuracy: 0.9200\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.1468 - accuracy: 0.9500 - val_loss: 0.4089 - val_accuracy: 0.9200\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.1394 - accuracy: 0.9575 - val_loss: 0.3928 - val_accuracy: 0.9200\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1286 - accuracy: 0.9750 - val_loss: 0.4245 - val_accuracy: 0.9300\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1274 - accuracy: 0.9575 - val_loss: 0.4031 - val_accuracy: 0.9200\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1248 - accuracy: 0.9725 - val_loss: 0.4057 - val_accuracy: 0.9200\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1234 - accuracy: 0.9625 - val_loss: 0.3932 - val_accuracy: 0.9100\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1185 - accuracy: 0.9750 - val_loss: 0.3972 - val_accuracy: 0.9200\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1075 - accuracy: 0.9700 - val_loss: 0.3967 - val_accuracy: 0.9200\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1050 - accuracy: 0.9775 - val_loss: 0.3943 - val_accuracy: 0.9200\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0975 - accuracy: 0.9725 - val_loss: 0.3936 - val_accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1022 - accuracy: 0.9725 - val_loss: 0.3930 - val_accuracy: 0.9200\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.0942 - accuracy: 0.9800 - val_loss: 0.4102 - val_accuracy: 0.9200\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0968 - accuracy: 0.9750 - val_loss: 0.3940 - val_accuracy: 0.9100\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0938 - accuracy: 0.9700 - val_loss: 0.3900 - val_accuracy: 0.9200\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0958 - accuracy: 0.9725 - val_loss: 0.4144 - val_accuracy: 0.9300\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0966 - accuracy: 0.9725 - val_loss: 0.4570 - val_accuracy: 0.8900\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1224 - accuracy: 0.9675 - val_loss: 0.4015 - val_accuracy: 0.9100\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0957 - accuracy: 0.9725 - val_loss: 0.4086 - val_accuracy: 0.9200\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0852 - accuracy: 0.9800 - val_loss: 0.3988 - val_accuracy: 0.9200\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.0783 - accuracy: 0.9800 - val_loss: 0.4076 - val_accuracy: 0.9200\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0727 - accuracy: 0.9850 - val_loss: 0.4056 - val_accuracy: 0.9200\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0687 - accuracy: 0.9800 - val_loss: 0.3902 - val_accuracy: 0.9100\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0649 - accuracy: 0.9875 - val_loss: 0.4057 - val_accuracy: 0.9200\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0658 - accuracy: 0.9825 - val_loss: 0.3997 - val_accuracy: 0.9100\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1015 - accuracy: 0.9800 - val_loss: 0.5039 - val_accuracy: 0.8900\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.1050 - accuracy: 0.9725 - val_loss: 0.4113 - val_accuracy: 0.9100\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0732 - accuracy: 0.9825 - val_loss: 0.3977 - val_accuracy: 0.9200\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0692 - accuracy: 0.9850 - val_loss: 0.4146 - val_accuracy: 0.9200\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0552 - accuracy: 0.9875 - val_loss: 0.4053 - val_accuracy: 0.9200\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0501 - accuracy: 0.9925 - val_loss: 0.4162 - val_accuracy: 0.9200\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0555 - accuracy: 0.9925 - val_loss: 0.4441 - val_accuracy: 0.9200\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0548 - accuracy: 0.9900 - val_loss: 0.4132 - val_accuracy: 0.9200\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0465 - accuracy: 0.9925 - val_loss: 0.3946 - val_accuracy: 0.9200\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.0465 - accuracy: 0.9925 - val_loss: 0.4142 - val_accuracy: 0.9100\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.47786295327703926\n",
      "F1 Micro: 0.9257\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5340042250032631\n",
      "F1 Micro: 0.9386\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 545us/step - loss: 2.3639 - accuracy: 0.0925 - val_loss: 2.2695 - val_accuracy: 0.0700\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 2.1358 - accuracy: 0.1975 - val_loss: 2.0612 - val_accuracy: 0.2900\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.9775 - accuracy: 0.3850 - val_loss: 1.9022 - val_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.8641 - accuracy: 0.4825 - val_loss: 1.7943 - val_accuracy: 0.4900\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.7833 - accuracy: 0.5325 - val_loss: 1.7149 - val_accuracy: 0.5600\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.7191 - accuracy: 0.5775 - val_loss: 1.6483 - val_accuracy: 0.5900\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.6595 - accuracy: 0.6025 - val_loss: 1.5913 - val_accuracy: 0.6100\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.6036 - accuracy: 0.6250 - val_loss: 1.5345 - val_accuracy: 0.6100\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.5481 - accuracy: 0.6425 - val_loss: 1.4778 - val_accuracy: 0.6500\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.4908 - accuracy: 0.6725 - val_loss: 1.4236 - val_accuracy: 0.6800\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.4327 - accuracy: 0.7025 - val_loss: 1.3695 - val_accuracy: 0.7000\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.3736 - accuracy: 0.7250 - val_loss: 1.3155 - val_accuracy: 0.7100\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 97us/step - loss: 1.3163 - accuracy: 0.7500 - val_loss: 1.2590 - val_accuracy: 0.7500\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 97us/step - loss: 1.2535 - accuracy: 0.7575 - val_loss: 1.2022 - val_accuracy: 0.7900\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.1922 - accuracy: 0.7775 - val_loss: 1.1463 - val_accuracy: 0.7900\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.1316 - accuracy: 0.8000 - val_loss: 1.0887 - val_accuracy: 0.7900\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.0691 - accuracy: 0.8175 - val_loss: 1.0347 - val_accuracy: 0.8300\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.0098 - accuracy: 0.8425 - val_loss: 0.9824 - val_accuracy: 0.8500\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.9516 - accuracy: 0.8575 - val_loss: 0.9325 - val_accuracy: 0.8600\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.8943 - accuracy: 0.8675 - val_loss: 0.8844 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.8403 - accuracy: 0.8875 - val_loss: 0.8371 - val_accuracy: 0.8600\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.7875 - accuracy: 0.8975 - val_loss: 0.7945 - val_accuracy: 0.8600\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.7385 - accuracy: 0.9100 - val_loss: 0.7567 - val_accuracy: 0.8600\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.6919 - accuracy: 0.9150 - val_loss: 0.7196 - val_accuracy: 0.8800\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.6501 - accuracy: 0.9200 - val_loss: 0.6817 - val_accuracy: 0.8800\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.6081 - accuracy: 0.9250 - val_loss: 0.6512 - val_accuracy: 0.8800\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.5693 - accuracy: 0.9300 - val_loss: 0.6225 - val_accuracy: 0.8800\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.5354 - accuracy: 0.9400 - val_loss: 0.5974 - val_accuracy: 0.8800\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.5020 - accuracy: 0.9475 - val_loss: 0.5718 - val_accuracy: 0.8800\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.4724 - accuracy: 0.9475 - val_loss: 0.5500 - val_accuracy: 0.8800\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 112us/step - loss: 0.4441 - accuracy: 0.9525 - val_loss: 0.5301 - val_accuracy: 0.8800\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.4186 - accuracy: 0.9600 - val_loss: 0.5102 - val_accuracy: 0.8800\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.3947 - accuracy: 0.9650 - val_loss: 0.4942 - val_accuracy: 0.8900\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.3718 - accuracy: 0.9675 - val_loss: 0.4784 - val_accuracy: 0.8900\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.3520 - accuracy: 0.9675 - val_loss: 0.4643 - val_accuracy: 0.8900\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.3337 - accuracy: 0.9650 - val_loss: 0.4501 - val_accuracy: 0.8900\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.3161 - accuracy: 0.9700 - val_loss: 0.4397 - val_accuracy: 0.9000\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.3000 - accuracy: 0.9700 - val_loss: 0.4295 - val_accuracy: 0.9000\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2849 - accuracy: 0.9700 - val_loss: 0.4190 - val_accuracy: 0.9000\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.2720 - accuracy: 0.9700 - val_loss: 0.4095 - val_accuracy: 0.9000\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.2586 - accuracy: 0.9700 - val_loss: 0.4012 - val_accuracy: 0.8900\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.2474 - accuracy: 0.9700 - val_loss: 0.3917 - val_accuracy: 0.9000\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2355 - accuracy: 0.9725 - val_loss: 0.3846 - val_accuracy: 0.9100\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2259 - accuracy: 0.9750 - val_loss: 0.3783 - val_accuracy: 0.9100\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2157 - accuracy: 0.9750 - val_loss: 0.3718 - val_accuracy: 0.9100\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.2067 - accuracy: 0.9750 - val_loss: 0.3666 - val_accuracy: 0.9100\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 92us/step - loss: 0.1988 - accuracy: 0.9750 - val_loss: 0.3615 - val_accuracy: 0.9100\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1909 - accuracy: 0.9750 - val_loss: 0.3556 - val_accuracy: 0.9100\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.1835 - accuracy: 0.9750 - val_loss: 0.3512 - val_accuracy: 0.9200\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1770 - accuracy: 0.9750 - val_loss: 0.3463 - val_accuracy: 0.9200\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.1704 - accuracy: 0.9750 - val_loss: 0.3441 - val_accuracy: 0.9100\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1645 - accuracy: 0.9775 - val_loss: 0.3403 - val_accuracy: 0.9200\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1594 - accuracy: 0.9800 - val_loss: 0.3370 - val_accuracy: 0.9200\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.1532 - accuracy: 0.9850 - val_loss: 0.3342 - val_accuracy: 0.9200\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1484 - accuracy: 0.9825 - val_loss: 0.3324 - val_accuracy: 0.9100\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1443 - accuracy: 0.9850 - val_loss: 0.3285 - val_accuracy: 0.9200\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1389 - accuracy: 0.9875 - val_loss: 0.3257 - val_accuracy: 0.9200\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1347 - accuracy: 0.9875 - val_loss: 0.3235 - val_accuracy: 0.9200\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1308 - accuracy: 0.9875 - val_loss: 0.3212 - val_accuracy: 0.9200\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.1270 - accuracy: 0.9875 - val_loss: 0.3188 - val_accuracy: 0.9200\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1237 - accuracy: 0.9875 - val_loss: 0.3178 - val_accuracy: 0.9200\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 90us/step - loss: 0.1204 - accuracy: 0.9900 - val_loss: 0.3175 - val_accuracy: 0.9200\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 92us/step - loss: 0.1174 - accuracy: 0.9900 - val_loss: 0.3160 - val_accuracy: 0.9200\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1140 - accuracy: 0.9900 - val_loss: 0.3148 - val_accuracy: 0.9200\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1113 - accuracy: 0.9900 - val_loss: 0.3137 - val_accuracy: 0.9300\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1087 - accuracy: 0.9900 - val_loss: 0.3120 - val_accuracy: 0.9300\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1067 - accuracy: 0.9900 - val_loss: 0.3121 - val_accuracy: 0.9300\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1032 - accuracy: 0.9900 - val_loss: 0.3099 - val_accuracy: 0.9300\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1013 - accuracy: 0.9900 - val_loss: 0.3099 - val_accuracy: 0.9300\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0990 - accuracy: 0.9900 - val_loss: 0.3108 - val_accuracy: 0.9300\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0973 - accuracy: 0.9900 - val_loss: 0.3105 - val_accuracy: 0.9200\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0952 - accuracy: 0.9900 - val_loss: 0.3108 - val_accuracy: 0.9200\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0925 - accuracy: 0.9900 - val_loss: 0.3107 - val_accuracy: 0.9200\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0910 - accuracy: 0.9900 - val_loss: 0.3107 - val_accuracy: 0.9200\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0894 - accuracy: 0.9925 - val_loss: 0.3088 - val_accuracy: 0.9300\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0876 - accuracy: 0.9900 - val_loss: 0.3101 - val_accuracy: 0.9200\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0854 - accuracy: 0.9925 - val_loss: 0.3099 - val_accuracy: 0.9200\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0840 - accuracy: 0.9900 - val_loss: 0.3091 - val_accuracy: 0.9200\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 100us/step - loss: 0.0827 - accuracy: 0.9900 - val_loss: 0.3081 - val_accuracy: 0.9200\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0808 - accuracy: 0.9900 - val_loss: 0.3098 - val_accuracy: 0.9200\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0794 - accuracy: 0.9925 - val_loss: 0.3093 - val_accuracy: 0.9200\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0779 - accuracy: 0.9925 - val_loss: 0.3091 - val_accuracy: 0.9200\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0762 - accuracy: 0.9925 - val_loss: 0.3080 - val_accuracy: 0.9200\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0749 - accuracy: 0.9925 - val_loss: 0.3080 - val_accuracy: 0.9200\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0738 - accuracy: 0.9925 - val_loss: 0.3071 - val_accuracy: 0.9200\n",
      "Epoch 86/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 80us/step - loss: 0.0724 - accuracy: 0.9925 - val_loss: 0.3071 - val_accuracy: 0.9200\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0710 - accuracy: 0.9925 - val_loss: 0.3078 - val_accuracy: 0.9200\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0698 - accuracy: 0.9925 - val_loss: 0.3081 - val_accuracy: 0.9200\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0687 - accuracy: 0.9925 - val_loss: 0.3079 - val_accuracy: 0.9300\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0674 - accuracy: 0.9950 - val_loss: 0.3080 - val_accuracy: 0.9200\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0668 - accuracy: 0.9950 - val_loss: 0.3087 - val_accuracy: 0.9200\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0660 - accuracy: 0.9925 - val_loss: 0.3068 - val_accuracy: 0.9200\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0644 - accuracy: 0.9925 - val_loss: 0.3097 - val_accuracy: 0.9200\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0628 - accuracy: 0.9950 - val_loss: 0.3100 - val_accuracy: 0.9200\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0620 - accuracy: 0.9950 - val_loss: 0.3103 - val_accuracy: 0.9200\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0611 - accuracy: 0.9950 - val_loss: 0.3099 - val_accuracy: 0.9200\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 92us/step - loss: 0.0598 - accuracy: 0.9950 - val_loss: 0.3093 - val_accuracy: 0.9200\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 97us/step - loss: 0.0590 - accuracy: 0.9950 - val_loss: 0.3094 - val_accuracy: 0.9200\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0583 - accuracy: 0.9950 - val_loss: 0.3109 - val_accuracy: 0.9200\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0572 - accuracy: 0.9950 - val_loss: 0.3105 - val_accuracy: 0.9200\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0561 - accuracy: 0.9950 - val_loss: 0.3103 - val_accuracy: 0.9200\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0549 - accuracy: 0.9950 - val_loss: 0.3117 - val_accuracy: 0.9200\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0543 - accuracy: 0.9950 - val_loss: 0.3119 - val_accuracy: 0.9200\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0535 - accuracy: 0.9950 - val_loss: 0.3098 - val_accuracy: 0.9200\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0523 - accuracy: 0.9950 - val_loss: 0.3110 - val_accuracy: 0.9200\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0515 - accuracy: 0.9950 - val_loss: 0.3116 - val_accuracy: 0.9200\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0507 - accuracy: 0.9950 - val_loss: 0.3120 - val_accuracy: 0.9200\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0499 - accuracy: 0.9950 - val_loss: 0.3113 - val_accuracy: 0.9200\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0492 - accuracy: 0.9950 - val_loss: 0.3122 - val_accuracy: 0.9200\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0483 - accuracy: 0.9950 - val_loss: 0.3120 - val_accuracy: 0.9200\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0475 - accuracy: 0.9950 - val_loss: 0.3141 - val_accuracy: 0.9200\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0466 - accuracy: 0.9950 - val_loss: 0.3139 - val_accuracy: 0.9200\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5329796501469029\n",
      "F1 Micro: 0.9364\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 795us/step - loss: 1.8220 - accuracy: 0.4650 - val_loss: 1.3457 - val_accuracy: 0.7600\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.7875 - accuracy: 0.8850 - val_loss: 0.6454 - val_accuracy: 0.8200\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.3922 - accuracy: 0.8925 - val_loss: 0.6784 - val_accuracy: 0.8200\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.3496 - accuracy: 0.9000 - val_loss: 0.5756 - val_accuracy: 0.8300\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 257us/step - loss: 0.3135 - accuracy: 0.9100 - val_loss: 0.5307 - val_accuracy: 0.8600\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2993 - accuracy: 0.9225 - val_loss: 0.5307 - val_accuracy: 0.8600\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2835 - accuracy: 0.9250 - val_loss: 0.5163 - val_accuracy: 0.8700\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.2704 - accuracy: 0.9300 - val_loss: 0.5049 - val_accuracy: 0.8800\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2602 - accuracy: 0.9300 - val_loss: 0.4919 - val_accuracy: 0.8800\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.2525 - accuracy: 0.9325 - val_loss: 0.4854 - val_accuracy: 0.8800\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.2416 - accuracy: 0.9325 - val_loss: 0.4616 - val_accuracy: 0.8900\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.2319 - accuracy: 0.9350 - val_loss: 0.4759 - val_accuracy: 0.8900\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2249 - accuracy: 0.9375 - val_loss: 0.4605 - val_accuracy: 0.8900\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2171 - accuracy: 0.9375 - val_loss: 0.4551 - val_accuracy: 0.8900\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.2099 - accuracy: 0.9425 - val_loss: 0.4497 - val_accuracy: 0.8900\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 259us/step - loss: 0.2045 - accuracy: 0.9500 - val_loss: 0.4502 - val_accuracy: 0.8900\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.1999 - accuracy: 0.9450 - val_loss: 0.4368 - val_accuracy: 0.8800\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.1913 - accuracy: 0.9475 - val_loss: 0.4294 - val_accuracy: 0.8800\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.1883 - accuracy: 0.9475 - val_loss: 0.4342 - val_accuracy: 0.8800\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.1827 - accuracy: 0.9550 - val_loss: 0.4152 - val_accuracy: 0.8900\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.1762 - accuracy: 0.9575 - val_loss: 0.4273 - val_accuracy: 0.8800\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 274us/step - loss: 0.1738 - accuracy: 0.9600 - val_loss: 0.4104 - val_accuracy: 0.8900\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.1671 - accuracy: 0.9600 - val_loss: 0.4147 - val_accuracy: 0.8800\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.1638 - accuracy: 0.9650 - val_loss: 0.4061 - val_accuracy: 0.8900\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.1585 - accuracy: 0.9650 - val_loss: 0.4071 - val_accuracy: 0.8900\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.1553 - accuracy: 0.9650 - val_loss: 0.3979 - val_accuracy: 0.8900\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 250us/step - loss: 0.1510 - accuracy: 0.9650 - val_loss: 0.4029 - val_accuracy: 0.8900\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 264us/step - loss: 0.1467 - accuracy: 0.9650 - val_loss: 0.3893 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1466 - accuracy: 0.9675 - val_loss: 0.3992 - val_accuracy: 0.8900\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1419 - accuracy: 0.9675 - val_loss: 0.3839 - val_accuracy: 0.9000\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1381 - accuracy: 0.9700 - val_loss: 0.3872 - val_accuracy: 0.9000\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1345 - accuracy: 0.9725 - val_loss: 0.3768 - val_accuracy: 0.9100\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.1332 - accuracy: 0.9700 - val_loss: 0.3906 - val_accuracy: 0.9000\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.1271 - accuracy: 0.9725 - val_loss: 0.3744 - val_accuracy: 0.9200\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1259 - accuracy: 0.9725 - val_loss: 0.3762 - val_accuracy: 0.9200\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1236 - accuracy: 0.9725 - val_loss: 0.3690 - val_accuracy: 0.9200\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1209 - accuracy: 0.9750 - val_loss: 0.3863 - val_accuracy: 0.9000\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1203 - accuracy: 0.9750 - val_loss: 0.3742 - val_accuracy: 0.9200\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.1165 - accuracy: 0.9750 - val_loss: 0.3780 - val_accuracy: 0.9100\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 254us/step - loss: 0.1119 - accuracy: 0.9775 - val_loss: 0.3635 - val_accuracy: 0.9200\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1098 - accuracy: 0.9775 - val_loss: 0.3635 - val_accuracy: 0.9200\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1071 - accuracy: 0.9775 - val_loss: 0.3680 - val_accuracy: 0.9200\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1050 - accuracy: 0.9775 - val_loss: 0.3695 - val_accuracy: 0.9200\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1039 - accuracy: 0.9775 - val_loss: 0.3599 - val_accuracy: 0.9200\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1050 - accuracy: 0.9800 - val_loss: 0.3789 - val_accuracy: 0.9100\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 269us/step - loss: 0.1007 - accuracy: 0.9775 - val_loss: 0.3616 - val_accuracy: 0.9200\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0961 - accuracy: 0.9775 - val_loss: 0.3769 - val_accuracy: 0.9100\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0945 - accuracy: 0.9800 - val_loss: 0.3584 - val_accuracy: 0.9200\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0926 - accuracy: 0.9775 - val_loss: 0.3620 - val_accuracy: 0.9200\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0904 - accuracy: 0.9775 - val_loss: 0.3494 - val_accuracy: 0.9200\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0899 - accuracy: 0.9825 - val_loss: 0.3689 - val_accuracy: 0.9100\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.0870 - accuracy: 0.9775 - val_loss: 0.3600 - val_accuracy: 0.9200\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0836 - accuracy: 0.9825 - val_loss: 0.3576 - val_accuracy: 0.9200\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0822 - accuracy: 0.9775 - val_loss: 0.3635 - val_accuracy: 0.9200\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0814 - accuracy: 0.9775 - val_loss: 0.3603 - val_accuracy: 0.9200\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0775 - accuracy: 0.9825 - val_loss: 0.3547 - val_accuracy: 0.9200\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0798 - accuracy: 0.9775 - val_loss: 0.3423 - val_accuracy: 0.9200\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.0756 - accuracy: 0.9850 - val_loss: 0.3665 - val_accuracy: 0.9200\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0740 - accuracy: 0.9800 - val_loss: 0.3538 - val_accuracy: 0.9200\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0718 - accuracy: 0.9925 - val_loss: 0.3554 - val_accuracy: 0.9200\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0708 - accuracy: 0.9775 - val_loss: 0.3619 - val_accuracy: 0.9200\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0712 - accuracy: 0.9925 - val_loss: 0.3617 - val_accuracy: 0.9200\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0670 - accuracy: 0.9850 - val_loss: 0.3586 - val_accuracy: 0.9200\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 244us/step - loss: 0.0646 - accuracy: 0.9875 - val_loss: 0.3510 - val_accuracy: 0.9200\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 249us/step - loss: 0.0627 - accuracy: 0.9900 - val_loss: 0.3646 - val_accuracy: 0.9200\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0615 - accuracy: 0.9850 - val_loss: 0.3436 - val_accuracy: 0.9200\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0603 - accuracy: 0.9900 - val_loss: 0.3657 - val_accuracy: 0.9200\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0579 - accuracy: 0.9875 - val_loss: 0.3565 - val_accuracy: 0.9200\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0556 - accuracy: 0.9925 - val_loss: 0.3708 - val_accuracy: 0.9200\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0550 - accuracy: 0.9900 - val_loss: 0.3556 - val_accuracy: 0.9200\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.0531 - accuracy: 0.9925 - val_loss: 0.3695 - val_accuracy: 0.9200\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0513 - accuracy: 0.9925 - val_loss: 0.3614 - val_accuracy: 0.9200\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0493 - accuracy: 0.9925 - val_loss: 0.3727 - val_accuracy: 0.9200\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0518 - accuracy: 0.9900 - val_loss: 0.3465 - val_accuracy: 0.9200\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0506 - accuracy: 0.9875 - val_loss: 0.3523 - val_accuracy: 0.9200\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0495 - accuracy: 0.9925 - val_loss: 0.3731 - val_accuracy: 0.9200\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 257us/step - loss: 0.0450 - accuracy: 0.9925 - val_loss: 0.3603 - val_accuracy: 0.9200\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.48928886640189667\n",
      "F1 Micro: 0.9292\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5415680112887654\n",
      "F1 Micro: 0.9409\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5855208004614174\n",
      "F1 Micro: 0.9431\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 6 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 267us/step - loss: 0.8815 - accuracy: 0.8455 - val_loss: 0.7137 - val_accuracy: 0.8400\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.6496 - accuracy: 0.8455 - val_loss: 0.6426 - val_accuracy: 0.8400\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.5699 - accuracy: 0.8470 - val_loss: 0.5257 - val_accuracy: 0.8470\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.4209 - accuracy: 0.8907 - val_loss: 0.4279 - val_accuracy: 0.8970\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.3659 - accuracy: 0.9045 - val_loss: 0.3579 - val_accuracy: 0.9050\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.3183 - accuracy: 0.9145 - val_loss: 0.3405 - val_accuracy: 0.9060\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.2855 - accuracy: 0.9200 - val_loss: 0.2995 - val_accuracy: 0.9190\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.2707 - accuracy: 0.9262 - val_loss: 0.2781 - val_accuracy: 0.9210\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.2490 - accuracy: 0.9300 - val_loss: 0.2513 - val_accuracy: 0.9290\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.2294 - accuracy: 0.9362 - val_loss: 0.2412 - val_accuracy: 0.9260\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.2157 - accuracy: 0.9342 - val_loss: 0.2505 - val_accuracy: 0.9250\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.2064 - accuracy: 0.9392 - val_loss: 0.2093 - val_accuracy: 0.9360\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1853 - accuracy: 0.9442 - val_loss: 0.2254 - val_accuracy: 0.9350\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.1769 - accuracy: 0.9452 - val_loss: 0.2168 - val_accuracy: 0.9320\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.1672 - accuracy: 0.9490 - val_loss: 0.1890 - val_accuracy: 0.9370\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.1576 - accuracy: 0.9488 - val_loss: 0.1936 - val_accuracy: 0.9370\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 211us/step - loss: 0.1601 - accuracy: 0.9503 - val_loss: 0.1707 - val_accuracy: 0.9460\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1465 - accuracy: 0.9523 - val_loss: 0.1670 - val_accuracy: 0.9450\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.1374 - accuracy: 0.9575 - val_loss: 0.1663 - val_accuracy: 0.9460\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.1400 - accuracy: 0.9570 - val_loss: 0.1748 - val_accuracy: 0.9440\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1347 - accuracy: 0.9570 - val_loss: 0.1655 - val_accuracy: 0.9480\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.1291 - accuracy: 0.9570 - val_loss: 0.1663 - val_accuracy: 0.9420\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.1255 - accuracy: 0.9575 - val_loss: 0.1770 - val_accuracy: 0.9450\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 215us/step - loss: 0.1153 - accuracy: 0.9613 - val_loss: 0.1520 - val_accuracy: 0.9450\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1100 - accuracy: 0.9625 - val_loss: 0.1506 - val_accuracy: 0.9510\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.1075 - accuracy: 0.9628 - val_loss: 0.1606 - val_accuracy: 0.9470\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.1022 - accuracy: 0.9657 - val_loss: 0.1426 - val_accuracy: 0.9530\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.1077 - accuracy: 0.9650 - val_loss: 0.1466 - val_accuracy: 0.9510\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.0978 - accuracy: 0.9685 - val_loss: 0.1417 - val_accuracy: 0.9550\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.0964 - accuracy: 0.9670 - val_loss: 0.1541 - val_accuracy: 0.9530\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0965 - accuracy: 0.9685 - val_loss: 0.1491 - val_accuracy: 0.9500\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0884 - accuracy: 0.9725 - val_loss: 0.1513 - val_accuracy: 0.9490\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0892 - accuracy: 0.9710 - val_loss: 0.2072 - val_accuracy: 0.9440\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0826 - accuracy: 0.9745 - val_loss: 0.1371 - val_accuracy: 0.9550\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.0845 - accuracy: 0.9750 - val_loss: 0.1454 - val_accuracy: 0.9530\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.0804 - accuracy: 0.9737 - val_loss: 0.1483 - val_accuracy: 0.9530\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0746 - accuracy: 0.9770 - val_loss: 0.1400 - val_accuracy: 0.9540\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.0690 - accuracy: 0.9765 - val_loss: 0.1453 - val_accuracy: 0.9540\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 212us/step - loss: 0.0682 - accuracy: 0.9803 - val_loss: 0.1635 - val_accuracy: 0.9500\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0684 - accuracy: 0.9790 - val_loss: 0.1636 - val_accuracy: 0.9490\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0623 - accuracy: 0.9812 - val_loss: 0.1437 - val_accuracy: 0.9570\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0539 - accuracy: 0.9835 - val_loss: 0.1536 - val_accuracy: 0.9560\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 211us/step - loss: 0.0580 - accuracy: 0.9815 - val_loss: 0.1417 - val_accuracy: 0.9520\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.0501 - accuracy: 0.9852 - val_loss: 0.1386 - val_accuracy: 0.9550\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0502 - accuracy: 0.9850 - val_loss: 0.1506 - val_accuracy: 0.9550\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.0470 - accuracy: 0.9858 - val_loss: 0.1498 - val_accuracy: 0.9550\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0450 - accuracy: 0.9860 - val_loss: 0.1531 - val_accuracy: 0.9550\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 213us/step - loss: 0.0445 - accuracy: 0.9855 - val_loss: 0.1726 - val_accuracy: 0.9490\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.0464 - accuracy: 0.9862 - val_loss: 0.1476 - val_accuracy: 0.9550\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 211us/step - loss: 0.0326 - accuracy: 0.9902 - val_loss: 0.1621 - val_accuracy: 0.9510\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0320 - accuracy: 0.9908 - val_loss: 0.1459 - val_accuracy: 0.9580\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0348 - accuracy: 0.9908 - val_loss: 0.1512 - val_accuracy: 0.9540\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 0.1520 - val_accuracy: 0.9570\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0278 - accuracy: 0.9927 - val_loss: 0.1571 - val_accuracy: 0.9550\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6779269321505856\n",
      "F1 Micro: 0.9565\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7418976617340944\n",
      "F1 Micro: 0.9578\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 87us/step - loss: 1.6564 - accuracy: 0.5408 - val_loss: 1.3097 - val_accuracy: 0.7070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 1.0048 - accuracy: 0.7993 - val_loss: 0.8073 - val_accuracy: 0.8580\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 64us/step - loss: 0.5844 - accuracy: 0.9078 - val_loss: 0.4887 - val_accuracy: 0.9090\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.3634 - accuracy: 0.9362 - val_loss: 0.3456 - val_accuracy: 0.9250\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.2639 - accuracy: 0.9480 - val_loss: 0.2784 - val_accuracy: 0.9330\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.2165 - accuracy: 0.9498 - val_loss: 0.2446 - val_accuracy: 0.9400\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.1908 - accuracy: 0.9515 - val_loss: 0.2205 - val_accuracy: 0.9430\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1744 - accuracy: 0.9540 - val_loss: 0.2073 - val_accuracy: 0.9440\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.1622 - accuracy: 0.9567 - val_loss: 0.1956 - val_accuracy: 0.9470\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.1535 - accuracy: 0.9582 - val_loss: 0.1862 - val_accuracy: 0.9480\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.1459 - accuracy: 0.9605 - val_loss: 0.1810 - val_accuracy: 0.9480\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1392 - accuracy: 0.9628 - val_loss: 0.1758 - val_accuracy: 0.9480\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.1342 - accuracy: 0.9622 - val_loss: 0.1733 - val_accuracy: 0.9470\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1287 - accuracy: 0.9638 - val_loss: 0.1719 - val_accuracy: 0.9470\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.1255 - accuracy: 0.9660 - val_loss: 0.1657 - val_accuracy: 0.9470\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1217 - accuracy: 0.9670 - val_loss: 0.1638 - val_accuracy: 0.9480\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1180 - accuracy: 0.9680 - val_loss: 0.1615 - val_accuracy: 0.9490\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1149 - accuracy: 0.9690 - val_loss: 0.1587 - val_accuracy: 0.9510\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 63us/step - loss: 0.1116 - accuracy: 0.9700 - val_loss: 0.1593 - val_accuracy: 0.9480\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1087 - accuracy: 0.9712 - val_loss: 0.1569 - val_accuracy: 0.9490\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1064 - accuracy: 0.9705 - val_loss: 0.1548 - val_accuracy: 0.9520\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.1039 - accuracy: 0.9722 - val_loss: 0.1538 - val_accuracy: 0.9490\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1014 - accuracy: 0.9728 - val_loss: 0.1533 - val_accuracy: 0.9510\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.0993 - accuracy: 0.9730 - val_loss: 0.1526 - val_accuracy: 0.9490\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0975 - accuracy: 0.9743 - val_loss: 0.1512 - val_accuracy: 0.9500\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0955 - accuracy: 0.9747 - val_loss: 0.1502 - val_accuracy: 0.9500\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0939 - accuracy: 0.9755 - val_loss: 0.1504 - val_accuracy: 0.9490\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0918 - accuracy: 0.9755 - val_loss: 0.1508 - val_accuracy: 0.9500\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0903 - accuracy: 0.9758 - val_loss: 0.1507 - val_accuracy: 0.9490\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0889 - accuracy: 0.9755 - val_loss: 0.1501 - val_accuracy: 0.9520\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0871 - accuracy: 0.9760 - val_loss: 0.1500 - val_accuracy: 0.9500\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0859 - accuracy: 0.9762 - val_loss: 0.1478 - val_accuracy: 0.9500\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0840 - accuracy: 0.9768 - val_loss: 0.1482 - val_accuracy: 0.9510\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.0826 - accuracy: 0.9768 - val_loss: 0.1472 - val_accuracy: 0.9510\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0814 - accuracy: 0.9768 - val_loss: 0.1486 - val_accuracy: 0.9520\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0804 - accuracy: 0.9778 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0794 - accuracy: 0.9780 - val_loss: 0.1481 - val_accuracy: 0.9500\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0776 - accuracy: 0.9778 - val_loss: 0.1479 - val_accuracy: 0.9520\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0767 - accuracy: 0.9790 - val_loss: 0.1474 - val_accuracy: 0.9520\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.0751 - accuracy: 0.9785 - val_loss: 0.1466 - val_accuracy: 0.9470\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0741 - accuracy: 0.9787 - val_loss: 0.1483 - val_accuracy: 0.9520\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0726 - accuracy: 0.9800 - val_loss: 0.1462 - val_accuracy: 0.9490\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0720 - accuracy: 0.9790 - val_loss: 0.1493 - val_accuracy: 0.9490\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0719 - accuracy: 0.9797 - val_loss: 0.1474 - val_accuracy: 0.9500\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 64us/step - loss: 0.0696 - accuracy: 0.9808 - val_loss: 0.1478 - val_accuracy: 0.9520\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0692 - accuracy: 0.9810 - val_loss: 0.1466 - val_accuracy: 0.9510\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0679 - accuracy: 0.9808 - val_loss: 0.1494 - val_accuracy: 0.9520\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0666 - accuracy: 0.9815 - val_loss: 0.1491 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 64us/step - loss: 0.0656 - accuracy: 0.9805 - val_loss: 0.1476 - val_accuracy: 0.9520\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0652 - accuracy: 0.9812 - val_loss: 0.1480 - val_accuracy: 0.9510\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 65us/step - loss: 0.0639 - accuracy: 0.9818 - val_loss: 0.1495 - val_accuracy: 0.9500\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0629 - accuracy: 0.9822 - val_loss: 0.1475 - val_accuracy: 0.9510\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 64us/step - loss: 0.0622 - accuracy: 0.9827 - val_loss: 0.1493 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0614 - accuracy: 0.9822 - val_loss: 0.1485 - val_accuracy: 0.9490\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 63us/step - loss: 0.0605 - accuracy: 0.9827 - val_loss: 0.1489 - val_accuracy: 0.9500\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0594 - accuracy: 0.9827 - val_loss: 0.1498 - val_accuracy: 0.9500\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0588 - accuracy: 0.9843 - val_loss: 0.1493 - val_accuracy: 0.9510\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 0.0578 - accuracy: 0.9840 - val_loss: 0.1502 - val_accuracy: 0.9500\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0576 - accuracy: 0.9840 - val_loss: 0.1514 - val_accuracy: 0.9510\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0561 - accuracy: 0.9837 - val_loss: 0.1516 - val_accuracy: 0.9510\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0556 - accuracy: 0.9852 - val_loss: 0.1501 - val_accuracy: 0.9510\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0547 - accuracy: 0.9852 - val_loss: 0.1505 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7277467325065503\n",
      "F1 Micro: 0.9607\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 264us/step - loss: 0.6547 - accuracy: 0.8332 - val_loss: 0.3869 - val_accuracy: 0.8920\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.3133 - accuracy: 0.9150 - val_loss: 0.3089 - val_accuracy: 0.9140\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.2590 - accuracy: 0.9298 - val_loss: 0.2664 - val_accuracy: 0.9220\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.2273 - accuracy: 0.9398 - val_loss: 0.2330 - val_accuracy: 0.9330\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.2059 - accuracy: 0.9442 - val_loss: 0.2132 - val_accuracy: 0.9360\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1861 - accuracy: 0.9480 - val_loss: 0.2010 - val_accuracy: 0.9450\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.1748 - accuracy: 0.9498 - val_loss: 0.1863 - val_accuracy: 0.9440\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1606 - accuracy: 0.9540 - val_loss: 0.1789 - val_accuracy: 0.9480\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1523 - accuracy: 0.9578 - val_loss: 0.1731 - val_accuracy: 0.9460\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1443 - accuracy: 0.9580 - val_loss: 0.1690 - val_accuracy: 0.9480\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1380 - accuracy: 0.9590 - val_loss: 0.1661 - val_accuracy: 0.9460\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.1335 - accuracy: 0.9610 - val_loss: 0.1603 - val_accuracy: 0.9530\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1289 - accuracy: 0.9643 - val_loss: 0.1651 - val_accuracy: 0.9460\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1247 - accuracy: 0.9638 - val_loss: 0.1562 - val_accuracy: 0.9500\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.1181 - accuracy: 0.9670 - val_loss: 0.1534 - val_accuracy: 0.9500\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1168 - accuracy: 0.9682 - val_loss: 0.1582 - val_accuracy: 0.9470\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1115 - accuracy: 0.9678 - val_loss: 0.1524 - val_accuracy: 0.9480\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.1065 - accuracy: 0.9693 - val_loss: 0.1513 - val_accuracy: 0.9520\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1048 - accuracy: 0.9705 - val_loss: 0.1511 - val_accuracy: 0.9490\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1008 - accuracy: 0.9705 - val_loss: 0.1488 - val_accuracy: 0.9520\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.1001 - accuracy: 0.9722 - val_loss: 0.1542 - val_accuracy: 0.9490\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0947 - accuracy: 0.9735 - val_loss: 0.1438 - val_accuracy: 0.9520\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0905 - accuracy: 0.9750 - val_loss: 0.1455 - val_accuracy: 0.9520\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0903 - accuracy: 0.9730 - val_loss: 0.1439 - val_accuracy: 0.9540\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0912 - accuracy: 0.9750 - val_loss: 0.1536 - val_accuracy: 0.9550\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0842 - accuracy: 0.9768 - val_loss: 0.1421 - val_accuracy: 0.9540\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0819 - accuracy: 0.9768 - val_loss: 0.1397 - val_accuracy: 0.9490\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0766 - accuracy: 0.9800 - val_loss: 0.1413 - val_accuracy: 0.9550\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0738 - accuracy: 0.9800 - val_loss: 0.1397 - val_accuracy: 0.9510\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0736 - accuracy: 0.9797 - val_loss: 0.1378 - val_accuracy: 0.9550\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.0674 - accuracy: 0.9808 - val_loss: 0.1394 - val_accuracy: 0.9560\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0648 - accuracy: 0.9810 - val_loss: 0.1387 - val_accuracy: 0.9510\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0615 - accuracy: 0.9827 - val_loss: 0.1457 - val_accuracy: 0.9550\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0581 - accuracy: 0.9833 - val_loss: 0.1409 - val_accuracy: 0.9560\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0536 - accuracy: 0.9870 - val_loss: 0.1386 - val_accuracy: 0.9540\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0504 - accuracy: 0.9860 - val_loss: 0.1463 - val_accuracy: 0.9530\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0450 - accuracy: 0.9898 - val_loss: 0.1381 - val_accuracy: 0.9570\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0417 - accuracy: 0.9893 - val_loss: 0.1347 - val_accuracy: 0.9570\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0362 - accuracy: 0.9918 - val_loss: 0.1438 - val_accuracy: 0.9530\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0336 - accuracy: 0.9942 - val_loss: 0.1419 - val_accuracy: 0.9560\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0276 - accuracy: 0.9950 - val_loss: 0.1489 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0252 - accuracy: 0.9962 - val_loss: 0.1414 - val_accuracy: 0.9550\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0212 - accuracy: 0.9960 - val_loss: 0.1422 - val_accuracy: 0.9580\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0203 - accuracy: 0.9973 - val_loss: 0.1526 - val_accuracy: 0.9590\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0186 - accuracy: 0.9970 - val_loss: 0.1670 - val_accuracy: 0.9570\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0163 - accuracy: 0.9992 - val_loss: 0.1457 - val_accuracy: 0.9590\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0154 - accuracy: 0.9983 - val_loss: 0.1518 - val_accuracy: 0.9590\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0157 - accuracy: 0.9987 - val_loss: 0.1536 - val_accuracy: 0.9580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0124 - accuracy: 0.9987 - val_loss: 0.1607 - val_accuracy: 0.9580\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0112 - accuracy: 0.9992 - val_loss: 0.1568 - val_accuracy: 0.9590\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.0100 - accuracy: 0.9995 - val_loss: 0.1679 - val_accuracy: 0.9570\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0091 - accuracy: 0.9995 - val_loss: 0.1686 - val_accuracy: 0.9590\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0088 - accuracy: 0.9995 - val_loss: 0.1652 - val_accuracy: 0.9570\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0076 - accuracy: 0.9995 - val_loss: 0.1718 - val_accuracy: 0.9560\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.1930 - val_accuracy: 0.9560\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 0.1789 - val_accuracy: 0.9570\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.1723 - val_accuracy: 0.9600\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9560\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7758168676284176\n",
      "F1 Micro: 0.9618\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7345063258326284\n",
      "F1 Micro: 0.9572\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7429417223177772\n",
      "F1 Micro: 0.9623\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 6 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.3801 - accuracy: 0.9061 - val_loss: 0.1987 - val_accuracy: 0.9452\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.1677 - accuracy: 0.9505 - val_loss: 0.1581 - val_accuracy: 0.9538\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.1374 - accuracy: 0.9568 - val_loss: 0.1333 - val_accuracy: 0.9575\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.1241 - accuracy: 0.9604 - val_loss: 0.1329 - val_accuracy: 0.9587\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.1102 - accuracy: 0.9648 - val_loss: 0.1158 - val_accuracy: 0.9622\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.1022 - accuracy: 0.9667 - val_loss: 0.1132 - val_accuracy: 0.9636\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0959 - accuracy: 0.9695 - val_loss: 0.1120 - val_accuracy: 0.9663\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.0912 - accuracy: 0.9706 - val_loss: 0.1043 - val_accuracy: 0.9673\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0844 - accuracy: 0.9718 - val_loss: 0.1046 - val_accuracy: 0.9668\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0813 - accuracy: 0.9734 - val_loss: 0.0998 - val_accuracy: 0.9674\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0767 - accuracy: 0.9742 - val_loss: 0.1022 - val_accuracy: 0.9659\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0733 - accuracy: 0.9759 - val_loss: 0.0995 - val_accuracy: 0.9699\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0672 - accuracy: 0.9776 - val_loss: 0.0994 - val_accuracy: 0.9682\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.0645 - accuracy: 0.9783 - val_loss: 0.1008 - val_accuracy: 0.9703\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0596 - accuracy: 0.9795 - val_loss: 0.0929 - val_accuracy: 0.9688\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0553 - accuracy: 0.9813 - val_loss: 0.1008 - val_accuracy: 0.9677\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0490 - accuracy: 0.9839 - val_loss: 0.1025 - val_accuracy: 0.9661\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0467 - accuracy: 0.9841 - val_loss: 0.1132 - val_accuracy: 0.9689\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0411 - accuracy: 0.9857 - val_loss: 0.1138 - val_accuracy: 0.9650\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0377 - accuracy: 0.9866 - val_loss: 0.0943 - val_accuracy: 0.9737\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0335 - accuracy: 0.9879 - val_loss: 0.0996 - val_accuracy: 0.9692\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.1040 - val_accuracy: 0.9708\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.1156 - val_accuracy: 0.9676\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.1164 - val_accuracy: 0.9707\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 0.1137 - val_accuracy: 0.9698\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.1129 - val_accuracy: 0.9704\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.1511 - val_accuracy: 0.9674\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.1723 - val_accuracy: 0.9680\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.1379 - val_accuracy: 0.9699\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1414 - val_accuracy: 0.9681\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.1625 - val_accuracy: 0.9716\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.1450 - val_accuracy: 0.9665\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1445 - val_accuracy: 0.9714\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1429 - val_accuracy: 0.9683\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.1528 - val_accuracy: 0.9702\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8166458329669474\n",
      "F1 Micro: 0.9712\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7996697283880295\n",
      "F1 Micro: 0.9669\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.4847 - accuracy: 0.8907 - val_loss: 0.1617 - val_accuracy: 0.9560\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1427 - accuracy: 0.9588 - val_loss: 0.1355 - val_accuracy: 0.9594\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1244 - accuracy: 0.9624 - val_loss: 0.1249 - val_accuracy: 0.9605\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1155 - accuracy: 0.9647 - val_loss: 0.1207 - val_accuracy: 0.9619\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.1090 - accuracy: 0.9659 - val_loss: 0.1155 - val_accuracy: 0.9632\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1044 - accuracy: 0.9681 - val_loss: 0.1130 - val_accuracy: 0.9637\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1005 - accuracy: 0.9690 - val_loss: 0.1095 - val_accuracy: 0.9645\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0976 - accuracy: 0.9700 - val_loss: 0.1075 - val_accuracy: 0.9657\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0946 - accuracy: 0.9705 - val_loss: 0.1077 - val_accuracy: 0.9664\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0925 - accuracy: 0.9710 - val_loss: 0.1061 - val_accuracy: 0.9666\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0905 - accuracy: 0.9716 - val_loss: 0.1051 - val_accuracy: 0.9669\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0884 - accuracy: 0.9722 - val_loss: 0.1044 - val_accuracy: 0.9676\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0863 - accuracy: 0.9733 - val_loss: 0.1046 - val_accuracy: 0.9681\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0852 - accuracy: 0.9731 - val_loss: 0.1025 - val_accuracy: 0.9682\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0837 - accuracy: 0.9739 - val_loss: 0.1011 - val_accuracy: 0.9694\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0824 - accuracy: 0.9746 - val_loss: 0.1029 - val_accuracy: 0.9688\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0811 - accuracy: 0.9748 - val_loss: 0.1027 - val_accuracy: 0.9680\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0796 - accuracy: 0.9752 - val_loss: 0.1018 - val_accuracy: 0.9678\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0785 - accuracy: 0.9756 - val_loss: 0.1026 - val_accuracy: 0.9674\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0776 - accuracy: 0.9757 - val_loss: 0.1004 - val_accuracy: 0.9686\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0765 - accuracy: 0.9764 - val_loss: 0.1022 - val_accuracy: 0.9688\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0753 - accuracy: 0.9765 - val_loss: 0.1019 - val_accuracy: 0.9688\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0742 - accuracy: 0.9772 - val_loss: 0.1007 - val_accuracy: 0.9688\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0734 - accuracy: 0.9771 - val_loss: 0.1005 - val_accuracy: 0.9692\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0724 - accuracy: 0.9770 - val_loss: 0.1003 - val_accuracy: 0.9687\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0717 - accuracy: 0.9782 - val_loss: 0.0992 - val_accuracy: 0.9685\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0707 - accuracy: 0.9778 - val_loss: 0.1007 - val_accuracy: 0.9689\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0699 - accuracy: 0.9783 - val_loss: 0.0980 - val_accuracy: 0.9690\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0689 - accuracy: 0.9786 - val_loss: 0.0991 - val_accuracy: 0.9701\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0682 - accuracy: 0.9785 - val_loss: 0.1003 - val_accuracy: 0.9687\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0672 - accuracy: 0.9791 - val_loss: 0.1010 - val_accuracy: 0.9681\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0665 - accuracy: 0.9789 - val_loss: 0.0984 - val_accuracy: 0.9692\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0658 - accuracy: 0.9791 - val_loss: 0.0988 - val_accuracy: 0.9704\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0649 - accuracy: 0.9794 - val_loss: 0.1009 - val_accuracy: 0.9696\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0642 - accuracy: 0.9797 - val_loss: 0.1000 - val_accuracy: 0.9688\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0636 - accuracy: 0.9804 - val_loss: 0.1001 - val_accuracy: 0.9692\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0629 - accuracy: 0.9802 - val_loss: 0.0999 - val_accuracy: 0.9691\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0619 - accuracy: 0.9801 - val_loss: 0.1005 - val_accuracy: 0.9688\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0613 - accuracy: 0.9808 - val_loss: 0.0999 - val_accuracy: 0.9680\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0608 - accuracy: 0.9813 - val_loss: 0.0997 - val_accuracy: 0.9692\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0601 - accuracy: 0.9808 - val_loss: 0.1036 - val_accuracy: 0.9691\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0591 - accuracy: 0.9814 - val_loss: 0.1003 - val_accuracy: 0.9698\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0585 - accuracy: 0.9819 - val_loss: 0.1031 - val_accuracy: 0.9693\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0583 - accuracy: 0.9825 - val_loss: 0.1013 - val_accuracy: 0.9695\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0577 - accuracy: 0.9819 - val_loss: 0.1000 - val_accuracy: 0.9700\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0568 - accuracy: 0.9824 - val_loss: 0.1008 - val_accuracy: 0.9687\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0561 - accuracy: 0.9827 - val_loss: 0.1021 - val_accuracy: 0.9697\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0555 - accuracy: 0.9827 - val_loss: 0.1019 - val_accuracy: 0.9702\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8261488362446909\n",
      "F1 Micro: 0.9688\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 0.2602 - accuracy: 0.9295 - val_loss: 0.1640 - val_accuracy: 0.9500\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.1429 - accuracy: 0.9571 - val_loss: 0.1325 - val_accuracy: 0.9594\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.1230 - accuracy: 0.9621 - val_loss: 0.1185 - val_accuracy: 0.9634\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.1112 - accuracy: 0.9650 - val_loss: 0.1123 - val_accuracy: 0.9658\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.1029 - accuracy: 0.9689 - val_loss: 0.1122 - val_accuracy: 0.9654\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0983 - accuracy: 0.9698 - val_loss: 0.1037 - val_accuracy: 0.9670\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0937 - accuracy: 0.9711 - val_loss: 0.1048 - val_accuracy: 0.9666\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0898 - accuracy: 0.9714 - val_loss: 0.1004 - val_accuracy: 0.9667\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0856 - accuracy: 0.9727 - val_loss: 0.0965 - val_accuracy: 0.9686\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0804 - accuracy: 0.9743 - val_loss: 0.0951 - val_accuracy: 0.9692\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0749 - accuracy: 0.9751 - val_loss: 0.0984 - val_accuracy: 0.9683\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0694 - accuracy: 0.9775 - val_loss: 0.0994 - val_accuracy: 0.9658\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0636 - accuracy: 0.9793 - val_loss: 0.0983 - val_accuracy: 0.9666\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0568 - accuracy: 0.9821 - val_loss: 0.0940 - val_accuracy: 0.9705\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0497 - accuracy: 0.9842 - val_loss: 0.0987 - val_accuracy: 0.9691\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.0977 - val_accuracy: 0.9695\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 208us/step - loss: 0.0362 - accuracy: 0.9890 - val_loss: 0.1010 - val_accuracy: 0.9694\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 0.1148 - val_accuracy: 0.9700\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.1128 - val_accuracy: 0.9689\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.1627 - val_accuracy: 0.9533\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.1336 - val_accuracy: 0.9709\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0145 - accuracy: 0.9961 - val_loss: 0.1347 - val_accuracy: 0.9690\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.1404 - val_accuracy: 0.9685\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.1398 - val_accuracy: 0.9681\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.1522 - val_accuracy: 0.9695\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.1529 - val_accuracy: 0.9660\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1484 - val_accuracy: 0.9664\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.1536 - val_accuracy: 0.9675\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1544 - val_accuracy: 0.9693\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1591 - val_accuracy: 0.9697\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.1584 - val_accuracy: 0.9672\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.1683 - val_accuracy: 0.9657\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.1660 - val_accuracy: 0.9697\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1704 - val_accuracy: 0.9647\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8340221455513148\n",
      "F1 Micro: 0.9699\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8035863728890463\n",
      "F1 Micro: 0.9661\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8713268146959253\n",
      "F1 Micro: 0.9753\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 6 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.2439 - accuracy: 0.9354 - val_loss: 0.1348 - val_accuracy: 0.9575\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.1207 - accuracy: 0.9623 - val_loss: 0.1141 - val_accuracy: 0.9627\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.1013 - accuracy: 0.9676 - val_loss: 0.1068 - val_accuracy: 0.9652\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0906 - accuracy: 0.9706 - val_loss: 0.0888 - val_accuracy: 0.9702\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0811 - accuracy: 0.9731 - val_loss: 0.0901 - val_accuracy: 0.9704\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0739 - accuracy: 0.9752 - val_loss: 0.0806 - val_accuracy: 0.9730\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0670 - accuracy: 0.9769 - val_loss: 0.0924 - val_accuracy: 0.9696\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0622 - accuracy: 0.9785 - val_loss: 0.0697 - val_accuracy: 0.9762\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0577 - accuracy: 0.9800 - val_loss: 0.0954 - val_accuracy: 0.9667\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0531 - accuracy: 0.9812 - val_loss: 0.0706 - val_accuracy: 0.9760\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0493 - accuracy: 0.9825 - val_loss: 0.0719 - val_accuracy: 0.9756\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0459 - accuracy: 0.9836 - val_loss: 0.0690 - val_accuracy: 0.9766\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0427 - accuracy: 0.9843 - val_loss: 0.0803 - val_accuracy: 0.9728\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0384 - accuracy: 0.9861 - val_loss: 0.0763 - val_accuracy: 0.9771\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0345 - accuracy: 0.9874 - val_loss: 0.0725 - val_accuracy: 0.9770\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0305 - accuracy: 0.9890 - val_loss: 0.0779 - val_accuracy: 0.9767\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0273 - accuracy: 0.9902 - val_loss: 0.0816 - val_accuracy: 0.9763\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0235 - accuracy: 0.9912 - val_loss: 0.0865 - val_accuracy: 0.9761\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0200 - accuracy: 0.9929 - val_loss: 0.0904 - val_accuracy: 0.9755\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0167 - accuracy: 0.9941 - val_loss: 0.1044 - val_accuracy: 0.9750\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.0936 - val_accuracy: 0.9760\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.1221 - val_accuracy: 0.9746\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.1045 - val_accuracy: 0.9768\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.1232 - val_accuracy: 0.9758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.1465 - val_accuracy: 0.9747\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.1241 - val_accuracy: 0.9748\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.1319 - val_accuracy: 0.9751\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1233 - val_accuracy: 0.9765\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.1303 - val_accuracy: 0.9738\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1220 - val_accuracy: 0.9770\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.1297 - val_accuracy: 0.9756\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.1551 - val_accuracy: 0.9710\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8766729307897048\n",
      "F1 Micro: 0.9762000000000001\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8363611946403562\n",
      "F1 Micro: 0.97\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.2588 - accuracy: 0.9336 - val_loss: 0.1243 - val_accuracy: 0.9616\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.1126 - accuracy: 0.9651 - val_loss: 0.1117 - val_accuracy: 0.9652\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.1027 - accuracy: 0.9677 - val_loss: 0.1079 - val_accuracy: 0.9660\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0974 - accuracy: 0.9693 - val_loss: 0.1019 - val_accuracy: 0.9682\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0933 - accuracy: 0.9705 - val_loss: 0.0992 - val_accuracy: 0.9691\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0903 - accuracy: 0.9717 - val_loss: 0.0974 - val_accuracy: 0.9694\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0878 - accuracy: 0.9721 - val_loss: 0.0949 - val_accuracy: 0.9701\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0857 - accuracy: 0.9728 - val_loss: 0.0944 - val_accuracy: 0.9699\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0840 - accuracy: 0.9731 - val_loss: 0.0927 - val_accuracy: 0.9706\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0821 - accuracy: 0.9740 - val_loss: 0.0946 - val_accuracy: 0.9705\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0807 - accuracy: 0.9743 - val_loss: 0.0916 - val_accuracy: 0.9708\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0793 - accuracy: 0.9746 - val_loss: 0.0901 - val_accuracy: 0.9713\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0781 - accuracy: 0.9752 - val_loss: 0.0892 - val_accuracy: 0.9712\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0770 - accuracy: 0.9752 - val_loss: 0.0895 - val_accuracy: 0.9714\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0756 - accuracy: 0.9758 - val_loss: 0.0890 - val_accuracy: 0.9716\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0748 - accuracy: 0.9758 - val_loss: 0.0877 - val_accuracy: 0.9717\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0735 - accuracy: 0.9763 - val_loss: 0.0875 - val_accuracy: 0.9725\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0728 - accuracy: 0.9765 - val_loss: 0.0874 - val_accuracy: 0.9722\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0719 - accuracy: 0.9767 - val_loss: 0.0876 - val_accuracy: 0.9726\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0710 - accuracy: 0.9768 - val_loss: 0.0864 - val_accuracy: 0.9724\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0702 - accuracy: 0.9773 - val_loss: 0.0857 - val_accuracy: 0.9727\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0694 - accuracy: 0.9775 - val_loss: 0.0880 - val_accuracy: 0.9721\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0687 - accuracy: 0.9778 - val_loss: 0.0852 - val_accuracy: 0.9732\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0679 - accuracy: 0.9778 - val_loss: 0.0857 - val_accuracy: 0.9728\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0672 - accuracy: 0.9779 - val_loss: 0.0872 - val_accuracy: 0.9728\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0665 - accuracy: 0.9782 - val_loss: 0.0843 - val_accuracy: 0.9734\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0657 - accuracy: 0.9786 - val_loss: 0.0850 - val_accuracy: 0.9730\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0650 - accuracy: 0.9788 - val_loss: 0.0852 - val_accuracy: 0.9734\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0644 - accuracy: 0.9791 - val_loss: 0.0848 - val_accuracy: 0.9732\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0638 - accuracy: 0.9790 - val_loss: 0.0844 - val_accuracy: 0.9738\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0631 - accuracy: 0.9792 - val_loss: 0.0852 - val_accuracy: 0.9731\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0625 - accuracy: 0.9795 - val_loss: 0.0844 - val_accuracy: 0.9731\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0619 - accuracy: 0.9797 - val_loss: 0.0846 - val_accuracy: 0.9736\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0613 - accuracy: 0.9799 - val_loss: 0.0850 - val_accuracy: 0.9738\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0604 - accuracy: 0.9803 - val_loss: 0.0862 - val_accuracy: 0.9728\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0599 - accuracy: 0.9803 - val_loss: 0.0854 - val_accuracy: 0.9734\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0595 - accuracy: 0.9806 - val_loss: 0.0864 - val_accuracy: 0.9730\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0589 - accuracy: 0.9810 - val_loss: 0.0860 - val_accuracy: 0.9731\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0583 - accuracy: 0.9808 - val_loss: 0.0846 - val_accuracy: 0.9739\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0576 - accuracy: 0.9811 - val_loss: 0.0857 - val_accuracy: 0.9736\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0570 - accuracy: 0.9813 - val_loss: 0.0853 - val_accuracy: 0.9726\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0566 - accuracy: 0.9815 - val_loss: 0.0855 - val_accuracy: 0.9735\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0561 - accuracy: 0.9816 - val_loss: 0.0850 - val_accuracy: 0.9731\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0554 - accuracy: 0.9818 - val_loss: 0.0848 - val_accuracy: 0.9736\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0548 - accuracy: 0.9823 - val_loss: 0.0860 - val_accuracy: 0.9733\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0541 - accuracy: 0.9822 - val_loss: 0.0871 - val_accuracy: 0.9731\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8503319897975199\n",
      "F1 Micro: 0.9724\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.1716 - accuracy: 0.9494 - val_loss: 0.1201 - val_accuracy: 0.9634\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.1050 - accuracy: 0.9668 - val_loss: 0.1006 - val_accuracy: 0.9678\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0892 - accuracy: 0.9711 - val_loss: 0.0879 - val_accuracy: 0.9724\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0799 - accuracy: 0.9739 - val_loss: 0.0842 - val_accuracy: 0.9734\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0729 - accuracy: 0.9760 - val_loss: 0.0799 - val_accuracy: 0.9742\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0675 - accuracy: 0.9772 - val_loss: 0.0757 - val_accuracy: 0.9748\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0618 - accuracy: 0.9791 - val_loss: 0.0769 - val_accuracy: 0.9746\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0563 - accuracy: 0.9809 - val_loss: 0.0741 - val_accuracy: 0.9754\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0505 - accuracy: 0.9827 - val_loss: 0.0701 - val_accuracy: 0.9769\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0453 - accuracy: 0.9841 - val_loss: 0.0736 - val_accuracy: 0.9762\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0399 - accuracy: 0.9860 - val_loss: 0.0697 - val_accuracy: 0.9780\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0337 - accuracy: 0.9883 - val_loss: 0.0778 - val_accuracy: 0.9752\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 0.0782 - val_accuracy: 0.9767\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0223 - accuracy: 0.9922 - val_loss: 0.0856 - val_accuracy: 0.9755\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.0882 - val_accuracy: 0.9774\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.1091 - val_accuracy: 0.9766\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.1033 - val_accuracy: 0.9764\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.1131 - val_accuracy: 0.9770\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1113 - val_accuracy: 0.9769\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1119 - val_accuracy: 0.9766\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.1177 - val_accuracy: 0.9768\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.1264 - val_accuracy: 0.9743\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.1293 - val_accuracy: 0.9771\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1431 - val_accuracy: 0.9763\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1407 - val_accuracy: 0.9765\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.1425 - val_accuracy: 0.9747\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1653 - val_accuracy: 0.9754\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.1376 - val_accuracy: 0.9772\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1276 - val_accuracy: 0.9770\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1356 - val_accuracy: 0.9763\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.1457 - val_accuracy: 0.9765\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8999286032856006\n",
      "F1 Micro: 0.9772\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8435918250295711\n",
      "F1 Micro: 0.9689\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8896885838326241\n",
      "F1 Micro: 0.978\n",
      "\n",
      "\n",
      " 54.15189350048701 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 7 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 7 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 2, 3, 4, 6, 8]\n",
      "label_list [0, 2, 3, 4, 6, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 1.9384 - accuracy: 0.7725 - val_loss: 1.5408 - val_accuracy: 0.8500\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 1.0493 - accuracy: 0.8650 - val_loss: 0.7840 - val_accuracy: 0.8500\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.6630 - accuracy: 0.8650 - val_loss: 0.7612 - val_accuracy: 0.8500\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6275 - accuracy: 0.8650 - val_loss: 0.7092 - val_accuracy: 0.8500\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.6011 - accuracy: 0.8650 - val_loss: 0.6863 - val_accuracy: 0.8500\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.5924 - accuracy: 0.8650 - val_loss: 0.6663 - val_accuracy: 0.8500\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 267us/step - loss: 0.5794 - accuracy: 0.8650 - val_loss: 0.6535 - val_accuracy: 0.8500\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.5752 - accuracy: 0.8650 - val_loss: 0.6430 - val_accuracy: 0.8500\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.5724 - accuracy: 0.8650 - val_loss: 0.6404 - val_accuracy: 0.8500\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.5668 - accuracy: 0.8650 - val_loss: 0.6406 - val_accuracy: 0.8500\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.5651 - accuracy: 0.8650 - val_loss: 0.6353 - val_accuracy: 0.8500\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.5631 - accuracy: 0.8650 - val_loss: 0.6297 - val_accuracy: 0.8500\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 252us/step - loss: 0.5608 - accuracy: 0.8650 - val_loss: 0.6389 - val_accuracy: 0.8500\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.5549 - accuracy: 0.8650 - val_loss: 0.6304 - val_accuracy: 0.8500\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 222us/step - loss: 0.5518 - accuracy: 0.8650 - val_loss: 0.6195 - val_accuracy: 0.8500\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.5511 - accuracy: 0.8650 - val_loss: 0.6158 - val_accuracy: 0.8500\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.5437 - accuracy: 0.8650 - val_loss: 0.6070 - val_accuracy: 0.8500\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.5375 - accuracy: 0.8650 - val_loss: 0.6049 - val_accuracy: 0.8500\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 259us/step - loss: 0.5413 - accuracy: 0.8650 - val_loss: 0.5907 - val_accuracy: 0.8500\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.5213 - accuracy: 0.8650 - val_loss: 0.5899 - val_accuracy: 0.8500\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.5137 - accuracy: 0.8650 - val_loss: 0.5706 - val_accuracy: 0.8500\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.5099 - accuracy: 0.8650 - val_loss: 0.5657 - val_accuracy: 0.8500\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.4942 - accuracy: 0.8650 - val_loss: 0.5769 - val_accuracy: 0.8500\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.4794 - accuracy: 0.8650 - val_loss: 0.5246 - val_accuracy: 0.8500\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 244us/step - loss: 0.4620 - accuracy: 0.8650 - val_loss: 0.5274 - val_accuracy: 0.8600\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.4389 - accuracy: 0.8725 - val_loss: 0.4907 - val_accuracy: 0.8600\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.4229 - accuracy: 0.8900 - val_loss: 0.4705 - val_accuracy: 0.9100\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.4152 - accuracy: 0.8900 - val_loss: 0.4705 - val_accuracy: 0.9100\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3897 - accuracy: 0.9075 - val_loss: 0.4375 - val_accuracy: 0.9100\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.3625 - accuracy: 0.9025 - val_loss: 0.4369 - val_accuracy: 0.9000\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.3611 - accuracy: 0.9100 - val_loss: 0.4025 - val_accuracy: 0.9100\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.3598 - accuracy: 0.9175 - val_loss: 0.3966 - val_accuracy: 0.9100\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.3395 - accuracy: 0.9100 - val_loss: 0.3914 - val_accuracy: 0.9100\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.3299 - accuracy: 0.9150 - val_loss: 0.3905 - val_accuracy: 0.9100\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.3080 - accuracy: 0.9175 - val_loss: 0.3769 - val_accuracy: 0.9100\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.3057 - accuracy: 0.9175 - val_loss: 0.3749 - val_accuracy: 0.9100\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.2914 - accuracy: 0.9200 - val_loss: 0.3244 - val_accuracy: 0.9000\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.2680 - accuracy: 0.9175 - val_loss: 0.3399 - val_accuracy: 0.9100\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2722 - accuracy: 0.9175 - val_loss: 0.3052 - val_accuracy: 0.9100\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.2616 - accuracy: 0.9125 - val_loss: 0.3050 - val_accuracy: 0.9000\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.2486 - accuracy: 0.9250 - val_loss: 0.2932 - val_accuracy: 0.9200\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.2379 - accuracy: 0.9325 - val_loss: 0.2880 - val_accuracy: 0.9100\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2338 - accuracy: 0.9325 - val_loss: 0.2867 - val_accuracy: 0.9100\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2243 - accuracy: 0.9325 - val_loss: 0.2598 - val_accuracy: 0.9300\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.2381 - accuracy: 0.9350 - val_loss: 0.2842 - val_accuracy: 0.9100\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.2109 - accuracy: 0.9400 - val_loss: 0.2387 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.2111 - accuracy: 0.9400 - val_loss: 0.2791 - val_accuracy: 0.9200\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.2082 - accuracy: 0.9375 - val_loss: 0.2265 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.2070 - accuracy: 0.9400 - val_loss: 0.2604 - val_accuracy: 0.9500\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1957 - accuracy: 0.9450 - val_loss: 0.2261 - val_accuracy: 0.9600\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2015 - accuracy: 0.9500 - val_loss: 0.2848 - val_accuracy: 0.9300\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1911 - accuracy: 0.9425 - val_loss: 0.2473 - val_accuracy: 0.9600\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1971 - accuracy: 0.9475 - val_loss: 0.2392 - val_accuracy: 0.9600\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1617 - accuracy: 0.9550 - val_loss: 0.2336 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1686 - accuracy: 0.9525 - val_loss: 0.2186 - val_accuracy: 0.9500\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1863 - accuracy: 0.9500 - val_loss: 0.2333 - val_accuracy: 0.9500\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1786 - accuracy: 0.9475 - val_loss: 0.2413 - val_accuracy: 0.9600\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1786 - accuracy: 0.9425 - val_loss: 0.2441 - val_accuracy: 0.9600\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1815 - accuracy: 0.9575 - val_loss: 0.4115 - val_accuracy: 0.9100\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.2192 - accuracy: 0.9425 - val_loss: 0.2199 - val_accuracy: 0.9600\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.1860 - accuracy: 0.9400 - val_loss: 0.2132 - val_accuracy: 0.9500\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1809 - accuracy: 0.9475 - val_loss: 0.2184 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1420 - accuracy: 0.9550 - val_loss: 0.2023 - val_accuracy: 0.9500\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1314 - accuracy: 0.9575 - val_loss: 0.2155 - val_accuracy: 0.9600\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1288 - accuracy: 0.9625 - val_loss: 0.2036 - val_accuracy: 0.9700\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1266 - accuracy: 0.9700 - val_loss: 0.2215 - val_accuracy: 0.9500\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.1182 - accuracy: 0.9675 - val_loss: 0.2019 - val_accuracy: 0.9600\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1076 - accuracy: 0.9725 - val_loss: 0.2342 - val_accuracy: 0.9600\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.1167 - accuracy: 0.9625 - val_loss: 0.1948 - val_accuracy: 0.9600\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1171 - accuracy: 0.9675 - val_loss: 0.2518 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1805 - accuracy: 0.9450 - val_loss: 0.2389 - val_accuracy: 0.9400\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.1544 - accuracy: 0.9450 - val_loss: 0.1939 - val_accuracy: 0.9600\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.1039 - accuracy: 0.9675 - val_loss: 0.1969 - val_accuracy: 0.9600\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.0969 - accuracy: 0.9750 - val_loss: 0.1983 - val_accuracy: 0.9600\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0936 - accuracy: 0.9700 - val_loss: 0.2074 - val_accuracy: 0.9600\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0849 - accuracy: 0.9775 - val_loss: 0.1958 - val_accuracy: 0.9600\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0925 - accuracy: 0.9725 - val_loss: 0.2026 - val_accuracy: 0.9600\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0769 - accuracy: 0.9725 - val_loss: 0.1898 - val_accuracy: 0.9700\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0784 - accuracy: 0.9775 - val_loss: 0.2001 - val_accuracy: 0.9600\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0849 - accuracy: 0.9725 - val_loss: 0.2005 - val_accuracy: 0.9700\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1037 - accuracy: 0.9700 - val_loss: 0.2220 - val_accuracy: 0.9700\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.1022 - accuracy: 0.9650 - val_loss: 0.1814 - val_accuracy: 0.9600\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 233us/step - loss: 0.0681 - accuracy: 0.9825 - val_loss: 0.2000 - val_accuracy: 0.9600\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0590 - accuracy: 0.9925 - val_loss: 0.1862 - val_accuracy: 0.9600\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.0590 - accuracy: 0.9850 - val_loss: 0.1936 - val_accuracy: 0.9600\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0572 - accuracy: 0.9825 - val_loss: 0.1916 - val_accuracy: 0.9600\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 202us/step - loss: 0.0566 - accuracy: 0.9850 - val_loss: 0.2050 - val_accuracy: 0.9600\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.0551 - accuracy: 0.9875 - val_loss: 0.1843 - val_accuracy: 0.9700\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0520 - accuracy: 0.9900 - val_loss: 0.1943 - val_accuracy: 0.9600\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0489 - accuracy: 0.9875 - val_loss: 0.1716 - val_accuracy: 0.9600\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 242us/step - loss: 0.0503 - accuracy: 0.9900 - val_loss: 0.1923 - val_accuracy: 0.9600\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0412 - accuracy: 0.9900 - val_loss: 0.1961 - val_accuracy: 0.9700\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0376 - accuracy: 0.9950 - val_loss: 0.2277 - val_accuracy: 0.9600\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0546 - accuracy: 0.9800 - val_loss: 0.2024 - val_accuracy: 0.9700\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0412 - accuracy: 0.9900 - val_loss: 0.2157 - val_accuracy: 0.9600\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0414 - accuracy: 0.9875 - val_loss: 0.1870 - val_accuracy: 0.9600\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0388 - accuracy: 0.9950 - val_loss: 0.2012 - val_accuracy: 0.9700\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0373 - accuracy: 0.9900 - val_loss: 0.2033 - val_accuracy: 0.9600\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0286 - accuracy: 0.9950 - val_loss: 0.1996 - val_accuracy: 0.9600\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0308 - accuracy: 0.9925 - val_loss: 0.2002 - val_accuracy: 0.9600\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0302 - accuracy: 0.9975 - val_loss: 0.1798 - val_accuracy: 0.9600\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0225 - accuracy: 0.9975 - val_loss: 0.2002 - val_accuracy: 0.9600\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0240 - accuracy: 0.9950 - val_loss: 0.1848 - val_accuracy: 0.9600\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9600\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0217 - accuracy: 0.9975 - val_loss: 0.2014 - val_accuracy: 0.9600\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9700\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 0.1938 - val_accuracy: 0.9600\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9600\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 202us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9600\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9700\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5408809662323432\n",
      "F1 Micro: 0.9282234165452811\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5199272044510808\n",
      "F1 Micro: 0.9339494700889044\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 319us/step - loss: 2.1062 - accuracy: 0.2600 - val_loss: 1.8890 - val_accuracy: 0.4500\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 95us/step - loss: 1.9210 - accuracy: 0.4525 - val_loss: 1.7156 - val_accuracy: 0.5500\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.8025 - accuracy: 0.5125 - val_loss: 1.5905 - val_accuracy: 0.5800\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.7077 - accuracy: 0.5500 - val_loss: 1.5090 - val_accuracy: 0.6100\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.6250 - accuracy: 0.5900 - val_loss: 1.4388 - val_accuracy: 0.6300\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.5444 - accuracy: 0.6125 - val_loss: 1.3794 - val_accuracy: 0.6700\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.4703 - accuracy: 0.6650 - val_loss: 1.3143 - val_accuracy: 0.7200\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.3962 - accuracy: 0.6950 - val_loss: 1.2520 - val_accuracy: 0.7600\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.3226 - accuracy: 0.7175 - val_loss: 1.1969 - val_accuracy: 0.7600\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.2504 - accuracy: 0.7475 - val_loss: 1.1398 - val_accuracy: 0.7800\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.1811 - accuracy: 0.7825 - val_loss: 1.0885 - val_accuracy: 0.7900\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.1148 - accuracy: 0.8000 - val_loss: 1.0418 - val_accuracy: 0.7900\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.0520 - accuracy: 0.8200 - val_loss: 0.9873 - val_accuracy: 0.7900\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.9926 - accuracy: 0.8500 - val_loss: 0.9429 - val_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.9366 - accuracy: 0.8625 - val_loss: 0.9026 - val_accuracy: 0.8200\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.8834 - accuracy: 0.8750 - val_loss: 0.8663 - val_accuracy: 0.8200\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 95us/step - loss: 0.8355 - accuracy: 0.8800 - val_loss: 0.8259 - val_accuracy: 0.8400\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.7881 - accuracy: 0.8900 - val_loss: 0.7914 - val_accuracy: 0.8400\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 97us/step - loss: 0.7447 - accuracy: 0.8925 - val_loss: 0.7569 - val_accuracy: 0.8600\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.7050 - accuracy: 0.8950 - val_loss: 0.7225 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.6658 - accuracy: 0.9050 - val_loss: 0.6929 - val_accuracy: 0.8700\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.6316 - accuracy: 0.9125 - val_loss: 0.6670 - val_accuracy: 0.8800\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.5948 - accuracy: 0.9225 - val_loss: 0.6396 - val_accuracy: 0.8900\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.5632 - accuracy: 0.9225 - val_loss: 0.6124 - val_accuracy: 0.8900\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.5310 - accuracy: 0.9275 - val_loss: 0.5885 - val_accuracy: 0.8900\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.5044 - accuracy: 0.9300 - val_loss: 0.5641 - val_accuracy: 0.9000\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.4734 - accuracy: 0.9400 - val_loss: 0.5395 - val_accuracy: 0.9100\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.4463 - accuracy: 0.9425 - val_loss: 0.5187 - val_accuracy: 0.9100\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.4218 - accuracy: 0.9450 - val_loss: 0.4973 - val_accuracy: 0.9200\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.3973 - accuracy: 0.9475 - val_loss: 0.4792 - val_accuracy: 0.9200\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.3749 - accuracy: 0.9525 - val_loss: 0.4608 - val_accuracy: 0.9200\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.3542 - accuracy: 0.9600 - val_loss: 0.4442 - val_accuracy: 0.9200\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.3358 - accuracy: 0.9625 - val_loss: 0.4269 - val_accuracy: 0.9200\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 95us/step - loss: 0.3157 - accuracy: 0.9675 - val_loss: 0.4117 - val_accuracy: 0.9200\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 97us/step - loss: 0.2991 - accuracy: 0.9725 - val_loss: 0.3978 - val_accuracy: 0.9200\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.2830 - accuracy: 0.9750 - val_loss: 0.3826 - val_accuracy: 0.9200\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2676 - accuracy: 0.9725 - val_loss: 0.3704 - val_accuracy: 0.9200\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.2534 - accuracy: 0.9750 - val_loss: 0.3582 - val_accuracy: 0.9200\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.2404 - accuracy: 0.9750 - val_loss: 0.3475 - val_accuracy: 0.9200\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.2281 - accuracy: 0.9725 - val_loss: 0.3373 - val_accuracy: 0.9200\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.2175 - accuracy: 0.9750 - val_loss: 0.3269 - val_accuracy: 0.9200\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.2053 - accuracy: 0.9750 - val_loss: 0.3178 - val_accuracy: 0.9200\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1958 - accuracy: 0.9800 - val_loss: 0.3095 - val_accuracy: 0.9200\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1858 - accuracy: 0.9800 - val_loss: 0.3014 - val_accuracy: 0.9200\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1779 - accuracy: 0.9775 - val_loss: 0.2936 - val_accuracy: 0.9200\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1689 - accuracy: 0.9775 - val_loss: 0.2863 - val_accuracy: 0.9200\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.1609 - accuracy: 0.9800 - val_loss: 0.2788 - val_accuracy: 0.9200\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1539 - accuracy: 0.9800 - val_loss: 0.2719 - val_accuracy: 0.9200\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1469 - accuracy: 0.9800 - val_loss: 0.2661 - val_accuracy: 0.9200\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1408 - accuracy: 0.9825 - val_loss: 0.2596 - val_accuracy: 0.9200\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 90us/step - loss: 0.1344 - accuracy: 0.9825 - val_loss: 0.2536 - val_accuracy: 0.9200\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 97us/step - loss: 0.1284 - accuracy: 0.9825 - val_loss: 0.2488 - val_accuracy: 0.9200\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1235 - accuracy: 0.9825 - val_loss: 0.2440 - val_accuracy: 0.9300\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1183 - accuracy: 0.9850 - val_loss: 0.2393 - val_accuracy: 0.9400\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1134 - accuracy: 0.9850 - val_loss: 0.2351 - val_accuracy: 0.9300\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1090 - accuracy: 0.9850 - val_loss: 0.2307 - val_accuracy: 0.9400\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1048 - accuracy: 0.9875 - val_loss: 0.2273 - val_accuracy: 0.9400\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1013 - accuracy: 0.9900 - val_loss: 0.2233 - val_accuracy: 0.9400\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0966 - accuracy: 0.9925 - val_loss: 0.2200 - val_accuracy: 0.9400\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0932 - accuracy: 0.9925 - val_loss: 0.2166 - val_accuracy: 0.9400\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0905 - accuracy: 0.9950 - val_loss: 0.2125 - val_accuracy: 0.9500\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0870 - accuracy: 0.9950 - val_loss: 0.2105 - val_accuracy: 0.9400\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0834 - accuracy: 0.9975 - val_loss: 0.2071 - val_accuracy: 0.9400\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0806 - accuracy: 0.9975 - val_loss: 0.2037 - val_accuracy: 0.9500\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0781 - accuracy: 0.9975 - val_loss: 0.2006 - val_accuracy: 0.9500\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0753 - accuracy: 0.9975 - val_loss: 0.1985 - val_accuracy: 0.9500\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 95us/step - loss: 0.0729 - accuracy: 0.9975 - val_loss: 0.1964 - val_accuracy: 0.9500\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0708 - accuracy: 0.9975 - val_loss: 0.1946 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 92us/step - loss: 0.0685 - accuracy: 0.9975 - val_loss: 0.1923 - val_accuracy: 0.9600\n",
      "Epoch 70/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 77us/step - loss: 0.0663 - accuracy: 0.9975 - val_loss: 0.1903 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0643 - accuracy: 0.9975 - val_loss: 0.1873 - val_accuracy: 0.9500\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9600\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9600\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9600\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9600\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9600\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9600\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 0.9600\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9600\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9600\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9600\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9600\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9600\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 90us/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9600\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9600\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9700\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9600\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9700\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9700\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9700\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9700\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9700\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9700\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9700\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9700\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9700\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9700\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9700\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9700\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9700\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9700\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 88us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9700\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 120us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9700\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9700\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9700\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 0.9700\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9700\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 0.9700\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9700\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9700\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9700\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9700\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9700\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9700\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1456 - val_accuracy: 0.9700\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9700\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9700\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9700\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9700\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 97us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9700\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9700\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9700\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9700\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9700\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9700\n",
      "Epoch 126/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 77us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9700\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9700\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9700\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9700\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9700\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9700\n",
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9700\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9700\n",
      "Epoch 134/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9700\n",
      "Epoch 135/1000\n",
      "400/400 [==============================] - 0s 95us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9700\n",
      "Epoch 136/1000\n",
      "400/400 [==============================] - 0s 112us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9700\n",
      "Epoch 137/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9700\n",
      "Epoch 138/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9700\n",
      "Epoch 139/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 1.00 - 0s 77us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9700\n",
      "Epoch 140/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9700\n",
      "Epoch 141/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9700\n",
      "Epoch 142/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9700\n",
      "Epoch 143/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9700\n",
      "Epoch 144/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9700\n",
      "Epoch 145/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9700\n",
      "Epoch 146/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9700\n",
      "Epoch 147/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9700\n",
      "Epoch 148/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9700\n",
      "Epoch 149/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9700\n",
      "Epoch 150/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9700\n",
      "Epoch 151/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9700\n",
      "Epoch 152/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9700\n",
      "Epoch 153/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9700\n",
      "Epoch 154/1000\n",
      "400/400 [==============================] - 0s 95us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9700\n",
      "Epoch 155/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9700\n",
      "Epoch 156/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9700\n",
      "Epoch 157/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9700\n",
      "Epoch 158/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9700\n",
      "Epoch 159/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9700\n",
      "Epoch 160/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9700\n",
      "Epoch 161/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9700\n",
      "Epoch 162/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9700\n",
      "Epoch 163/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9700\n",
      "Epoch 164/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9700\n",
      "Epoch 165/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9700\n",
      "Epoch 166/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9700\n",
      "Epoch 167/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9700\n",
      "Epoch 168/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9700\n",
      "Epoch 169/1000\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9700\n",
      "Epoch 170/1000\n",
      "400/400 [==============================] - 0s 90us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9700\n",
      "Epoch 171/1000\n",
      "400/400 [==============================] - 0s 100us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9700\n",
      "Epoch 172/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9700\n",
      "Epoch 173/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9700\n",
      "Epoch 174/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9700\n",
      "Epoch 175/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9700\n",
      "Epoch 176/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9700\n",
      "Epoch 177/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9700\n",
      "Epoch 178/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9700\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5955044128885679\n",
      "F1 Micro: 0.9345522125671807\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 798us/step - loss: 1.9113 - accuracy: 0.4825 - val_loss: 1.4679 - val_accuracy: 0.7600\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 1.0443 - accuracy: 0.8650 - val_loss: 0.5497 - val_accuracy: 0.8700\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.4768 - accuracy: 0.8900 - val_loss: 0.5617 - val_accuracy: 0.8600\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.3981 - accuracy: 0.8950 - val_loss: 0.4501 - val_accuracy: 0.8800\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.3433 - accuracy: 0.9125 - val_loss: 0.4253 - val_accuracy: 0.8800\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.3165 - accuracy: 0.9150 - val_loss: 0.4240 - val_accuracy: 0.8800\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 259us/step - loss: 0.2970 - accuracy: 0.9125 - val_loss: 0.4057 - val_accuracy: 0.8800\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2797 - accuracy: 0.9200 - val_loss: 0.3967 - val_accuracy: 0.8900\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2667 - accuracy: 0.9250 - val_loss: 0.3874 - val_accuracy: 0.8900\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 237us/step - loss: 0.2543 - accuracy: 0.9275 - val_loss: 0.3674 - val_accuracy: 0.9000\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.2455 - accuracy: 0.9300 - val_loss: 0.3652 - val_accuracy: 0.9100\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2326 - accuracy: 0.9325 - val_loss: 0.3459 - val_accuracy: 0.9100\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 259us/step - loss: 0.2250 - accuracy: 0.9325 - val_loss: 0.3345 - val_accuracy: 0.9100\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2167 - accuracy: 0.9350 - val_loss: 0.3348 - val_accuracy: 0.9100\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2064 - accuracy: 0.9425 - val_loss: 0.3251 - val_accuracy: 0.9100\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1991 - accuracy: 0.9400 - val_loss: 0.3103 - val_accuracy: 0.9200\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1925 - accuracy: 0.9525 - val_loss: 0.3017 - val_accuracy: 0.9200\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1849 - accuracy: 0.9500 - val_loss: 0.2950 - val_accuracy: 0.9200\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 254us/step - loss: 0.1797 - accuracy: 0.9525 - val_loss: 0.2962 - val_accuracy: 0.9200\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1714 - accuracy: 0.9550 - val_loss: 0.2830 - val_accuracy: 0.9300\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1672 - accuracy: 0.9575 - val_loss: 0.2758 - val_accuracy: 0.9400\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1604 - accuracy: 0.9550 - val_loss: 0.2721 - val_accuracy: 0.9400\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1560 - accuracy: 0.9550 - val_loss: 0.2722 - val_accuracy: 0.9300\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1513 - accuracy: 0.9575 - val_loss: 0.2606 - val_accuracy: 0.9300\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 257us/step - loss: 0.1454 - accuracy: 0.9600 - val_loss: 0.2610 - val_accuracy: 0.9300\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1396 - accuracy: 0.9600 - val_loss: 0.2509 - val_accuracy: 0.9300\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.1368 - accuracy: 0.9700 - val_loss: 0.2523 - val_accuracy: 0.9300\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1313 - accuracy: 0.9625 - val_loss: 0.2510 - val_accuracy: 0.9300\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1265 - accuracy: 0.9650 - val_loss: 0.2464 - val_accuracy: 0.9300\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1242 - accuracy: 0.9700 - val_loss: 0.2399 - val_accuracy: 0.9400\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 254us/step - loss: 0.1218 - accuracy: 0.9700 - val_loss: 0.2455 - val_accuracy: 0.9300\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1155 - accuracy: 0.9675 - val_loss: 0.2337 - val_accuracy: 0.9400\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1135 - accuracy: 0.9700 - val_loss: 0.2348 - val_accuracy: 0.9400\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1109 - accuracy: 0.9700 - val_loss: 0.2289 - val_accuracy: 0.9400\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1046 - accuracy: 0.9725 - val_loss: 0.2229 - val_accuracy: 0.9400\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1023 - accuracy: 0.9725 - val_loss: 0.2218 - val_accuracy: 0.9400\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.0993 - accuracy: 0.9750 - val_loss: 0.2245 - val_accuracy: 0.9400\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 244us/step - loss: 0.0958 - accuracy: 0.9725 - val_loss: 0.2195 - val_accuracy: 0.9400\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0933 - accuracy: 0.9725 - val_loss: 0.2099 - val_accuracy: 0.9400\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0907 - accuracy: 0.9775 - val_loss: 0.2180 - val_accuracy: 0.9400\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0873 - accuracy: 0.9725 - val_loss: 0.2066 - val_accuracy: 0.9400\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0846 - accuracy: 0.9800 - val_loss: 0.2063 - val_accuracy: 0.9400\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 247us/step - loss: 0.0826 - accuracy: 0.9750 - val_loss: 0.2065 - val_accuracy: 0.9400\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0821 - accuracy: 0.9775 - val_loss: 0.2083 - val_accuracy: 0.9400\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0770 - accuracy: 0.9775 - val_loss: 0.1999 - val_accuracy: 0.9400\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0752 - accuracy: 0.9775 - val_loss: 0.1998 - val_accuracy: 0.9400\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0741 - accuracy: 0.9850 - val_loss: 0.1943 - val_accuracy: 0.9400\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0703 - accuracy: 0.9850 - val_loss: 0.2070 - val_accuracy: 0.9400\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0727 - accuracy: 0.9775 - val_loss: 0.1935 - val_accuracy: 0.9400\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.0656 - accuracy: 0.9875 - val_loss: 0.1978 - val_accuracy: 0.9400\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0643 - accuracy: 0.9850 - val_loss: 0.1960 - val_accuracy: 0.9400\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0639 - accuracy: 0.9825 - val_loss: 0.1908 - val_accuracy: 0.9400\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0637 - accuracy: 0.9825 - val_loss: 0.1911 - val_accuracy: 0.9400\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0578 - accuracy: 0.9875 - val_loss: 0.1899 - val_accuracy: 0.9400\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0566 - accuracy: 0.9850 - val_loss: 0.1953 - val_accuracy: 0.9400\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.0564 - accuracy: 0.9875 - val_loss: 0.1848 - val_accuracy: 0.9400\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0548 - accuracy: 0.9850 - val_loss: 0.1859 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0512 - accuracy: 0.9875 - val_loss: 0.1871 - val_accuracy: 0.9400\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0497 - accuracy: 0.9900 - val_loss: 0.1850 - val_accuracy: 0.9500\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0486 - accuracy: 0.9900 - val_loss: 0.1833 - val_accuracy: 0.9500\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0465 - accuracy: 0.9925 - val_loss: 0.1874 - val_accuracy: 0.9500\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 264us/step - loss: 0.0458 - accuracy: 0.9900 - val_loss: 0.1863 - val_accuracy: 0.9600\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0504 - accuracy: 0.9950 - val_loss: 0.1889 - val_accuracy: 0.9500\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0437 - accuracy: 0.9875 - val_loss: 0.1829 - val_accuracy: 0.9600\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0397 - accuracy: 0.9900 - val_loss: 0.1842 - val_accuracy: 0.9600\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0382 - accuracy: 0.9900 - val_loss: 0.1856 - val_accuracy: 0.9600\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.0372 - accuracy: 0.9925 - val_loss: 0.1887 - val_accuracy: 0.9600\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 252us/step - loss: 0.0367 - accuracy: 0.9900 - val_loss: 0.1795 - val_accuracy: 0.9600\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0347 - accuracy: 0.9975 - val_loss: 0.1875 - val_accuracy: 0.9600\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0338 - accuracy: 0.9900 - val_loss: 0.1863 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0329 - accuracy: 0.9975 - val_loss: 0.1912 - val_accuracy: 0.9600\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0335 - accuracy: 0.9900 - val_loss: 0.1741 - val_accuracy: 0.9600\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0306 - accuracy: 0.9975 - val_loss: 0.1975 - val_accuracy: 0.9600\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0328 - accuracy: 0.9925 - val_loss: 0.1823 - val_accuracy: 0.9600\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0283 - accuracy: 0.9950 - val_loss: 0.1839 - val_accuracy: 0.9600\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0270 - accuracy: 0.9925 - val_loss: 0.1812 - val_accuracy: 0.9600\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9600\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0256 - accuracy: 0.9950 - val_loss: 0.1858 - val_accuracy: 0.9600\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0243 - accuracy: 0.9975 - val_loss: 0.1803 - val_accuracy: 0.9600\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9600\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 252us/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9600\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9600\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9600\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9600\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9600\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9600\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 239us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9600\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 1.00 - 0s 227us/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9600\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9600\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9600\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9600\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9600\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5715780760719958\n",
      "F1 Micro: 0.9368627254005726\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5380412560468906\n",
      "F1 Micro: 0.9333467276106284\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5897183551649796\n",
      "F1 Micro: 0.9353558692048823\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 7 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 260us/step - loss: 0.8890 - accuracy: 0.8305 - val_loss: 0.7070 - val_accuracy: 0.8330\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.6284 - accuracy: 0.8512 - val_loss: 0.6221 - val_accuracy: 0.8330\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.5338 - accuracy: 0.8547 - val_loss: 0.5027 - val_accuracy: 0.8440\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.4078 - accuracy: 0.9018 - val_loss: 0.4284 - val_accuracy: 0.8920\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.3484 - accuracy: 0.9133 - val_loss: 0.3499 - val_accuracy: 0.9060\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.3173 - accuracy: 0.9183 - val_loss: 0.3412 - val_accuracy: 0.9070\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.3141 - accuracy: 0.9187 - val_loss: 0.3745 - val_accuracy: 0.8990\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.2785 - accuracy: 0.9225 - val_loss: 0.2817 - val_accuracy: 0.9250\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.2594 - accuracy: 0.9262 - val_loss: 0.2777 - val_accuracy: 0.9210\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.2481 - accuracy: 0.9323 - val_loss: 0.2601 - val_accuracy: 0.9250\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.2204 - accuracy: 0.9345 - val_loss: 0.2189 - val_accuracy: 0.9360\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.2037 - accuracy: 0.9415 - val_loss: 0.2393 - val_accuracy: 0.9320\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1981 - accuracy: 0.9423 - val_loss: 0.2849 - val_accuracy: 0.9220\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1882 - accuracy: 0.9463 - val_loss: 0.1901 - val_accuracy: 0.9440\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1745 - accuracy: 0.9482 - val_loss: 0.1779 - val_accuracy: 0.9450\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1693 - accuracy: 0.9503 - val_loss: 0.2075 - val_accuracy: 0.9360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1608 - accuracy: 0.9505 - val_loss: 0.1966 - val_accuracy: 0.9430\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.1549 - accuracy: 0.9530 - val_loss: 0.1862 - val_accuracy: 0.9460\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1493 - accuracy: 0.9565 - val_loss: 0.1582 - val_accuracy: 0.9490\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1352 - accuracy: 0.9553 - val_loss: 0.1608 - val_accuracy: 0.9480\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1404 - accuracy: 0.9555 - val_loss: 0.1532 - val_accuracy: 0.9520\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1325 - accuracy: 0.9567 - val_loss: 0.1582 - val_accuracy: 0.9480\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1266 - accuracy: 0.9585 - val_loss: 0.1910 - val_accuracy: 0.9440\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.1232 - accuracy: 0.9613 - val_loss: 0.1450 - val_accuracy: 0.9520\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1194 - accuracy: 0.9610 - val_loss: 0.1413 - val_accuracy: 0.9540\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1119 - accuracy: 0.9628 - val_loss: 0.1623 - val_accuracy: 0.9440\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1029 - accuracy: 0.9693 - val_loss: 0.1456 - val_accuracy: 0.9560\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0985 - accuracy: 0.9688 - val_loss: 0.1609 - val_accuracy: 0.9540\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.1135 - accuracy: 0.9630 - val_loss: 0.1520 - val_accuracy: 0.9560\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0941 - accuracy: 0.9725 - val_loss: 0.1713 - val_accuracy: 0.9500\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0956 - accuracy: 0.9693 - val_loss: 0.1536 - val_accuracy: 0.9570\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0852 - accuracy: 0.9735 - val_loss: 0.1466 - val_accuracy: 0.9570\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0837 - accuracy: 0.9737 - val_loss: 0.1404 - val_accuracy: 0.9550\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0792 - accuracy: 0.9758 - val_loss: 0.1395 - val_accuracy: 0.9600\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0782 - accuracy: 0.9755 - val_loss: 0.1451 - val_accuracy: 0.9520\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0713 - accuracy: 0.9775 - val_loss: 0.1477 - val_accuracy: 0.9570\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0767 - accuracy: 0.9760 - val_loss: 0.1545 - val_accuracy: 0.9560\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0641 - accuracy: 0.9797 - val_loss: 0.1378 - val_accuracy: 0.9590\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0693 - accuracy: 0.9812 - val_loss: 0.1471 - val_accuracy: 0.9600\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0631 - accuracy: 0.9822 - val_loss: 0.1363 - val_accuracy: 0.9610\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0653 - accuracy: 0.9797 - val_loss: 0.1411 - val_accuracy: 0.9580\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0595 - accuracy: 0.9827 - val_loss: 0.1418 - val_accuracy: 0.9560\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0494 - accuracy: 0.9868 - val_loss: 0.1386 - val_accuracy: 0.9550\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0465 - accuracy: 0.9875 - val_loss: 0.1390 - val_accuracy: 0.9630\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0475 - accuracy: 0.9872 - val_loss: 0.1482 - val_accuracy: 0.9570\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0381 - accuracy: 0.9895 - val_loss: 0.1499 - val_accuracy: 0.9540\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0389 - accuracy: 0.9887 - val_loss: 0.1537 - val_accuracy: 0.9570\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0356 - accuracy: 0.9900 - val_loss: 0.1591 - val_accuracy: 0.9560\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0304 - accuracy: 0.9933 - val_loss: 0.1405 - val_accuracy: 0.9640\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0332 - accuracy: 0.9918 - val_loss: 0.1720 - val_accuracy: 0.9560\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0293 - accuracy: 0.9910 - val_loss: 0.1428 - val_accuracy: 0.9590\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0247 - accuracy: 0.9952 - val_loss: 0.1504 - val_accuracy: 0.9510\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0230 - accuracy: 0.9952 - val_loss: 0.1563 - val_accuracy: 0.9550\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0237 - accuracy: 0.9935 - val_loss: 0.1656 - val_accuracy: 0.9560\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0213 - accuracy: 0.9952 - val_loss: 0.2050 - val_accuracy: 0.9560\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.1542 - val_accuracy: 0.9630\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.1887 - val_accuracy: 0.9540\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0193 - accuracy: 0.9952 - val_loss: 0.1717 - val_accuracy: 0.9550\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0125 - accuracy: 0.9983 - val_loss: 0.1782 - val_accuracy: 0.9550\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 0.1588 - val_accuracy: 0.9620\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7208158542763222\n",
      "F1 Micro: 0.9606\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.683638423439083\n",
      "F1 Micro: 0.956\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 89us/step - loss: 1.6763 - accuracy: 0.5390 - val_loss: 1.3230 - val_accuracy: 0.7000\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 1.0627 - accuracy: 0.7900 - val_loss: 0.7995 - val_accuracy: 0.8630\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.6263 - accuracy: 0.8913 - val_loss: 0.4751 - val_accuracy: 0.9180\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.3934 - accuracy: 0.9237 - val_loss: 0.3279 - val_accuracy: 0.9330\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.2838 - accuracy: 0.9370 - val_loss: 0.2596 - val_accuracy: 0.9390\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.2295 - accuracy: 0.9408 - val_loss: 0.2226 - val_accuracy: 0.9500\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.2004 - accuracy: 0.9465 - val_loss: 0.2016 - val_accuracy: 0.9530\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1818 - accuracy: 0.9495 - val_loss: 0.1874 - val_accuracy: 0.9560\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.1695 - accuracy: 0.9513 - val_loss: 0.1789 - val_accuracy: 0.9560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1597 - accuracy: 0.9548 - val_loss: 0.1709 - val_accuracy: 0.9550\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1522 - accuracy: 0.9548 - val_loss: 0.1656 - val_accuracy: 0.9540\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1459 - accuracy: 0.9580 - val_loss: 0.1610 - val_accuracy: 0.9550\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1405 - accuracy: 0.9575 - val_loss: 0.1577 - val_accuracy: 0.9540\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1359 - accuracy: 0.9607 - val_loss: 0.1540 - val_accuracy: 0.9540\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.1320 - accuracy: 0.9613 - val_loss: 0.1526 - val_accuracy: 0.9540\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1282 - accuracy: 0.9625 - val_loss: 0.1504 - val_accuracy: 0.9560\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1250 - accuracy: 0.9622 - val_loss: 0.1486 - val_accuracy: 0.9580\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1215 - accuracy: 0.9643 - val_loss: 0.1454 - val_accuracy: 0.9570\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1199 - accuracy: 0.9643 - val_loss: 0.1439 - val_accuracy: 0.9570\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1158 - accuracy: 0.9663 - val_loss: 0.1433 - val_accuracy: 0.9570\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1133 - accuracy: 0.9678 - val_loss: 0.1425 - val_accuracy: 0.9570\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1104 - accuracy: 0.9688 - val_loss: 0.1432 - val_accuracy: 0.9600\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1094 - accuracy: 0.9697 - val_loss: 0.1408 - val_accuracy: 0.9590\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1069 - accuracy: 0.9693 - val_loss: 0.1381 - val_accuracy: 0.9590\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1044 - accuracy: 0.9710 - val_loss: 0.1379 - val_accuracy: 0.9600\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1023 - accuracy: 0.9720 - val_loss: 0.1379 - val_accuracy: 0.9600\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1007 - accuracy: 0.9718 - val_loss: 0.1365 - val_accuracy: 0.9630\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0989 - accuracy: 0.9725 - val_loss: 0.1363 - val_accuracy: 0.9610\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0981 - accuracy: 0.9720 - val_loss: 0.1359 - val_accuracy: 0.9620\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.1346 - val_accuracy: 0.9620\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0941 - accuracy: 0.9750 - val_loss: 0.1339 - val_accuracy: 0.9630\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0928 - accuracy: 0.9747 - val_loss: 0.1347 - val_accuracy: 0.9630\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0905 - accuracy: 0.9747 - val_loss: 0.1342 - val_accuracy: 0.9610\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0895 - accuracy: 0.9765 - val_loss: 0.1338 - val_accuracy: 0.9620\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0882 - accuracy: 0.9770 - val_loss: 0.1339 - val_accuracy: 0.9620\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0872 - accuracy: 0.9772 - val_loss: 0.1334 - val_accuracy: 0.9620\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0862 - accuracy: 0.9765 - val_loss: 0.1339 - val_accuracy: 0.9620\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0842 - accuracy: 0.9775 - val_loss: 0.1333 - val_accuracy: 0.9620\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0836 - accuracy: 0.9770 - val_loss: 0.1324 - val_accuracy: 0.9620\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0816 - accuracy: 0.9780 - val_loss: 0.1327 - val_accuracy: 0.9610\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0806 - accuracy: 0.9790 - val_loss: 0.1326 - val_accuracy: 0.9610\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0802 - accuracy: 0.9785 - val_loss: 0.1332 - val_accuracy: 0.9590\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0787 - accuracy: 0.9790 - val_loss: 0.1313 - val_accuracy: 0.9630\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0778 - accuracy: 0.9793 - val_loss: 0.1314 - val_accuracy: 0.9620\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0762 - accuracy: 0.9800 - val_loss: 0.1335 - val_accuracy: 0.9620\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0754 - accuracy: 0.9803 - val_loss: 0.1334 - val_accuracy: 0.9630\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0743 - accuracy: 0.9810 - val_loss: 0.1315 - val_accuracy: 0.9620\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0732 - accuracy: 0.9800 - val_loss: 0.1315 - val_accuracy: 0.9620\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0725 - accuracy: 0.9818 - val_loss: 0.1332 - val_accuracy: 0.9640\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0712 - accuracy: 0.9820 - val_loss: 0.1318 - val_accuracy: 0.9630\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0703 - accuracy: 0.9803 - val_loss: 0.1309 - val_accuracy: 0.9620\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0695 - accuracy: 0.9818 - val_loss: 0.1320 - val_accuracy: 0.9620\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0686 - accuracy: 0.9825 - val_loss: 0.1302 - val_accuracy: 0.9600\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0677 - accuracy: 0.9815 - val_loss: 0.1313 - val_accuracy: 0.9620\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0672 - accuracy: 0.9822 - val_loss: 0.1313 - val_accuracy: 0.9640\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0661 - accuracy: 0.9830 - val_loss: 0.1311 - val_accuracy: 0.9610\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0652 - accuracy: 0.9833 - val_loss: 0.1310 - val_accuracy: 0.9620\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0638 - accuracy: 0.9825 - val_loss: 0.1296 - val_accuracy: 0.9610\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0634 - accuracy: 0.9837 - val_loss: 0.1304 - val_accuracy: 0.9620\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0627 - accuracy: 0.9845 - val_loss: 0.1306 - val_accuracy: 0.9620\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0618 - accuracy: 0.9837 - val_loss: 0.1309 - val_accuracy: 0.9610\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0610 - accuracy: 0.9833 - val_loss: 0.1323 - val_accuracy: 0.9630\n",
      "Epoch 63/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0603 - accuracy: 0.9852 - val_loss: 0.1322 - val_accuracy: 0.9620\n",
      "Epoch 64/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0591 - accuracy: 0.9852 - val_loss: 0.1299 - val_accuracy: 0.9620\n",
      "Epoch 65/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0590 - accuracy: 0.9868 - val_loss: 0.1320 - val_accuracy: 0.9630\n",
      "Epoch 66/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0578 - accuracy: 0.9855 - val_loss: 0.1303 - val_accuracy: 0.9620\n",
      "Epoch 67/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0574 - accuracy: 0.9868 - val_loss: 0.1308 - val_accuracy: 0.9620\n",
      "Epoch 68/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0568 - accuracy: 0.9865 - val_loss: 0.1322 - val_accuracy: 0.9610\n",
      "Epoch 69/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0553 - accuracy: 0.9855 - val_loss: 0.1304 - val_accuracy: 0.9610\n",
      "Epoch 70/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0555 - accuracy: 0.9858 - val_loss: 0.1305 - val_accuracy: 0.9600\n",
      "Epoch 71/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0544 - accuracy: 0.9858 - val_loss: 0.1326 - val_accuracy: 0.9600\n",
      "Epoch 72/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0538 - accuracy: 0.9872 - val_loss: 0.1310 - val_accuracy: 0.9630\n",
      "Epoch 73/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0528 - accuracy: 0.9872 - val_loss: 0.1313 - val_accuracy: 0.9620\n",
      "Epoch 74/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0519 - accuracy: 0.9875 - val_loss: 0.1331 - val_accuracy: 0.9620\n",
      "Epoch 75/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0520 - accuracy: 0.9870 - val_loss: 0.1329 - val_accuracy: 0.9610\n",
      "Epoch 76/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.0508 - accuracy: 0.9875 - val_loss: 0.1335 - val_accuracy: 0.9620\n",
      "Epoch 77/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0501 - accuracy: 0.9883 - val_loss: 0.1332 - val_accuracy: 0.9610\n",
      "Epoch 78/1000\n",
      "4000/4000 [==============================] - 0s 66us/step - loss: 0.0494 - accuracy: 0.9880 - val_loss: 0.1341 - val_accuracy: 0.9610\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.70498412799365\n",
      "F1 Micro: 0.9567\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 268us/step - loss: 0.6162 - accuracy: 0.8367 - val_loss: 0.4194 - val_accuracy: 0.8730\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.3115 - accuracy: 0.9178 - val_loss: 0.3169 - val_accuracy: 0.9070\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.2624 - accuracy: 0.9287 - val_loss: 0.2679 - val_accuracy: 0.9280\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.2312 - accuracy: 0.9383 - val_loss: 0.2414 - val_accuracy: 0.9330\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.2104 - accuracy: 0.9417 - val_loss: 0.2298 - val_accuracy: 0.9330\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1948 - accuracy: 0.9467 - val_loss: 0.2145 - val_accuracy: 0.9380\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1847 - accuracy: 0.9477 - val_loss: 0.1990 - val_accuracy: 0.9400\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1740 - accuracy: 0.9507 - val_loss: 0.1906 - val_accuracy: 0.9450\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1680 - accuracy: 0.9523 - val_loss: 0.1862 - val_accuracy: 0.9460\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1610 - accuracy: 0.9532 - val_loss: 0.1770 - val_accuracy: 0.9490\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1551 - accuracy: 0.9550 - val_loss: 0.1764 - val_accuracy: 0.9450\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1473 - accuracy: 0.9575 - val_loss: 0.1670 - val_accuracy: 0.9490\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.1443 - accuracy: 0.9555 - val_loss: 0.1614 - val_accuracy: 0.9520\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1372 - accuracy: 0.9605 - val_loss: 0.1558 - val_accuracy: 0.9510\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 210us/step - loss: 0.1346 - accuracy: 0.9622 - val_loss: 0.1556 - val_accuracy: 0.9560\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.1287 - accuracy: 0.9628 - val_loss: 0.1521 - val_accuracy: 0.9500\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.1273 - accuracy: 0.9635 - val_loss: 0.1492 - val_accuracy: 0.9510\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 208us/step - loss: 0.1211 - accuracy: 0.9628 - val_loss: 0.1549 - val_accuracy: 0.9520\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1168 - accuracy: 0.9650 - val_loss: 0.1432 - val_accuracy: 0.9510\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.1160 - accuracy: 0.9668 - val_loss: 0.1434 - val_accuracy: 0.9530\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1131 - accuracy: 0.9688 - val_loss: 0.1400 - val_accuracy: 0.9560\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1072 - accuracy: 0.9675 - val_loss: 0.1433 - val_accuracy: 0.9550\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 207us/step - loss: 0.1040 - accuracy: 0.9700 - val_loss: 0.1386 - val_accuracy: 0.9540\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1010 - accuracy: 0.9712 - val_loss: 0.1371 - val_accuracy: 0.9570\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0976 - accuracy: 0.9725 - val_loss: 0.1392 - val_accuracy: 0.9570\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0944 - accuracy: 0.9735 - val_loss: 0.1392 - val_accuracy: 0.9570\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0913 - accuracy: 0.9728 - val_loss: 0.1440 - val_accuracy: 0.9560\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0887 - accuracy: 0.9760 - val_loss: 0.1324 - val_accuracy: 0.9560\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0814 - accuracy: 0.9775 - val_loss: 0.1366 - val_accuracy: 0.9570\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0783 - accuracy: 0.9775 - val_loss: 0.1351 - val_accuracy: 0.9600\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0765 - accuracy: 0.9795 - val_loss: 0.1430 - val_accuracy: 0.9580\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0718 - accuracy: 0.9805 - val_loss: 0.1345 - val_accuracy: 0.9580\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0633 - accuracy: 0.9822 - val_loss: 0.1410 - val_accuracy: 0.9560\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0582 - accuracy: 0.9835 - val_loss: 0.1344 - val_accuracy: 0.9560\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0529 - accuracy: 0.9877 - val_loss: 0.1559 - val_accuracy: 0.9580\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0458 - accuracy: 0.9893 - val_loss: 0.1355 - val_accuracy: 0.9520\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0418 - accuracy: 0.9912 - val_loss: 0.1392 - val_accuracy: 0.9570\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0386 - accuracy: 0.9915 - val_loss: 0.1664 - val_accuracy: 0.9580\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0335 - accuracy: 0.9927 - val_loss: 0.1662 - val_accuracy: 0.9560\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0311 - accuracy: 0.9942 - val_loss: 0.1483 - val_accuracy: 0.9590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0271 - accuracy: 0.9948 - val_loss: 0.1562 - val_accuracy: 0.9570\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0242 - accuracy: 0.9958 - val_loss: 0.1732 - val_accuracy: 0.9570\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0236 - accuracy: 0.9952 - val_loss: 0.1649 - val_accuracy: 0.9520\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.0208 - accuracy: 0.9962 - val_loss: 0.1676 - val_accuracy: 0.9560\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0172 - accuracy: 0.9977 - val_loss: 0.1809 - val_accuracy: 0.9550\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 206us/step - loss: 0.0152 - accuracy: 0.9985 - val_loss: 0.1693 - val_accuracy: 0.9530\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0134 - accuracy: 0.9995 - val_loss: 0.1752 - val_accuracy: 0.9530\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0120 - accuracy: 0.9992 - val_loss: 0.1706 - val_accuracy: 0.9540\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7243428813149348\n",
      "F1 Micro: 0.96\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7017012576366104\n",
      "F1 Micro: 0.9584\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7654427655221385\n",
      "F1 Micro: 0.9644\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 7 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.4121 - accuracy: 0.8998 - val_loss: 0.2079 - val_accuracy: 0.9388\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.1700 - accuracy: 0.9504 - val_loss: 0.1476 - val_accuracy: 0.9532\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.1354 - accuracy: 0.9590 - val_loss: 0.1442 - val_accuracy: 0.9564\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.1206 - accuracy: 0.9618 - val_loss: 0.1139 - val_accuracy: 0.9613\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.1094 - accuracy: 0.9665 - val_loss: 0.1125 - val_accuracy: 0.9636\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.1032 - accuracy: 0.9680 - val_loss: 0.1203 - val_accuracy: 0.9590\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0951 - accuracy: 0.9700 - val_loss: 0.1035 - val_accuracy: 0.9635\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0903 - accuracy: 0.9715 - val_loss: 0.1003 - val_accuracy: 0.9670\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0860 - accuracy: 0.9729 - val_loss: 0.1162 - val_accuracy: 0.9597\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0826 - accuracy: 0.9740 - val_loss: 0.0927 - val_accuracy: 0.9676\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0767 - accuracy: 0.9747 - val_loss: 0.0899 - val_accuracy: 0.9700\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0722 - accuracy: 0.9764 - val_loss: 0.0902 - val_accuracy: 0.9679\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0674 - accuracy: 0.9776 - val_loss: 0.0933 - val_accuracy: 0.9687\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0628 - accuracy: 0.9790 - val_loss: 0.1062 - val_accuracy: 0.9627\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0588 - accuracy: 0.9804 - val_loss: 0.1023 - val_accuracy: 0.9672\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0534 - accuracy: 0.9821 - val_loss: 0.0960 - val_accuracy: 0.9714\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0479 - accuracy: 0.9839 - val_loss: 0.0965 - val_accuracy: 0.9670\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0462 - accuracy: 0.9844 - val_loss: 0.1067 - val_accuracy: 0.9701\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0394 - accuracy: 0.9864 - val_loss: 0.0927 - val_accuracy: 0.9723\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0340 - accuracy: 0.9882 - val_loss: 0.0902 - val_accuracy: 0.9710\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 0.1114 - val_accuracy: 0.9660\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0248 - accuracy: 0.9920 - val_loss: 0.1227 - val_accuracy: 0.9713\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.1261 - val_accuracy: 0.9691\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.2144 - val_accuracy: 0.9622\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.1049 - val_accuracy: 0.9726\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1594 - val_accuracy: 0.9551\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.1253 - val_accuracy: 0.9724\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.1275 - val_accuracy: 0.9716\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.1271 - val_accuracy: 0.9709\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.1474 - val_accuracy: 0.9695\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.1377 - val_accuracy: 0.9706\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7867905884904882\n",
      "F1 Micro: 0.9699\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7876787599229346\n",
      "F1 Micro: 0.9656\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.5292 - accuracy: 0.8785 - val_loss: 0.1678 - val_accuracy: 0.9523\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1437 - accuracy: 0.9584 - val_loss: 0.1375 - val_accuracy: 0.9557\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1256 - accuracy: 0.9627 - val_loss: 0.1254 - val_accuracy: 0.9587\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1158 - accuracy: 0.9654 - val_loss: 0.1203 - val_accuracy: 0.9600\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1100 - accuracy: 0.9668 - val_loss: 0.1145 - val_accuracy: 0.9605\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.1051 - accuracy: 0.9682 - val_loss: 0.1138 - val_accuracy: 0.9615\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1015 - accuracy: 0.9693 - val_loss: 0.1091 - val_accuracy: 0.9628\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0986 - accuracy: 0.9698 - val_loss: 0.1068 - val_accuracy: 0.9634\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0961 - accuracy: 0.9710 - val_loss: 0.1050 - val_accuracy: 0.9640\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0939 - accuracy: 0.9713 - val_loss: 0.1043 - val_accuracy: 0.9643\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0920 - accuracy: 0.9717 - val_loss: 0.1023 - val_accuracy: 0.9650\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0904 - accuracy: 0.9720 - val_loss: 0.1019 - val_accuracy: 0.9654\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0887 - accuracy: 0.9724 - val_loss: 0.1008 - val_accuracy: 0.9660\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0872 - accuracy: 0.9736 - val_loss: 0.0994 - val_accuracy: 0.9659\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0861 - accuracy: 0.9735 - val_loss: 0.0992 - val_accuracy: 0.9674\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0843 - accuracy: 0.9742 - val_loss: 0.0977 - val_accuracy: 0.9672\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0833 - accuracy: 0.9744 - val_loss: 0.0975 - val_accuracy: 0.9665\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0818 - accuracy: 0.9747 - val_loss: 0.0958 - val_accuracy: 0.9678\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0808 - accuracy: 0.9749 - val_loss: 0.0985 - val_accuracy: 0.9671\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0800 - accuracy: 0.9752 - val_loss: 0.0956 - val_accuracy: 0.9684\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0789 - accuracy: 0.9759 - val_loss: 0.0942 - val_accuracy: 0.9674\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0775 - accuracy: 0.9760 - val_loss: 0.0953 - val_accuracy: 0.9675\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0767 - accuracy: 0.9761 - val_loss: 0.0947 - val_accuracy: 0.9680\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0757 - accuracy: 0.9768 - val_loss: 0.0945 - val_accuracy: 0.9674\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0748 - accuracy: 0.9764 - val_loss: 0.0938 - val_accuracy: 0.9677\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0738 - accuracy: 0.9771 - val_loss: 0.0936 - val_accuracy: 0.9679\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0731 - accuracy: 0.9776 - val_loss: 0.0931 - val_accuracy: 0.9678\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0723 - accuracy: 0.9782 - val_loss: 0.0940 - val_accuracy: 0.9688\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0710 - accuracy: 0.9783 - val_loss: 0.0935 - val_accuracy: 0.9682\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0707 - accuracy: 0.9783 - val_loss: 0.0918 - val_accuracy: 0.9686\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0697 - accuracy: 0.9787 - val_loss: 0.0924 - val_accuracy: 0.9681\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0692 - accuracy: 0.9784 - val_loss: 0.0923 - val_accuracy: 0.9683\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0681 - accuracy: 0.9793 - val_loss: 0.0907 - val_accuracy: 0.9699\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0675 - accuracy: 0.9793 - val_loss: 0.0922 - val_accuracy: 0.9690\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0666 - accuracy: 0.9798 - val_loss: 0.0924 - val_accuracy: 0.9682\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0657 - accuracy: 0.9801 - val_loss: 0.0914 - val_accuracy: 0.9688\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0652 - accuracy: 0.9801 - val_loss: 0.0906 - val_accuracy: 0.9694\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0644 - accuracy: 0.9807 - val_loss: 0.0909 - val_accuracy: 0.9697\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0638 - accuracy: 0.9804 - val_loss: 0.0938 - val_accuracy: 0.9696\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0628 - accuracy: 0.9809 - val_loss: 0.0916 - val_accuracy: 0.9694\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0625 - accuracy: 0.9809 - val_loss: 0.0921 - val_accuracy: 0.9692\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0615 - accuracy: 0.9816 - val_loss: 0.0915 - val_accuracy: 0.9697\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0609 - accuracy: 0.9820 - val_loss: 0.0911 - val_accuracy: 0.9695\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0600 - accuracy: 0.9823 - val_loss: 0.0918 - val_accuracy: 0.9688\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0598 - accuracy: 0.9825 - val_loss: 0.0909 - val_accuracy: 0.9709\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0588 - accuracy: 0.9824 - val_loss: 0.0912 - val_accuracy: 0.9704\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0584 - accuracy: 0.9825 - val_loss: 0.0921 - val_accuracy: 0.9698\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0575 - accuracy: 0.9829 - val_loss: 0.0933 - val_accuracy: 0.9699\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0571 - accuracy: 0.9832 - val_loss: 0.0906 - val_accuracy: 0.9698\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0564 - accuracy: 0.9836 - val_loss: 0.0915 - val_accuracy: 0.9693\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0557 - accuracy: 0.9839 - val_loss: 0.0905 - val_accuracy: 0.9695\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0552 - accuracy: 0.9839 - val_loss: 0.0902 - val_accuracy: 0.9707\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0545 - accuracy: 0.9840 - val_loss: 0.0910 - val_accuracy: 0.9701\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0539 - accuracy: 0.9844 - val_loss: 0.0924 - val_accuracy: 0.9696\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0534 - accuracy: 0.9843 - val_loss: 0.0911 - val_accuracy: 0.9696\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0526 - accuracy: 0.9845 - val_loss: 0.0910 - val_accuracy: 0.9715\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0521 - accuracy: 0.9848 - val_loss: 0.0916 - val_accuracy: 0.9700\n",
      "Epoch 58/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0516 - accuracy: 0.9852 - val_loss: 0.0911 - val_accuracy: 0.9708\n",
      "Epoch 59/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0510 - accuracy: 0.9857 - val_loss: 0.0931 - val_accuracy: 0.9689\n",
      "Epoch 60/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0502 - accuracy: 0.9856 - val_loss: 0.0927 - val_accuracy: 0.9701\n",
      "Epoch 61/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0496 - accuracy: 0.9856 - val_loss: 0.0933 - val_accuracy: 0.9701\n",
      "Epoch 62/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0494 - accuracy: 0.9859 - val_loss: 0.0921 - val_accuracy: 0.9701\n",
      "Epoch 63/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0487 - accuracy: 0.9860 - val_loss: 0.0924 - val_accuracy: 0.9705\n",
      "Epoch 64/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0481 - accuracy: 0.9860 - val_loss: 0.0933 - val_accuracy: 0.9701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0476 - accuracy: 0.9861 - val_loss: 0.0925 - val_accuracy: 0.9698\n",
      "Epoch 66/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0467 - accuracy: 0.9866 - val_loss: 0.0930 - val_accuracy: 0.9696\n",
      "Epoch 67/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0463 - accuracy: 0.9868 - val_loss: 0.0946 - val_accuracy: 0.9694\n",
      "Epoch 68/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0457 - accuracy: 0.9869 - val_loss: 0.0949 - val_accuracy: 0.9694\n",
      "Epoch 69/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0450 - accuracy: 0.9871 - val_loss: 0.0927 - val_accuracy: 0.9692\n",
      "Epoch 70/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0447 - accuracy: 0.9869 - val_loss: 0.0953 - val_accuracy: 0.9701\n",
      "Epoch 71/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0441 - accuracy: 0.9872 - val_loss: 0.0946 - val_accuracy: 0.9692\n",
      "Epoch 72/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0435 - accuracy: 0.9871 - val_loss: 0.0945 - val_accuracy: 0.9701\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.861016348116163\n",
      "F1 Micro: 0.9713\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 210us/step - loss: 0.2624 - accuracy: 0.9287 - val_loss: 0.1715 - val_accuracy: 0.9451\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.1439 - accuracy: 0.9560 - val_loss: 0.1337 - val_accuracy: 0.9602\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.1229 - accuracy: 0.9618 - val_loss: 0.1210 - val_accuracy: 0.9621\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.1111 - accuracy: 0.9662 - val_loss: 0.1129 - val_accuracy: 0.9624\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.1028 - accuracy: 0.9678 - val_loss: 0.1099 - val_accuracy: 0.9625\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0960 - accuracy: 0.9697 - val_loss: 0.0970 - val_accuracy: 0.9676\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0887 - accuracy: 0.9714 - val_loss: 0.0911 - val_accuracy: 0.9699\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0832 - accuracy: 0.9733 - val_loss: 0.0972 - val_accuracy: 0.9671\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0772 - accuracy: 0.9758 - val_loss: 0.0862 - val_accuracy: 0.9704\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0713 - accuracy: 0.9772 - val_loss: 0.0847 - val_accuracy: 0.9705\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0667 - accuracy: 0.9783 - val_loss: 0.0841 - val_accuracy: 0.9727\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0616 - accuracy: 0.9797 - val_loss: 0.0847 - val_accuracy: 0.9707\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0562 - accuracy: 0.9818 - val_loss: 0.0890 - val_accuracy: 0.9717\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0507 - accuracy: 0.9830 - val_loss: 0.0974 - val_accuracy: 0.9679\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0444 - accuracy: 0.9855 - val_loss: 0.0865 - val_accuracy: 0.9708\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0373 - accuracy: 0.9879 - val_loss: 0.0941 - val_accuracy: 0.9716\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0305 - accuracy: 0.9904 - val_loss: 0.0957 - val_accuracy: 0.9711\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.1039 - val_accuracy: 0.9702\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.1092 - val_accuracy: 0.9708\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.1141 - val_accuracy: 0.9717\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 0.1215 - val_accuracy: 0.9702\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.1330 - val_accuracy: 0.9715\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.1398 - val_accuracy: 0.9688\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1335 - val_accuracy: 0.9676\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.1361 - val_accuracy: 0.9707\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.1463 - val_accuracy: 0.9709\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.1476 - val_accuracy: 0.9699\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.1470 - val_accuracy: 0.9686\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.1541 - val_accuracy: 0.9676\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.1416 - val_accuracy: 0.9717\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1452 - val_accuracy: 0.9712\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8470275887586397\n",
      "F1 Micro: 0.9729\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7928340495070895\n",
      "F1 Micro: 0.9642\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8781063964325853\n",
      "F1 Micro: 0.9759\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 7 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.2240 - accuracy: 0.9385 - val_loss: 0.1194 - val_accuracy: 0.9639\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.1158 - accuracy: 0.9636 - val_loss: 0.1174 - val_accuracy: 0.9627\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.1006 - accuracy: 0.9669 - val_loss: 0.0911 - val_accuracy: 0.9708\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0907 - accuracy: 0.9704 - val_loss: 0.0805 - val_accuracy: 0.9733\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0816 - accuracy: 0.9734 - val_loss: 0.0829 - val_accuracy: 0.9713\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0737 - accuracy: 0.9747 - val_loss: 0.0779 - val_accuracy: 0.9739\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0666 - accuracy: 0.9769 - val_loss: 0.0660 - val_accuracy: 0.9774\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0616 - accuracy: 0.9785 - val_loss: 0.0717 - val_accuracy: 0.9748\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0568 - accuracy: 0.9801 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0524 - accuracy: 0.9813 - val_loss: 0.0681 - val_accuracy: 0.9775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0483 - accuracy: 0.9827 - val_loss: 0.0647 - val_accuracy: 0.9788\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0436 - accuracy: 0.9845 - val_loss: 0.0702 - val_accuracy: 0.9778\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0399 - accuracy: 0.9854 - val_loss: 0.0658 - val_accuracy: 0.9783\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0359 - accuracy: 0.9870 - val_loss: 0.0657 - val_accuracy: 0.9786\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0312 - accuracy: 0.9888 - val_loss: 0.0671 - val_accuracy: 0.9781\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0266 - accuracy: 0.9903 - val_loss: 0.0789 - val_accuracy: 0.9758\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0229 - accuracy: 0.9918 - val_loss: 0.0760 - val_accuracy: 0.9789\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0191 - accuracy: 0.9930 - val_loss: 0.0852 - val_accuracy: 0.9751\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0154 - accuracy: 0.9944 - val_loss: 0.0866 - val_accuracy: 0.9789\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.1125 - val_accuracy: 0.9752\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0876 - val_accuracy: 0.9774\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 27s 207us/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.1039 - val_accuracy: 0.9770\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.1008 - val_accuracy: 0.9768\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.1070 - val_accuracy: 0.9789\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.1109 - val_accuracy: 0.9774\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.1163 - val_accuracy: 0.9785\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.1202 - val_accuracy: 0.9764\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.1303 - val_accuracy: 0.9737\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 27s 203us/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.1236 - val_accuracy: 0.9764\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.1668 - val_accuracy: 0.9754\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.1424 - val_accuracy: 0.9714\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8882572601274555\n",
      "F1 Micro: 0.9794\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8145619983098975\n",
      "F1 Micro: 0.9692\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.2502 - accuracy: 0.9357 - val_loss: 0.1192 - val_accuracy: 0.9634\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.1136 - accuracy: 0.9645 - val_loss: 0.1055 - val_accuracy: 0.9682\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.1039 - accuracy: 0.9674 - val_loss: 0.0991 - val_accuracy: 0.9691\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 68us/step - loss: 0.0981 - accuracy: 0.9690 - val_loss: 0.0950 - val_accuracy: 0.9711\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0945 - accuracy: 0.9702 - val_loss: 0.0950 - val_accuracy: 0.9706\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0915 - accuracy: 0.9710 - val_loss: 0.0912 - val_accuracy: 0.9716\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0891 - accuracy: 0.9715 - val_loss: 0.0890 - val_accuracy: 0.9718\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0872 - accuracy: 0.9722 - val_loss: 0.0882 - val_accuracy: 0.9720\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0854 - accuracy: 0.9727 - val_loss: 0.0866 - val_accuracy: 0.9719\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0838 - accuracy: 0.9729 - val_loss: 0.0869 - val_accuracy: 0.9722\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0823 - accuracy: 0.9736 - val_loss: 0.0851 - val_accuracy: 0.9727\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0809 - accuracy: 0.9740 - val_loss: 0.0841 - val_accuracy: 0.9728\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0796 - accuracy: 0.9744 - val_loss: 0.0853 - val_accuracy: 0.9723\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0787 - accuracy: 0.9748 - val_loss: 0.0841 - val_accuracy: 0.9721\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0775 - accuracy: 0.9748 - val_loss: 0.0824 - val_accuracy: 0.9739\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0766 - accuracy: 0.9751 - val_loss: 0.0825 - val_accuracy: 0.9734\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0754 - accuracy: 0.9755 - val_loss: 0.0839 - val_accuracy: 0.9728\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0746 - accuracy: 0.9757 - val_loss: 0.0815 - val_accuracy: 0.9733\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0737 - accuracy: 0.9763 - val_loss: 0.0807 - val_accuracy: 0.9736\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0729 - accuracy: 0.9763 - val_loss: 0.0805 - val_accuracy: 0.9738\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0721 - accuracy: 0.9765 - val_loss: 0.0810 - val_accuracy: 0.9730\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0714 - accuracy: 0.9767 - val_loss: 0.0800 - val_accuracy: 0.9736\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0705 - accuracy: 0.9772 - val_loss: 0.0795 - val_accuracy: 0.9740\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0698 - accuracy: 0.9772 - val_loss: 0.0806 - val_accuracy: 0.9735\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0691 - accuracy: 0.9776 - val_loss: 0.0796 - val_accuracy: 0.9739\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0684 - accuracy: 0.9779 - val_loss: 0.0792 - val_accuracy: 0.9741\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0678 - accuracy: 0.9780 - val_loss: 0.0802 - val_accuracy: 0.9736\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0670 - accuracy: 0.9786 - val_loss: 0.0790 - val_accuracy: 0.9741\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0663 - accuracy: 0.9786 - val_loss: 0.0792 - val_accuracy: 0.9745\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0657 - accuracy: 0.9787 - val_loss: 0.0784 - val_accuracy: 0.9746\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0651 - accuracy: 0.9790 - val_loss: 0.0778 - val_accuracy: 0.9746\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0644 - accuracy: 0.9790 - val_loss: 0.0789 - val_accuracy: 0.9745\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0639 - accuracy: 0.9793 - val_loss: 0.0782 - val_accuracy: 0.9747\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0632 - accuracy: 0.9797 - val_loss: 0.0808 - val_accuracy: 0.9738\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0627 - accuracy: 0.9797 - val_loss: 0.0780 - val_accuracy: 0.9747\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0620 - accuracy: 0.9800 - val_loss: 0.0803 - val_accuracy: 0.9743\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0614 - accuracy: 0.9803 - val_loss: 0.0781 - val_accuracy: 0.9746\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0608 - accuracy: 0.9803 - val_loss: 0.0790 - val_accuracy: 0.9742\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0603 - accuracy: 0.9807 - val_loss: 0.0782 - val_accuracy: 0.9749\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0596 - accuracy: 0.9807 - val_loss: 0.0785 - val_accuracy: 0.9744\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0592 - accuracy: 0.9808 - val_loss: 0.0784 - val_accuracy: 0.9748\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0586 - accuracy: 0.9812 - val_loss: 0.0794 - val_accuracy: 0.9742\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0582 - accuracy: 0.9808 - val_loss: 0.0791 - val_accuracy: 0.9744\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0573 - accuracy: 0.9814 - val_loss: 0.0789 - val_accuracy: 0.9746\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0570 - accuracy: 0.9815 - val_loss: 0.0783 - val_accuracy: 0.9748\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0562 - accuracy: 0.9817 - val_loss: 0.0795 - val_accuracy: 0.9748\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0558 - accuracy: 0.9820 - val_loss: 0.0801 - val_accuracy: 0.9740\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 0.0806 - val_accuracy: 0.9741\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0547 - accuracy: 0.9823 - val_loss: 0.0795 - val_accuracy: 0.9747\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0542 - accuracy: 0.9824 - val_loss: 0.0803 - val_accuracy: 0.9742\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0536 - accuracy: 0.9827 - val_loss: 0.0798 - val_accuracy: 0.9749\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8798756042105188\n",
      "F1 Micro: 0.9762999999999998\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.1702 - accuracy: 0.9500 - val_loss: 0.1141 - val_accuracy: 0.9643\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.1081 - accuracy: 0.9656 - val_loss: 0.1004 - val_accuracy: 0.9697\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.0912 - accuracy: 0.9704 - val_loss: 0.0893 - val_accuracy: 0.9722\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0820 - accuracy: 0.9727 - val_loss: 0.0817 - val_accuracy: 0.9734\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.0754 - accuracy: 0.9750 - val_loss: 0.0742 - val_accuracy: 0.9755\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0697 - accuracy: 0.9766 - val_loss: 0.0757 - val_accuracy: 0.9752\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0646 - accuracy: 0.9783 - val_loss: 0.0679 - val_accuracy: 0.9774\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0597 - accuracy: 0.9799 - val_loss: 0.0703 - val_accuracy: 0.9774\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0545 - accuracy: 0.9816 - val_loss: 0.0700 - val_accuracy: 0.9762\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0489 - accuracy: 0.9836 - val_loss: 0.0645 - val_accuracy: 0.9791\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0431 - accuracy: 0.9850 - val_loss: 0.0696 - val_accuracy: 0.9778\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0365 - accuracy: 0.9876 - val_loss: 0.0726 - val_accuracy: 0.9781\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.0745 - val_accuracy: 0.9782\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.0751 - val_accuracy: 0.9786\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 27s 203us/step - loss: 0.0183 - accuracy: 0.9938 - val_loss: 0.0804 - val_accuracy: 0.9794\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0872 - val_accuracy: 0.9782\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0990 - val_accuracy: 0.9776\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1072 - val_accuracy: 0.9756\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.1074 - val_accuracy: 0.9780\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.1173 - val_accuracy: 0.9764\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.1204 - val_accuracy: 0.9769\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.1156 - val_accuracy: 0.9759\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1244 - val_accuracy: 0.9772\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1246 - val_accuracy: 0.9767\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1311 - val_accuracy: 0.9780\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.1338 - val_accuracy: 0.9772\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1290 - val_accuracy: 0.9778\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.1369 - val_accuracy: 0.9770\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.1378 - val_accuracy: 0.9767\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.1395 - val_accuracy: 0.9769\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8973169162833445\n",
      "F1 Micro: 0.9782\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8222804555778312\n",
      "F1 Micro: 0.9687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.9053395272420968\n",
      "F1 Micro: 0.9807\n",
      "\n",
      "\n",
      " 53.830908783276875 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 8 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 8 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 6, 8]\n",
      "label_list [0, 1, 2, 3, 4, 6, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 768us/step - loss: 1.9412 - accuracy: 0.7175 - val_loss: 1.4961 - val_accuracy: 0.8300\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 1.0845 - accuracy: 0.8400 - val_loss: 0.8363 - val_accuracy: 0.8300\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.7938 - accuracy: 0.8400 - val_loss: 0.7789 - val_accuracy: 0.8300\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.7382 - accuracy: 0.8400 - val_loss: 0.7347 - val_accuracy: 0.8300\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.7142 - accuracy: 0.8400 - val_loss: 0.7209 - val_accuracy: 0.8300\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.7044 - accuracy: 0.8400 - val_loss: 0.7119 - val_accuracy: 0.8300\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6915 - accuracy: 0.8400 - val_loss: 0.7033 - val_accuracy: 0.8300\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.6826 - accuracy: 0.8400 - val_loss: 0.6976 - val_accuracy: 0.8300\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.6781 - accuracy: 0.8400 - val_loss: 0.6912 - val_accuracy: 0.8300\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.6706 - accuracy: 0.8400 - val_loss: 0.6875 - val_accuracy: 0.8300\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.6691 - accuracy: 0.8400 - val_loss: 0.6840 - val_accuracy: 0.8300\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.6664 - accuracy: 0.8400 - val_loss: 0.6767 - val_accuracy: 0.8300\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.6624 - accuracy: 0.8400 - val_loss: 0.6716 - val_accuracy: 0.8300\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.6506 - accuracy: 0.8400 - val_loss: 0.6668 - val_accuracy: 0.8300\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.6465 - accuracy: 0.8400 - val_loss: 0.6633 - val_accuracy: 0.8300\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.6441 - accuracy: 0.8400 - val_loss: 0.6523 - val_accuracy: 0.8300\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.6424 - accuracy: 0.8400 - val_loss: 0.6569 - val_accuracy: 0.8300\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.6420 - accuracy: 0.8400 - val_loss: 0.6475 - val_accuracy: 0.8300\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.6178 - accuracy: 0.8400 - val_loss: 0.6299 - val_accuracy: 0.8300\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.6130 - accuracy: 0.8400 - val_loss: 0.6191 - val_accuracy: 0.8300\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.6040 - accuracy: 0.8400 - val_loss: 0.6119 - val_accuracy: 0.8300\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.5861 - accuracy: 0.8400 - val_loss: 0.5878 - val_accuracy: 0.8300\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.5676 - accuracy: 0.8400 - val_loss: 0.5752 - val_accuracy: 0.8300\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.5567 - accuracy: 0.8400 - val_loss: 0.5549 - val_accuracy: 0.8500\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.5474 - accuracy: 0.8500 - val_loss: 0.5599 - val_accuracy: 0.8300\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.5957 - accuracy: 0.8500 - val_loss: 0.5398 - val_accuracy: 0.8300\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.5171 - accuracy: 0.8675 - val_loss: 0.5130 - val_accuracy: 0.8300\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.4919 - accuracy: 0.8625 - val_loss: 0.4930 - val_accuracy: 0.8800\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.4751 - accuracy: 0.8800 - val_loss: 0.4743 - val_accuracy: 0.8900\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.4532 - accuracy: 0.8825 - val_loss: 0.4622 - val_accuracy: 0.8900\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.4474 - accuracy: 0.8900 - val_loss: 0.4633 - val_accuracy: 0.8800\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.4639 - accuracy: 0.8775 - val_loss: 0.4428 - val_accuracy: 0.8900\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.4242 - accuracy: 0.8900 - val_loss: 0.4388 - val_accuracy: 0.9000\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.4043 - accuracy: 0.8900 - val_loss: 0.4422 - val_accuracy: 0.8900\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.3915 - accuracy: 0.8875 - val_loss: 0.4558 - val_accuracy: 0.8900\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.3917 - accuracy: 0.8875 - val_loss: 0.4346 - val_accuracy: 0.8900\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.3686 - accuracy: 0.8900 - val_loss: 0.4114 - val_accuracy: 0.8800\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.3613 - accuracy: 0.8975 - val_loss: 0.4115 - val_accuracy: 0.8900\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.3533 - accuracy: 0.9000 - val_loss: 0.4611 - val_accuracy: 0.8900\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.3408 - accuracy: 0.9000 - val_loss: 0.4114 - val_accuracy: 0.8900\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.3272 - accuracy: 0.9050 - val_loss: 0.4004 - val_accuracy: 0.8800\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.3329 - accuracy: 0.9050 - val_loss: 0.4009 - val_accuracy: 0.9000\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.3369 - accuracy: 0.9075 - val_loss: 0.4028 - val_accuracy: 0.8900\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.3255 - accuracy: 0.9075 - val_loss: 0.4014 - val_accuracy: 0.8900\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.3120 - accuracy: 0.9175 - val_loss: 0.3785 - val_accuracy: 0.8900\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.3123 - accuracy: 0.9075 - val_loss: 0.3741 - val_accuracy: 0.8900\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.2909 - accuracy: 0.9125 - val_loss: 0.3903 - val_accuracy: 0.8900\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.2827 - accuracy: 0.9050 - val_loss: 0.3712 - val_accuracy: 0.8900\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.2901 - accuracy: 0.9200 - val_loss: 0.4033 - val_accuracy: 0.8700\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2693 - accuracy: 0.9150 - val_loss: 0.3651 - val_accuracy: 0.8900\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2556 - accuracy: 0.9175 - val_loss: 0.3558 - val_accuracy: 0.8800\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2498 - accuracy: 0.9250 - val_loss: 0.3689 - val_accuracy: 0.8900\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.2345 - accuracy: 0.9300 - val_loss: 0.3474 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2330 - accuracy: 0.9400 - val_loss: 0.3736 - val_accuracy: 0.8900\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2753 - accuracy: 0.9150 - val_loss: 0.3419 - val_accuracy: 0.8800\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2383 - accuracy: 0.9425 - val_loss: 0.3458 - val_accuracy: 0.8800\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2137 - accuracy: 0.9400 - val_loss: 0.3404 - val_accuracy: 0.8800\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2119 - accuracy: 0.9475 - val_loss: 0.3555 - val_accuracy: 0.8800\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.2211 - accuracy: 0.9325 - val_loss: 0.3473 - val_accuracy: 0.8900\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2551 - accuracy: 0.9225 - val_loss: 0.4055 - val_accuracy: 0.8800\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.2213 - accuracy: 0.9325 - val_loss: 0.3366 - val_accuracy: 0.9000\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1970 - accuracy: 0.9450 - val_loss: 0.3475 - val_accuracy: 0.8800\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.1946 - accuracy: 0.9425 - val_loss: 0.3306 - val_accuracy: 0.9000\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1854 - accuracy: 0.9500 - val_loss: 0.3203 - val_accuracy: 0.8900\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.1788 - accuracy: 0.9550 - val_loss: 0.3364 - val_accuracy: 0.8900\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1833 - accuracy: 0.9375 - val_loss: 0.3282 - val_accuracy: 0.9100\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1923 - accuracy: 0.9500 - val_loss: 0.3506 - val_accuracy: 0.9000\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1839 - accuracy: 0.9550 - val_loss: 0.3416 - val_accuracy: 0.9000\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.1719 - accuracy: 0.9500 - val_loss: 0.3196 - val_accuracy: 0.9200\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.1870 - accuracy: 0.9425 - val_loss: 0.3366 - val_accuracy: 0.9000\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1874 - accuracy: 0.9450 - val_loss: 0.3623 - val_accuracy: 0.9200\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1690 - accuracy: 0.9600 - val_loss: 0.3126 - val_accuracy: 0.9000\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1562 - accuracy: 0.9600 - val_loss: 0.3639 - val_accuracy: 0.9000\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1676 - accuracy: 0.9525 - val_loss: 0.3131 - val_accuracy: 0.9100\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1572 - accuracy: 0.9650 - val_loss: 0.3268 - val_accuracy: 0.9100\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1483 - accuracy: 0.9625 - val_loss: 0.3124 - val_accuracy: 0.9200\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.1459 - accuracy: 0.9600 - val_loss: 0.3144 - val_accuracy: 0.9200\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.1406 - accuracy: 0.9650 - val_loss: 0.3394 - val_accuracy: 0.9000\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1352 - accuracy: 0.9575 - val_loss: 0.3111 - val_accuracy: 0.9000\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.1356 - accuracy: 0.9675 - val_loss: 0.3889 - val_accuracy: 0.9000\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1742 - accuracy: 0.9500 - val_loss: 0.3101 - val_accuracy: 0.9000\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1361 - accuracy: 0.9625 - val_loss: 0.3711 - val_accuracy: 0.9000\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1470 - accuracy: 0.9625 - val_loss: 0.3379 - val_accuracy: 0.9000\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.1619 - accuracy: 0.9325 - val_loss: 0.3190 - val_accuracy: 0.9300\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1596 - accuracy: 0.9475 - val_loss: 0.3205 - val_accuracy: 0.9300\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.1322 - accuracy: 0.9675 - val_loss: 0.3349 - val_accuracy: 0.9200\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.1290 - accuracy: 0.9600 - val_loss: 0.3047 - val_accuracy: 0.9200\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1255 - accuracy: 0.9675 - val_loss: 0.3341 - val_accuracy: 0.9100\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1199 - accuracy: 0.9675 - val_loss: 0.3342 - val_accuracy: 0.9200\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.1601 - accuracy: 0.9550 - val_loss: 0.3241 - val_accuracy: 0.9300\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.1398 - accuracy: 0.9575 - val_loss: 0.3601 - val_accuracy: 0.9000\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.1101 - accuracy: 0.9650 - val_loss: 0.3050 - val_accuracy: 0.9300\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1062 - accuracy: 0.9725 - val_loss: 0.3395 - val_accuracy: 0.9100\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1032 - accuracy: 0.9725 - val_loss: 0.3296 - val_accuracy: 0.9100\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0983 - accuracy: 0.9775 - val_loss: 0.3520 - val_accuracy: 0.9100\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.1034 - accuracy: 0.9750 - val_loss: 0.3421 - val_accuracy: 0.9200\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1065 - accuracy: 0.9725 - val_loss: 0.3125 - val_accuracy: 0.9300\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1019 - accuracy: 0.9700 - val_loss: 0.3366 - val_accuracy: 0.9100\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.0883 - accuracy: 0.9825 - val_loss: 0.3210 - val_accuracy: 0.9300\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0862 - accuracy: 0.9750 - val_loss: 0.3635 - val_accuracy: 0.9000\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0897 - accuracy: 0.9750 - val_loss: 0.3162 - val_accuracy: 0.9100\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0895 - accuracy: 0.9800 - val_loss: 0.3670 - val_accuracy: 0.9100\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0855 - accuracy: 0.9750 - val_loss: 0.3239 - val_accuracy: 0.9200\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0864 - accuracy: 0.9700 - val_loss: 0.3403 - val_accuracy: 0.9300\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0820 - accuracy: 0.9875 - val_loss: 0.3182 - val_accuracy: 0.9200\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0750 - accuracy: 0.9800 - val_loss: 0.3633 - val_accuracy: 0.9100\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0732 - accuracy: 0.9850 - val_loss: 0.3603 - val_accuracy: 0.9100\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.4648030571594048\n",
      "F1 Micro: 0.9271350483927586\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.47826521488272117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Micro: 0.9367634521839426\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 287us/step - loss: 2.2971 - accuracy: 0.0925 - val_loss: 2.1958 - val_accuracy: 0.2600\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 2.0716 - accuracy: 0.3575 - val_loss: 2.0482 - val_accuracy: 0.4500\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 1.9074 - accuracy: 0.4975 - val_loss: 1.9465 - val_accuracy: 0.5200\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 1.7848 - accuracy: 0.5475 - val_loss: 1.8742 - val_accuracy: 0.5700\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.6912 - accuracy: 0.5700 - val_loss: 1.8148 - val_accuracy: 0.5800\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.6124 - accuracy: 0.5950 - val_loss: 1.7630 - val_accuracy: 0.5900\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.5401 - accuracy: 0.6300 - val_loss: 1.7121 - val_accuracy: 0.6200\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.4740 - accuracy: 0.6500 - val_loss: 1.6613 - val_accuracy: 0.6300\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.4057 - accuracy: 0.6625 - val_loss: 1.6125 - val_accuracy: 0.6500\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.3426 - accuracy: 0.6825 - val_loss: 1.5585 - val_accuracy: 0.6700\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.2766 - accuracy: 0.7025 - val_loss: 1.5094 - val_accuracy: 0.6800\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.2117 - accuracy: 0.7275 - val_loss: 1.4552 - val_accuracy: 0.6800\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.1507 - accuracy: 0.7425 - val_loss: 1.3972 - val_accuracy: 0.7100\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.0859 - accuracy: 0.7675 - val_loss: 1.3462 - val_accuracy: 0.7100\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.0252 - accuracy: 0.7875 - val_loss: 1.3008 - val_accuracy: 0.7200\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.9659 - accuracy: 0.8100 - val_loss: 1.2463 - val_accuracy: 0.7500\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.9082 - accuracy: 0.8275 - val_loss: 1.1949 - val_accuracy: 0.7600\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.8524 - accuracy: 0.8575 - val_loss: 1.1470 - val_accuracy: 0.7700\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.8003 - accuracy: 0.8750 - val_loss: 1.0986 - val_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.7511 - accuracy: 0.8825 - val_loss: 1.0547 - val_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.7042 - accuracy: 0.9075 - val_loss: 1.0179 - val_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.6620 - accuracy: 0.9100 - val_loss: 0.9721 - val_accuracy: 0.8100\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.6205 - accuracy: 0.9175 - val_loss: 0.9378 - val_accuracy: 0.8200\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.5833 - accuracy: 0.9200 - val_loss: 0.9092 - val_accuracy: 0.8300\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.5483 - accuracy: 0.9200 - val_loss: 0.8770 - val_accuracy: 0.8400\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.5156 - accuracy: 0.9225 - val_loss: 0.8452 - val_accuracy: 0.8400\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.4861 - accuracy: 0.9275 - val_loss: 0.8160 - val_accuracy: 0.8400\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.4585 - accuracy: 0.9300 - val_loss: 0.7914 - val_accuracy: 0.8600\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.4329 - accuracy: 0.9300 - val_loss: 0.7581 - val_accuracy: 0.8600\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.4087 - accuracy: 0.9350 - val_loss: 0.7384 - val_accuracy: 0.8700\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 88us/step - loss: 0.3861 - accuracy: 0.9375 - val_loss: 0.7233 - val_accuracy: 0.8700\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.3666 - accuracy: 0.9425 - val_loss: 0.7025 - val_accuracy: 0.8700\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.3475 - accuracy: 0.9500 - val_loss: 0.6853 - val_accuracy: 0.8700\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.3307 - accuracy: 0.9525 - val_loss: 0.6605 - val_accuracy: 0.8700\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.3143 - accuracy: 0.9525 - val_loss: 0.6490 - val_accuracy: 0.8800\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.3000 - accuracy: 0.9550 - val_loss: 0.6326 - val_accuracy: 0.8800\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.2864 - accuracy: 0.9550 - val_loss: 0.6239 - val_accuracy: 0.8700\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.2730 - accuracy: 0.9550 - val_loss: 0.6170 - val_accuracy: 0.8700\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.2613 - accuracy: 0.9550 - val_loss: 0.6084 - val_accuracy: 0.8800\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2504 - accuracy: 0.9550 - val_loss: 0.5955 - val_accuracy: 0.8700\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2397 - accuracy: 0.9550 - val_loss: 0.5871 - val_accuracy: 0.8700\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2303 - accuracy: 0.9525 - val_loss: 0.5815 - val_accuracy: 0.8700\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.2210 - accuracy: 0.9550 - val_loss: 0.5758 - val_accuracy: 0.8700\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.2128 - accuracy: 0.9550 - val_loss: 0.5589 - val_accuracy: 0.8700\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.2050 - accuracy: 0.9600 - val_loss: 0.5587 - val_accuracy: 0.8700\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1976 - accuracy: 0.9625 - val_loss: 0.5463 - val_accuracy: 0.8700\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1896 - accuracy: 0.9675 - val_loss: 0.5418 - val_accuracy: 0.8700\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1831 - accuracy: 0.9675 - val_loss: 0.5404 - val_accuracy: 0.8700\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.1769 - accuracy: 0.9675 - val_loss: 0.5369 - val_accuracy: 0.8700\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1713 - accuracy: 0.9700 - val_loss: 0.5220 - val_accuracy: 0.8800\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1650 - accuracy: 0.9725 - val_loss: 0.5262 - val_accuracy: 0.8700\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.1595 - accuracy: 0.9725 - val_loss: 0.5202 - val_accuracy: 0.8800\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.1545 - accuracy: 0.9725 - val_loss: 0.5208 - val_accuracy: 0.8800\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1494 - accuracy: 0.9750 - val_loss: 0.5193 - val_accuracy: 0.8800\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1451 - accuracy: 0.9750 - val_loss: 0.5101 - val_accuracy: 0.8800\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.1405 - accuracy: 0.9750 - val_loss: 0.5130 - val_accuracy: 0.8800\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1365 - accuracy: 0.9750 - val_loss: 0.5129 - val_accuracy: 0.8800\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1324 - accuracy: 0.9775 - val_loss: 0.5065 - val_accuracy: 0.8800\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.1293 - accuracy: 0.9800 - val_loss: 0.4918 - val_accuracy: 0.8800\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.1251 - accuracy: 0.9800 - val_loss: 0.4949 - val_accuracy: 0.8800\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1216 - accuracy: 0.9800 - val_loss: 0.5026 - val_accuracy: 0.8800\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1182 - accuracy: 0.9800 - val_loss: 0.4961 - val_accuracy: 0.8800\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.1149 - accuracy: 0.9800 - val_loss: 0.4982 - val_accuracy: 0.8800\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1121 - accuracy: 0.9800 - val_loss: 0.4943 - val_accuracy: 0.8800\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1090 - accuracy: 0.9850 - val_loss: 0.4893 - val_accuracy: 0.8800\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1061 - accuracy: 0.9850 - val_loss: 0.4847 - val_accuracy: 0.8800\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.1034 - accuracy: 0.9850 - val_loss: 0.4886 - val_accuracy: 0.8800\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.1008 - accuracy: 0.9850 - val_loss: 0.4864 - val_accuracy: 0.8800\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0984 - accuracy: 0.9850 - val_loss: 0.4902 - val_accuracy: 0.8800\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0960 - accuracy: 0.9850 - val_loss: 0.4877 - val_accuracy: 0.8800\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.0934 - accuracy: 0.9850 - val_loss: 0.4869 - val_accuracy: 0.8800\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0917 - accuracy: 0.9850 - val_loss: 0.4716 - val_accuracy: 0.8800\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0891 - accuracy: 0.9850 - val_loss: 0.4777 - val_accuracy: 0.8800\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0872 - accuracy: 0.9850 - val_loss: 0.4806 - val_accuracy: 0.8800\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.0849 - accuracy: 0.9850 - val_loss: 0.4846 - val_accuracy: 0.8800\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0830 - accuracy: 0.9850 - val_loss: 0.4849 - val_accuracy: 0.8800\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0809 - accuracy: 0.9850 - val_loss: 0.4861 - val_accuracy: 0.8800\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0793 - accuracy: 0.9850 - val_loss: 0.4808 - val_accuracy: 0.8800\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0774 - accuracy: 0.9850 - val_loss: 0.4811 - val_accuracy: 0.8800\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0756 - accuracy: 0.9850 - val_loss: 0.4894 - val_accuracy: 0.8800\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0739 - accuracy: 0.9900 - val_loss: 0.4892 - val_accuracy: 0.8800\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0724 - accuracy: 0.9875 - val_loss: 0.4846 - val_accuracy: 0.8800\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0707 - accuracy: 0.9875 - val_loss: 0.4802 - val_accuracy: 0.8800\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0694 - accuracy: 0.9850 - val_loss: 0.4792 - val_accuracy: 0.8800\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0677 - accuracy: 0.9900 - val_loss: 0.4839 - val_accuracy: 0.8800\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0663 - accuracy: 0.9900 - val_loss: 0.4860 - val_accuracy: 0.8800\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0648 - accuracy: 0.9900 - val_loss: 0.4877 - val_accuracy: 0.8800\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 85us/step - loss: 0.0637 - accuracy: 0.9900 - val_loss: 0.4868 - val_accuracy: 0.8800\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0622 - accuracy: 0.9900 - val_loss: 0.4902 - val_accuracy: 0.8800\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0612 - accuracy: 0.9900 - val_loss: 0.4863 - val_accuracy: 0.8800\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0595 - accuracy: 0.9900 - val_loss: 0.4824 - val_accuracy: 0.8800\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.0583 - accuracy: 0.9900 - val_loss: 0.4846 - val_accuracy: 0.8800\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5665394973223544\n",
      "F1 Micro: 0.9378604744470637\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 751us/step - loss: 2.1472 - accuracy: 0.2400 - val_loss: 1.6398 - val_accuracy: 0.7500\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 1.1256 - accuracy: 0.8300 - val_loss: 0.6340 - val_accuracy: 0.8400\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.5820 - accuracy: 0.8400 - val_loss: 0.5545 - val_accuracy: 0.8400\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.4842 - accuracy: 0.8650 - val_loss: 0.5117 - val_accuracy: 0.8800\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.4364 - accuracy: 0.8850 - val_loss: 0.4929 - val_accuracy: 0.8800\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.4062 - accuracy: 0.8825 - val_loss: 0.4763 - val_accuracy: 0.8700\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 235us/step - loss: 0.3820 - accuracy: 0.8875 - val_loss: 0.4642 - val_accuracy: 0.8700\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.3634 - accuracy: 0.8925 - val_loss: 0.4594 - val_accuracy: 0.8600\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.3512 - accuracy: 0.9000 - val_loss: 0.4536 - val_accuracy: 0.8600\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.3345 - accuracy: 0.8975 - val_loss: 0.4338 - val_accuracy: 0.8700\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.3199 - accuracy: 0.9025 - val_loss: 0.4349 - val_accuracy: 0.8700\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.3099 - accuracy: 0.9125 - val_loss: 0.4272 - val_accuracy: 0.8800\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 231us/step - loss: 0.2990 - accuracy: 0.9175 - val_loss: 0.4158 - val_accuracy: 0.8700\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2897 - accuracy: 0.9125 - val_loss: 0.4175 - val_accuracy: 0.8800\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.2774 - accuracy: 0.9200 - val_loss: 0.4056 - val_accuracy: 0.8800\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 233us/step - loss: 0.2724 - accuracy: 0.9225 - val_loss: 0.4017 - val_accuracy: 0.8900\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.2630 - accuracy: 0.9250 - val_loss: 0.4024 - val_accuracy: 0.9000\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2537 - accuracy: 0.9225 - val_loss: 0.3885 - val_accuracy: 0.8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2462 - accuracy: 0.9300 - val_loss: 0.3901 - val_accuracy: 0.8900\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 234us/step - loss: 0.2365 - accuracy: 0.9350 - val_loss: 0.3801 - val_accuracy: 0.8900\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.2282 - accuracy: 0.9325 - val_loss: 0.3877 - val_accuracy: 0.8900\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.2245 - accuracy: 0.9375 - val_loss: 0.3736 - val_accuracy: 0.8900\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2183 - accuracy: 0.9400 - val_loss: 0.3697 - val_accuracy: 0.9000\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2133 - accuracy: 0.9425 - val_loss: 0.3678 - val_accuracy: 0.9100\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.2093 - accuracy: 0.9375 - val_loss: 0.3654 - val_accuracy: 0.8800\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1988 - accuracy: 0.9400 - val_loss: 0.3678 - val_accuracy: 0.8900\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1954 - accuracy: 0.9425 - val_loss: 0.3606 - val_accuracy: 0.9100\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.1892 - accuracy: 0.9475 - val_loss: 0.3680 - val_accuracy: 0.8900\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1864 - accuracy: 0.9450 - val_loss: 0.3576 - val_accuracy: 0.8900\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.1779 - accuracy: 0.9475 - val_loss: 0.3621 - val_accuracy: 0.9000\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1753 - accuracy: 0.9500 - val_loss: 0.3546 - val_accuracy: 0.8900\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.1717 - accuracy: 0.9525 - val_loss: 0.3531 - val_accuracy: 0.9000\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1665 - accuracy: 0.9450 - val_loss: 0.3535 - val_accuracy: 0.9000\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 236us/step - loss: 0.1625 - accuracy: 0.9575 - val_loss: 0.3524 - val_accuracy: 0.9000\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1592 - accuracy: 0.9475 - val_loss: 0.3530 - val_accuracy: 0.8900\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1523 - accuracy: 0.9625 - val_loss: 0.3539 - val_accuracy: 0.8900\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1488 - accuracy: 0.9625 - val_loss: 0.3476 - val_accuracy: 0.8900\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.1458 - accuracy: 0.9575 - val_loss: 0.3441 - val_accuracy: 0.8900\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.1425 - accuracy: 0.9575 - val_loss: 0.3495 - val_accuracy: 0.8900\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 233us/step - loss: 0.1389 - accuracy: 0.9600 - val_loss: 0.3443 - val_accuracy: 0.9000\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1367 - accuracy: 0.9650 - val_loss: 0.3416 - val_accuracy: 0.9100\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1324 - accuracy: 0.9600 - val_loss: 0.3466 - val_accuracy: 0.8900\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1295 - accuracy: 0.9625 - val_loss: 0.3431 - val_accuracy: 0.9100\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.1292 - accuracy: 0.9575 - val_loss: 0.3484 - val_accuracy: 0.8900\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.1242 - accuracy: 0.9700 - val_loss: 0.3459 - val_accuracy: 0.9100\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1199 - accuracy: 0.9650 - val_loss: 0.3388 - val_accuracy: 0.9100\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1173 - accuracy: 0.9650 - val_loss: 0.3452 - val_accuracy: 0.9000\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1164 - accuracy: 0.9700 - val_loss: 0.3538 - val_accuracy: 0.8900\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1104 - accuracy: 0.9800 - val_loss: 0.3423 - val_accuracy: 0.9000\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1105 - accuracy: 0.9700 - val_loss: 0.3461 - val_accuracy: 0.9000\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1066 - accuracy: 0.9825 - val_loss: 0.3446 - val_accuracy: 0.9100\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1041 - accuracy: 0.9725 - val_loss: 0.3448 - val_accuracy: 0.9000\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1027 - accuracy: 0.9750 - val_loss: 0.3508 - val_accuracy: 0.8900\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1010 - accuracy: 0.9800 - val_loss: 0.3432 - val_accuracy: 0.9100\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0963 - accuracy: 0.9775 - val_loss: 0.3564 - val_accuracy: 0.8900\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.0966 - accuracy: 0.9800 - val_loss: 0.3409 - val_accuracy: 0.9100\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0912 - accuracy: 0.9825 - val_loss: 0.3513 - val_accuracy: 0.8900\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0967 - accuracy: 0.9750 - val_loss: 0.3574 - val_accuracy: 0.8900\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1011 - accuracy: 0.9825 - val_loss: 0.3460 - val_accuracy: 0.9100\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0900 - accuracy: 0.9725 - val_loss: 0.3550 - val_accuracy: 0.8900\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0859 - accuracy: 0.9875 - val_loss: 0.3461 - val_accuracy: 0.9000\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.0818 - accuracy: 0.9825 - val_loss: 0.3452 - val_accuracy: 0.9100\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.0807 - accuracy: 0.9900 - val_loss: 0.3436 - val_accuracy: 0.9100\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0823 - accuracy: 0.9775 - val_loss: 0.3535 - val_accuracy: 0.9000\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.0762 - accuracy: 0.9900 - val_loss: 0.3425 - val_accuracy: 0.9100\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0774 - accuracy: 0.9900 - val_loss: 0.3610 - val_accuracy: 0.9000\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5359855677509898\n",
      "F1 Micro: 0.9398726242415126\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5175616979676566\n",
      "F1 Micro: 0.9364625645654682\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5680305025958932\n",
      "F1 Micro: 0.941377062333885\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 8 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 255us/step - loss: 0.9446 - accuracy: 0.8285 - val_loss: 0.5989 - val_accuracy: 0.8710\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.6642 - accuracy: 0.8468 - val_loss: 0.5493 - val_accuracy: 0.8710\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.5874 - accuracy: 0.8468 - val_loss: 0.4751 - val_accuracy: 0.8710\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.4865 - accuracy: 0.8627 - val_loss: 0.3568 - val_accuracy: 0.9230\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.3894 - accuracy: 0.9038 - val_loss: 0.3065 - val_accuracy: 0.9280\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.3659 - accuracy: 0.9040 - val_loss: 0.3156 - val_accuracy: 0.9280\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.3079 - accuracy: 0.9180 - val_loss: 0.2628 - val_accuracy: 0.9360\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.2894 - accuracy: 0.9205 - val_loss: 0.2436 - val_accuracy: 0.9390\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.2606 - accuracy: 0.9260 - val_loss: 0.2332 - val_accuracy: 0.9420\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.2439 - accuracy: 0.9315 - val_loss: 0.2268 - val_accuracy: 0.9440\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.2303 - accuracy: 0.9362 - val_loss: 0.2689 - val_accuracy: 0.9290\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.2069 - accuracy: 0.9415 - val_loss: 0.2492 - val_accuracy: 0.9340\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1959 - accuracy: 0.9445 - val_loss: 0.1927 - val_accuracy: 0.9490\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.1881 - accuracy: 0.9467 - val_loss: 0.2126 - val_accuracy: 0.9480\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.1869 - accuracy: 0.9425 - val_loss: 0.1805 - val_accuracy: 0.9520\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1701 - accuracy: 0.9490 - val_loss: 0.1767 - val_accuracy: 0.9510\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1584 - accuracy: 0.9513 - val_loss: 0.1801 - val_accuracy: 0.9460\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1490 - accuracy: 0.9572 - val_loss: 0.1667 - val_accuracy: 0.9500\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1506 - accuracy: 0.9548 - val_loss: 0.1672 - val_accuracy: 0.9520\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1430 - accuracy: 0.9582 - val_loss: 0.1607 - val_accuracy: 0.9530\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.1349 - accuracy: 0.9595 - val_loss: 0.1571 - val_accuracy: 0.9530\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1274 - accuracy: 0.9620 - val_loss: 0.1543 - val_accuracy: 0.9550\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1280 - accuracy: 0.9615 - val_loss: 0.1520 - val_accuracy: 0.9590\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.1182 - accuracy: 0.9647 - val_loss: 0.1542 - val_accuracy: 0.9530\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1176 - accuracy: 0.9640 - val_loss: 0.2245 - val_accuracy: 0.9480\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.1223 - accuracy: 0.9600 - val_loss: 0.1683 - val_accuracy: 0.9450\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.1189 - accuracy: 0.9635 - val_loss: 0.1652 - val_accuracy: 0.9520\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1036 - accuracy: 0.9678 - val_loss: 0.1498 - val_accuracy: 0.9540\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0999 - accuracy: 0.9697 - val_loss: 0.1453 - val_accuracy: 0.9530\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1026 - accuracy: 0.9695 - val_loss: 0.1452 - val_accuracy: 0.9620\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0906 - accuracy: 0.9722 - val_loss: 0.1592 - val_accuracy: 0.9570\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0971 - accuracy: 0.9688 - val_loss: 0.1451 - val_accuracy: 0.9550\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0822 - accuracy: 0.9740 - val_loss: 0.1681 - val_accuracy: 0.9470\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0814 - accuracy: 0.9735 - val_loss: 0.1679 - val_accuracy: 0.9600\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0847 - accuracy: 0.9730 - val_loss: 0.1472 - val_accuracy: 0.9620\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0822 - accuracy: 0.9735 - val_loss: 0.1733 - val_accuracy: 0.9470\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0852 - accuracy: 0.9718 - val_loss: 0.1484 - val_accuracy: 0.9610\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0662 - accuracy: 0.9778 - val_loss: 0.1406 - val_accuracy: 0.9560\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0604 - accuracy: 0.9795 - val_loss: 0.1553 - val_accuracy: 0.9490\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0649 - accuracy: 0.9797 - val_loss: 0.1536 - val_accuracy: 0.9500\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0633 - accuracy: 0.9803 - val_loss: 0.1407 - val_accuracy: 0.9560\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0498 - accuracy: 0.9858 - val_loss: 0.1845 - val_accuracy: 0.9450\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0583 - accuracy: 0.9822 - val_loss: 0.1999 - val_accuracy: 0.9430\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0522 - accuracy: 0.9820 - val_loss: 0.1445 - val_accuracy: 0.9620\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0454 - accuracy: 0.9847 - val_loss: 0.1467 - val_accuracy: 0.9630\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0408 - accuracy: 0.9872 - val_loss: 0.1729 - val_accuracy: 0.9590\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0443 - accuracy: 0.9868 - val_loss: 0.1515 - val_accuracy: 0.9590\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0370 - accuracy: 0.9883 - val_loss: 0.2226 - val_accuracy: 0.9390\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 0.1680 - val_accuracy: 0.9510\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0294 - accuracy: 0.9915 - val_loss: 0.1759 - val_accuracy: 0.9600\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0296 - accuracy: 0.9910 - val_loss: 0.2021 - val_accuracy: 0.9490\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.1537 - val_accuracy: 0.9620\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.1586 - val_accuracy: 0.9570\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0233 - accuracy: 0.9942 - val_loss: 0.1657 - val_accuracy: 0.9580\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0341 - accuracy: 0.9905 - val_loss: 0.2995 - val_accuracy: 0.9520\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0435 - accuracy: 0.9887 - val_loss: 0.1642 - val_accuracy: 0.9550\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0166 - accuracy: 0.9973 - val_loss: 0.1605 - val_accuracy: 0.9620\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0145 - accuracy: 0.9975 - val_loss: 0.1715 - val_accuracy: 0.9580\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6462687404079631\n",
      "F1 Micro: 0.9559301685758591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7132175417403408\n",
      "F1 Micro: 0.9581311590215598\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 92us/step - loss: 1.6262 - accuracy: 0.5907 - val_loss: 1.3457 - val_accuracy: 0.6990\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 1.0287 - accuracy: 0.8015 - val_loss: 0.7871 - val_accuracy: 0.8790\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.5939 - accuracy: 0.9038 - val_loss: 0.4471 - val_accuracy: 0.9240\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.3646 - accuracy: 0.9362 - val_loss: 0.2943 - val_accuracy: 0.9470\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.2643 - accuracy: 0.9430 - val_loss: 0.2274 - val_accuracy: 0.9570\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.2174 - accuracy: 0.9495 - val_loss: 0.1944 - val_accuracy: 0.9620\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1919 - accuracy: 0.9507 - val_loss: 0.1756 - val_accuracy: 0.9630\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.1763 - accuracy: 0.9557 - val_loss: 0.1632 - val_accuracy: 0.9650\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.1647 - accuracy: 0.9588 - val_loss: 0.1551 - val_accuracy: 0.9650\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1555 - accuracy: 0.9592 - val_loss: 0.1486 - val_accuracy: 0.9670\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1485 - accuracy: 0.9615 - val_loss: 0.1447 - val_accuracy: 0.9670\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1424 - accuracy: 0.9603 - val_loss: 0.1413 - val_accuracy: 0.9680\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1371 - accuracy: 0.9617 - val_loss: 0.1382 - val_accuracy: 0.9680\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1331 - accuracy: 0.9615 - val_loss: 0.1374 - val_accuracy: 0.9680\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1293 - accuracy: 0.9628 - val_loss: 0.1339 - val_accuracy: 0.9680\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1256 - accuracy: 0.9635 - val_loss: 0.1328 - val_accuracy: 0.9680\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1220 - accuracy: 0.9643 - val_loss: 0.1321 - val_accuracy: 0.9670\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1189 - accuracy: 0.9663 - val_loss: 0.1291 - val_accuracy: 0.9680\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1158 - accuracy: 0.9660 - val_loss: 0.1295 - val_accuracy: 0.9690\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.1134 - accuracy: 0.9675 - val_loss: 0.1283 - val_accuracy: 0.9690\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1108 - accuracy: 0.9688 - val_loss: 0.1262 - val_accuracy: 0.9680\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.1082 - accuracy: 0.9680 - val_loss: 0.1265 - val_accuracy: 0.9680\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1062 - accuracy: 0.9700 - val_loss: 0.1256 - val_accuracy: 0.9680\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 80us/step - loss: 0.1043 - accuracy: 0.9697 - val_loss: 0.1256 - val_accuracy: 0.9690\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 79us/step - loss: 0.1015 - accuracy: 0.9705 - val_loss: 0.1244 - val_accuracy: 0.9680\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1004 - accuracy: 0.9712 - val_loss: 0.1241 - val_accuracy: 0.9690\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0980 - accuracy: 0.9712 - val_loss: 0.1246 - val_accuracy: 0.9680\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0971 - accuracy: 0.9722 - val_loss: 0.1238 - val_accuracy: 0.9670\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0954 - accuracy: 0.9728 - val_loss: 0.1235 - val_accuracy: 0.9660\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0936 - accuracy: 0.9735 - val_loss: 0.1232 - val_accuracy: 0.9660\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0917 - accuracy: 0.9743 - val_loss: 0.1222 - val_accuracy: 0.9660\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0903 - accuracy: 0.9747 - val_loss: 0.1237 - val_accuracy: 0.9670\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0888 - accuracy: 0.9743 - val_loss: 0.1221 - val_accuracy: 0.9680\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0871 - accuracy: 0.9760 - val_loss: 0.1221 - val_accuracy: 0.9680\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0858 - accuracy: 0.9745 - val_loss: 0.1212 - val_accuracy: 0.9660\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0845 - accuracy: 0.9762 - val_loss: 0.1234 - val_accuracy: 0.9680\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0829 - accuracy: 0.9760 - val_loss: 0.1219 - val_accuracy: 0.9660\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0818 - accuracy: 0.9755 - val_loss: 0.1230 - val_accuracy: 0.9690\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0807 - accuracy: 0.9760 - val_loss: 0.1210 - val_accuracy: 0.9680\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0791 - accuracy: 0.9778 - val_loss: 0.1205 - val_accuracy: 0.9650\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0780 - accuracy: 0.9780 - val_loss: 0.1209 - val_accuracy: 0.9670\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0768 - accuracy: 0.9785 - val_loss: 0.1209 - val_accuracy: 0.9680\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0757 - accuracy: 0.9795 - val_loss: 0.1208 - val_accuracy: 0.9680\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0746 - accuracy: 0.9793 - val_loss: 0.1215 - val_accuracy: 0.9670\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0733 - accuracy: 0.9790 - val_loss: 0.1218 - val_accuracy: 0.9680\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0728 - accuracy: 0.9808 - val_loss: 0.1212 - val_accuracy: 0.9680\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0711 - accuracy: 0.9808 - val_loss: 0.1213 - val_accuracy: 0.9670\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0703 - accuracy: 0.9803 - val_loss: 0.1235 - val_accuracy: 0.9690\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0694 - accuracy: 0.9797 - val_loss: 0.1220 - val_accuracy: 0.9680\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 79us/step - loss: 0.0683 - accuracy: 0.9812 - val_loss: 0.1213 - val_accuracy: 0.9690\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0676 - accuracy: 0.9812 - val_loss: 0.1209 - val_accuracy: 0.9690\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0666 - accuracy: 0.9815 - val_loss: 0.1214 - val_accuracy: 0.9690\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0655 - accuracy: 0.9815 - val_loss: 0.1243 - val_accuracy: 0.9690\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0648 - accuracy: 0.9830 - val_loss: 0.1215 - val_accuracy: 0.9680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0637 - accuracy: 0.9830 - val_loss: 0.1219 - val_accuracy: 0.9700\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0633 - accuracy: 0.9840 - val_loss: 0.1217 - val_accuracy: 0.9700\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0617 - accuracy: 0.9837 - val_loss: 0.1225 - val_accuracy: 0.9680\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0612 - accuracy: 0.9840 - val_loss: 0.1229 - val_accuracy: 0.9690\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 79us/step - loss: 0.0604 - accuracy: 0.9850 - val_loss: 0.1231 - val_accuracy: 0.9690\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0600 - accuracy: 0.9843 - val_loss: 0.1228 - val_accuracy: 0.9670\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7288859349926278\n",
      "F1 Micro: 0.9583312490620779\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 255us/step - loss: 0.6423 - accuracy: 0.8332 - val_loss: 0.3205 - val_accuracy: 0.9270\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.3206 - accuracy: 0.9128 - val_loss: 0.2465 - val_accuracy: 0.9420\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.2651 - accuracy: 0.9308 - val_loss: 0.2199 - val_accuracy: 0.9480\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.2294 - accuracy: 0.9392 - val_loss: 0.1910 - val_accuracy: 0.9520\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.2038 - accuracy: 0.9442 - val_loss: 0.1758 - val_accuracy: 0.9560\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1884 - accuracy: 0.9465 - val_loss: 0.1685 - val_accuracy: 0.9570\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1728 - accuracy: 0.9500 - val_loss: 0.1595 - val_accuracy: 0.9540\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1622 - accuracy: 0.9550 - val_loss: 0.1515 - val_accuracy: 0.9570\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1541 - accuracy: 0.9542 - val_loss: 0.1484 - val_accuracy: 0.9580\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1478 - accuracy: 0.9582 - val_loss: 0.1490 - val_accuracy: 0.9590\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 205us/step - loss: 0.1442 - accuracy: 0.9563 - val_loss: 0.1419 - val_accuracy: 0.9610\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1347 - accuracy: 0.9607 - val_loss: 0.1392 - val_accuracy: 0.9610\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1298 - accuracy: 0.9625 - val_loss: 0.1456 - val_accuracy: 0.9630\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1263 - accuracy: 0.9615 - val_loss: 0.1377 - val_accuracy: 0.9620\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1213 - accuracy: 0.9643 - val_loss: 0.1419 - val_accuracy: 0.9620\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1156 - accuracy: 0.9670 - val_loss: 0.1348 - val_accuracy: 0.9620\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1127 - accuracy: 0.9665 - val_loss: 0.1358 - val_accuracy: 0.9660\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1057 - accuracy: 0.9680 - val_loss: 0.1348 - val_accuracy: 0.9640\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1029 - accuracy: 0.9685 - val_loss: 0.1330 - val_accuracy: 0.9690\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0974 - accuracy: 0.9700 - val_loss: 0.1323 - val_accuracy: 0.9650\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0931 - accuracy: 0.9732 - val_loss: 0.1303 - val_accuracy: 0.9670\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0920 - accuracy: 0.9722 - val_loss: 0.1310 - val_accuracy: 0.9700\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0842 - accuracy: 0.9745 - val_loss: 0.1331 - val_accuracy: 0.9670\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0783 - accuracy: 0.9762 - val_loss: 0.1305 - val_accuracy: 0.9700\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0791 - accuracy: 0.9768 - val_loss: 0.1312 - val_accuracy: 0.9690\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0691 - accuracy: 0.9778 - val_loss: 0.1288 - val_accuracy: 0.9660\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0708 - accuracy: 0.9787 - val_loss: 0.1286 - val_accuracy: 0.9670\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0596 - accuracy: 0.9835 - val_loss: 0.1335 - val_accuracy: 0.9660\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0552 - accuracy: 0.9845 - val_loss: 0.1364 - val_accuracy: 0.9630\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0485 - accuracy: 0.9870 - val_loss: 0.1370 - val_accuracy: 0.9660\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0434 - accuracy: 0.9883 - val_loss: 0.1365 - val_accuracy: 0.9650\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0465 - accuracy: 0.9860 - val_loss: 0.1416 - val_accuracy: 0.9680\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0362 - accuracy: 0.9910 - val_loss: 0.1404 - val_accuracy: 0.9660\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 0.1431 - val_accuracy: 0.9660\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0271 - accuracy: 0.9948 - val_loss: 0.1447 - val_accuracy: 0.9650\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0250 - accuracy: 0.9950 - val_loss: 0.1518 - val_accuracy: 0.9690\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0205 - accuracy: 0.9960 - val_loss: 0.1597 - val_accuracy: 0.9640\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0182 - accuracy: 0.9983 - val_loss: 0.1538 - val_accuracy: 0.9680\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0149 - accuracy: 0.9987 - val_loss: 0.1581 - val_accuracy: 0.9640\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0137 - accuracy: 0.9992 - val_loss: 0.1551 - val_accuracy: 0.9660\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0120 - accuracy: 0.9992 - val_loss: 0.1577 - val_accuracy: 0.9640\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0102 - accuracy: 0.9995 - val_loss: 0.1595 - val_accuracy: 0.9690\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9650\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9660\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9650\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 0.1739 - val_accuracy: 0.9650\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9630\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.723635934133086\n",
      "F1 Micro: 0.9584312940823371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7186019807742174\n",
      "F1 Micro: 0.9596318343254464\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7571802077840446\n",
      "F1 Micro: 0.9625331399129609\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 8 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.3993 - accuracy: 0.9032 - val_loss: 0.2168 - val_accuracy: 0.9379\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.1833 - accuracy: 0.9467 - val_loss: 0.1478 - val_accuracy: 0.9519\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.1430 - accuracy: 0.9559 - val_loss: 0.1358 - val_accuracy: 0.9568\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.1282 - accuracy: 0.9602 - val_loss: 0.1230 - val_accuracy: 0.9601\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.1187 - accuracy: 0.9628 - val_loss: 0.1144 - val_accuracy: 0.9624\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.1094 - accuracy: 0.9650 - val_loss: 0.1023 - val_accuracy: 0.9684\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.1004 - accuracy: 0.9683 - val_loss: 0.1044 - val_accuracy: 0.9659\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0961 - accuracy: 0.9688 - val_loss: 0.1039 - val_accuracy: 0.9669\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0902 - accuracy: 0.9700 - val_loss: 0.0973 - val_accuracy: 0.9694\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0848 - accuracy: 0.9721 - val_loss: 0.0939 - val_accuracy: 0.9696\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0796 - accuracy: 0.9734 - val_loss: 0.1005 - val_accuracy: 0.9651\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0745 - accuracy: 0.9747 - val_loss: 0.0892 - val_accuracy: 0.9711\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0701 - accuracy: 0.9764 - val_loss: 0.0927 - val_accuracy: 0.9726\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0674 - accuracy: 0.9773 - val_loss: 0.0940 - val_accuracy: 0.9693\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0619 - accuracy: 0.9790 - val_loss: 0.0888 - val_accuracy: 0.9723\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0565 - accuracy: 0.9809 - val_loss: 0.0840 - val_accuracy: 0.9720\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0524 - accuracy: 0.9816 - val_loss: 0.0829 - val_accuracy: 0.9717\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0476 - accuracy: 0.9831 - val_loss: 0.1347 - val_accuracy: 0.9646\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0437 - accuracy: 0.9846 - val_loss: 0.0829 - val_accuracy: 0.9736\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 0.0837 - val_accuracy: 0.9719\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0321 - accuracy: 0.9889 - val_loss: 0.0888 - val_accuracy: 0.9737\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 0.1119 - val_accuracy: 0.9716\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.0939 - val_accuracy: 0.9723\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.0935 - val_accuracy: 0.9745\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.1196 - val_accuracy: 0.9651\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.1287 - val_accuracy: 0.9722\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.1389 - val_accuracy: 0.9706\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.1077 - val_accuracy: 0.9738\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.1321 - val_accuracy: 0.9730\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.1535 - val_accuracy: 0.9727\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.1587 - val_accuracy: 0.9687\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.1435 - val_accuracy: 0.9671\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.1300 - val_accuracy: 0.9733\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.1416 - val_accuracy: 0.9726\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.1319 - val_accuracy: 0.9744\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1483 - val_accuracy: 0.9709\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.1531 - val_accuracy: 0.9682\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.1344 - val_accuracy: 0.9727\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.1502 - val_accuracy: 0.9707\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8416832778232777\n",
      "F1 Micro: 0.9712\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8292291975183639\n",
      "F1 Micro: 0.9682\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.5369 - accuracy: 0.8743 - val_loss: 0.1584 - val_accuracy: 0.9565\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1429 - accuracy: 0.9579 - val_loss: 0.1315 - val_accuracy: 0.9601\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1251 - accuracy: 0.9623 - val_loss: 0.1222 - val_accuracy: 0.9613\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1164 - accuracy: 0.9643 - val_loss: 0.1169 - val_accuracy: 0.9618\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1106 - accuracy: 0.9656 - val_loss: 0.1142 - val_accuracy: 0.9649\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1060 - accuracy: 0.9671 - val_loss: 0.1082 - val_accuracy: 0.9648\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1026 - accuracy: 0.9678 - val_loss: 0.1056 - val_accuracy: 0.9662\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0994 - accuracy: 0.9685 - val_loss: 0.1041 - val_accuracy: 0.9661\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0967 - accuracy: 0.9693 - val_loss: 0.1045 - val_accuracy: 0.9670\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0949 - accuracy: 0.9701 - val_loss: 0.1009 - val_accuracy: 0.9686\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0930 - accuracy: 0.9706 - val_loss: 0.1010 - val_accuracy: 0.9668\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0910 - accuracy: 0.9714 - val_loss: 0.0994 - val_accuracy: 0.9681\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0896 - accuracy: 0.9719 - val_loss: 0.0994 - val_accuracy: 0.9681\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0877 - accuracy: 0.9725 - val_loss: 0.0972 - val_accuracy: 0.9689\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0863 - accuracy: 0.9726 - val_loss: 0.0974 - val_accuracy: 0.9678\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0851 - accuracy: 0.9730 - val_loss: 0.0973 - val_accuracy: 0.9687\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0843 - accuracy: 0.9737 - val_loss: 0.0964 - val_accuracy: 0.9684\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0826 - accuracy: 0.9739 - val_loss: 0.0958 - val_accuracy: 0.9678\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0818 - accuracy: 0.9740 - val_loss: 0.0952 - val_accuracy: 0.9698\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0804 - accuracy: 0.9745 - val_loss: 0.0950 - val_accuracy: 0.9693\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0796 - accuracy: 0.9748 - val_loss: 0.0959 - val_accuracy: 0.9684\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0786 - accuracy: 0.9752 - val_loss: 0.0940 - val_accuracy: 0.9705\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0777 - accuracy: 0.9756 - val_loss: 0.0959 - val_accuracy: 0.9697\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0764 - accuracy: 0.9757 - val_loss: 0.0946 - val_accuracy: 0.9692\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0754 - accuracy: 0.9762 - val_loss: 0.0929 - val_accuracy: 0.9708\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0748 - accuracy: 0.9765 - val_loss: 0.0945 - val_accuracy: 0.9707\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0736 - accuracy: 0.9770 - val_loss: 0.0936 - val_accuracy: 0.9711\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0730 - accuracy: 0.9769 - val_loss: 0.0928 - val_accuracy: 0.9707\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0722 - accuracy: 0.9769 - val_loss: 0.0930 - val_accuracy: 0.9710\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0714 - accuracy: 0.9777 - val_loss: 0.0928 - val_accuracy: 0.9705\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0707 - accuracy: 0.9774 - val_loss: 0.0930 - val_accuracy: 0.9712\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0697 - accuracy: 0.9786 - val_loss: 0.0945 - val_accuracy: 0.9709\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0692 - accuracy: 0.9782 - val_loss: 0.0939 - val_accuracy: 0.9702\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0682 - accuracy: 0.9787 - val_loss: 0.0925 - val_accuracy: 0.9710\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0678 - accuracy: 0.9786 - val_loss: 0.0917 - val_accuracy: 0.9707\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0667 - accuracy: 0.9787 - val_loss: 0.0927 - val_accuracy: 0.9702\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0661 - accuracy: 0.9793 - val_loss: 0.0924 - val_accuracy: 0.9710\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0653 - accuracy: 0.9793 - val_loss: 0.0940 - val_accuracy: 0.9698\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0646 - accuracy: 0.9796 - val_loss: 0.0923 - val_accuracy: 0.9702\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0641 - accuracy: 0.9799 - val_loss: 0.0928 - val_accuracy: 0.9706\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0634 - accuracy: 0.9801 - val_loss: 0.0940 - val_accuracy: 0.9700\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0627 - accuracy: 0.9805 - val_loss: 0.0924 - val_accuracy: 0.9705\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0618 - accuracy: 0.9809 - val_loss: 0.0936 - val_accuracy: 0.9708\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0615 - accuracy: 0.9807 - val_loss: 0.0949 - val_accuracy: 0.9695\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0611 - accuracy: 0.9807 - val_loss: 0.0928 - val_accuracy: 0.9719\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0601 - accuracy: 0.9811 - val_loss: 0.0931 - val_accuracy: 0.9710\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0597 - accuracy: 0.9811 - val_loss: 0.0936 - val_accuracy: 0.9705\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0590 - accuracy: 0.9815 - val_loss: 0.0945 - val_accuracy: 0.9704\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0585 - accuracy: 0.9815 - val_loss: 0.0949 - val_accuracy: 0.9702\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0575 - accuracy: 0.9825 - val_loss: 0.0948 - val_accuracy: 0.9711\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0570 - accuracy: 0.9826 - val_loss: 0.0937 - val_accuracy: 0.9714\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0567 - accuracy: 0.9823 - val_loss: 0.0940 - val_accuracy: 0.9708\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0559 - accuracy: 0.9826 - val_loss: 0.0948 - val_accuracy: 0.9709\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0554 - accuracy: 0.9834 - val_loss: 0.0934 - val_accuracy: 0.9713\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0548 - accuracy: 0.9833 - val_loss: 0.0965 - val_accuracy: 0.9707\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8261816281415048\n",
      "F1 Micro: 0.9704\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 0.2586 - accuracy: 0.9298 - val_loss: 0.1568 - val_accuracy: 0.9524\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.1423 - accuracy: 0.9571 - val_loss: 0.1279 - val_accuracy: 0.9588\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.1200 - accuracy: 0.9625 - val_loss: 0.1122 - val_accuracy: 0.9625\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.1044 - accuracy: 0.9672 - val_loss: 0.0995 - val_accuracy: 0.9676\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0939 - accuracy: 0.9702 - val_loss: 0.1097 - val_accuracy: 0.9633\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0863 - accuracy: 0.9713 - val_loss: 0.0988 - val_accuracy: 0.9674\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0807 - accuracy: 0.9739 - val_loss: 0.0973 - val_accuracy: 0.9674\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0747 - accuracy: 0.9748 - val_loss: 0.0862 - val_accuracy: 0.9729\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0702 - accuracy: 0.9764 - val_loss: 0.0853 - val_accuracy: 0.9714\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0651 - accuracy: 0.9778 - val_loss: 0.0808 - val_accuracy: 0.9733\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0594 - accuracy: 0.9804 - val_loss: 0.0857 - val_accuracy: 0.9730\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0559 - accuracy: 0.9813 - val_loss: 0.0850 - val_accuracy: 0.9733\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0504 - accuracy: 0.9836 - val_loss: 0.0950 - val_accuracy: 0.9723\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0440 - accuracy: 0.9854 - val_loss: 0.0824 - val_accuracy: 0.9735\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 0.0892 - val_accuracy: 0.9743\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0325 - accuracy: 0.9898 - val_loss: 0.0953 - val_accuracy: 0.9740\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0932 - val_accuracy: 0.9744\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0191 - accuracy: 0.9946 - val_loss: 0.1022 - val_accuracy: 0.9724\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.1060 - val_accuracy: 0.9727\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.1076 - val_accuracy: 0.9727\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.1168 - val_accuracy: 0.9744\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.1582 - val_accuracy: 0.9605\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.1411 - val_accuracy: 0.9720\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.1451 - val_accuracy: 0.9690\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.1403 - val_accuracy: 0.9690\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1679 - val_accuracy: 0.9721\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.1380 - val_accuracy: 0.9742\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.1420 - val_accuracy: 0.9733\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 205us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.1806 - val_accuracy: 0.9623\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1466 - val_accuracy: 0.9741\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8240483491099135\n",
      "F1 Micro: 0.972\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8407671729939332\n",
      "F1 Micro: 0.971\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8458363505096854\n",
      "F1 Micro: 0.973\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 8 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.2552 - accuracy: 0.9323 - val_loss: 0.1335 - val_accuracy: 0.9585\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.1162 - accuracy: 0.9638 - val_loss: 0.1245 - val_accuracy: 0.9590\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0994 - accuracy: 0.9680 - val_loss: 0.0939 - val_accuracy: 0.9689\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0885 - accuracy: 0.9712 - val_loss: 0.0928 - val_accuracy: 0.9697\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 25s 191us/step - loss: 0.0796 - accuracy: 0.9736 - val_loss: 0.0787 - val_accuracy: 0.9741\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0724 - accuracy: 0.9760 - val_loss: 0.0786 - val_accuracy: 0.9740\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0668 - accuracy: 0.9767 - val_loss: 0.0754 - val_accuracy: 0.9749\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0615 - accuracy: 0.9789 - val_loss: 0.0794 - val_accuracy: 0.9734\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0578 - accuracy: 0.9801 - val_loss: 0.0658 - val_accuracy: 0.9767\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0531 - accuracy: 0.9812 - val_loss: 0.0688 - val_accuracy: 0.9767\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0496 - accuracy: 0.9821 - val_loss: 0.0684 - val_accuracy: 0.9774\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0464 - accuracy: 0.9834 - val_loss: 0.0700 - val_accuracy: 0.9762\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0421 - accuracy: 0.9844 - val_loss: 0.0731 - val_accuracy: 0.9767\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0386 - accuracy: 0.9861 - val_loss: 0.0693 - val_accuracy: 0.9770\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0339 - accuracy: 0.9879 - val_loss: 0.0687 - val_accuracy: 0.9765\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 24s 186us/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 0.0718 - val_accuracy: 0.9768\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0268 - accuracy: 0.9901 - val_loss: 0.0779 - val_accuracy: 0.9775\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0227 - accuracy: 0.9917 - val_loss: 0.0785 - val_accuracy: 0.9757\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 0.0869 - val_accuracy: 0.9772\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 25s 196us/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.0846 - val_accuracy: 0.9776\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0139 - accuracy: 0.9950 - val_loss: 0.0984 - val_accuracy: 0.9739\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0994 - val_accuracy: 0.9766\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.0993 - val_accuracy: 0.9763\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.1360 - val_accuracy: 0.9755\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.1049 - val_accuracy: 0.9763\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1285 - val_accuracy: 0.9761\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.1148 - val_accuracy: 0.9757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.1189 - val_accuracy: 0.9770\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.1227 - val_accuracy: 0.9748\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8763647359186201\n",
      "F1 Micro: 0.977\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8470708309399149\n",
      "F1 Micro: 0.9713\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.2467 - accuracy: 0.9369 - val_loss: 0.1207 - val_accuracy: 0.9626\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.1139 - accuracy: 0.9644 - val_loss: 0.1076 - val_accuracy: 0.9660\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.1040 - accuracy: 0.9677 - val_loss: 0.1017 - val_accuracy: 0.9683\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0985 - accuracy: 0.9693 - val_loss: 0.0983 - val_accuracy: 0.9686\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0944 - accuracy: 0.9705 - val_loss: 0.0956 - val_accuracy: 0.9690\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0916 - accuracy: 0.9711 - val_loss: 0.0934 - val_accuracy: 0.9698\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0890 - accuracy: 0.9716 - val_loss: 0.0915 - val_accuracy: 0.9704\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0869 - accuracy: 0.9727 - val_loss: 0.0902 - val_accuracy: 0.9711\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0848 - accuracy: 0.9734 - val_loss: 0.0902 - val_accuracy: 0.9710\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0831 - accuracy: 0.9737 - val_loss: 0.0901 - val_accuracy: 0.9709\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0816 - accuracy: 0.9741 - val_loss: 0.0877 - val_accuracy: 0.9717\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0802 - accuracy: 0.9745 - val_loss: 0.0860 - val_accuracy: 0.9718\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0788 - accuracy: 0.9747 - val_loss: 0.0869 - val_accuracy: 0.9706\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0777 - accuracy: 0.9752 - val_loss: 0.0845 - val_accuracy: 0.9724\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0765 - accuracy: 0.9757 - val_loss: 0.0864 - val_accuracy: 0.9716\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0753 - accuracy: 0.9759 - val_loss: 0.0863 - val_accuracy: 0.9710\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0745 - accuracy: 0.9762 - val_loss: 0.0844 - val_accuracy: 0.9726\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0736 - accuracy: 0.9764 - val_loss: 0.0839 - val_accuracy: 0.9725\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0726 - accuracy: 0.9767 - val_loss: 0.0844 - val_accuracy: 0.9719\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0716 - accuracy: 0.9772 - val_loss: 0.0829 - val_accuracy: 0.9724\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0710 - accuracy: 0.9774 - val_loss: 0.0829 - val_accuracy: 0.9728\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0703 - accuracy: 0.9774 - val_loss: 0.0825 - val_accuracy: 0.9730\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0692 - accuracy: 0.9776 - val_loss: 0.0841 - val_accuracy: 0.9723\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0684 - accuracy: 0.9780 - val_loss: 0.0832 - val_accuracy: 0.9723\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0678 - accuracy: 0.9782 - val_loss: 0.0815 - val_accuracy: 0.9729\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 10s 75us/step - loss: 0.0670 - accuracy: 0.9785 - val_loss: 0.0827 - val_accuracy: 0.9725\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0663 - accuracy: 0.9786 - val_loss: 0.0821 - val_accuracy: 0.9724\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0656 - accuracy: 0.9789 - val_loss: 0.0822 - val_accuracy: 0.9728\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0650 - accuracy: 0.9790 - val_loss: 0.0829 - val_accuracy: 0.9725\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0642 - accuracy: 0.9791 - val_loss: 0.0819 - val_accuracy: 0.9730\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0638 - accuracy: 0.9793 - val_loss: 0.0811 - val_accuracy: 0.9732\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0630 - accuracy: 0.9795 - val_loss: 0.0860 - val_accuracy: 0.9710\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 10s 74us/step - loss: 0.0623 - accuracy: 0.9798 - val_loss: 0.0820 - val_accuracy: 0.9734\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0620 - accuracy: 0.9799 - val_loss: 0.0815 - val_accuracy: 0.9731\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0612 - accuracy: 0.9799 - val_loss: 0.0819 - val_accuracy: 0.9730\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0607 - accuracy: 0.9804 - val_loss: 0.0819 - val_accuracy: 0.9730\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 10s 73us/step - loss: 0.0601 - accuracy: 0.9805 - val_loss: 0.0811 - val_accuracy: 0.9732\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 73us/step - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.0855 - val_accuracy: 0.9714\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0588 - accuracy: 0.9809 - val_loss: 0.0819 - val_accuracy: 0.9725\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0582 - accuracy: 0.9813 - val_loss: 0.0854 - val_accuracy: 0.9712\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0577 - accuracy: 0.9813 - val_loss: 0.0829 - val_accuracy: 0.9725\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0572 - accuracy: 0.9814 - val_loss: 0.0820 - val_accuracy: 0.9732\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0566 - accuracy: 0.9819 - val_loss: 0.0816 - val_accuracy: 0.9731\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0559 - accuracy: 0.9820 - val_loss: 0.0847 - val_accuracy: 0.9724\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0556 - accuracy: 0.9822 - val_loss: 0.0827 - val_accuracy: 0.9723\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0549 - accuracy: 0.9823 - val_loss: 0.0820 - val_accuracy: 0.9724\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0544 - accuracy: 0.9824 - val_loss: 0.0824 - val_accuracy: 0.9727\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 69us/step - loss: 0.0540 - accuracy: 0.9826 - val_loss: 0.0838 - val_accuracy: 0.9721\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0533 - accuracy: 0.9829 - val_loss: 0.0821 - val_accuracy: 0.9731\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0529 - accuracy: 0.9828 - val_loss: 0.0818 - val_accuracy: 0.9736\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0523 - accuracy: 0.9833 - val_loss: 0.0831 - val_accuracy: 0.9727\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0517 - accuracy: 0.9835 - val_loss: 0.0831 - val_accuracy: 0.9727\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 9s 70us/step - loss: 0.0512 - accuracy: 0.9835 - val_loss: 0.0837 - val_accuracy: 0.9722\n",
      "Epoch 54/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0506 - accuracy: 0.9840 - val_loss: 0.0838 - val_accuracy: 0.9729\n",
      "Epoch 55/1000\n",
      "130356/130356 [==============================] - 9s 71us/step - loss: 0.0503 - accuracy: 0.9837 - val_loss: 0.0836 - val_accuracy: 0.9729\n",
      "Epoch 56/1000\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0497 - accuracy: 0.9841 - val_loss: 0.0839 - val_accuracy: 0.9725\n",
      "Epoch 57/1000\n",
      "130356/130356 [==============================] - 9s 72us/step - loss: 0.0492 - accuracy: 0.9841 - val_loss: 0.0839 - val_accuracy: 0.9725\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8762026722441958\n",
      "F1 Micro: 0.9766\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 27s 206us/step - loss: 0.1762 - accuracy: 0.9488 - val_loss: 0.1175 - val_accuracy: 0.9630\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.1074 - accuracy: 0.9663 - val_loss: 0.0976 - val_accuracy: 0.9686\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0909 - accuracy: 0.9712 - val_loss: 0.0845 - val_accuracy: 0.9714\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.0821 - accuracy: 0.9730 - val_loss: 0.0788 - val_accuracy: 0.9728\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0753 - accuracy: 0.9753 - val_loss: 0.0835 - val_accuracy: 0.9724\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 27s 205us/step - loss: 0.0693 - accuracy: 0.9770 - val_loss: 0.0741 - val_accuracy: 0.9748\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0635 - accuracy: 0.9789 - val_loss: 0.0742 - val_accuracy: 0.9739\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0574 - accuracy: 0.9808 - val_loss: 0.0686 - val_accuracy: 0.9770\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.0516 - accuracy: 0.9826 - val_loss: 0.0674 - val_accuracy: 0.9778\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0459 - accuracy: 0.9842 - val_loss: 0.0679 - val_accuracy: 0.9769\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0400 - accuracy: 0.9860 - val_loss: 0.0672 - val_accuracy: 0.9774\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0336 - accuracy: 0.9883 - val_loss: 0.0725 - val_accuracy: 0.9759\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0276 - accuracy: 0.9906 - val_loss: 0.0755 - val_accuracy: 0.9758\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0858 - val_accuracy: 0.9769\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.0864 - val_accuracy: 0.9756\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0932 - val_accuracy: 0.9763\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.1065 - val_accuracy: 0.9724\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.1068 - val_accuracy: 0.9765\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.1142 - val_accuracy: 0.9736\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1217 - val_accuracy: 0.9727\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1192 - val_accuracy: 0.9757\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.1238 - val_accuracy: 0.9753\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.1258 - val_accuracy: 0.9747\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.1265 - val_accuracy: 0.9757\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1237 - val_accuracy: 0.9757\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1365 - val_accuracy: 0.9756\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1332 - val_accuracy: 0.9761\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1383 - val_accuracy: 0.9750\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 27s 204us/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1478 - val_accuracy: 0.9758\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 26s 203us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.1526 - val_accuracy: 0.9756\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.1436 - val_accuracy: 0.9753\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8623847311659085\n",
      "F1 Micro: 0.977\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8436043769765839\n",
      "F1 Micro: 0.9705\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8960616062190834\n",
      "F1 Micro: 0.9802\n",
      "\n",
      "\n",
      " 53.55708928902944 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 9 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 9 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 1.8133 - accuracy: 0.7975 - val_loss: 1.2791 - val_accuracy: 0.8300\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.9320 - accuracy: 0.8350 - val_loss: 0.8294 - val_accuracy: 0.8300\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.8129 - accuracy: 0.8350 - val_loss: 0.7665 - val_accuracy: 0.8300\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.7348 - accuracy: 0.8350 - val_loss: 0.7373 - val_accuracy: 0.8300\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.7179 - accuracy: 0.8350 - val_loss: 0.7342 - val_accuracy: 0.8300\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.7029 - accuracy: 0.8350 - val_loss: 0.7237 - val_accuracy: 0.8300\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6891 - accuracy: 0.8350 - val_loss: 0.7174 - val_accuracy: 0.8300\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6827 - accuracy: 0.8350 - val_loss: 0.7111 - val_accuracy: 0.8300\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 232us/step - loss: 0.6775 - accuracy: 0.8350 - val_loss: 0.7070 - val_accuracy: 0.8300\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 228us/step - loss: 0.6690 - accuracy: 0.8350 - val_loss: 0.7036 - val_accuracy: 0.8300\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.6636 - accuracy: 0.8350 - val_loss: 0.6973 - val_accuracy: 0.8300\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.6608 - accuracy: 0.8350 - val_loss: 0.6882 - val_accuracy: 0.8300\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.6519 - accuracy: 0.8350 - val_loss: 0.6864 - val_accuracy: 0.8300\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.6395 - accuracy: 0.8350 - val_loss: 0.6714 - val_accuracy: 0.8300\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.6285 - accuracy: 0.8350 - val_loss: 0.6640 - val_accuracy: 0.8300\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 233us/step - loss: 0.6184 - accuracy: 0.8350 - val_loss: 0.6569 - val_accuracy: 0.8300\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 236us/step - loss: 0.6040 - accuracy: 0.8350 - val_loss: 0.6375 - val_accuracy: 0.8300\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.5909 - accuracy: 0.8350 - val_loss: 0.6316 - val_accuracy: 0.8300\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 230us/step - loss: 0.5673 - accuracy: 0.8350 - val_loss: 0.6147 - val_accuracy: 0.8300\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.5428 - accuracy: 0.8350 - val_loss: 0.5867 - val_accuracy: 0.8300\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.5165 - accuracy: 0.8375 - val_loss: 0.5618 - val_accuracy: 0.8500\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.4940 - accuracy: 0.8500 - val_loss: 0.6055 - val_accuracy: 0.8900\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.5301 - accuracy: 0.8675 - val_loss: 0.5386 - val_accuracy: 0.8800\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.4588 - accuracy: 0.8775 - val_loss: 0.5190 - val_accuracy: 0.8700\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.4394 - accuracy: 0.8750 - val_loss: 0.4963 - val_accuracy: 0.8600\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.4245 - accuracy: 0.8950 - val_loss: 0.5056 - val_accuracy: 0.8900\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.4160 - accuracy: 0.8850 - val_loss: 0.4652 - val_accuracy: 0.8800\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3980 - accuracy: 0.8975 - val_loss: 0.4602 - val_accuracy: 0.8800\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.3769 - accuracy: 0.9000 - val_loss: 0.4863 - val_accuracy: 0.8900\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.3701 - accuracy: 0.9000 - val_loss: 0.4231 - val_accuracy: 0.9000\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.3763 - accuracy: 0.9000 - val_loss: 0.4354 - val_accuracy: 0.9000\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.3531 - accuracy: 0.9100 - val_loss: 0.4453 - val_accuracy: 0.8800\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.3542 - accuracy: 0.9025 - val_loss: 0.5063 - val_accuracy: 0.8600\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.3316 - accuracy: 0.9150 - val_loss: 0.3879 - val_accuracy: 0.9100\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.3068 - accuracy: 0.9225 - val_loss: 0.3949 - val_accuracy: 0.8900\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.2971 - accuracy: 0.9225 - val_loss: 0.4030 - val_accuracy: 0.8800\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.3307 - accuracy: 0.9175 - val_loss: 0.3889 - val_accuracy: 0.8900\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3088 - accuracy: 0.9200 - val_loss: 0.4232 - val_accuracy: 0.8900\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2703 - accuracy: 0.9200 - val_loss: 0.3872 - val_accuracy: 0.9000\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2941 - accuracy: 0.9175 - val_loss: 0.3455 - val_accuracy: 0.9300\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2675 - accuracy: 0.9200 - val_loss: 0.3617 - val_accuracy: 0.9000\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2455 - accuracy: 0.9225 - val_loss: 0.3456 - val_accuracy: 0.9200\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.2562 - accuracy: 0.9250 - val_loss: 0.3831 - val_accuracy: 0.9100\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2346 - accuracy: 0.9300 - val_loss: 0.3527 - val_accuracy: 0.9000\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2360 - accuracy: 0.9200 - val_loss: 0.3602 - val_accuracy: 0.9300\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2250 - accuracy: 0.9300 - val_loss: 0.3338 - val_accuracy: 0.9300\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2131 - accuracy: 0.9400 - val_loss: 0.3652 - val_accuracy: 0.9100\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2138 - accuracy: 0.9350 - val_loss: 0.3253 - val_accuracy: 0.9100\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2414 - accuracy: 0.9250 - val_loss: 0.3340 - val_accuracy: 0.9400\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2361 - accuracy: 0.9225 - val_loss: 0.4307 - val_accuracy: 0.8800\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.2294 - accuracy: 0.9250 - val_loss: 0.3590 - val_accuracy: 0.9000\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2227 - accuracy: 0.9375 - val_loss: 0.3634 - val_accuracy: 0.9100\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2448 - accuracy: 0.9400 - val_loss: 0.3246 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2137 - accuracy: 0.9375 - val_loss: 0.3850 - val_accuracy: 0.8900\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2004 - accuracy: 0.9400 - val_loss: 0.3232 - val_accuracy: 0.9300\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1827 - accuracy: 0.9450 - val_loss: 0.3145 - val_accuracy: 0.9300\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1600 - accuracy: 0.9500 - val_loss: 0.3234 - val_accuracy: 0.9300\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1644 - accuracy: 0.9525 - val_loss: 0.3174 - val_accuracy: 0.9100\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1613 - accuracy: 0.9475 - val_loss: 0.3177 - val_accuracy: 0.9200\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1693 - accuracy: 0.9400 - val_loss: 0.3335 - val_accuracy: 0.9100\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1486 - accuracy: 0.9575 - val_loss: 0.3158 - val_accuracy: 0.9100\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1503 - accuracy: 0.9525 - val_loss: 0.3261 - val_accuracy: 0.9100\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.1388 - accuracy: 0.9600 - val_loss: 0.3096 - val_accuracy: 0.9300\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1310 - accuracy: 0.9650 - val_loss: 0.3279 - val_accuracy: 0.9100\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1323 - accuracy: 0.9600 - val_loss: 0.3298 - val_accuracy: 0.9100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1314 - accuracy: 0.9600 - val_loss: 0.3156 - val_accuracy: 0.9300\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1215 - accuracy: 0.9600 - val_loss: 0.3848 - val_accuracy: 0.9100\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1483 - accuracy: 0.9625 - val_loss: 0.3455 - val_accuracy: 0.9100\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1293 - accuracy: 0.9600 - val_loss: 0.3542 - val_accuracy: 0.9100\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.1401 - accuracy: 0.9575 - val_loss: 0.3481 - val_accuracy: 0.9100\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1402 - accuracy: 0.9600 - val_loss: 0.3264 - val_accuracy: 0.9200\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1145 - accuracy: 0.9650 - val_loss: 0.3247 - val_accuracy: 0.9200\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1089 - accuracy: 0.9650 - val_loss: 0.3023 - val_accuracy: 0.9400\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1121 - accuracy: 0.9625 - val_loss: 0.3304 - val_accuracy: 0.9100\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1093 - accuracy: 0.9625 - val_loss: 0.3188 - val_accuracy: 0.9200\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.1180 - accuracy: 0.9600 - val_loss: 0.3302 - val_accuracy: 0.9200\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1252 - accuracy: 0.9775 - val_loss: 0.3063 - val_accuracy: 0.9400\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1342 - accuracy: 0.9550 - val_loss: 0.3293 - val_accuracy: 0.9200\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.1112 - accuracy: 0.9650 - val_loss: 0.3056 - val_accuracy: 0.9500\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.0885 - accuracy: 0.9725 - val_loss: 0.3686 - val_accuracy: 0.9100\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0993 - accuracy: 0.9725 - val_loss: 0.3604 - val_accuracy: 0.9100\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1006 - accuracy: 0.9700 - val_loss: 0.3826 - val_accuracy: 0.9100\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0950 - accuracy: 0.9775 - val_loss: 0.3088 - val_accuracy: 0.9200\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0891 - accuracy: 0.9800 - val_loss: 0.3107 - val_accuracy: 0.9200\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1326 - accuracy: 0.9550 - val_loss: 0.4267 - val_accuracy: 0.9100\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1820 - accuracy: 0.9500 - val_loss: 0.3406 - val_accuracy: 0.9100\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0883 - accuracy: 0.9725 - val_loss: 0.3092 - val_accuracy: 0.9300\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0762 - accuracy: 0.9800 - val_loss: 0.3178 - val_accuracy: 0.9200\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0714 - accuracy: 0.9825 - val_loss: 0.3105 - val_accuracy: 0.9300\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.0723 - accuracy: 0.9850 - val_loss: 0.3092 - val_accuracy: 0.9300\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0666 - accuracy: 0.9875 - val_loss: 0.3120 - val_accuracy: 0.9300\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.0650 - accuracy: 0.9900 - val_loss: 0.3183 - val_accuracy: 0.9200\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.0663 - accuracy: 0.9800 - val_loss: 0.3188 - val_accuracy: 0.9200\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.44836480596343137\n",
      "F1 Micro: 0.9341431583174381\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6011150560178169\n",
      "F1 Micro: 0.9431783957433993\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 289us/step - loss: 1.9434 - accuracy: 0.4525 - val_loss: 1.9860 - val_accuracy: 0.4400\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.7833 - accuracy: 0.5350 - val_loss: 1.8872 - val_accuracy: 0.4900\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.6717 - accuracy: 0.5925 - val_loss: 1.8157 - val_accuracy: 0.5300\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.5913 - accuracy: 0.6325 - val_loss: 1.7562 - val_accuracy: 0.5500\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.5216 - accuracy: 0.6475 - val_loss: 1.6962 - val_accuracy: 0.5900\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 1.4580 - accuracy: 0.6700 - val_loss: 1.6363 - val_accuracy: 0.6100\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.3979 - accuracy: 0.6900 - val_loss: 1.5803 - val_accuracy: 0.6500\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 1.3385 - accuracy: 0.7100 - val_loss: 1.5180 - val_accuracy: 0.6600\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.2793 - accuracy: 0.7300 - val_loss: 1.4565 - val_accuracy: 0.6800\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.2227 - accuracy: 0.7375 - val_loss: 1.3920 - val_accuracy: 0.7200\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.1631 - accuracy: 0.7600 - val_loss: 1.3276 - val_accuracy: 0.7200\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.1028 - accuracy: 0.7650 - val_loss: 1.2706 - val_accuracy: 0.7200\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.0452 - accuracy: 0.7900 - val_loss: 1.2099 - val_accuracy: 0.7200\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.9865 - accuracy: 0.8125 - val_loss: 1.1462 - val_accuracy: 0.7500\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.9291 - accuracy: 0.8300 - val_loss: 1.0833 - val_accuracy: 0.7600\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.8735 - accuracy: 0.8550 - val_loss: 1.0176 - val_accuracy: 0.7700\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.8194 - accuracy: 0.8650 - val_loss: 0.9630 - val_accuracy: 0.7800\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.7691 - accuracy: 0.8750 - val_loss: 0.9081 - val_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.7186 - accuracy: 0.8875 - val_loss: 0.8624 - val_accuracy: 0.8100\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.6724 - accuracy: 0.8900 - val_loss: 0.8138 - val_accuracy: 0.8200\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.6289 - accuracy: 0.8975 - val_loss: 0.7666 - val_accuracy: 0.8400\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.5879 - accuracy: 0.9125 - val_loss: 0.7241 - val_accuracy: 0.8500\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.5495 - accuracy: 0.9175 - val_loss: 0.6840 - val_accuracy: 0.8600\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.5154 - accuracy: 0.9225 - val_loss: 0.6504 - val_accuracy: 0.8700\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.4849 - accuracy: 0.9275 - val_loss: 0.6123 - val_accuracy: 0.8800\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.4532 - accuracy: 0.9300 - val_loss: 0.5894 - val_accuracy: 0.8900\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.4264 - accuracy: 0.9375 - val_loss: 0.5602 - val_accuracy: 0.9000\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.4015 - accuracy: 0.9425 - val_loss: 0.5365 - val_accuracy: 0.9000\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.3795 - accuracy: 0.9425 - val_loss: 0.5032 - val_accuracy: 0.9300\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.3572 - accuracy: 0.9475 - val_loss: 0.4856 - val_accuracy: 0.9300\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.3383 - accuracy: 0.9500 - val_loss: 0.4677 - val_accuracy: 0.9300\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.3197 - accuracy: 0.9500 - val_loss: 0.4456 - val_accuracy: 0.9300\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.3047 - accuracy: 0.9550 - val_loss: 0.4255 - val_accuracy: 0.9300\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2888 - accuracy: 0.9600 - val_loss: 0.4173 - val_accuracy: 0.9200\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.2760 - accuracy: 0.9600 - val_loss: 0.4058 - val_accuracy: 0.9100\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2628 - accuracy: 0.9625 - val_loss: 0.3928 - val_accuracy: 0.9200\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.2517 - accuracy: 0.9625 - val_loss: 0.3754 - val_accuracy: 0.9200\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2408 - accuracy: 0.9625 - val_loss: 0.3658 - val_accuracy: 0.9200\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2305 - accuracy: 0.9650 - val_loss: 0.3601 - val_accuracy: 0.9200\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2213 - accuracy: 0.9650 - val_loss: 0.3517 - val_accuracy: 0.9200\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2131 - accuracy: 0.9675 - val_loss: 0.3390 - val_accuracy: 0.9200\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2044 - accuracy: 0.9700 - val_loss: 0.3344 - val_accuracy: 0.9200\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.1972 - accuracy: 0.9700 - val_loss: 0.3246 - val_accuracy: 0.9300\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1906 - accuracy: 0.9725 - val_loss: 0.3174 - val_accuracy: 0.9300\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1835 - accuracy: 0.9750 - val_loss: 0.3132 - val_accuracy: 0.9300\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1772 - accuracy: 0.9725 - val_loss: 0.3081 - val_accuracy: 0.9300\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1711 - accuracy: 0.9725 - val_loss: 0.3029 - val_accuracy: 0.9300\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.1659 - accuracy: 0.9750 - val_loss: 0.2926 - val_accuracy: 0.9300\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1605 - accuracy: 0.9750 - val_loss: 0.2898 - val_accuracy: 0.9300\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.1560 - accuracy: 0.9750 - val_loss: 0.2832 - val_accuracy: 0.9300\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.1507 - accuracy: 0.9750 - val_loss: 0.2818 - val_accuracy: 0.9300\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1467 - accuracy: 0.9750 - val_loss: 0.2766 - val_accuracy: 0.9300\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1424 - accuracy: 0.9750 - val_loss: 0.2771 - val_accuracy: 0.9300\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1383 - accuracy: 0.9750 - val_loss: 0.2709 - val_accuracy: 0.9300\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1349 - accuracy: 0.9750 - val_loss: 0.2637 - val_accuracy: 0.9400\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1306 - accuracy: 0.9775 - val_loss: 0.2650 - val_accuracy: 0.9400\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1275 - accuracy: 0.9775 - val_loss: 0.2624 - val_accuracy: 0.9400\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1240 - accuracy: 0.9775 - val_loss: 0.2606 - val_accuracy: 0.9400\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1207 - accuracy: 0.9825 - val_loss: 0.2583 - val_accuracy: 0.9400\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1179 - accuracy: 0.9825 - val_loss: 0.2539 - val_accuracy: 0.9400\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1147 - accuracy: 0.9800 - val_loss: 0.2528 - val_accuracy: 0.9400\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.1123 - accuracy: 0.9800 - val_loss: 0.2512 - val_accuracy: 0.9400\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.1093 - accuracy: 0.9825 - val_loss: 0.2519 - val_accuracy: 0.9400\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1073 - accuracy: 0.9825 - val_loss: 0.2473 - val_accuracy: 0.9400\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1043 - accuracy: 0.9825 - val_loss: 0.2466 - val_accuracy: 0.9400\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1024 - accuracy: 0.9825 - val_loss: 0.2456 - val_accuracy: 0.9400\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0999 - accuracy: 0.9825 - val_loss: 0.2452 - val_accuracy: 0.9400\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0983 - accuracy: 0.9825 - val_loss: 0.2399 - val_accuracy: 0.9400\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0956 - accuracy: 0.9825 - val_loss: 0.2414 - val_accuracy: 0.9400\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0938 - accuracy: 0.9825 - val_loss: 0.2394 - val_accuracy: 0.9300\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0916 - accuracy: 0.9825 - val_loss: 0.2396 - val_accuracy: 0.9300\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0900 - accuracy: 0.9850 - val_loss: 0.2371 - val_accuracy: 0.9300\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0881 - accuracy: 0.9850 - val_loss: 0.2365 - val_accuracy: 0.9300\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0865 - accuracy: 0.9850 - val_loss: 0.2361 - val_accuracy: 0.9300\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0848 - accuracy: 0.9850 - val_loss: 0.2353 - val_accuracy: 0.9300\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.0829 - accuracy: 0.9850 - val_loss: 0.2355 - val_accuracy: 0.9300\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 84us/step - loss: 0.0814 - accuracy: 0.9850 - val_loss: 0.2342 - val_accuracy: 0.9300\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0799 - accuracy: 0.9850 - val_loss: 0.2332 - val_accuracy: 0.9300\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0785 - accuracy: 0.9850 - val_loss: 0.2325 - val_accuracy: 0.9300\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0770 - accuracy: 0.9850 - val_loss: 0.2344 - val_accuracy: 0.9300\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0755 - accuracy: 0.9850 - val_loss: 0.2331 - val_accuracy: 0.9300\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 77us/step - loss: 0.0739 - accuracy: 0.9850 - val_loss: 0.2324 - val_accuracy: 0.9300\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0730 - accuracy: 0.9850 - val_loss: 0.2323 - val_accuracy: 0.9300\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0716 - accuracy: 0.9850 - val_loss: 0.2342 - val_accuracy: 0.9300\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0702 - accuracy: 0.9850 - val_loss: 0.2336 - val_accuracy: 0.9300\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0690 - accuracy: 0.9850 - val_loss: 0.2326 - val_accuracy: 0.9300\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0679 - accuracy: 0.9850 - val_loss: 0.2328 - val_accuracy: 0.9300\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0666 - accuracy: 0.9850 - val_loss: 0.2318 - val_accuracy: 0.9300\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0656 - accuracy: 0.9850 - val_loss: 0.2324 - val_accuracy: 0.9300\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0646 - accuracy: 0.9850 - val_loss: 0.2330 - val_accuracy: 0.9300\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0632 - accuracy: 0.9850 - val_loss: 0.2321 - val_accuracy: 0.9300\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0623 - accuracy: 0.9850 - val_loss: 0.2309 - val_accuracy: 0.9300\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0612 - accuracy: 0.9850 - val_loss: 0.2324 - val_accuracy: 0.9300\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0603 - accuracy: 0.9850 - val_loss: 0.2324 - val_accuracy: 0.9300\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0593 - accuracy: 0.9875 - val_loss: 0.2327 - val_accuracy: 0.9300\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0584 - accuracy: 0.9875 - val_loss: 0.2351 - val_accuracy: 0.9300\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0574 - accuracy: 0.9875 - val_loss: 0.2354 - val_accuracy: 0.9300\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0563 - accuracy: 0.9875 - val_loss: 0.2338 - val_accuracy: 0.9300\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0554 - accuracy: 0.9875 - val_loss: 0.2349 - val_accuracy: 0.9300\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0545 - accuracy: 0.9875 - val_loss: 0.2339 - val_accuracy: 0.9300\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0536 - accuracy: 0.9875 - val_loss: 0.2355 - val_accuracy: 0.9300\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0528 - accuracy: 0.9875 - val_loss: 0.2363 - val_accuracy: 0.9200\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0519 - accuracy: 0.9875 - val_loss: 0.2368 - val_accuracy: 0.9200\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0510 - accuracy: 0.9875 - val_loss: 0.2381 - val_accuracy: 0.9200\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0503 - accuracy: 0.9875 - val_loss: 0.2394 - val_accuracy: 0.9200\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.0494 - accuracy: 0.9875 - val_loss: 0.2370 - val_accuracy: 0.9200\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0486 - accuracy: 0.9875 - val_loss: 0.2392 - val_accuracy: 0.9200\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0479 - accuracy: 0.9875 - val_loss: 0.2383 - val_accuracy: 0.9200\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0468 - accuracy: 0.9875 - val_loss: 0.2404 - val_accuracy: 0.9200\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0463 - accuracy: 0.9875 - val_loss: 0.2408 - val_accuracy: 0.9200\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0455 - accuracy: 0.9875 - val_loss: 0.2402 - val_accuracy: 0.9200\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0446 - accuracy: 0.9900 - val_loss: 0.2406 - val_accuracy: 0.9200\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6152689186043317\n",
      "F1 Micro: 0.9465917076598735\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 774us/step - loss: 1.9707 - accuracy: 0.4175 - val_loss: 1.5042 - val_accuracy: 0.7500\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 1.0309 - accuracy: 0.8050 - val_loss: 0.5774 - val_accuracy: 0.8500\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.5856 - accuracy: 0.8450 - val_loss: 0.5503 - val_accuracy: 0.8300\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.5082 - accuracy: 0.8625 - val_loss: 0.4669 - val_accuracy: 0.8700\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.4601 - accuracy: 0.8775 - val_loss: 0.4445 - val_accuracy: 0.8700\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.4287 - accuracy: 0.8825 - val_loss: 0.4200 - val_accuracy: 0.8700\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.4027 - accuracy: 0.8875 - val_loss: 0.4025 - val_accuracy: 0.8800\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.3823 - accuracy: 0.8975 - val_loss: 0.3903 - val_accuracy: 0.8800\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3647 - accuracy: 0.9000 - val_loss: 0.3716 - val_accuracy: 0.8800\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.3486 - accuracy: 0.9050 - val_loss: 0.3604 - val_accuracy: 0.9000\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.3344 - accuracy: 0.9100 - val_loss: 0.3482 - val_accuracy: 0.9000\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.3227 - accuracy: 0.9125 - val_loss: 0.3388 - val_accuracy: 0.9200\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3098 - accuracy: 0.9150 - val_loss: 0.3273 - val_accuracy: 0.9300\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.3005 - accuracy: 0.9175 - val_loss: 0.3161 - val_accuracy: 0.9400\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2899 - accuracy: 0.9200 - val_loss: 0.3074 - val_accuracy: 0.9400\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2793 - accuracy: 0.9200 - val_loss: 0.3006 - val_accuracy: 0.9400\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.2752 - accuracy: 0.9225 - val_loss: 0.2891 - val_accuracy: 0.9400\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2627 - accuracy: 0.9225 - val_loss: 0.2866 - val_accuracy: 0.9400\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2549 - accuracy: 0.9250 - val_loss: 0.2740 - val_accuracy: 0.9400\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2493 - accuracy: 0.9250 - val_loss: 0.2689 - val_accuracy: 0.9500\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2398 - accuracy: 0.9275 - val_loss: 0.2635 - val_accuracy: 0.9400\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2334 - accuracy: 0.9300 - val_loss: 0.2581 - val_accuracy: 0.9400\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2277 - accuracy: 0.9300 - val_loss: 0.2509 - val_accuracy: 0.9500\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2193 - accuracy: 0.9325 - val_loss: 0.2490 - val_accuracy: 0.9400\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.2164 - accuracy: 0.9350 - val_loss: 0.2439 - val_accuracy: 0.9400\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2096 - accuracy: 0.9350 - val_loss: 0.2380 - val_accuracy: 0.9400\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2030 - accuracy: 0.9375 - val_loss: 0.2364 - val_accuracy: 0.9500\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1944 - accuracy: 0.9350 - val_loss: 0.2309 - val_accuracy: 0.9400\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1907 - accuracy: 0.9350 - val_loss: 0.2255 - val_accuracy: 0.9500\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1858 - accuracy: 0.9425 - val_loss: 0.2282 - val_accuracy: 0.9500\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1791 - accuracy: 0.9400 - val_loss: 0.2189 - val_accuracy: 0.9500\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1745 - accuracy: 0.9400 - val_loss: 0.2204 - val_accuracy: 0.9500\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1697 - accuracy: 0.9425 - val_loss: 0.2162 - val_accuracy: 0.9500\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1682 - accuracy: 0.9425 - val_loss: 0.2136 - val_accuracy: 0.9500\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1657 - accuracy: 0.9550 - val_loss: 0.2087 - val_accuracy: 0.9500\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1565 - accuracy: 0.9450 - val_loss: 0.2084 - val_accuracy: 0.9500\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1519 - accuracy: 0.9550 - val_loss: 0.2094 - val_accuracy: 0.9500\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1477 - accuracy: 0.9550 - val_loss: 0.2049 - val_accuracy: 0.9500\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1452 - accuracy: 0.9575 - val_loss: 0.2067 - val_accuracy: 0.9500\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.1401 - accuracy: 0.9575 - val_loss: 0.2004 - val_accuracy: 0.9500\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1356 - accuracy: 0.9575 - val_loss: 0.2002 - val_accuracy: 0.9500\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1316 - accuracy: 0.9600 - val_loss: 0.1998 - val_accuracy: 0.9500\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1279 - accuracy: 0.9650 - val_loss: 0.2023 - val_accuracy: 0.9500\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1257 - accuracy: 0.9600 - val_loss: 0.2009 - val_accuracy: 0.9500\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1215 - accuracy: 0.9625 - val_loss: 0.1966 - val_accuracy: 0.9500\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1191 - accuracy: 0.9700 - val_loss: 0.1972 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1160 - accuracy: 0.9650 - val_loss: 0.1976 - val_accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1121 - accuracy: 0.9750 - val_loss: 0.1962 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1092 - accuracy: 0.9700 - val_loss: 0.1968 - val_accuracy: 0.9500\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.1057 - accuracy: 0.9750 - val_loss: 0.1962 - val_accuracy: 0.9500\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1028 - accuracy: 0.9775 - val_loss: 0.1983 - val_accuracy: 0.9500\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.1018 - accuracy: 0.9675 - val_loss: 0.1964 - val_accuracy: 0.9500\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0985 - accuracy: 0.9775 - val_loss: 0.1970 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0987 - accuracy: 0.9650 - val_loss: 0.1969 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0964 - accuracy: 0.9800 - val_loss: 0.1961 - val_accuracy: 0.9500\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0908 - accuracy: 0.9775 - val_loss: 0.1938 - val_accuracy: 0.9500\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0879 - accuracy: 0.9800 - val_loss: 0.1947 - val_accuracy: 0.9500\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0858 - accuracy: 0.9800 - val_loss: 0.2003 - val_accuracy: 0.9500\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0837 - accuracy: 0.9775 - val_loss: 0.1985 - val_accuracy: 0.9500\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0801 - accuracy: 0.9775 - val_loss: 0.1976 - val_accuracy: 0.9500\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0788 - accuracy: 0.9800 - val_loss: 0.2006 - val_accuracy: 0.9500\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0777 - accuracy: 0.9800 - val_loss: 0.2006 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0742 - accuracy: 0.9850 - val_loss: 0.2071 - val_accuracy: 0.9400\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0730 - accuracy: 0.9800 - val_loss: 0.1983 - val_accuracy: 0.9500\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0711 - accuracy: 0.9850 - val_loss: 0.2038 - val_accuracy: 0.9500\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.0721 - accuracy: 0.9800 - val_loss: 0.1939 - val_accuracy: 0.9500\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0693 - accuracy: 0.9825 - val_loss: 0.2141 - val_accuracy: 0.9500\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0688 - accuracy: 0.9825 - val_loss: 0.2097 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0697 - accuracy: 0.9850 - val_loss: 0.2164 - val_accuracy: 0.9500\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.0626 - accuracy: 0.9875 - val_loss: 0.1984 - val_accuracy: 0.9500\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0592 - accuracy: 0.9900 - val_loss: 0.2081 - val_accuracy: 0.9400\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.0566 - accuracy: 0.9950 - val_loss: 0.2058 - val_accuracy: 0.9500\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0555 - accuracy: 0.9900 - val_loss: 0.2047 - val_accuracy: 0.9500\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0528 - accuracy: 0.9950 - val_loss: 0.2154 - val_accuracy: 0.9400\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0527 - accuracy: 0.9900 - val_loss: 0.2004 - val_accuracy: 0.9500\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0520 - accuracy: 0.9925 - val_loss: 0.2247 - val_accuracy: 0.9400\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6421287844437092\n",
      "F1 Micro: 0.9455877923903223\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6326807515746692\n",
      "F1 Micro: 0.946190141552053\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6283337440776059\n",
      "F1 Micro: 0.9472944483485595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 9 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 249us/step - loss: 0.9038 - accuracy: 0.8380 - val_loss: 0.7163 - val_accuracy: 0.8350\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.6679 - accuracy: 0.8443 - val_loss: 0.6886 - val_accuracy: 0.8350\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.5925 - accuracy: 0.8447 - val_loss: 0.5586 - val_accuracy: 0.8380\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.4872 - accuracy: 0.8668 - val_loss: 0.4353 - val_accuracy: 0.8950\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.3987 - accuracy: 0.8990 - val_loss: 0.3824 - val_accuracy: 0.9120\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.3618 - accuracy: 0.9050 - val_loss: 0.3295 - val_accuracy: 0.9130\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.3112 - accuracy: 0.9145 - val_loss: 0.2972 - val_accuracy: 0.9240\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.2877 - accuracy: 0.9193 - val_loss: 0.2743 - val_accuracy: 0.9290\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.2653 - accuracy: 0.9255 - val_loss: 0.3802 - val_accuracy: 0.9090\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.2517 - accuracy: 0.9305 - val_loss: 0.2353 - val_accuracy: 0.9350\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.2239 - accuracy: 0.9375 - val_loss: 0.2205 - val_accuracy: 0.9370\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.2030 - accuracy: 0.9392 - val_loss: 0.2328 - val_accuracy: 0.9370\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.1892 - accuracy: 0.9433 - val_loss: 0.1897 - val_accuracy: 0.9420\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1681 - accuracy: 0.9490 - val_loss: 0.2020 - val_accuracy: 0.9380\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.1659 - accuracy: 0.9482 - val_loss: 0.1935 - val_accuracy: 0.9440\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1636 - accuracy: 0.9507 - val_loss: 0.1700 - val_accuracy: 0.9490\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1464 - accuracy: 0.9553 - val_loss: 0.1956 - val_accuracy: 0.9410\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1351 - accuracy: 0.9607 - val_loss: 0.1833 - val_accuracy: 0.9400\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1376 - accuracy: 0.9597 - val_loss: 0.1624 - val_accuracy: 0.9520\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1281 - accuracy: 0.9588 - val_loss: 0.1512 - val_accuracy: 0.9480\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1176 - accuracy: 0.9625 - val_loss: 0.1575 - val_accuracy: 0.9530\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1192 - accuracy: 0.9653 - val_loss: 0.1569 - val_accuracy: 0.9500\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1122 - accuracy: 0.9653 - val_loss: 0.1461 - val_accuracy: 0.9560\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.1022 - accuracy: 0.9670 - val_loss: 0.1497 - val_accuracy: 0.9530\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0985 - accuracy: 0.9710 - val_loss: 0.1402 - val_accuracy: 0.9590\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0912 - accuracy: 0.9722 - val_loss: 0.1425 - val_accuracy: 0.9580\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0908 - accuracy: 0.9710 - val_loss: 0.1357 - val_accuracy: 0.9580\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.0900 - accuracy: 0.9700 - val_loss: 0.1480 - val_accuracy: 0.9610\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0801 - accuracy: 0.9740 - val_loss: 0.1425 - val_accuracy: 0.9590\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0836 - accuracy: 0.9735 - val_loss: 0.1433 - val_accuracy: 0.9600\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0740 - accuracy: 0.9758 - val_loss: 0.1337 - val_accuracy: 0.9570\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0748 - accuracy: 0.9772 - val_loss: 0.1345 - val_accuracy: 0.9600\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.0614 - accuracy: 0.9810 - val_loss: 0.1492 - val_accuracy: 0.9620\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0616 - accuracy: 0.9805 - val_loss: 0.1419 - val_accuracy: 0.9630\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0609 - accuracy: 0.9843 - val_loss: 0.1371 - val_accuracy: 0.9600\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0545 - accuracy: 0.9833 - val_loss: 0.1384 - val_accuracy: 0.9620\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0583 - accuracy: 0.9793 - val_loss: 0.1438 - val_accuracy: 0.9600\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0577 - accuracy: 0.9818 - val_loss: 0.1466 - val_accuracy: 0.9610\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0429 - accuracy: 0.9870 - val_loss: 0.1593 - val_accuracy: 0.9500\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0421 - accuracy: 0.9877 - val_loss: 0.1391 - val_accuracy: 0.9680\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 0.1652 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0318 - accuracy: 0.9920 - val_loss: 0.1516 - val_accuracy: 0.9580\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0293 - accuracy: 0.9918 - val_loss: 0.1467 - val_accuracy: 0.9650\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0302 - accuracy: 0.9918 - val_loss: 0.1534 - val_accuracy: 0.9570\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0228 - accuracy: 0.9950 - val_loss: 0.1439 - val_accuracy: 0.9610\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0285 - accuracy: 0.9920 - val_loss: 0.1502 - val_accuracy: 0.9620\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0246 - accuracy: 0.9925 - val_loss: 0.1684 - val_accuracy: 0.9660\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0235 - accuracy: 0.9940 - val_loss: 0.1521 - val_accuracy: 0.9620\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0166 - accuracy: 0.9958 - val_loss: 0.1575 - val_accuracy: 0.9610\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.1604 - val_accuracy: 0.9660\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 0.1572 - val_accuracy: 0.9620\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6079838126400985\n",
      "F1 Micro: 0.9574\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6685912541983812\n",
      "F1 Micro: 0.957\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 92us/step - loss: 1.6345 - accuracy: 0.5623 - val_loss: 1.2317 - val_accuracy: 0.7360\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 1.0017 - accuracy: 0.8015 - val_loss: 0.7341 - val_accuracy: 0.8810\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.5860 - accuracy: 0.9003 - val_loss: 0.4550 - val_accuracy: 0.9070\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.3663 - accuracy: 0.9325 - val_loss: 0.3195 - val_accuracy: 0.9290\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.2655 - accuracy: 0.9450 - val_loss: 0.2553 - val_accuracy: 0.9380\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.2175 - accuracy: 0.9473 - val_loss: 0.2259 - val_accuracy: 0.9400\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.1919 - accuracy: 0.9485 - val_loss: 0.2065 - val_accuracy: 0.9430\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1753 - accuracy: 0.9503 - val_loss: 0.1968 - val_accuracy: 0.9440\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1645 - accuracy: 0.9513 - val_loss: 0.1886 - val_accuracy: 0.9470\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 0.1560 - accuracy: 0.9530 - val_loss: 0.1820 - val_accuracy: 0.9480\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1492 - accuracy: 0.9542 - val_loss: 0.1773 - val_accuracy: 0.9480\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1433 - accuracy: 0.9567 - val_loss: 0.1745 - val_accuracy: 0.9500\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1387 - accuracy: 0.9575 - val_loss: 0.1727 - val_accuracy: 0.9480\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1353 - accuracy: 0.9588 - val_loss: 0.1682 - val_accuracy: 0.9510\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1302 - accuracy: 0.9600 - val_loss: 0.1660 - val_accuracy: 0.9520\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1277 - accuracy: 0.9610 - val_loss: 0.1629 - val_accuracy: 0.9520\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1234 - accuracy: 0.9605 - val_loss: 0.1612 - val_accuracy: 0.9520\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.1198 - accuracy: 0.9613 - val_loss: 0.1596 - val_accuracy: 0.9520\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1184 - accuracy: 0.9640 - val_loss: 0.1570 - val_accuracy: 0.9530\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1147 - accuracy: 0.9645 - val_loss: 0.1562 - val_accuracy: 0.9550\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1119 - accuracy: 0.9657 - val_loss: 0.1545 - val_accuracy: 0.9560\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1097 - accuracy: 0.9665 - val_loss: 0.1523 - val_accuracy: 0.9560\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1072 - accuracy: 0.9668 - val_loss: 0.1505 - val_accuracy: 0.9560\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.1047 - accuracy: 0.9682 - val_loss: 0.1491 - val_accuracy: 0.9570\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1031 - accuracy: 0.9685 - val_loss: 0.1488 - val_accuracy: 0.9580\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1007 - accuracy: 0.9688 - val_loss: 0.1476 - val_accuracy: 0.9570\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0983 - accuracy: 0.9695 - val_loss: 0.1468 - val_accuracy: 0.9570\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0969 - accuracy: 0.9707 - val_loss: 0.1459 - val_accuracy: 0.9580\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0950 - accuracy: 0.9718 - val_loss: 0.1442 - val_accuracy: 0.9590\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0933 - accuracy: 0.9722 - val_loss: 0.1445 - val_accuracy: 0.9580\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0921 - accuracy: 0.9725 - val_loss: 0.1422 - val_accuracy: 0.9590\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0900 - accuracy: 0.9732 - val_loss: 0.1428 - val_accuracy: 0.9600\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0886 - accuracy: 0.9725 - val_loss: 0.1408 - val_accuracy: 0.9590\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0867 - accuracy: 0.9737 - val_loss: 0.1410 - val_accuracy: 0.9590\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0850 - accuracy: 0.9745 - val_loss: 0.1405 - val_accuracy: 0.9590\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0833 - accuracy: 0.9750 - val_loss: 0.1420 - val_accuracy: 0.9570\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0820 - accuracy: 0.9760 - val_loss: 0.1412 - val_accuracy: 0.9570\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0803 - accuracy: 0.9760 - val_loss: 0.1397 - val_accuracy: 0.9580\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0801 - accuracy: 0.9758 - val_loss: 0.1381 - val_accuracy: 0.9590\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0782 - accuracy: 0.9760 - val_loss: 0.1387 - val_accuracy: 0.9580\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0770 - accuracy: 0.9772 - val_loss: 0.1372 - val_accuracy: 0.9600\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0752 - accuracy: 0.9780 - val_loss: 0.1373 - val_accuracy: 0.9590\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0747 - accuracy: 0.9785 - val_loss: 0.1376 - val_accuracy: 0.9590\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0731 - accuracy: 0.9790 - val_loss: 0.1373 - val_accuracy: 0.9590\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0718 - accuracy: 0.9808 - val_loss: 0.1375 - val_accuracy: 0.9610\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0703 - accuracy: 0.9810 - val_loss: 0.1360 - val_accuracy: 0.9600\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0696 - accuracy: 0.9795 - val_loss: 0.1363 - val_accuracy: 0.9590\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0678 - accuracy: 0.9803 - val_loss: 0.1361 - val_accuracy: 0.9590\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0677 - accuracy: 0.9820 - val_loss: 0.1366 - val_accuracy: 0.9580\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0663 - accuracy: 0.9815 - val_loss: 0.1368 - val_accuracy: 0.9600\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0650 - accuracy: 0.9810 - val_loss: 0.1359 - val_accuracy: 0.9580\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0645 - accuracy: 0.9818 - val_loss: 0.1369 - val_accuracy: 0.9590\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0634 - accuracy: 0.9812 - val_loss: 0.1371 - val_accuracy: 0.9580\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0629 - accuracy: 0.9822 - val_loss: 0.1359 - val_accuracy: 0.9570\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0624 - accuracy: 0.9812 - val_loss: 0.1359 - val_accuracy: 0.9600\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0605 - accuracy: 0.9825 - val_loss: 0.1357 - val_accuracy: 0.9590\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0600 - accuracy: 0.9827 - val_loss: 0.1368 - val_accuracy: 0.9590\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0582 - accuracy: 0.9830 - val_loss: 0.1362 - val_accuracy: 0.9580\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 0s 79us/step - loss: 0.0583 - accuracy: 0.9837 - val_loss: 0.1367 - val_accuracy: 0.9590\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0572 - accuracy: 0.9837 - val_loss: 0.1370 - val_accuracy: 0.9600\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0562 - accuracy: 0.9830 - val_loss: 0.1365 - val_accuracy: 0.9580\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0558 - accuracy: 0.9837 - val_loss: 0.1374 - val_accuracy: 0.9580\n",
      "Epoch 63/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0543 - accuracy: 0.9843 - val_loss: 0.1389 - val_accuracy: 0.9590\n",
      "Epoch 64/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0537 - accuracy: 0.9855 - val_loss: 0.1385 - val_accuracy: 0.9590\n",
      "Epoch 65/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0528 - accuracy: 0.9852 - val_loss: 0.1385 - val_accuracy: 0.9570\n",
      "Epoch 66/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0522 - accuracy: 0.9837 - val_loss: 0.1382 - val_accuracy: 0.9580\n",
      "Epoch 67/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0513 - accuracy: 0.9862 - val_loss: 0.1386 - val_accuracy: 0.9590\n",
      "Epoch 68/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0504 - accuracy: 0.9855 - val_loss: 0.1383 - val_accuracy: 0.9560\n",
      "Epoch 69/1000\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 0.0498 - accuracy: 0.9850 - val_loss: 0.1394 - val_accuracy: 0.9570\n",
      "Epoch 70/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0488 - accuracy: 0.9852 - val_loss: 0.1384 - val_accuracy: 0.9580\n",
      "Epoch 71/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0487 - accuracy: 0.9847 - val_loss: 0.1402 - val_accuracy: 0.9560\n",
      "Epoch 72/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0478 - accuracy: 0.9858 - val_loss: 0.1399 - val_accuracy: 0.9560\n",
      "Epoch 73/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0471 - accuracy: 0.9862 - val_loss: 0.1402 - val_accuracy: 0.9560\n",
      "Epoch 74/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0463 - accuracy: 0.9875 - val_loss: 0.1404 - val_accuracy: 0.9560\n",
      "Epoch 75/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.0460 - accuracy: 0.9860 - val_loss: 0.1404 - val_accuracy: 0.9560\n",
      "Epoch 76/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 0.1408 - val_accuracy: 0.9560\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6450370761803542\n",
      "F1 Micro: 0.9598\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 250us/step - loss: 0.6688 - accuracy: 0.8102 - val_loss: 0.3755 - val_accuracy: 0.8990\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.3220 - accuracy: 0.9150 - val_loss: 0.2998 - val_accuracy: 0.9240\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.2644 - accuracy: 0.9283 - val_loss: 0.2608 - val_accuracy: 0.9330\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.2331 - accuracy: 0.9367 - val_loss: 0.2345 - val_accuracy: 0.9380\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.2105 - accuracy: 0.9417 - val_loss: 0.2179 - val_accuracy: 0.9380\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1929 - accuracy: 0.9460 - val_loss: 0.2087 - val_accuracy: 0.9430\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1799 - accuracy: 0.9475 - val_loss: 0.1964 - val_accuracy: 0.9430\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1715 - accuracy: 0.9490 - val_loss: 0.1977 - val_accuracy: 0.9450\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1619 - accuracy: 0.9532 - val_loss: 0.1858 - val_accuracy: 0.9470\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1532 - accuracy: 0.9542 - val_loss: 0.1807 - val_accuracy: 0.9520\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1515 - accuracy: 0.9557 - val_loss: 0.1761 - val_accuracy: 0.9470\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1412 - accuracy: 0.9588 - val_loss: 0.1730 - val_accuracy: 0.9520\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.1376 - accuracy: 0.9585 - val_loss: 0.1720 - val_accuracy: 0.9500\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1337 - accuracy: 0.9605 - val_loss: 0.1706 - val_accuracy: 0.9490\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1315 - accuracy: 0.9597 - val_loss: 0.1660 - val_accuracy: 0.9480\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1229 - accuracy: 0.9638 - val_loss: 0.1650 - val_accuracy: 0.9500\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1194 - accuracy: 0.9640 - val_loss: 0.1595 - val_accuracy: 0.9510\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1168 - accuracy: 0.9665 - val_loss: 0.1620 - val_accuracy: 0.9480\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.1137 - accuracy: 0.9647 - val_loss: 0.1608 - val_accuracy: 0.9530\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1100 - accuracy: 0.9663 - val_loss: 0.1577 - val_accuracy: 0.9510\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1054 - accuracy: 0.9682 - val_loss: 0.1531 - val_accuracy: 0.9510\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1016 - accuracy: 0.9705 - val_loss: 0.1561 - val_accuracy: 0.9520\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1002 - accuracy: 0.9690 - val_loss: 0.1543 - val_accuracy: 0.9520\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0941 - accuracy: 0.9722 - val_loss: 0.1541 - val_accuracy: 0.9510\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0932 - accuracy: 0.9720 - val_loss: 0.1477 - val_accuracy: 0.9550\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0897 - accuracy: 0.9735 - val_loss: 0.1460 - val_accuracy: 0.9500\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0849 - accuracy: 0.9747 - val_loss: 0.1478 - val_accuracy: 0.9510\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0814 - accuracy: 0.9760 - val_loss: 0.1468 - val_accuracy: 0.9540\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0795 - accuracy: 0.9760 - val_loss: 0.1442 - val_accuracy: 0.9520\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0762 - accuracy: 0.9783 - val_loss: 0.1490 - val_accuracy: 0.9530\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0686 - accuracy: 0.9795 - val_loss: 0.1415 - val_accuracy: 0.9520\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0623 - accuracy: 0.9820 - val_loss: 0.1486 - val_accuracy: 0.9550\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0637 - accuracy: 0.9803 - val_loss: 0.1522 - val_accuracy: 0.9540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0558 - accuracy: 0.9840 - val_loss: 0.1452 - val_accuracy: 0.9540\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0493 - accuracy: 0.9870 - val_loss: 0.1467 - val_accuracy: 0.9530\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0493 - accuracy: 0.9855 - val_loss: 0.1504 - val_accuracy: 0.9530\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0402 - accuracy: 0.9890 - val_loss: 0.1411 - val_accuracy: 0.9520\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0368 - accuracy: 0.9912 - val_loss: 0.1571 - val_accuracy: 0.9530\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0328 - accuracy: 0.9912 - val_loss: 0.1476 - val_accuracy: 0.9510\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0298 - accuracy: 0.9930 - val_loss: 0.1545 - val_accuracy: 0.9570\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0255 - accuracy: 0.9952 - val_loss: 0.1613 - val_accuracy: 0.9580\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0248 - accuracy: 0.9942 - val_loss: 0.1550 - val_accuracy: 0.9530\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0214 - accuracy: 0.9955 - val_loss: 0.1707 - val_accuracy: 0.9510\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0190 - accuracy: 0.9967 - val_loss: 0.1590 - val_accuracy: 0.9540\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0198 - accuracy: 0.9962 - val_loss: 0.1903 - val_accuracy: 0.9570\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0164 - accuracy: 0.9977 - val_loss: 0.1638 - val_accuracy: 0.9560\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0135 - accuracy: 0.9985 - val_loss: 0.1893 - val_accuracy: 0.9530\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0123 - accuracy: 0.9992 - val_loss: 0.1704 - val_accuracy: 0.9520\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0113 - accuracy: 0.9990 - val_loss: 0.1720 - val_accuracy: 0.9560\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 0.0093 - accuracy: 0.9998 - val_loss: 0.1763 - val_accuracy: 0.9540\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0086 - accuracy: 0.9998 - val_loss: 0.1868 - val_accuracy: 0.9540\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 0.1853 - val_accuracy: 0.9550\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0064 - accuracy: 0.9998 - val_loss: 0.2077 - val_accuracy: 0.9540\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0063 - accuracy: 0.9998 - val_loss: 0.2055 - val_accuracy: 0.9520\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9540\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9540\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9530\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6595443451274362\n",
      "F1 Micro: 0.9614\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6869983435586859\n",
      "F1 Micro: 0.9582\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6774445674555973\n",
      "F1 Micro: 0.9644\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 9 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.4178 - accuracy: 0.8991 - val_loss: 0.2032 - val_accuracy: 0.9398\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.1762 - accuracy: 0.9483 - val_loss: 0.1391 - val_accuracy: 0.9562\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.1395 - accuracy: 0.9578 - val_loss: 0.1258 - val_accuracy: 0.9625\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.1241 - accuracy: 0.9607 - val_loss: 0.1103 - val_accuracy: 0.9633\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.1135 - accuracy: 0.9641 - val_loss: 0.1134 - val_accuracy: 0.9646\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.1063 - accuracy: 0.9660 - val_loss: 0.1092 - val_accuracy: 0.9660\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0981 - accuracy: 0.9685 - val_loss: 0.1028 - val_accuracy: 0.9668\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0942 - accuracy: 0.9694 - val_loss: 0.0953 - val_accuracy: 0.9692\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0874 - accuracy: 0.9707 - val_loss: 0.0948 - val_accuracy: 0.9702\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0833 - accuracy: 0.9728 - val_loss: 0.0991 - val_accuracy: 0.9677\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0793 - accuracy: 0.9736 - val_loss: 0.0999 - val_accuracy: 0.9695\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0747 - accuracy: 0.9754 - val_loss: 0.0890 - val_accuracy: 0.9713\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0703 - accuracy: 0.9769 - val_loss: 0.0847 - val_accuracy: 0.9722\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0669 - accuracy: 0.9785 - val_loss: 0.0946 - val_accuracy: 0.9706\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0625 - accuracy: 0.9797 - val_loss: 0.0880 - val_accuracy: 0.9723\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0558 - accuracy: 0.9807 - val_loss: 0.0897 - val_accuracy: 0.9712\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0533 - accuracy: 0.9813 - val_loss: 0.0834 - val_accuracy: 0.9733\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0477 - accuracy: 0.9836 - val_loss: 0.0849 - val_accuracy: 0.9709\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0434 - accuracy: 0.9854 - val_loss: 0.0970 - val_accuracy: 0.9712\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0395 - accuracy: 0.9863 - val_loss: 0.0819 - val_accuracy: 0.9740\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0350 - accuracy: 0.9880 - val_loss: 0.1042 - val_accuracy: 0.9725\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0312 - accuracy: 0.9891 - val_loss: 0.0904 - val_accuracy: 0.9725\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0266 - accuracy: 0.9908 - val_loss: 0.0993 - val_accuracy: 0.9729\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.0930 - val_accuracy: 0.9732\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.1154 - val_accuracy: 0.9737\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.1065 - val_accuracy: 0.9738\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.1184 - val_accuracy: 0.9731\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.1170 - val_accuracy: 0.9727\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.1139 - val_accuracy: 0.9731\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.1296 - val_accuracy: 0.9698\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.1228 - val_accuracy: 0.9714\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.1290 - val_accuracy: 0.9708\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.1242 - val_accuracy: 0.9720\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.1334 - val_accuracy: 0.9721\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1436 - val_accuracy: 0.9699\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.1602 - val_accuracy: 0.9712\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.1482 - val_accuracy: 0.9719\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.1301 - val_accuracy: 0.9738\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.1514 - val_accuracy: 0.9706\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1460 - val_accuracy: 0.9706\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8200526237932668\n",
      "F1 Micro: 0.9744\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8024204228535515\n",
      "F1 Micro: 0.9676\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.5272 - accuracy: 0.8793 - val_loss: 0.1559 - val_accuracy: 0.9573\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.1415 - accuracy: 0.9593 - val_loss: 0.1287 - val_accuracy: 0.9623\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.1239 - accuracy: 0.9632 - val_loss: 0.1206 - val_accuracy: 0.9652\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1152 - accuracy: 0.9652 - val_loss: 0.1155 - val_accuracy: 0.9663\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1093 - accuracy: 0.9668 - val_loss: 0.1090 - val_accuracy: 0.9666\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1049 - accuracy: 0.9675 - val_loss: 0.1057 - val_accuracy: 0.9681\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1012 - accuracy: 0.9689 - val_loss: 0.1037 - val_accuracy: 0.9686\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0985 - accuracy: 0.9693 - val_loss: 0.1024 - val_accuracy: 0.9692\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0960 - accuracy: 0.9702 - val_loss: 0.1000 - val_accuracy: 0.9694\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0939 - accuracy: 0.9707 - val_loss: 0.0982 - val_accuracy: 0.9694\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0917 - accuracy: 0.9715 - val_loss: 0.0984 - val_accuracy: 0.9698\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0903 - accuracy: 0.9715 - val_loss: 0.0969 - val_accuracy: 0.9703\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0885 - accuracy: 0.9719 - val_loss: 0.0956 - val_accuracy: 0.9705\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0868 - accuracy: 0.9727 - val_loss: 0.0953 - val_accuracy: 0.9708\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0858 - accuracy: 0.9729 - val_loss: 0.0962 - val_accuracy: 0.9707\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0845 - accuracy: 0.9733 - val_loss: 0.0945 - val_accuracy: 0.9698\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0831 - accuracy: 0.9740 - val_loss: 0.0945 - val_accuracy: 0.9715\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0820 - accuracy: 0.9746 - val_loss: 0.0931 - val_accuracy: 0.9712\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0809 - accuracy: 0.9747 - val_loss: 0.0933 - val_accuracy: 0.9710\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0797 - accuracy: 0.9752 - val_loss: 0.0922 - val_accuracy: 0.9712\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0786 - accuracy: 0.9754 - val_loss: 0.0936 - val_accuracy: 0.9710\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0775 - accuracy: 0.9758 - val_loss: 0.0920 - val_accuracy: 0.9721\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0767 - accuracy: 0.9758 - val_loss: 0.0933 - val_accuracy: 0.9719\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0758 - accuracy: 0.9764 - val_loss: 0.0902 - val_accuracy: 0.9724\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0747 - accuracy: 0.9766 - val_loss: 0.0915 - val_accuracy: 0.9713\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0740 - accuracy: 0.9770 - val_loss: 0.0905 - val_accuracy: 0.9712\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0731 - accuracy: 0.9769 - val_loss: 0.0904 - val_accuracy: 0.9718\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0724 - accuracy: 0.9777 - val_loss: 0.0896 - val_accuracy: 0.9716\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0713 - accuracy: 0.9781 - val_loss: 0.0899 - val_accuracy: 0.9717\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0706 - accuracy: 0.9777 - val_loss: 0.0889 - val_accuracy: 0.9722\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0698 - accuracy: 0.9782 - val_loss: 0.0881 - val_accuracy: 0.9720\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0689 - accuracy: 0.9791 - val_loss: 0.0894 - val_accuracy: 0.9718\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0682 - accuracy: 0.9789 - val_loss: 0.0887 - val_accuracy: 0.9719\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0673 - accuracy: 0.9792 - val_loss: 0.0890 - val_accuracy: 0.9722\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0667 - accuracy: 0.9791 - val_loss: 0.0882 - val_accuracy: 0.9731\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0659 - accuracy: 0.9790 - val_loss: 0.0881 - val_accuracy: 0.9719\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0653 - accuracy: 0.9798 - val_loss: 0.0891 - val_accuracy: 0.9713\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0645 - accuracy: 0.9798 - val_loss: 0.0878 - val_accuracy: 0.9723\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0636 - accuracy: 0.9799 - val_loss: 0.0885 - val_accuracy: 0.9723\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0632 - accuracy: 0.9803 - val_loss: 0.0911 - val_accuracy: 0.9723\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0624 - accuracy: 0.9807 - val_loss: 0.0880 - val_accuracy: 0.9727\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0616 - accuracy: 0.9804 - val_loss: 0.0894 - val_accuracy: 0.9725\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0608 - accuracy: 0.9813 - val_loss: 0.0889 - val_accuracy: 0.9730\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0603 - accuracy: 0.9814 - val_loss: 0.0883 - val_accuracy: 0.9730\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0597 - accuracy: 0.9818 - val_loss: 0.0894 - val_accuracy: 0.9727\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0589 - accuracy: 0.9821 - val_loss: 0.0869 - val_accuracy: 0.9725\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0585 - accuracy: 0.9822 - val_loss: 0.0890 - val_accuracy: 0.9726\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0576 - accuracy: 0.9825 - val_loss: 0.0882 - val_accuracy: 0.9734\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0569 - accuracy: 0.9825 - val_loss: 0.0888 - val_accuracy: 0.9732\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0568 - accuracy: 0.9824 - val_loss: 0.0870 - val_accuracy: 0.9727\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0558 - accuracy: 0.9828 - val_loss: 0.0874 - val_accuracy: 0.9742\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0552 - accuracy: 0.9830 - val_loss: 0.0880 - val_accuracy: 0.9723\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0546 - accuracy: 0.9832 - val_loss: 0.0879 - val_accuracy: 0.9720\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0540 - accuracy: 0.9835 - val_loss: 0.0890 - val_accuracy: 0.9724\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0536 - accuracy: 0.9835 - val_loss: 0.0882 - val_accuracy: 0.9733\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.0881 - val_accuracy: 0.9727\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0520 - accuracy: 0.9839 - val_loss: 0.0906 - val_accuracy: 0.9720\n",
      "Epoch 58/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0518 - accuracy: 0.9840 - val_loss: 0.0892 - val_accuracy: 0.9725\n",
      "Epoch 59/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.0880 - val_accuracy: 0.9737\n",
      "Epoch 60/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0503 - accuracy: 0.9845 - val_loss: 0.0887 - val_accuracy: 0.9726\n",
      "Epoch 61/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0499 - accuracy: 0.9847 - val_loss: 0.0899 - val_accuracy: 0.9730\n",
      "Epoch 62/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0494 - accuracy: 0.9850 - val_loss: 0.0907 - val_accuracy: 0.9713\n",
      "Epoch 63/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0487 - accuracy: 0.9852 - val_loss: 0.0904 - val_accuracy: 0.9731\n",
      "Epoch 64/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0485 - accuracy: 0.9850 - val_loss: 0.0890 - val_accuracy: 0.9727\n",
      "Epoch 65/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0479 - accuracy: 0.9854 - val_loss: 0.0898 - val_accuracy: 0.9725\n",
      "Epoch 66/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0472 - accuracy: 0.9855 - val_loss: 0.0900 - val_accuracy: 0.9720\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8311197312843276\n",
      "F1 Micro: 0.9723\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.2524 - accuracy: 0.9305 - val_loss: 0.1543 - val_accuracy: 0.9567\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.1397 - accuracy: 0.9575 - val_loss: 0.1251 - val_accuracy: 0.9629\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.1203 - accuracy: 0.9637 - val_loss: 0.1158 - val_accuracy: 0.9657\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.1102 - accuracy: 0.9659 - val_loss: 0.1095 - val_accuracy: 0.9670\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.1037 - accuracy: 0.9676 - val_loss: 0.1024 - val_accuracy: 0.9694\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0989 - accuracy: 0.9686 - val_loss: 0.1002 - val_accuracy: 0.9696\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0944 - accuracy: 0.9700 - val_loss: 0.0972 - val_accuracy: 0.9703\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0889 - accuracy: 0.9721 - val_loss: 0.0932 - val_accuracy: 0.9711\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0852 - accuracy: 0.9728 - val_loss: 0.0927 - val_accuracy: 0.9716\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0811 - accuracy: 0.9732 - val_loss: 0.0883 - val_accuracy: 0.9736\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0761 - accuracy: 0.9752 - val_loss: 0.0946 - val_accuracy: 0.9704\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0713 - accuracy: 0.9762 - val_loss: 0.0944 - val_accuracy: 0.9677\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0673 - accuracy: 0.9779 - val_loss: 0.0860 - val_accuracy: 0.9738\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0607 - accuracy: 0.9803 - val_loss: 0.0839 - val_accuracy: 0.9741\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0553 - accuracy: 0.9814 - val_loss: 0.0847 - val_accuracy: 0.9743\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0496 - accuracy: 0.9837 - val_loss: 0.0848 - val_accuracy: 0.9737\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0424 - accuracy: 0.9866 - val_loss: 0.0872 - val_accuracy: 0.9748\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0356 - accuracy: 0.9886 - val_loss: 0.0972 - val_accuracy: 0.9691\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0297 - accuracy: 0.9901 - val_loss: 0.0977 - val_accuracy: 0.9746\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.1032 - val_accuracy: 0.9728\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.1193 - val_accuracy: 0.9734\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.1125 - val_accuracy: 0.9694\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.1194 - val_accuracy: 0.9675\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 0.1167 - val_accuracy: 0.9743\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.1249 - val_accuracy: 0.9724\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.1334 - val_accuracy: 0.9720\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 0.1366 - val_accuracy: 0.9717\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.1364 - val_accuracy: 0.9720\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.1369 - val_accuracy: 0.9718\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.1442 - val_accuracy: 0.9731\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.1469 - val_accuracy: 0.9732\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.1387 - val_accuracy: 0.9730\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.1517 - val_accuracy: 0.9738\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1407 - val_accuracy: 0.9735\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8329563764252301\n",
      "F1 Micro: 0.9727\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8241954295310543\n",
      "F1 Micro: 0.9702\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8413289838099349\n",
      "F1 Micro: 0.9752\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 9 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.2442 - accuracy: 0.9342 - val_loss: 0.1298 - val_accuracy: 0.9601\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.1159 - accuracy: 0.9633 - val_loss: 0.1003 - val_accuracy: 0.9677\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0974 - accuracy: 0.9685 - val_loss: 0.0914 - val_accuracy: 0.9698\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0881 - accuracy: 0.9711 - val_loss: 0.0852 - val_accuracy: 0.9720\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0785 - accuracy: 0.9735 - val_loss: 0.0776 - val_accuracy: 0.9742\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0707 - accuracy: 0.9759 - val_loss: 0.0877 - val_accuracy: 0.9714\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0645 - accuracy: 0.9780 - val_loss: 0.0858 - val_accuracy: 0.9701\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0593 - accuracy: 0.9794 - val_loss: 0.0729 - val_accuracy: 0.9751\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0552 - accuracy: 0.9806 - val_loss: 0.0728 - val_accuracy: 0.9754\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0510 - accuracy: 0.9820 - val_loss: 0.0681 - val_accuracy: 0.9766\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0469 - accuracy: 0.9832 - val_loss: 0.0637 - val_accuracy: 0.9788\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0438 - accuracy: 0.9841 - val_loss: 0.0705 - val_accuracy: 0.9774\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0391 - accuracy: 0.9859 - val_loss: 0.0681 - val_accuracy: 0.9770\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0355 - accuracy: 0.9875 - val_loss: 0.0733 - val_accuracy: 0.9766\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0319 - accuracy: 0.9884 - val_loss: 0.0705 - val_accuracy: 0.9766\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0270 - accuracy: 0.9901 - val_loss: 0.0788 - val_accuracy: 0.9742\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0231 - accuracy: 0.9915 - val_loss: 0.0803 - val_accuracy: 0.9774\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0200 - accuracy: 0.9929 - val_loss: 0.0832 - val_accuracy: 0.9775\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0174 - accuracy: 0.9938 - val_loss: 0.0966 - val_accuracy: 0.9742\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.1055 - val_accuracy: 0.9712\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0915 - val_accuracy: 0.9776\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.1047 - val_accuracy: 0.9737\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.1179 - val_accuracy: 0.9774\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.1011 - val_accuracy: 0.9773\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.1258 - val_accuracy: 0.9770\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1167 - val_accuracy: 0.9759\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1174 - val_accuracy: 0.9762\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.1136 - val_accuracy: 0.9764\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.1410 - val_accuracy: 0.9766\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.1390 - val_accuracy: 0.9773\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 25s 189us/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.1322 - val_accuracy: 0.9732\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8907974838018698\n",
      "F1 Micro: 0.9798\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8443582651855802\n",
      "F1 Micro: 0.9722\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.2510 - accuracy: 0.9363 - val_loss: 0.1230 - val_accuracy: 0.9631\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 9s 65us/step - loss: 0.1139 - accuracy: 0.9646 - val_loss: 0.1083 - val_accuracy: 0.9664\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.1041 - accuracy: 0.9670 - val_loss: 0.1035 - val_accuracy: 0.9676\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0986 - accuracy: 0.9687 - val_loss: 0.0992 - val_accuracy: 0.9695\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0946 - accuracy: 0.9701 - val_loss: 0.0964 - val_accuracy: 0.9690\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 8s 65us/step - loss: 0.0918 - accuracy: 0.9707 - val_loss: 0.0939 - val_accuracy: 0.9706\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 8s 65us/step - loss: 0.0893 - accuracy: 0.9718 - val_loss: 0.0925 - val_accuracy: 0.9707\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 8s 65us/step - loss: 0.0872 - accuracy: 0.9722 - val_loss: 0.0911 - val_accuracy: 0.9708\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 8s 65us/step - loss: 0.0853 - accuracy: 0.9726 - val_loss: 0.0907 - val_accuracy: 0.9710\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0836 - accuracy: 0.9729 - val_loss: 0.0900 - val_accuracy: 0.9713\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0822 - accuracy: 0.9734 - val_loss: 0.0897 - val_accuracy: 0.9721\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0806 - accuracy: 0.9738 - val_loss: 0.0882 - val_accuracy: 0.9716\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0794 - accuracy: 0.9744 - val_loss: 0.0888 - val_accuracy: 0.9710\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0783 - accuracy: 0.9747 - val_loss: 0.0874 - val_accuracy: 0.9725\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 8s 65us/step - loss: 0.0774 - accuracy: 0.9750 - val_loss: 0.0859 - val_accuracy: 0.9724\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0761 - accuracy: 0.9754 - val_loss: 0.0861 - val_accuracy: 0.9716\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0751 - accuracy: 0.9755 - val_loss: 0.0853 - val_accuracy: 0.9730\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 8s 65us/step - loss: 0.0741 - accuracy: 0.9760 - val_loss: 0.0850 - val_accuracy: 0.9729\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0732 - accuracy: 0.9763 - val_loss: 0.0850 - val_accuracy: 0.9729\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 9s 65us/step - loss: 0.0723 - accuracy: 0.9765 - val_loss: 0.0851 - val_accuracy: 0.9727\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0715 - accuracy: 0.9767 - val_loss: 0.0845 - val_accuracy: 0.9736\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 8s 65us/step - loss: 0.0709 - accuracy: 0.9768 - val_loss: 0.0849 - val_accuracy: 0.9729\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0698 - accuracy: 0.9770 - val_loss: 0.0839 - val_accuracy: 0.9732\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 9s 65us/step - loss: 0.0691 - accuracy: 0.9777 - val_loss: 0.0835 - val_accuracy: 0.9734\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0684 - accuracy: 0.9777 - val_loss: 0.0836 - val_accuracy: 0.9729\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0676 - accuracy: 0.9780 - val_loss: 0.0841 - val_accuracy: 0.9726\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 9s 65us/step - loss: 0.0672 - accuracy: 0.9780 - val_loss: 0.0832 - val_accuracy: 0.9727\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0663 - accuracy: 0.9786 - val_loss: 0.0830 - val_accuracy: 0.9733\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0657 - accuracy: 0.9788 - val_loss: 0.0829 - val_accuracy: 0.9734\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 8s 65us/step - loss: 0.0651 - accuracy: 0.9788 - val_loss: 0.0826 - val_accuracy: 0.9729\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0643 - accuracy: 0.9792 - val_loss: 0.0845 - val_accuracy: 0.9734\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0636 - accuracy: 0.9792 - val_loss: 0.0834 - val_accuracy: 0.9730\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0630 - accuracy: 0.9798 - val_loss: 0.0825 - val_accuracy: 0.9735\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0624 - accuracy: 0.9798 - val_loss: 0.0837 - val_accuracy: 0.9732\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0618 - accuracy: 0.9799 - val_loss: 0.0817 - val_accuracy: 0.9738\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0612 - accuracy: 0.9802 - val_loss: 0.0832 - val_accuracy: 0.9734\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 8s 65us/step - loss: 0.0606 - accuracy: 0.9802 - val_loss: 0.0831 - val_accuracy: 0.9729\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0600 - accuracy: 0.9804 - val_loss: 0.0830 - val_accuracy: 0.9737\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 9s 65us/step - loss: 0.0593 - accuracy: 0.9807 - val_loss: 0.0827 - val_accuracy: 0.9728\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0588 - accuracy: 0.9808 - val_loss: 0.0842 - val_accuracy: 0.9726\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0585 - accuracy: 0.9811 - val_loss: 0.0832 - val_accuracy: 0.9736\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0577 - accuracy: 0.9813 - val_loss: 0.0835 - val_accuracy: 0.9733\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 8s 65us/step - loss: 0.0571 - accuracy: 0.9816 - val_loss: 0.0831 - val_accuracy: 0.9736\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 8s 65us/step - loss: 0.0565 - accuracy: 0.9816 - val_loss: 0.0848 - val_accuracy: 0.9731\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0559 - accuracy: 0.9818 - val_loss: 0.0842 - val_accuracy: 0.9734\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 9s 65us/step - loss: 0.0556 - accuracy: 0.9819 - val_loss: 0.0840 - val_accuracy: 0.9739\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0550 - accuracy: 0.9820 - val_loss: 0.0832 - val_accuracy: 0.9736\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0544 - accuracy: 0.9825 - val_loss: 0.0849 - val_accuracy: 0.9733\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0539 - accuracy: 0.9825 - val_loss: 0.0855 - val_accuracy: 0.9735\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 9s 67us/step - loss: 0.0534 - accuracy: 0.9829 - val_loss: 0.0846 - val_accuracy: 0.9737\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0529 - accuracy: 0.9832 - val_loss: 0.0854 - val_accuracy: 0.9735\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0523 - accuracy: 0.9830 - val_loss: 0.0843 - val_accuracy: 0.9732\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0517 - accuracy: 0.9833 - val_loss: 0.0853 - val_accuracy: 0.9732\n",
      "Epoch 54/1000\n",
      "130356/130356 [==============================] - 8s 65us/step - loss: 0.0512 - accuracy: 0.9835 - val_loss: 0.0865 - val_accuracy: 0.9727\n",
      "Epoch 55/1000\n",
      "130356/130356 [==============================] - 9s 66us/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.0855 - val_accuracy: 0.9732\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8649814139566724\n",
      "F1 Micro: 0.9759\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.1654 - accuracy: 0.9513 - val_loss: 0.1122 - val_accuracy: 0.9651\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.1021 - accuracy: 0.9675 - val_loss: 0.0918 - val_accuracy: 0.9707\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0873 - accuracy: 0.9715 - val_loss: 0.0858 - val_accuracy: 0.9731\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0794 - accuracy: 0.9740 - val_loss: 0.0831 - val_accuracy: 0.9738\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.0737 - accuracy: 0.9759 - val_loss: 0.0800 - val_accuracy: 0.9726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0676 - accuracy: 0.9775 - val_loss: 0.0733 - val_accuracy: 0.9761\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0625 - accuracy: 0.9789 - val_loss: 0.0751 - val_accuracy: 0.9749\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0568 - accuracy: 0.9809 - val_loss: 0.0732 - val_accuracy: 0.9761\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0510 - accuracy: 0.9829 - val_loss: 0.0679 - val_accuracy: 0.9765\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0450 - accuracy: 0.9843 - val_loss: 0.0721 - val_accuracy: 0.9768\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0391 - accuracy: 0.9865 - val_loss: 0.0756 - val_accuracy: 0.9767\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0329 - accuracy: 0.9885 - val_loss: 0.0717 - val_accuracy: 0.9774\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 0.0798 - val_accuracy: 0.9777\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0210 - accuracy: 0.9928 - val_loss: 0.0997 - val_accuracy: 0.9761\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.0975 - val_accuracy: 0.9780\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0928 - val_accuracy: 0.9776\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.1069 - val_accuracy: 0.9768\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.1115 - val_accuracy: 0.9769\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.1057 - val_accuracy: 0.9769\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1173 - val_accuracy: 0.9767\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.1282 - val_accuracy: 0.9770\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.1316 - val_accuracy: 0.9770\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1307 - val_accuracy: 0.9768\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1382 - val_accuracy: 0.9775\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1379 - val_accuracy: 0.9771\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1451 - val_accuracy: 0.9777\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1395 - val_accuracy: 0.9756\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.1513 - val_accuracy: 0.9771\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1428 - val_accuracy: 0.9768\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8734119042351352\n",
      "F1 Micro: 0.9777\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8442975653755302\n",
      "F1 Micro: 0.9715\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8987579695271819\n",
      "F1 Micro: 0.9814\n",
      "\n",
      "\n",
      " 53.5521143913269 min per replication\n",
      "\n",
      "\n",
      "\n",
      " &&&&&&&&&&&&&&&&&&&& 10 replication &&&&&&&&&&&&&&&&&&&& \n",
      "\n",
      "\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 10 replication 500 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.9505 - accuracy: 0.7850 - val_loss: 1.4404 - val_accuracy: 0.9300\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 1.0251 - accuracy: 0.8600 - val_loss: 0.4472 - val_accuracy: 0.9300\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.7981 - accuracy: 0.8600 - val_loss: 0.4113 - val_accuracy: 0.9300\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.7289 - accuracy: 0.8600 - val_loss: 0.4315 - val_accuracy: 0.9300\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.6864 - accuracy: 0.8600 - val_loss: 0.4224 - val_accuracy: 0.9300\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.6690 - accuracy: 0.8600 - val_loss: 0.3933 - val_accuracy: 0.9300\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.6487 - accuracy: 0.8600 - val_loss: 0.4022 - val_accuracy: 0.9300\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.6390 - accuracy: 0.8600 - val_loss: 0.4020 - val_accuracy: 0.9300\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.6334 - accuracy: 0.8600 - val_loss: 0.3917 - val_accuracy: 0.9300\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.6292 - accuracy: 0.8600 - val_loss: 0.4063 - val_accuracy: 0.9300\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.6306 - accuracy: 0.8600 - val_loss: 0.3991 - val_accuracy: 0.9300\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.6226 - accuracy: 0.8600 - val_loss: 0.3932 - val_accuracy: 0.9300\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.6183 - accuracy: 0.8600 - val_loss: 0.3993 - val_accuracy: 0.9300\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.6140 - accuracy: 0.8600 - val_loss: 0.3966 - val_accuracy: 0.9300\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.6129 - accuracy: 0.8600 - val_loss: 0.3851 - val_accuracy: 0.9300\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.6089 - accuracy: 0.8600 - val_loss: 0.4002 - val_accuracy: 0.9300\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.6299 - accuracy: 0.8600 - val_loss: 0.3684 - val_accuracy: 0.9300\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.6116 - accuracy: 0.8600 - val_loss: 0.4085 - val_accuracy: 0.9300\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.5981 - accuracy: 0.8600 - val_loss: 0.3826 - val_accuracy: 0.9300\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.5933 - accuracy: 0.8600 - val_loss: 0.3721 - val_accuracy: 0.9300\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.5852 - accuracy: 0.8600 - val_loss: 0.4062 - val_accuracy: 0.9300\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.5830 - accuracy: 0.8600 - val_loss: 0.3988 - val_accuracy: 0.9300\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.5704 - accuracy: 0.8600 - val_loss: 0.3593 - val_accuracy: 0.9300\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.5545 - accuracy: 0.8600 - val_loss: 0.3568 - val_accuracy: 0.9300\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.5483 - accuracy: 0.8600 - val_loss: 0.3627 - val_accuracy: 0.9300\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.5353 - accuracy: 0.8600 - val_loss: 0.3361 - val_accuracy: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.5297 - accuracy: 0.8600 - val_loss: 0.3825 - val_accuracy: 0.9300\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.5131 - accuracy: 0.8600 - val_loss: 0.3376 - val_accuracy: 0.9300\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.5013 - accuracy: 0.8600 - val_loss: 0.3190 - val_accuracy: 0.9300\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.4883 - accuracy: 0.8600 - val_loss: 0.3345 - val_accuracy: 0.9300\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.4647 - accuracy: 0.8600 - val_loss: 0.2950 - val_accuracy: 0.9300\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.4798 - accuracy: 0.8600 - val_loss: 0.2981 - val_accuracy: 0.9300\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.4700 - accuracy: 0.8650 - val_loss: 0.2995 - val_accuracy: 0.9300\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.4421 - accuracy: 0.8625 - val_loss: 0.2946 - val_accuracy: 0.9300\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.4338 - accuracy: 0.8650 - val_loss: 0.3032 - val_accuracy: 0.9300\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.4142 - accuracy: 0.8650 - val_loss: 0.2789 - val_accuracy: 0.9300\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.4139 - accuracy: 0.8650 - val_loss: 0.2691 - val_accuracy: 0.9200\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.3928 - accuracy: 0.8750 - val_loss: 0.2899 - val_accuracy: 0.9500\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.3976 - accuracy: 0.8750 - val_loss: 0.3636 - val_accuracy: 0.9600\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.4253 - accuracy: 0.8850 - val_loss: 0.3902 - val_accuracy: 0.9700\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3998 - accuracy: 0.8850 - val_loss: 0.3955 - val_accuracy: 0.9500\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.3706 - accuracy: 0.8975 - val_loss: 0.2524 - val_accuracy: 0.9300\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.3579 - accuracy: 0.8950 - val_loss: 0.3122 - val_accuracy: 0.9500\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.3745 - accuracy: 0.8900 - val_loss: 0.2588 - val_accuracy: 0.9500\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.3354 - accuracy: 0.8975 - val_loss: 0.2547 - val_accuracy: 0.9300\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.3395 - accuracy: 0.9050 - val_loss: 0.2442 - val_accuracy: 0.9300\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.3251 - accuracy: 0.9050 - val_loss: 0.3057 - val_accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3353 - accuracy: 0.9025 - val_loss: 0.2844 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3020 - accuracy: 0.9075 - val_loss: 0.2426 - val_accuracy: 0.9500\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.2962 - accuracy: 0.9150 - val_loss: 0.2622 - val_accuracy: 0.9500\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.3044 - accuracy: 0.9025 - val_loss: 0.2538 - val_accuracy: 0.9500\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2872 - accuracy: 0.9175 - val_loss: 0.2542 - val_accuracy: 0.9500\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2859 - accuracy: 0.9050 - val_loss: 0.2494 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2753 - accuracy: 0.9100 - val_loss: 0.2778 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2773 - accuracy: 0.9075 - val_loss: 0.3157 - val_accuracy: 0.9500\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.2782 - accuracy: 0.9100 - val_loss: 0.2660 - val_accuracy: 0.9500\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2674 - accuracy: 0.9200 - val_loss: 0.2362 - val_accuracy: 0.9500\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2529 - accuracy: 0.9225 - val_loss: 0.2427 - val_accuracy: 0.9500\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2581 - accuracy: 0.9125 - val_loss: 0.2558 - val_accuracy: 0.9500\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.3033 - accuracy: 0.9075 - val_loss: 0.3277 - val_accuracy: 0.9600\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.2722 - accuracy: 0.9100 - val_loss: 0.3235 - val_accuracy: 0.9600\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2399 - accuracy: 0.9250 - val_loss: 0.2344 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.2314 - accuracy: 0.9150 - val_loss: 0.2375 - val_accuracy: 0.9500\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2463 - accuracy: 0.9125 - val_loss: 0.2320 - val_accuracy: 0.9500\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2562 - accuracy: 0.9125 - val_loss: 0.2307 - val_accuracy: 0.9500\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.2533 - accuracy: 0.9200 - val_loss: 0.2340 - val_accuracy: 0.9500\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2321 - accuracy: 0.9200 - val_loss: 0.2315 - val_accuracy: 0.9500\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2155 - accuracy: 0.9225 - val_loss: 0.2451 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2091 - accuracy: 0.9350 - val_loss: 0.2430 - val_accuracy: 0.9500\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.2208 - accuracy: 0.9225 - val_loss: 0.2345 - val_accuracy: 0.9500\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2064 - accuracy: 0.9225 - val_loss: 0.2391 - val_accuracy: 0.9400\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2228 - accuracy: 0.9325 - val_loss: 0.2327 - val_accuracy: 0.9500\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2004 - accuracy: 0.9300 - val_loss: 0.2291 - val_accuracy: 0.9500\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.1968 - accuracy: 0.9325 - val_loss: 0.2320 - val_accuracy: 0.9500\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2191 - accuracy: 0.9275 - val_loss: 0.2341 - val_accuracy: 0.9500\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.2157 - accuracy: 0.9225 - val_loss: 0.2254 - val_accuracy: 0.9500\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1881 - accuracy: 0.9400 - val_loss: 0.2332 - val_accuracy: 0.9500\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1814 - accuracy: 0.9375 - val_loss: 0.2533 - val_accuracy: 0.9600\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1830 - accuracy: 0.9300 - val_loss: 0.2329 - val_accuracy: 0.9500\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1790 - accuracy: 0.9325 - val_loss: 0.2296 - val_accuracy: 0.9500\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1824 - accuracy: 0.9300 - val_loss: 0.2305 - val_accuracy: 0.9500\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1640 - accuracy: 0.9375 - val_loss: 0.2326 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1627 - accuracy: 0.9400 - val_loss: 0.2619 - val_accuracy: 0.9600\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1760 - accuracy: 0.9400 - val_loss: 0.2783 - val_accuracy: 0.9400\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1660 - accuracy: 0.9400 - val_loss: 0.2432 - val_accuracy: 0.9500\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1705 - accuracy: 0.9350 - val_loss: 0.2283 - val_accuracy: 0.9500\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1866 - accuracy: 0.9325 - val_loss: 0.2349 - val_accuracy: 0.9500\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1754 - accuracy: 0.9425 - val_loss: 0.2286 - val_accuracy: 0.9500\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.1559 - accuracy: 0.9375 - val_loss: 0.2565 - val_accuracy: 0.9600\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1520 - accuracy: 0.9450 - val_loss: 0.2965 - val_accuracy: 0.9300\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1379 - accuracy: 0.9450 - val_loss: 0.2294 - val_accuracy: 0.9500\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1458 - accuracy: 0.9450 - val_loss: 0.2349 - val_accuracy: 0.9500\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1431 - accuracy: 0.9400 - val_loss: 0.2456 - val_accuracy: 0.9600\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1637 - accuracy: 0.9400 - val_loss: 0.2244 - val_accuracy: 0.9500\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1892 - accuracy: 0.9450 - val_loss: 0.2222 - val_accuracy: 0.9500\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.1507 - accuracy: 0.9475 - val_loss: 0.2145 - val_accuracy: 0.9500\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1422 - accuracy: 0.9450 - val_loss: 0.2250 - val_accuracy: 0.9500\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.2124 - accuracy: 0.9375 - val_loss: 0.2160 - val_accuracy: 0.9600\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1561 - accuracy: 0.9425 - val_loss: 0.2203 - val_accuracy: 0.9500\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1416 - accuracy: 0.9525 - val_loss: 0.2248 - val_accuracy: 0.9500\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1272 - accuracy: 0.9475 - val_loss: 0.2477 - val_accuracy: 0.9500\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1227 - accuracy: 0.9500 - val_loss: 0.2674 - val_accuracy: 0.9500\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.1194 - accuracy: 0.9575 - val_loss: 0.2544 - val_accuracy: 0.9400\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1288 - accuracy: 0.9550 - val_loss: 0.2738 - val_accuracy: 0.9400\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1219 - accuracy: 0.9600 - val_loss: 0.2799 - val_accuracy: 0.9300\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.1184 - accuracy: 0.9525 - val_loss: 0.2931 - val_accuracy: 0.9300\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1140 - accuracy: 0.9625 - val_loss: 0.2321 - val_accuracy: 0.9500\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1429 - accuracy: 0.9550 - val_loss: 0.2339 - val_accuracy: 0.9600\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.1078 - accuracy: 0.9550 - val_loss: 0.2169 - val_accuracy: 0.9500\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.1024 - accuracy: 0.9575 - val_loss: 0.2218 - val_accuracy: 0.9500\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.0996 - accuracy: 0.9750 - val_loss: 0.2349 - val_accuracy: 0.9600\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1018 - accuracy: 0.9700 - val_loss: 0.2452 - val_accuracy: 0.9500\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.0924 - accuracy: 0.9700 - val_loss: 0.2426 - val_accuracy: 0.9500\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1117 - accuracy: 0.9600 - val_loss: 0.2236 - val_accuracy: 0.9500\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 221us/step - loss: 0.1033 - accuracy: 0.9700 - val_loss: 0.2221 - val_accuracy: 0.9500\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 0.0918 - accuracy: 0.9700 - val_loss: 0.2298 - val_accuracy: 0.9500\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.44427864149133056\n",
      "F1 Micro: 0.9199879530167653\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5350608430245885\n",
      "F1 Micro: 0.9356210294632584\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 287us/step - loss: 2.2387 - accuracy: 0.2100 - val_loss: 2.1987 - val_accuracy: 0.3800\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 2.0159 - accuracy: 0.4525 - val_loss: 2.0277 - val_accuracy: 0.4500\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.8675 - accuracy: 0.5325 - val_loss: 1.9156 - val_accuracy: 0.5100\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 1.7651 - accuracy: 0.5650 - val_loss: 1.8370 - val_accuracy: 0.5300\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.6892 - accuracy: 0.5900 - val_loss: 1.7703 - val_accuracy: 0.5600\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.6237 - accuracy: 0.6175 - val_loss: 1.7134 - val_accuracy: 0.5900\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.5635 - accuracy: 0.6275 - val_loss: 1.6593 - val_accuracy: 0.5900\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.5071 - accuracy: 0.6450 - val_loss: 1.6069 - val_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.4501 - accuracy: 0.6775 - val_loss: 1.5507 - val_accuracy: 0.6200\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.3933 - accuracy: 0.7025 - val_loss: 1.4976 - val_accuracy: 0.6200\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 1.3368 - accuracy: 0.7125 - val_loss: 1.4440 - val_accuracy: 0.6400\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 1.2804 - accuracy: 0.7375 - val_loss: 1.3847 - val_accuracy: 0.6700\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 1.2233 - accuracy: 0.7450 - val_loss: 1.3289 - val_accuracy: 0.7000\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 1.1671 - accuracy: 0.7600 - val_loss: 1.2740 - val_accuracy: 0.7200\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.1100 - accuracy: 0.7750 - val_loss: 1.2171 - val_accuracy: 0.7500\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 1.0543 - accuracy: 0.8075 - val_loss: 1.1593 - val_accuracy: 0.7500\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 1.0002 - accuracy: 0.8300 - val_loss: 1.0996 - val_accuracy: 0.7700\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.9439 - accuracy: 0.8400 - val_loss: 1.0458 - val_accuracy: 0.7800\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.8907 - accuracy: 0.8600 - val_loss: 0.9921 - val_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.8404 - accuracy: 0.8750 - val_loss: 0.9380 - val_accuracy: 0.8200\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.7914 - accuracy: 0.8950 - val_loss: 0.8890 - val_accuracy: 0.8300\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.7463 - accuracy: 0.9050 - val_loss: 0.8404 - val_accuracy: 0.8400\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.7021 - accuracy: 0.9150 - val_loss: 0.7939 - val_accuracy: 0.8500\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.6604 - accuracy: 0.9250 - val_loss: 0.7528 - val_accuracy: 0.8700\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.6214 - accuracy: 0.9375 - val_loss: 0.7093 - val_accuracy: 0.8800\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.5845 - accuracy: 0.9450 - val_loss: 0.6720 - val_accuracy: 0.9000\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.5497 - accuracy: 0.9475 - val_loss: 0.6354 - val_accuracy: 0.9000\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.5178 - accuracy: 0.9475 - val_loss: 0.6000 - val_accuracy: 0.9000\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.4865 - accuracy: 0.9475 - val_loss: 0.5697 - val_accuracy: 0.9100\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.4584 - accuracy: 0.9550 - val_loss: 0.5390 - val_accuracy: 0.9100\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.4335 - accuracy: 0.9550 - val_loss: 0.5096 - val_accuracy: 0.9100\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.4079 - accuracy: 0.9575 - val_loss: 0.4878 - val_accuracy: 0.9100\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.3846 - accuracy: 0.9625 - val_loss: 0.4648 - val_accuracy: 0.9200\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.3644 - accuracy: 0.9625 - val_loss: 0.4399 - val_accuracy: 0.9200\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.3426 - accuracy: 0.9650 - val_loss: 0.4216 - val_accuracy: 0.9200\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.3238 - accuracy: 0.9650 - val_loss: 0.4045 - val_accuracy: 0.9200\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.3064 - accuracy: 0.9675 - val_loss: 0.3858 - val_accuracy: 0.9200\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2932 - accuracy: 0.9625 - val_loss: 0.3672 - val_accuracy: 0.9300\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 71us/step - loss: 0.2751 - accuracy: 0.9650 - val_loss: 0.3537 - val_accuracy: 0.9300\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.2616 - accuracy: 0.9675 - val_loss: 0.3428 - val_accuracy: 0.9300\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.2484 - accuracy: 0.9675 - val_loss: 0.3275 - val_accuracy: 0.9400\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2363 - accuracy: 0.9675 - val_loss: 0.3166 - val_accuracy: 0.9400\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.2251 - accuracy: 0.9675 - val_loss: 0.3054 - val_accuracy: 0.9500\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.2143 - accuracy: 0.9700 - val_loss: 0.2958 - val_accuracy: 0.9500\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.2050 - accuracy: 0.9750 - val_loss: 0.2852 - val_accuracy: 0.9500\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.1957 - accuracy: 0.9800 - val_loss: 0.2768 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1871 - accuracy: 0.9800 - val_loss: 0.2694 - val_accuracy: 0.9500\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.1790 - accuracy: 0.9800 - val_loss: 0.2593 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1719 - accuracy: 0.9825 - val_loss: 0.2534 - val_accuracy: 0.9500\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1653 - accuracy: 0.9825 - val_loss: 0.2453 - val_accuracy: 0.9500\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1584 - accuracy: 0.9850 - val_loss: 0.2413 - val_accuracy: 0.9500\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1526 - accuracy: 0.9825 - val_loss: 0.2372 - val_accuracy: 0.9500\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1470 - accuracy: 0.9825 - val_loss: 0.2294 - val_accuracy: 0.9500\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1412 - accuracy: 0.9825 - val_loss: 0.2254 - val_accuracy: 0.9500\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1363 - accuracy: 0.9850 - val_loss: 0.2212 - val_accuracy: 0.9500\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1318 - accuracy: 0.9850 - val_loss: 0.2190 - val_accuracy: 0.9500\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1271 - accuracy: 0.9850 - val_loss: 0.2151 - val_accuracy: 0.9500\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1231 - accuracy: 0.9875 - val_loss: 0.2111 - val_accuracy: 0.9500\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.1194 - accuracy: 0.9900 - val_loss: 0.2073 - val_accuracy: 0.9500\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.1152 - accuracy: 0.9925 - val_loss: 0.2036 - val_accuracy: 0.9500\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1120 - accuracy: 0.9925 - val_loss: 0.2002 - val_accuracy: 0.9500\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.1084 - accuracy: 0.9900 - val_loss: 0.1977 - val_accuracy: 0.9500\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.1050 - accuracy: 0.9925 - val_loss: 0.1932 - val_accuracy: 0.9500\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.1021 - accuracy: 0.9925 - val_loss: 0.1909 - val_accuracy: 0.9500\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.0993 - accuracy: 0.9925 - val_loss: 0.1904 - val_accuracy: 0.9500\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0964 - accuracy: 0.9925 - val_loss: 0.1877 - val_accuracy: 0.9500\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0940 - accuracy: 0.9925 - val_loss: 0.1847 - val_accuracy: 0.9500\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0909 - accuracy: 0.9925 - val_loss: 0.1845 - val_accuracy: 0.9500\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0885 - accuracy: 0.9925 - val_loss: 0.1836 - val_accuracy: 0.9500\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0863 - accuracy: 0.9925 - val_loss: 0.1806 - val_accuracy: 0.9500\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0839 - accuracy: 0.9925 - val_loss: 0.1792 - val_accuracy: 0.9500\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0819 - accuracy: 0.9925 - val_loss: 0.1800 - val_accuracy: 0.9500\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0797 - accuracy: 0.9925 - val_loss: 0.1774 - val_accuracy: 0.9500\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0778 - accuracy: 0.9925 - val_loss: 0.1762 - val_accuracy: 0.9500\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0757 - accuracy: 0.9925 - val_loss: 0.1761 - val_accuracy: 0.9500\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 82us/step - loss: 0.0739 - accuracy: 0.9925 - val_loss: 0.1734 - val_accuracy: 0.9500\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0723 - accuracy: 0.9925 - val_loss: 0.1725 - val_accuracy: 0.9500\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0704 - accuracy: 0.9925 - val_loss: 0.1715 - val_accuracy: 0.9500\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0689 - accuracy: 0.9925 - val_loss: 0.1702 - val_accuracy: 0.9500\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0672 - accuracy: 0.9925 - val_loss: 0.1706 - val_accuracy: 0.9500\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0657 - accuracy: 0.9925 - val_loss: 0.1690 - val_accuracy: 0.9500\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0643 - accuracy: 0.9925 - val_loss: 0.1683 - val_accuracy: 0.9500\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0630 - accuracy: 0.9950 - val_loss: 0.1672 - val_accuracy: 0.9500\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0614 - accuracy: 0.9950 - val_loss: 0.1660 - val_accuracy: 0.9500\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0601 - accuracy: 0.9950 - val_loss: 0.1659 - val_accuracy: 0.9500\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0587 - accuracy: 0.9950 - val_loss: 0.1648 - val_accuracy: 0.9500\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0574 - accuracy: 0.9950 - val_loss: 0.1656 - val_accuracy: 0.9500\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0563 - accuracy: 0.9950 - val_loss: 0.1650 - val_accuracy: 0.9500\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0551 - accuracy: 0.9950 - val_loss: 0.1644 - val_accuracy: 0.9500\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0539 - accuracy: 0.9950 - val_loss: 0.1645 - val_accuracy: 0.9500\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0527 - accuracy: 0.9950 - val_loss: 0.1628 - val_accuracy: 0.9500\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0516 - accuracy: 0.9950 - val_loss: 0.1611 - val_accuracy: 0.9500\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0506 - accuracy: 0.9950 - val_loss: 0.1608 - val_accuracy: 0.9500\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0495 - accuracy: 0.9950 - val_loss: 0.1606 - val_accuracy: 0.9500\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0488 - accuracy: 0.9950 - val_loss: 0.1608 - val_accuracy: 0.9500\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0476 - accuracy: 0.9950 - val_loss: 0.1599 - val_accuracy: 0.9500\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0467 - accuracy: 0.9950 - val_loss: 0.1586 - val_accuracy: 0.9500\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0456 - accuracy: 0.9950 - val_loss: 0.1583 - val_accuracy: 0.9500\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0448 - accuracy: 0.9975 - val_loss: 0.1573 - val_accuracy: 0.9500\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0439 - accuracy: 0.9975 - val_loss: 0.1574 - val_accuracy: 0.9500\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0431 - accuracy: 0.9975 - val_loss: 0.1568 - val_accuracy: 0.9500\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0422 - accuracy: 0.9975 - val_loss: 0.1576 - val_accuracy: 0.9500\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0414 - accuracy: 0.9975 - val_loss: 0.1569 - val_accuracy: 0.9500\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0405 - accuracy: 0.9975 - val_loss: 0.1554 - val_accuracy: 0.9500\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0400 - accuracy: 0.9975 - val_loss: 0.1557 - val_accuracy: 0.9500\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0391 - accuracy: 0.9975 - val_loss: 0.1544 - val_accuracy: 0.9500\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0383 - accuracy: 0.9975 - val_loss: 0.1539 - val_accuracy: 0.9500\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0377 - accuracy: 0.9975 - val_loss: 0.1543 - val_accuracy: 0.9500\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0369 - accuracy: 0.9975 - val_loss: 0.1547 - val_accuracy: 0.9500\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0363 - accuracy: 0.9975 - val_loss: 0.1541 - val_accuracy: 0.9500\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0354 - accuracy: 0.9975 - val_loss: 0.1537 - val_accuracy: 0.9500\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 0s 71us/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9500\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 0s 83us/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9500\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9500\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9500\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9500\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9500\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9500\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9500\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9500\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9500\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9500\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9500\n",
      "Epoch 124/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9500\n",
      "Epoch 125/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9500\n",
      "Epoch 126/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9400\n",
      "Epoch 127/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9400\n",
      "Epoch 128/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9400\n",
      "Epoch 129/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9400\n",
      "Epoch 130/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9400\n",
      "Epoch 131/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9400\n",
      "Epoch 133/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9400\n",
      "Epoch 134/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9400\n",
      "Epoch 135/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9400\n",
      "Epoch 136/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9400\n",
      "Epoch 137/1000\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9400\n",
      "Epoch 138/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9400\n",
      "Epoch 139/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9400\n",
      "Epoch 140/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9400\n",
      "Epoch 141/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 0.9400\n",
      "Epoch 142/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9400\n",
      "Epoch 143/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9400\n",
      "Epoch 144/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9400\n",
      "Epoch 145/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9400\n",
      "Epoch 146/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9400\n",
      "Epoch 147/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9400\n",
      "Epoch 148/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9400\n",
      "Epoch 149/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9400\n",
      "Epoch 150/1000\n",
      "400/400 [==============================] - 0s 81us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9400\n",
      "Epoch 151/1000\n",
      "400/400 [==============================] - 0s 78us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 0.9400\n",
      "Epoch 152/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9400\n",
      "Epoch 153/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9400\n",
      "Epoch 154/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9400\n",
      "Epoch 155/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9400\n",
      "Epoch 156/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9400\n",
      "Epoch 157/1000\n",
      "400/400 [==============================] - 0s 73us/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9400\n",
      "Epoch 158/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9400\n",
      "Epoch 159/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9400\n",
      "Epoch 160/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9400\n",
      "Epoch 161/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9400\n",
      "Epoch 162/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9400\n",
      "Epoch 163/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9400\n",
      "Epoch 164/1000\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9400\n",
      "Epoch 165/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9400\n",
      "Epoch 166/1000\n",
      "400/400 [==============================] - 0s 82us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 0.9400\n",
      "Epoch 167/1000\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9400\n",
      "Epoch 168/1000\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9400\n",
      "Epoch 169/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9400\n",
      "Epoch 170/1000\n",
      "400/400 [==============================] - 0s 79us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9400\n",
      "Epoch 171/1000\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9400\n",
      "Epoch 172/1000\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9400\n",
      "Epoch 173/1000\n",
      "400/400 [==============================] - 0s 76us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9400\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.641627024998182\n",
      "F1 Micro: 0.946290533079008\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 0s 753us/step - loss: 2.0608 - accuracy: 0.2825 - val_loss: 1.6050 - val_accuracy: 0.7900\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 0s 226us/step - loss: 1.1032 - accuracy: 0.8425 - val_loss: 0.4025 - val_accuracy: 0.9300\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.4916 - accuracy: 0.8625 - val_loss: 0.2493 - val_accuracy: 0.9500\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.4537 - accuracy: 0.8725 - val_loss: 0.2402 - val_accuracy: 0.9500\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 0s 229us/step - loss: 0.3876 - accuracy: 0.8850 - val_loss: 0.2403 - val_accuracy: 0.9500\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 0s 227us/step - loss: 0.3626 - accuracy: 0.8925 - val_loss: 0.2249 - val_accuracy: 0.9600\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 0s 228us/step - loss: 0.3408 - accuracy: 0.8975 - val_loss: 0.2080 - val_accuracy: 0.9500\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 0s 223us/step - loss: 0.3208 - accuracy: 0.9050 - val_loss: 0.2014 - val_accuracy: 0.9500\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 0s 225us/step - loss: 0.3057 - accuracy: 0.9150 - val_loss: 0.1930 - val_accuracy: 0.9600\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2898 - accuracy: 0.9200 - val_loss: 0.1823 - val_accuracy: 0.9600\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2787 - accuracy: 0.9250 - val_loss: 0.1787 - val_accuracy: 0.9600\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.2667 - accuracy: 0.9325 - val_loss: 0.1804 - val_accuracy: 0.9600\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 0s 222us/step - loss: 0.2561 - accuracy: 0.9350 - val_loss: 0.1693 - val_accuracy: 0.9600\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2472 - accuracy: 0.9375 - val_loss: 0.1705 - val_accuracy: 0.9600\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2363 - accuracy: 0.9350 - val_loss: 0.1602 - val_accuracy: 0.9700\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2306 - accuracy: 0.9400 - val_loss: 0.1607 - val_accuracy: 0.9600\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.2237 - accuracy: 0.9450 - val_loss: 0.1560 - val_accuracy: 0.9700\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.2147 - accuracy: 0.9475 - val_loss: 0.1577 - val_accuracy: 0.9700\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2081 - accuracy: 0.9500 - val_loss: 0.1535 - val_accuracy: 0.9700\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.2021 - accuracy: 0.9450 - val_loss: 0.1476 - val_accuracy: 0.9700\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1951 - accuracy: 0.9500 - val_loss: 0.1499 - val_accuracy: 0.9700\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1908 - accuracy: 0.9500 - val_loss: 0.1448 - val_accuracy: 0.9700\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1853 - accuracy: 0.9475 - val_loss: 0.1400 - val_accuracy: 0.9700\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1819 - accuracy: 0.9500 - val_loss: 0.1481 - val_accuracy: 0.9700\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1768 - accuracy: 0.9525 - val_loss: 0.1392 - val_accuracy: 0.9700\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1696 - accuracy: 0.9525 - val_loss: 0.1390 - val_accuracy: 0.9700\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1680 - accuracy: 0.9525 - val_loss: 0.1385 - val_accuracy: 0.9700\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1621 - accuracy: 0.9575 - val_loss: 0.1382 - val_accuracy: 0.9700\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1599 - accuracy: 0.9575 - val_loss: 0.1343 - val_accuracy: 0.9700\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1536 - accuracy: 0.9575 - val_loss: 0.1321 - val_accuracy: 0.9700\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1493 - accuracy: 0.9600 - val_loss: 0.1337 - val_accuracy: 0.9700\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1450 - accuracy: 0.9650 - val_loss: 0.1323 - val_accuracy: 0.9700\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1426 - accuracy: 0.9600 - val_loss: 0.1317 - val_accuracy: 0.9700\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1406 - accuracy: 0.9625 - val_loss: 0.1291 - val_accuracy: 0.9700\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1366 - accuracy: 0.9600 - val_loss: 0.1271 - val_accuracy: 0.9700\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 0s 224us/step - loss: 0.1311 - accuracy: 0.9650 - val_loss: 0.1314 - val_accuracy: 0.9700\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1292 - accuracy: 0.9675 - val_loss: 0.1277 - val_accuracy: 0.9700\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1255 - accuracy: 0.9650 - val_loss: 0.1265 - val_accuracy: 0.9700\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.1231 - accuracy: 0.9675 - val_loss: 0.1267 - val_accuracy: 0.9700\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.1227 - accuracy: 0.9650 - val_loss: 0.1309 - val_accuracy: 0.9700\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1175 - accuracy: 0.9650 - val_loss: 0.1240 - val_accuracy: 0.9700\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1142 - accuracy: 0.9675 - val_loss: 0.1298 - val_accuracy: 0.9700\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.1114 - accuracy: 0.9650 - val_loss: 0.1230 - val_accuracy: 0.9700\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1114 - accuracy: 0.9700 - val_loss: 0.1243 - val_accuracy: 0.9700\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.1051 - accuracy: 0.9675 - val_loss: 0.1217 - val_accuracy: 0.9700\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.1020 - accuracy: 0.9675 - val_loss: 0.1234 - val_accuracy: 0.9700\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.1001 - accuracy: 0.9750 - val_loss: 0.1211 - val_accuracy: 0.9700\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0999 - accuracy: 0.9675 - val_loss: 0.1207 - val_accuracy: 0.9700\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 0s 220us/step - loss: 0.0952 - accuracy: 0.9675 - val_loss: 0.1216 - val_accuracy: 0.9700\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0936 - accuracy: 0.9700 - val_loss: 0.1207 - val_accuracy: 0.9700\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0906 - accuracy: 0.9800 - val_loss: 0.1207 - val_accuracy: 0.9700\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0880 - accuracy: 0.9675 - val_loss: 0.1217 - val_accuracy: 0.9700\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0859 - accuracy: 0.9775 - val_loss: 0.1202 - val_accuracy: 0.9700\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0850 - accuracy: 0.9750 - val_loss: 0.1201 - val_accuracy: 0.9700\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0839 - accuracy: 0.9775 - val_loss: 0.1268 - val_accuracy: 0.9800\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0814 - accuracy: 0.9775 - val_loss: 0.1202 - val_accuracy: 0.9700\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0778 - accuracy: 0.9750 - val_loss: 0.1226 - val_accuracy: 0.9700\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0765 - accuracy: 0.9825 - val_loss: 0.1201 - val_accuracy: 0.9700\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0724 - accuracy: 0.9850 - val_loss: 0.1204 - val_accuracy: 0.9700\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0709 - accuracy: 0.9850 - val_loss: 0.1199 - val_accuracy: 0.9700\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0729 - accuracy: 0.9775 - val_loss: 0.1276 - val_accuracy: 0.9800\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0680 - accuracy: 0.9850 - val_loss: 0.1244 - val_accuracy: 0.9700\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0694 - accuracy: 0.9825 - val_loss: 0.1336 - val_accuracy: 0.9800\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0736 - accuracy: 0.9825 - val_loss: 0.1204 - val_accuracy: 0.9700\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0633 - accuracy: 0.9850 - val_loss: 0.1258 - val_accuracy: 0.9800\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0621 - accuracy: 0.9850 - val_loss: 0.1222 - val_accuracy: 0.9700\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0617 - accuracy: 0.9875 - val_loss: 0.1171 - val_accuracy: 0.9700\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0641 - accuracy: 0.9800 - val_loss: 0.1218 - val_accuracy: 0.9700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0592 - accuracy: 0.9825 - val_loss: 0.1206 - val_accuracy: 0.9700\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0550 - accuracy: 0.9875 - val_loss: 0.1206 - val_accuracy: 0.9700\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0559 - accuracy: 0.9850 - val_loss: 0.1236 - val_accuracy: 0.9700\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0532 - accuracy: 0.9875 - val_loss: 0.1168 - val_accuracy: 0.9700\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 0s 218us/step - loss: 0.0508 - accuracy: 0.9825 - val_loss: 0.1202 - val_accuracy: 0.9700\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0498 - accuracy: 0.9900 - val_loss: 0.1245 - val_accuracy: 0.9700\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 0s 209us/step - loss: 0.0496 - accuracy: 0.9875 - val_loss: 0.1330 - val_accuracy: 0.9700\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 0s 216us/step - loss: 0.0631 - accuracy: 0.9825 - val_loss: 0.1203 - val_accuracy: 0.9700\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0509 - accuracy: 0.9875 - val_loss: 0.1226 - val_accuracy: 0.9700\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 0s 215us/step - loss: 0.0444 - accuracy: 0.9925 - val_loss: 0.1278 - val_accuracy: 0.9700\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0456 - accuracy: 0.9900 - val_loss: 0.1254 - val_accuracy: 0.9700\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0404 - accuracy: 0.9900 - val_loss: 0.1259 - val_accuracy: 0.9600\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0424 - accuracy: 0.9875 - val_loss: 0.1220 - val_accuracy: 0.9600\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0416 - accuracy: 0.9925 - val_loss: 0.1241 - val_accuracy: 0.9700\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.0439 - accuracy: 0.9925 - val_loss: 0.1249 - val_accuracy: 0.9700\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0397 - accuracy: 0.9925 - val_loss: 0.1265 - val_accuracy: 0.9600\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0389 - accuracy: 0.9925 - val_loss: 0.1237 - val_accuracy: 0.9600\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.0351 - accuracy: 0.9975 - val_loss: 0.1251 - val_accuracy: 0.9600\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0331 - accuracy: 0.9950 - val_loss: 0.1228 - val_accuracy: 0.9600\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.0329 - accuracy: 0.9925 - val_loss: 0.1238 - val_accuracy: 0.9600\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 0s 212us/step - loss: 0.0329 - accuracy: 0.9950 - val_loss: 0.1264 - val_accuracy: 0.9600\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.0311 - accuracy: 0.9975 - val_loss: 0.1237 - val_accuracy: 0.9600\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 0s 210us/step - loss: 0.0304 - accuracy: 0.9950 - val_loss: 0.1276 - val_accuracy: 0.9600\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 0s 219us/step - loss: 0.0314 - accuracy: 0.9975 - val_loss: 0.1257 - val_accuracy: 0.9600\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6042787804001001\n",
      "F1 Micro: 0.9434795703242645\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5714044863017058\n",
      "F1 Micro: 0.9391226051723275\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.5567482971507466\n",
      "F1 Micro: 0.9417237756990647\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 10 replication 5000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 250us/step - loss: 0.8420 - accuracy: 0.8470 - val_loss: 0.6645 - val_accuracy: 0.8500\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.6430 - accuracy: 0.8503 - val_loss: 0.6148 - val_accuracy: 0.8500\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.5913 - accuracy: 0.8500 - val_loss: 0.5424 - val_accuracy: 0.8500\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.5037 - accuracy: 0.8615 - val_loss: 0.4301 - val_accuracy: 0.8960\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.4074 - accuracy: 0.9018 - val_loss: 0.3760 - val_accuracy: 0.9030\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.3686 - accuracy: 0.9070 - val_loss: 0.3344 - val_accuracy: 0.9110\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.3621 - accuracy: 0.9072 - val_loss: 0.3309 - val_accuracy: 0.9110\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.3313 - accuracy: 0.9120 - val_loss: 0.3069 - val_accuracy: 0.9140\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.3106 - accuracy: 0.9195 - val_loss: 0.2873 - val_accuracy: 0.9180\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.2899 - accuracy: 0.9225 - val_loss: 0.2845 - val_accuracy: 0.9200\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.2820 - accuracy: 0.9245 - val_loss: 0.2851 - val_accuracy: 0.9220\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.2666 - accuracy: 0.9280 - val_loss: 0.2546 - val_accuracy: 0.9260\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.2489 - accuracy: 0.9323 - val_loss: 0.2398 - val_accuracy: 0.9320\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.2198 - accuracy: 0.9400 - val_loss: 0.2371 - val_accuracy: 0.9320\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.2144 - accuracy: 0.9405 - val_loss: 0.2260 - val_accuracy: 0.9330\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1998 - accuracy: 0.9423 - val_loss: 0.2092 - val_accuracy: 0.9410\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1830 - accuracy: 0.9473 - val_loss: 0.2163 - val_accuracy: 0.9370\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1865 - accuracy: 0.9480 - val_loss: 0.2019 - val_accuracy: 0.9380\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1663 - accuracy: 0.9528 - val_loss: 0.1940 - val_accuracy: 0.9430\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1544 - accuracy: 0.9538 - val_loss: 0.1938 - val_accuracy: 0.9390\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1505 - accuracy: 0.9567 - val_loss: 0.1911 - val_accuracy: 0.9440\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1374 - accuracy: 0.9600 - val_loss: 0.1842 - val_accuracy: 0.9430\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1379 - accuracy: 0.9613 - val_loss: 0.1849 - val_accuracy: 0.9430\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.1274 - accuracy: 0.9635 - val_loss: 0.1873 - val_accuracy: 0.9400\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.1277 - accuracy: 0.9617 - val_loss: 0.1884 - val_accuracy: 0.9380\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1164 - accuracy: 0.9650 - val_loss: 0.1864 - val_accuracy: 0.9390\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.1196 - accuracy: 0.9650 - val_loss: 0.1771 - val_accuracy: 0.9460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.1097 - accuracy: 0.9653 - val_loss: 0.1846 - val_accuracy: 0.9450\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1065 - accuracy: 0.9670 - val_loss: 0.1667 - val_accuracy: 0.9490\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1098 - accuracy: 0.9675 - val_loss: 0.1899 - val_accuracy: 0.9410\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.1076 - accuracy: 0.9678 - val_loss: 0.1936 - val_accuracy: 0.9460\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0893 - accuracy: 0.9735 - val_loss: 0.2580 - val_accuracy: 0.9150\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0907 - accuracy: 0.9728 - val_loss: 0.1743 - val_accuracy: 0.9510\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0764 - accuracy: 0.9760 - val_loss: 0.1973 - val_accuracy: 0.9440\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.0823 - accuracy: 0.9750 - val_loss: 0.1961 - val_accuracy: 0.9500\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0689 - accuracy: 0.9810 - val_loss: 0.1817 - val_accuracy: 0.9430\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0749 - accuracy: 0.9778 - val_loss: 0.1894 - val_accuracy: 0.9470\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0730 - accuracy: 0.9745 - val_loss: 0.1826 - val_accuracy: 0.9480\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0567 - accuracy: 0.9835 - val_loss: 0.1697 - val_accuracy: 0.9530\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0524 - accuracy: 0.9843 - val_loss: 0.1690 - val_accuracy: 0.9550\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0573 - accuracy: 0.9835 - val_loss: 0.1658 - val_accuracy: 0.9520\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.0506 - accuracy: 0.9847 - val_loss: 0.1642 - val_accuracy: 0.9540\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0473 - accuracy: 0.9858 - val_loss: 0.1779 - val_accuracy: 0.9530\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0387 - accuracy: 0.9895 - val_loss: 0.1686 - val_accuracy: 0.9510\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0365 - accuracy: 0.9900 - val_loss: 0.2008 - val_accuracy: 0.9500\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.0347 - accuracy: 0.9915 - val_loss: 0.1833 - val_accuracy: 0.9550\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0367 - accuracy: 0.9893 - val_loss: 0.2231 - val_accuracy: 0.9460\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0301 - accuracy: 0.9918 - val_loss: 0.1892 - val_accuracy: 0.9510\n",
      "Epoch 49/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0303 - accuracy: 0.9923 - val_loss: 0.1869 - val_accuracy: 0.9540\n",
      "Epoch 50/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0268 - accuracy: 0.9930 - val_loss: 0.2026 - val_accuracy: 0.9420\n",
      "Epoch 51/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.1945 - val_accuracy: 0.9490\n",
      "Epoch 52/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0371 - accuracy: 0.9890 - val_loss: 0.1847 - val_accuracy: 0.9530\n",
      "Epoch 53/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0191 - accuracy: 0.9955 - val_loss: 0.1918 - val_accuracy: 0.9520\n",
      "Epoch 54/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0183 - accuracy: 0.9958 - val_loss: 0.2260 - val_accuracy: 0.9540\n",
      "Epoch 55/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0147 - accuracy: 0.9975 - val_loss: 0.2041 - val_accuracy: 0.9510\n",
      "Epoch 56/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0160 - accuracy: 0.9980 - val_loss: 0.1894 - val_accuracy: 0.9530\n",
      "Epoch 57/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.2659 - val_accuracy: 0.9500\n",
      "Epoch 58/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 0.2330 - val_accuracy: 0.9520\n",
      "Epoch 59/1000\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.0088 - accuracy: 0.9992 - val_loss: 0.2334 - val_accuracy: 0.9510\n",
      "Epoch 60/1000\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.0191 - accuracy: 0.9967 - val_loss: 0.2858 - val_accuracy: 0.9430\n",
      "Epoch 61/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0189 - accuracy: 0.9967 - val_loss: 0.2084 - val_accuracy: 0.9540\n",
      "Epoch 62/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0078 - accuracy: 0.9990 - val_loss: 0.2156 - val_accuracy: 0.9550\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7058039984758747\n",
      "F1 Micro: 0.956\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6751715402473712\n",
      "F1 Micro: 0.9539\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 0s 92us/step - loss: 1.6219 - accuracy: 0.5767 - val_loss: 1.2306 - val_accuracy: 0.7230\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.9846 - accuracy: 0.8133 - val_loss: 0.7237 - val_accuracy: 0.8750\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.5674 - accuracy: 0.9043 - val_loss: 0.4324 - val_accuracy: 0.9140\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.3632 - accuracy: 0.9342 - val_loss: 0.3031 - val_accuracy: 0.9370\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.2702 - accuracy: 0.9457 - val_loss: 0.2450 - val_accuracy: 0.9410\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.2239 - accuracy: 0.9495 - val_loss: 0.2153 - val_accuracy: 0.9470\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1978 - accuracy: 0.9498 - val_loss: 0.1989 - val_accuracy: 0.9470\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1803 - accuracy: 0.9532 - val_loss: 0.1921 - val_accuracy: 0.9480\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.1681 - accuracy: 0.9550 - val_loss: 0.1823 - val_accuracy: 0.9490\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1589 - accuracy: 0.9563 - val_loss: 0.1768 - val_accuracy: 0.9480\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1516 - accuracy: 0.9588 - val_loss: 0.1760 - val_accuracy: 0.9470\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.1450 - accuracy: 0.9592 - val_loss: 0.1716 - val_accuracy: 0.9490\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 0s 69us/step - loss: 0.1395 - accuracy: 0.9613 - val_loss: 0.1688 - val_accuracy: 0.9490\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1353 - accuracy: 0.9640 - val_loss: 0.1697 - val_accuracy: 0.9470\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.1310 - accuracy: 0.9638 - val_loss: 0.1654 - val_accuracy: 0.9480\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1269 - accuracy: 0.9655 - val_loss: 0.1664 - val_accuracy: 0.9470\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 0s 70us/step - loss: 0.1225 - accuracy: 0.9670 - val_loss: 0.1645 - val_accuracy: 0.9470\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1201 - accuracy: 0.9672 - val_loss: 0.1648 - val_accuracy: 0.9460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1172 - accuracy: 0.9685 - val_loss: 0.1666 - val_accuracy: 0.9460\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.1145 - accuracy: 0.9688 - val_loss: 0.1627 - val_accuracy: 0.9470\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1124 - accuracy: 0.9697 - val_loss: 0.1643 - val_accuracy: 0.9450\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1097 - accuracy: 0.9700 - val_loss: 0.1648 - val_accuracy: 0.9470\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1074 - accuracy: 0.9700 - val_loss: 0.1656 - val_accuracy: 0.9440\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.1051 - accuracy: 0.9707 - val_loss: 0.1646 - val_accuracy: 0.9460\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.1032 - accuracy: 0.9700 - val_loss: 0.1673 - val_accuracy: 0.9430\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.1015 - accuracy: 0.9712 - val_loss: 0.1642 - val_accuracy: 0.9450\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0998 - accuracy: 0.9710 - val_loss: 0.1642 - val_accuracy: 0.9470\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0972 - accuracy: 0.9707 - val_loss: 0.1641 - val_accuracy: 0.9450\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0959 - accuracy: 0.9725 - val_loss: 0.1667 - val_accuracy: 0.9440\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 0.0943 - accuracy: 0.9732 - val_loss: 0.1685 - val_accuracy: 0.9440\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 0.0922 - accuracy: 0.9730 - val_loss: 0.1664 - val_accuracy: 0.9450\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0912 - accuracy: 0.9740 - val_loss: 0.1661 - val_accuracy: 0.9450\n",
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0897 - accuracy: 0.9728 - val_loss: 0.1658 - val_accuracy: 0.9440\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 0s 76us/step - loss: 0.0876 - accuracy: 0.9743 - val_loss: 0.1705 - val_accuracy: 0.9450\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 0s 77us/step - loss: 0.0867 - accuracy: 0.9753 - val_loss: 0.1667 - val_accuracy: 0.9490\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 0.0849 - accuracy: 0.9758 - val_loss: 0.1705 - val_accuracy: 0.9460\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 0.0841 - accuracy: 0.9762 - val_loss: 0.1693 - val_accuracy: 0.9460\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0817 - accuracy: 0.9770 - val_loss: 0.1674 - val_accuracy: 0.9410\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 0.0815 - accuracy: 0.9775 - val_loss: 0.1694 - val_accuracy: 0.9450\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 0.0798 - accuracy: 0.9785 - val_loss: 0.1699 - val_accuracy: 0.9460\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6686776091479523\n",
      "F1 Micro: 0.9574\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "4000/4000 [==============================] - 1s 252us/step - loss: 0.6278 - accuracy: 0.8307 - val_loss: 0.3325 - val_accuracy: 0.9140\n",
      "Epoch 2/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.3116 - accuracy: 0.9172 - val_loss: 0.2750 - val_accuracy: 0.9260\n",
      "Epoch 3/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.2612 - accuracy: 0.9300 - val_loss: 0.2595 - val_accuracy: 0.9350\n",
      "Epoch 4/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.2299 - accuracy: 0.9370 - val_loss: 0.2208 - val_accuracy: 0.9380\n",
      "Epoch 5/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.2076 - accuracy: 0.9438 - val_loss: 0.2148 - val_accuracy: 0.9410\n",
      "Epoch 6/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.1935 - accuracy: 0.9465 - val_loss: 0.1963 - val_accuracy: 0.9450\n",
      "Epoch 7/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.1764 - accuracy: 0.9503 - val_loss: 0.1860 - val_accuracy: 0.9440\n",
      "Epoch 8/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1670 - accuracy: 0.9520 - val_loss: 0.1810 - val_accuracy: 0.9460\n",
      "Epoch 9/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.1593 - accuracy: 0.9528 - val_loss: 0.1761 - val_accuracy: 0.9440\n",
      "Epoch 10/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.1507 - accuracy: 0.9560 - val_loss: 0.1781 - val_accuracy: 0.9450\n",
      "Epoch 11/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.1448 - accuracy: 0.9580 - val_loss: 0.1703 - val_accuracy: 0.9490\n",
      "Epoch 12/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.1379 - accuracy: 0.9605 - val_loss: 0.1684 - val_accuracy: 0.9480\n",
      "Epoch 13/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1327 - accuracy: 0.9613 - val_loss: 0.1648 - val_accuracy: 0.9500\n",
      "Epoch 14/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.1283 - accuracy: 0.9622 - val_loss: 0.1634 - val_accuracy: 0.9480\n",
      "Epoch 15/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1252 - accuracy: 0.9638 - val_loss: 0.1650 - val_accuracy: 0.9480\n",
      "Epoch 16/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1198 - accuracy: 0.9655 - val_loss: 0.1610 - val_accuracy: 0.9490\n",
      "Epoch 17/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.1172 - accuracy: 0.9643 - val_loss: 0.1618 - val_accuracy: 0.9520\n",
      "Epoch 18/1000\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 0.1137 - accuracy: 0.9663 - val_loss: 0.1620 - val_accuracy: 0.9500\n",
      "Epoch 19/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.1094 - accuracy: 0.9678 - val_loss: 0.1620 - val_accuracy: 0.9500\n",
      "Epoch 20/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.1075 - accuracy: 0.9682 - val_loss: 0.1631 - val_accuracy: 0.9480\n",
      "Epoch 21/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.1027 - accuracy: 0.9685 - val_loss: 0.1582 - val_accuracy: 0.9520\n",
      "Epoch 22/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.1000 - accuracy: 0.9690 - val_loss: 0.1665 - val_accuracy: 0.9500\n",
      "Epoch 23/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0979 - accuracy: 0.9707 - val_loss: 0.1611 - val_accuracy: 0.9520\n",
      "Epoch 24/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0932 - accuracy: 0.9720 - val_loss: 0.1639 - val_accuracy: 0.9510\n",
      "Epoch 25/1000\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.0912 - accuracy: 0.9730 - val_loss: 0.1617 - val_accuracy: 0.9490\n",
      "Epoch 26/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0889 - accuracy: 0.9735 - val_loss: 0.1705 - val_accuracy: 0.9500\n",
      "Epoch 27/1000\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.0850 - accuracy: 0.9745 - val_loss: 0.1692 - val_accuracy: 0.9520\n",
      "Epoch 28/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.0844 - accuracy: 0.9740 - val_loss: 0.1558 - val_accuracy: 0.9510\n",
      "Epoch 29/1000\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.0794 - accuracy: 0.9743 - val_loss: 0.1590 - val_accuracy: 0.9500\n",
      "Epoch 30/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0756 - accuracy: 0.9762 - val_loss: 0.1642 - val_accuracy: 0.9480\n",
      "Epoch 31/1000\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 0.0753 - accuracy: 0.9775 - val_loss: 0.1735 - val_accuracy: 0.9520\n",
      "Epoch 32/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.0699 - accuracy: 0.9790 - val_loss: 0.1580 - val_accuracy: 0.9540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0638 - accuracy: 0.9810 - val_loss: 0.1665 - val_accuracy: 0.9520\n",
      "Epoch 34/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0636 - accuracy: 0.9790 - val_loss: 0.1666 - val_accuracy: 0.9510\n",
      "Epoch 35/1000\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.0572 - accuracy: 0.9837 - val_loss: 0.1610 - val_accuracy: 0.9500\n",
      "Epoch 36/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0552 - accuracy: 0.9830 - val_loss: 0.1610 - val_accuracy: 0.9510\n",
      "Epoch 37/1000\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.0479 - accuracy: 0.9868 - val_loss: 0.1643 - val_accuracy: 0.9510\n",
      "Epoch 38/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0453 - accuracy: 0.9877 - val_loss: 0.1901 - val_accuracy: 0.9520\n",
      "Epoch 39/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0412 - accuracy: 0.9895 - val_loss: 0.1636 - val_accuracy: 0.9490\n",
      "Epoch 40/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.0343 - accuracy: 0.9923 - val_loss: 0.1800 - val_accuracy: 0.9520\n",
      "Epoch 41/1000\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.0302 - accuracy: 0.9933 - val_loss: 0.1957 - val_accuracy: 0.9520\n",
      "Epoch 42/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0296 - accuracy: 0.9935 - val_loss: 0.1863 - val_accuracy: 0.9520\n",
      "Epoch 43/1000\n",
      "4000/4000 [==============================] - 1s 192us/step - loss: 0.0251 - accuracy: 0.9950 - val_loss: 0.1747 - val_accuracy: 0.9500\n",
      "Epoch 44/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0249 - accuracy: 0.9948 - val_loss: 0.1717 - val_accuracy: 0.9500\n",
      "Epoch 45/1000\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 0.0209 - accuracy: 0.9962 - val_loss: 0.1843 - val_accuracy: 0.9530\n",
      "Epoch 46/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0224 - accuracy: 0.9948 - val_loss: 0.1782 - val_accuracy: 0.9500\n",
      "Epoch 47/1000\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.0179 - accuracy: 0.9973 - val_loss: 0.1754 - val_accuracy: 0.9540\n",
      "Epoch 48/1000\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.0166 - accuracy: 0.9970 - val_loss: 0.1894 - val_accuracy: 0.9440\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.6960054258554647\n",
      "F1 Micro: 0.9578\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7066216669438516\n",
      "F1 Micro: 0.9575\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7224984460077509\n",
      "F1 Micro: 0.957\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 10 replication 50000 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.4384 - accuracy: 0.8946 - val_loss: 0.2484 - val_accuracy: 0.9297\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.1958 - accuracy: 0.9437 - val_loss: 0.1648 - val_accuracy: 0.9513\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.1454 - accuracy: 0.9560 - val_loss: 0.1319 - val_accuracy: 0.9604\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.1276 - accuracy: 0.9607 - val_loss: 0.1321 - val_accuracy: 0.9600\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.1147 - accuracy: 0.9641 - val_loss: 0.1157 - val_accuracy: 0.9643\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.1079 - accuracy: 0.9657 - val_loss: 0.1124 - val_accuracy: 0.9655\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.1001 - accuracy: 0.9683 - val_loss: 0.1117 - val_accuracy: 0.9634\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0957 - accuracy: 0.9690 - val_loss: 0.1013 - val_accuracy: 0.9680\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0916 - accuracy: 0.9704 - val_loss: 0.1093 - val_accuracy: 0.9656\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0856 - accuracy: 0.9721 - val_loss: 0.0981 - val_accuracy: 0.9695\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0810 - accuracy: 0.9733 - val_loss: 0.1047 - val_accuracy: 0.9672\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0787 - accuracy: 0.9740 - val_loss: 0.1122 - val_accuracy: 0.9642\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0743 - accuracy: 0.9752 - val_loss: 0.0875 - val_accuracy: 0.9726\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0698 - accuracy: 0.9773 - val_loss: 0.0921 - val_accuracy: 0.9705\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0666 - accuracy: 0.9774 - val_loss: 0.0939 - val_accuracy: 0.9693\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0608 - accuracy: 0.9798 - val_loss: 0.0892 - val_accuracy: 0.9715\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0564 - accuracy: 0.9815 - val_loss: 0.0884 - val_accuracy: 0.9717\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0539 - accuracy: 0.9813 - val_loss: 0.0945 - val_accuracy: 0.9723\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0475 - accuracy: 0.9837 - val_loss: 0.0903 - val_accuracy: 0.9706\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0447 - accuracy: 0.9845 - val_loss: 0.0998 - val_accuracy: 0.9701\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 0.0896 - val_accuracy: 0.9722\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.0349 - accuracy: 0.9883 - val_loss: 0.0929 - val_accuracy: 0.9705\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0323 - accuracy: 0.9890 - val_loss: 0.0921 - val_accuracy: 0.9727\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0894 - val_accuracy: 0.9739\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.1177 - val_accuracy: 0.9655\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 0.1093 - val_accuracy: 0.9718\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.1032 - val_accuracy: 0.9711\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.1187 - val_accuracy: 0.9726\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.1040 - val_accuracy: 0.9742\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.1565 - val_accuracy: 0.9691\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.1248 - val_accuracy: 0.9688\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.1422 - val_accuracy: 0.9712\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1541 - val_accuracy: 0.9723\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7944393736503694\n",
      "F1 Micro: 0.9701\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7936362557266229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Micro: 0.9644\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.5122 - accuracy: 0.8820 - val_loss: 0.1648 - val_accuracy: 0.9529\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.1415 - accuracy: 0.9585 - val_loss: 0.1355 - val_accuracy: 0.9585\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1236 - accuracy: 0.9618 - val_loss: 0.1257 - val_accuracy: 0.9620\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.1145 - accuracy: 0.9650 - val_loss: 0.1197 - val_accuracy: 0.9618\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1084 - accuracy: 0.9671 - val_loss: 0.1156 - val_accuracy: 0.9629\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1037 - accuracy: 0.9677 - val_loss: 0.1117 - val_accuracy: 0.9640\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.1000 - accuracy: 0.9684 - val_loss: 0.1092 - val_accuracy: 0.9644\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0971 - accuracy: 0.9690 - val_loss: 0.1075 - val_accuracy: 0.9646\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0945 - accuracy: 0.9697 - val_loss: 0.1056 - val_accuracy: 0.9667\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0921 - accuracy: 0.9709 - val_loss: 0.1066 - val_accuracy: 0.9666\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0901 - accuracy: 0.9714 - val_loss: 0.1042 - val_accuracy: 0.9664\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0884 - accuracy: 0.9718 - val_loss: 0.1026 - val_accuracy: 0.9676\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0868 - accuracy: 0.9721 - val_loss: 0.1003 - val_accuracy: 0.9682\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0850 - accuracy: 0.9728 - val_loss: 0.0990 - val_accuracy: 0.9687\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0837 - accuracy: 0.9732 - val_loss: 0.0984 - val_accuracy: 0.9685\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0825 - accuracy: 0.9735 - val_loss: 0.0980 - val_accuracy: 0.9674\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0809 - accuracy: 0.9743 - val_loss: 0.0992 - val_accuracy: 0.9683\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0799 - accuracy: 0.9740 - val_loss: 0.0966 - val_accuracy: 0.9688\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0789 - accuracy: 0.9748 - val_loss: 0.0952 - val_accuracy: 0.9693\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0775 - accuracy: 0.9748 - val_loss: 0.0954 - val_accuracy: 0.9692\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0762 - accuracy: 0.9758 - val_loss: 0.0960 - val_accuracy: 0.9685\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0753 - accuracy: 0.9754 - val_loss: 0.0946 - val_accuracy: 0.9695\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0746 - accuracy: 0.9758 - val_loss: 0.0941 - val_accuracy: 0.9694\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0737 - accuracy: 0.9763 - val_loss: 0.0945 - val_accuracy: 0.9688\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0724 - accuracy: 0.9767 - val_loss: 0.0939 - val_accuracy: 0.9705\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0717 - accuracy: 0.9768 - val_loss: 0.0931 - val_accuracy: 0.9697\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0709 - accuracy: 0.9772 - val_loss: 0.0943 - val_accuracy: 0.9708\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0701 - accuracy: 0.9776 - val_loss: 0.0932 - val_accuracy: 0.9691\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0690 - accuracy: 0.9777 - val_loss: 0.0934 - val_accuracy: 0.9695\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0683 - accuracy: 0.9779 - val_loss: 0.0948 - val_accuracy: 0.9690\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0679 - accuracy: 0.9782 - val_loss: 0.0924 - val_accuracy: 0.9702\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0668 - accuracy: 0.9786 - val_loss: 0.0925 - val_accuracy: 0.9703\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 3s 70us/step - loss: 0.0657 - accuracy: 0.9791 - val_loss: 0.0931 - val_accuracy: 0.9706\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0652 - accuracy: 0.9794 - val_loss: 0.0912 - val_accuracy: 0.9699\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0646 - accuracy: 0.9795 - val_loss: 0.0931 - val_accuracy: 0.9702\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0637 - accuracy: 0.9795 - val_loss: 0.0914 - val_accuracy: 0.9717\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0628 - accuracy: 0.9805 - val_loss: 0.0913 - val_accuracy: 0.9706\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 3s 68us/step - loss: 0.0622 - accuracy: 0.9809 - val_loss: 0.0927 - val_accuracy: 0.9714\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0616 - accuracy: 0.9802 - val_loss: 0.0905 - val_accuracy: 0.9698\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0608 - accuracy: 0.9812 - val_loss: 0.0933 - val_accuracy: 0.9694\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 3s 69us/step - loss: 0.0603 - accuracy: 0.9809 - val_loss: 0.0905 - val_accuracy: 0.9695\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0597 - accuracy: 0.9810 - val_loss: 0.0922 - val_accuracy: 0.9709\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0589 - accuracy: 0.9816 - val_loss: 0.0906 - val_accuracy: 0.9709\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0581 - accuracy: 0.9816 - val_loss: 0.0910 - val_accuracy: 0.9698\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0574 - accuracy: 0.9818 - val_loss: 0.0906 - val_accuracy: 0.9710\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0569 - accuracy: 0.9825 - val_loss: 0.0916 - val_accuracy: 0.9713\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0562 - accuracy: 0.9829 - val_loss: 0.0923 - val_accuracy: 0.9707\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0555 - accuracy: 0.9825 - val_loss: 0.0901 - val_accuracy: 0.9712\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0550 - accuracy: 0.9829 - val_loss: 0.0931 - val_accuracy: 0.9706\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0543 - accuracy: 0.9835 - val_loss: 0.0908 - val_accuracy: 0.9713\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0535 - accuracy: 0.9833 - val_loss: 0.0923 - val_accuracy: 0.9702\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0531 - accuracy: 0.9836 - val_loss: 0.0904 - val_accuracy: 0.9705\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0524 - accuracy: 0.9839 - val_loss: 0.0913 - val_accuracy: 0.9712\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.0904 - val_accuracy: 0.9715\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0511 - accuracy: 0.9845 - val_loss: 0.0909 - val_accuracy: 0.9702\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0507 - accuracy: 0.9845 - val_loss: 0.0925 - val_accuracy: 0.9710\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0499 - accuracy: 0.9844 - val_loss: 0.0918 - val_accuracy: 0.9705\n",
      "Epoch 58/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0495 - accuracy: 0.9850 - val_loss: 0.0919 - val_accuracy: 0.9706\n",
      "Epoch 59/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0489 - accuracy: 0.9854 - val_loss: 0.0924 - val_accuracy: 0.9696\n",
      "Epoch 60/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0483 - accuracy: 0.9852 - val_loss: 0.0919 - val_accuracy: 0.9715\n",
      "Epoch 61/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0477 - accuracy: 0.9851 - val_loss: 0.0910 - val_accuracy: 0.9706\n",
      "Epoch 62/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0472 - accuracy: 0.9855 - val_loss: 0.0934 - val_accuracy: 0.9711\n",
      "Epoch 63/1000\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 0.0916 - val_accuracy: 0.9707\n",
      "Epoch 64/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0461 - accuracy: 0.9859 - val_loss: 0.0939 - val_accuracy: 0.9703\n",
      "Epoch 65/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0453 - accuracy: 0.9865 - val_loss: 0.0936 - val_accuracy: 0.9706\n",
      "Epoch 66/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0448 - accuracy: 0.9864 - val_loss: 0.0937 - val_accuracy: 0.9716\n",
      "Epoch 67/1000\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0443 - accuracy: 0.9868 - val_loss: 0.0933 - val_accuracy: 0.9704\n",
      "Epoch 68/1000\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0436 - accuracy: 0.9867 - val_loss: 0.0926 - val_accuracy: 0.9707\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8411950287163638\n",
      "F1 Micro: 0.9709\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 0.2510 - accuracy: 0.9317 - val_loss: 0.1587 - val_accuracy: 0.9534\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.1402 - accuracy: 0.9579 - val_loss: 0.1423 - val_accuracy: 0.9572\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.1210 - accuracy: 0.9623 - val_loss: 0.1218 - val_accuracy: 0.9624\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.1104 - accuracy: 0.9660 - val_loss: 0.1158 - val_accuracy: 0.9629\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.1032 - accuracy: 0.9673 - val_loss: 0.1148 - val_accuracy: 0.9634\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.0993 - accuracy: 0.9687 - val_loss: 0.1062 - val_accuracy: 0.9659\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.0941 - accuracy: 0.9701 - val_loss: 0.1070 - val_accuracy: 0.9651\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0910 - accuracy: 0.9710 - val_loss: 0.1028 - val_accuracy: 0.9667\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0876 - accuracy: 0.9721 - val_loss: 0.0989 - val_accuracy: 0.9674\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0833 - accuracy: 0.9731 - val_loss: 0.0982 - val_accuracy: 0.9681\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0796 - accuracy: 0.9742 - val_loss: 0.0957 - val_accuracy: 0.9675\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0737 - accuracy: 0.9762 - val_loss: 0.0969 - val_accuracy: 0.9673\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0682 - accuracy: 0.9775 - val_loss: 0.0970 - val_accuracy: 0.9699\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0605 - accuracy: 0.9807 - val_loss: 0.0942 - val_accuracy: 0.9700\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.0531 - accuracy: 0.9826 - val_loss: 0.0981 - val_accuracy: 0.9699\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.0449 - accuracy: 0.9857 - val_loss: 0.1063 - val_accuracy: 0.9691\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 0.1163 - val_accuracy: 0.9688\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0322 - accuracy: 0.9899 - val_loss: 0.1139 - val_accuracy: 0.9681\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 0.1230 - val_accuracy: 0.9663\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0248 - accuracy: 0.9920 - val_loss: 0.1399 - val_accuracy: 0.9682\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.0217 - accuracy: 0.9937 - val_loss: 0.1438 - val_accuracy: 0.9678\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.1326 - val_accuracy: 0.9675\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.1417 - val_accuracy: 0.9684\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.1577 - val_accuracy: 0.9678\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.1455 - val_accuracy: 0.9662\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.1546 - val_accuracy: 0.9640\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.1606 - val_accuracy: 0.9677\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.1772 - val_accuracy: 0.9682\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.1699 - val_accuracy: 0.9696\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.1534 - val_accuracy: 0.9692\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.1883 - val_accuracy: 0.9690\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1674 - val_accuracy: 0.9685\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.1806 - val_accuracy: 0.9696\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.2025 - val_accuracy: 0.9633\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8307843393879604\n",
      "F1 Micro: 0.9698\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.7900108399246767\n",
      "F1 Micro: 0.9636\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8519832508600241\n",
      "F1 Micro: 0.9734\n",
      "\n",
      " @@@@@@@@@@@@@@@@@@@@ 10 replication 162946 @@@@@@@@@@@@@@@@@@@@ \n",
      "\n",
      "\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "label_list [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "**********model1**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.2361 - accuracy: 0.9361 - val_loss: 0.1191 - val_accuracy: 0.9629\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.1154 - accuracy: 0.9632 - val_loss: 0.1062 - val_accuracy: 0.9658\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0985 - accuracy: 0.9685 - val_loss: 0.0949 - val_accuracy: 0.9686\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0884 - accuracy: 0.9708 - val_loss: 0.0847 - val_accuracy: 0.9721\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0812 - accuracy: 0.9729 - val_loss: 0.0808 - val_accuracy: 0.9724\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 25s 188us/step - loss: 0.0746 - accuracy: 0.9748 - val_loss: 0.0882 - val_accuracy: 0.9731\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0678 - accuracy: 0.9768 - val_loss: 0.0773 - val_accuracy: 0.9738\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0624 - accuracy: 0.9782 - val_loss: 0.0757 - val_accuracy: 0.9749\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0579 - accuracy: 0.9796 - val_loss: 0.0714 - val_accuracy: 0.9754\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 26s 199us/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.0861 - val_accuracy: 0.9696\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0503 - accuracy: 0.9821 - val_loss: 0.0677 - val_accuracy: 0.9776\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 25s 196us/step - loss: 0.0469 - accuracy: 0.9832 - val_loss: 0.0720 - val_accuracy: 0.9738\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0436 - accuracy: 0.9840 - val_loss: 0.0769 - val_accuracy: 0.9762\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0392 - accuracy: 0.9856 - val_loss: 0.0681 - val_accuracy: 0.9772\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0367 - accuracy: 0.9866 - val_loss: 0.1115 - val_accuracy: 0.9724\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0334 - accuracy: 0.9878 - val_loss: 0.0689 - val_accuracy: 0.9776\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0296 - accuracy: 0.9895 - val_loss: 0.0762 - val_accuracy: 0.9763\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.0259 - accuracy: 0.9905 - val_loss: 0.0788 - val_accuracy: 0.9773\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0227 - accuracy: 0.9917 - val_loss: 0.0823 - val_accuracy: 0.9769\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.0202 - accuracy: 0.9926 - val_loss: 0.0838 - val_accuracy: 0.9766\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0164 - accuracy: 0.9941 - val_loss: 0.0929 - val_accuracy: 0.9771\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.1011 - val_accuracy: 0.9747\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.1064 - val_accuracy: 0.9752\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.1314 - val_accuracy: 0.9743\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.1130 - val_accuracy: 0.9771\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 25s 191us/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.1070 - val_accuracy: 0.9764\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 25s 191us/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1159 - val_accuracy: 0.9753\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1177 - val_accuracy: 0.9777\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.1171 - val_accuracy: 0.9761\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 24s 188us/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.1202 - val_accuracy: 0.9779\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 24s 187us/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.1250 - val_accuracy: 0.9774\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8727151703751157\n",
      "F1 Micro: 0.9773000000000001\n",
      "\n",
      "**********model2**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8243405387344116\n",
      "F1 Micro: 0.9685\n",
      "\n",
      "**********model3**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.2465 - accuracy: 0.9380 - val_loss: 0.1216 - val_accuracy: 0.9635\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.1133 - accuracy: 0.9649 - val_loss: 0.1084 - val_accuracy: 0.9664\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.1037 - accuracy: 0.9675 - val_loss: 0.1026 - val_accuracy: 0.9681\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0981 - accuracy: 0.9692 - val_loss: 0.1001 - val_accuracy: 0.9682\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 10s 78us/step - loss: 0.0940 - accuracy: 0.9701 - val_loss: 0.0985 - val_accuracy: 0.9689\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0912 - accuracy: 0.9711 - val_loss: 0.0952 - val_accuracy: 0.9696\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0887 - accuracy: 0.9717 - val_loss: 0.0943 - val_accuracy: 0.9705\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 10s 78us/step - loss: 0.0865 - accuracy: 0.9724 - val_loss: 0.0928 - val_accuracy: 0.9708\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0846 - accuracy: 0.9731 - val_loss: 0.0917 - val_accuracy: 0.9708\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0830 - accuracy: 0.9738 - val_loss: 0.0911 - val_accuracy: 0.9711\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0815 - accuracy: 0.9742 - val_loss: 0.0903 - val_accuracy: 0.9716\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0802 - accuracy: 0.9745 - val_loss: 0.0891 - val_accuracy: 0.9716\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0789 - accuracy: 0.9747 - val_loss: 0.0886 - val_accuracy: 0.9717\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0777 - accuracy: 0.9749 - val_loss: 0.0883 - val_accuracy: 0.9720\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0764 - accuracy: 0.9757 - val_loss: 0.0877 - val_accuracy: 0.9721\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 10s 78us/step - loss: 0.0754 - accuracy: 0.9758 - val_loss: 0.0871 - val_accuracy: 0.9724\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0745 - accuracy: 0.9761 - val_loss: 0.0881 - val_accuracy: 0.9716\n",
      "Epoch 18/1000\n",
      "130356/130356 [==============================] - 10s 78us/step - loss: 0.0734 - accuracy: 0.9764 - val_loss: 0.0870 - val_accuracy: 0.9724\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0724 - accuracy: 0.9767 - val_loss: 0.0869 - val_accuracy: 0.9726\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0716 - accuracy: 0.9771 - val_loss: 0.0870 - val_accuracy: 0.9724\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0708 - accuracy: 0.9771 - val_loss: 0.0866 - val_accuracy: 0.9722\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0700 - accuracy: 0.9775 - val_loss: 0.0854 - val_accuracy: 0.9723\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0691 - accuracy: 0.9775 - val_loss: 0.0849 - val_accuracy: 0.9730\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0683 - accuracy: 0.9777 - val_loss: 0.0855 - val_accuracy: 0.9727\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0675 - accuracy: 0.9780 - val_loss: 0.0869 - val_accuracy: 0.9721\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0668 - accuracy: 0.9785 - val_loss: 0.0853 - val_accuracy: 0.9728\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0662 - accuracy: 0.9784 - val_loss: 0.0853 - val_accuracy: 0.9729\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0656 - accuracy: 0.9785 - val_loss: 0.0863 - val_accuracy: 0.9721\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0649 - accuracy: 0.9790 - val_loss: 0.0849 - val_accuracy: 0.9732\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0642 - accuracy: 0.9791 - val_loss: 0.0854 - val_accuracy: 0.9726\n",
      "Epoch 31/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0635 - accuracy: 0.9793 - val_loss: 0.0849 - val_accuracy: 0.9732\n",
      "Epoch 32/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0628 - accuracy: 0.9796 - val_loss: 0.0858 - val_accuracy: 0.9725\n",
      "Epoch 33/1000\n",
      "130356/130356 [==============================] - 10s 78us/step - loss: 0.0623 - accuracy: 0.9798 - val_loss: 0.0852 - val_accuracy: 0.9728\n",
      "Epoch 34/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0616 - accuracy: 0.9799 - val_loss: 0.0853 - val_accuracy: 0.9729\n",
      "Epoch 35/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0610 - accuracy: 0.9801 - val_loss: 0.0860 - val_accuracy: 0.9723\n",
      "Epoch 36/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0604 - accuracy: 0.9802 - val_loss: 0.0841 - val_accuracy: 0.9736\n",
      "Epoch 37/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0598 - accuracy: 0.9805 - val_loss: 0.0850 - val_accuracy: 0.9726\n",
      "Epoch 38/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0592 - accuracy: 0.9809 - val_loss: 0.0843 - val_accuracy: 0.9728\n",
      "Epoch 39/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0587 - accuracy: 0.9808 - val_loss: 0.0855 - val_accuracy: 0.9731\n",
      "Epoch 40/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0582 - accuracy: 0.9814 - val_loss: 0.0868 - val_accuracy: 0.9727\n",
      "Epoch 41/1000\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0575 - accuracy: 0.9816 - val_loss: 0.0844 - val_accuracy: 0.9730\n",
      "Epoch 42/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0570 - accuracy: 0.9812 - val_loss: 0.0861 - val_accuracy: 0.9727\n",
      "Epoch 43/1000\n",
      "130356/130356 [==============================] - 10s 78us/step - loss: 0.0564 - accuracy: 0.9817 - val_loss: 0.0849 - val_accuracy: 0.9731\n",
      "Epoch 44/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0560 - accuracy: 0.9818 - val_loss: 0.0862 - val_accuracy: 0.9730\n",
      "Epoch 45/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0554 - accuracy: 0.9820 - val_loss: 0.0861 - val_accuracy: 0.9724\n",
      "Epoch 46/1000\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0550 - accuracy: 0.9820 - val_loss: 0.0852 - val_accuracy: 0.9724\n",
      "Epoch 47/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0544 - accuracy: 0.9826 - val_loss: 0.0857 - val_accuracy: 0.9737\n",
      "Epoch 48/1000\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0538 - accuracy: 0.9827 - val_loss: 0.0851 - val_accuracy: 0.9731\n",
      "Epoch 49/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0535 - accuracy: 0.9826 - val_loss: 0.0861 - val_accuracy: 0.9730\n",
      "Epoch 50/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0526 - accuracy: 0.9831 - val_loss: 0.0864 - val_accuracy: 0.9725\n",
      "Epoch 51/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0524 - accuracy: 0.9831 - val_loss: 0.0870 - val_accuracy: 0.9722\n",
      "Epoch 52/1000\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0518 - accuracy: 0.9833 - val_loss: 0.0861 - val_accuracy: 0.9728\n",
      "Epoch 53/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0514 - accuracy: 0.9836 - val_loss: 0.0861 - val_accuracy: 0.9729\n",
      "Epoch 54/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0509 - accuracy: 0.9838 - val_loss: 0.0861 - val_accuracy: 0.9728\n",
      "Epoch 55/1000\n",
      "130356/130356 [==============================] - 10s 76us/step - loss: 0.0503 - accuracy: 0.9841 - val_loss: 0.0863 - val_accuracy: 0.9726\n",
      "Epoch 56/1000\n",
      "130356/130356 [==============================] - 10s 77us/step - loss: 0.0498 - accuracy: 0.9839 - val_loss: 0.0869 - val_accuracy: 0.9729\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8626511344482792\n",
      "F1 Micro: 0.9739\n",
      "\n",
      "**********model4**********\n",
      "\n",
      "Train on 130356 samples, validate on 32590 samples\n",
      "Epoch 1/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.1700 - accuracy: 0.9507 - val_loss: 0.1164 - val_accuracy: 0.9631\n",
      "Epoch 2/1000\n",
      "130356/130356 [==============================] - 26s 202us/step - loss: 0.1070 - accuracy: 0.9663 - val_loss: 0.1010 - val_accuracy: 0.9680\n",
      "Epoch 3/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0958 - accuracy: 0.9695 - val_loss: 0.0924 - val_accuracy: 0.9707\n",
      "Epoch 4/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0878 - accuracy: 0.9717 - val_loss: 0.0879 - val_accuracy: 0.9714\n",
      "Epoch 5/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0813 - accuracy: 0.9738 - val_loss: 0.0849 - val_accuracy: 0.9724\n",
      "Epoch 6/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0750 - accuracy: 0.9754 - val_loss: 0.0815 - val_accuracy: 0.9732\n",
      "Epoch 7/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0697 - accuracy: 0.9771 - val_loss: 0.0844 - val_accuracy: 0.9728\n",
      "Epoch 8/1000\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.0644 - accuracy: 0.9788 - val_loss: 0.0760 - val_accuracy: 0.9747\n",
      "Epoch 9/1000\n",
      "130356/130356 [==============================] - 25s 193us/step - loss: 0.0587 - accuracy: 0.9800 - val_loss: 0.0744 - val_accuracy: 0.9755\n",
      "Epoch 10/1000\n",
      "130356/130356 [==============================] - 26s 201us/step - loss: 0.0535 - accuracy: 0.9818 - val_loss: 0.0716 - val_accuracy: 0.9767\n",
      "Epoch 11/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0473 - accuracy: 0.9840 - val_loss: 0.0737 - val_accuracy: 0.9767\n",
      "Epoch 12/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0412 - accuracy: 0.9860 - val_loss: 0.0804 - val_accuracy: 0.9764\n",
      "Epoch 13/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0354 - accuracy: 0.9880 - val_loss: 0.0750 - val_accuracy: 0.9770\n",
      "Epoch 14/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0290 - accuracy: 0.9900 - val_loss: 0.0849 - val_accuracy: 0.9769\n",
      "Epoch 15/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.0875 - val_accuracy: 0.9751\n",
      "Epoch 16/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0188 - accuracy: 0.9935 - val_loss: 0.0920 - val_accuracy: 0.9765\n",
      "Epoch 17/1000\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.1052 - val_accuracy: 0.9747\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.1016 - val_accuracy: 0.9762\n",
      "Epoch 19/1000\n",
      "130356/130356 [==============================] - 25s 191us/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.1110 - val_accuracy: 0.9762\n",
      "Epoch 20/1000\n",
      "130356/130356 [==============================] - 25s 192us/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1199 - val_accuracy: 0.9742\n",
      "Epoch 21/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.1303 - val_accuracy: 0.9719\n",
      "Epoch 22/1000\n",
      "130356/130356 [==============================] - 26s 197us/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.1331 - val_accuracy: 0.9755\n",
      "Epoch 23/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1330 - val_accuracy: 0.9753\n",
      "Epoch 24/1000\n",
      "130356/130356 [==============================] - 25s 194us/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1424 - val_accuracy: 0.9742\n",
      "Epoch 25/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1339 - val_accuracy: 0.9746\n",
      "Epoch 26/1000\n",
      "130356/130356 [==============================] - 26s 200us/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1581 - val_accuracy: 0.9752\n",
      "Epoch 27/1000\n",
      "130356/130356 [==============================] - 26s 198us/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1401 - val_accuracy: 0.9742\n",
      "Epoch 28/1000\n",
      "130356/130356 [==============================] - 25s 195us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.1496 - val_accuracy: 0.9758\n",
      "Epoch 29/1000\n",
      "130356/130356 [==============================] - 25s 190us/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1547 - val_accuracy: 0.9748\n",
      "Epoch 30/1000\n",
      "130356/130356 [==============================] - 26s 196us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1575 - val_accuracy: 0.9750\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8784715076613451\n",
      "F1 Micro: 0.9772\n",
      "\n",
      "**********model5**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8353927946692192\n",
      "F1 Micro: 0.9677\n",
      "\n",
      "**********model6**********\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n",
      "F1 Macro: 0.8915472588488931\n",
      "F1 Micro: 0.9797\n",
      "\n",
      "\n",
      " 54.802048325538635 min per replication\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "savefile = '0430'\n",
    "model_list = ['model1', 'model2', 'model3', 'model4', 'model5','model6']\n",
    "pattern_list = [0, 1, 2, 3, 4, 5, 6, 7 ,8]\n",
    "n_trnval_list = [500,5000,50000,162946]\n",
    "coeff_dict = {}\n",
    "f1_dict = {}\n",
    "model6_list = []\n",
    "for k in n_trnval_list:\n",
    "    coeff_dict[k] = []\n",
    "for t in n_trnval_list:\n",
    "    f1_dict[t] = {}\n",
    "    for label in pattern_list:\n",
    "        f1_dict[t][label] = {}\n",
    "        for model in model_list:\n",
    "            f1_dict[t][label][str(model)] = []\n",
    "\n",
    "replication=10\n",
    "random_seed=777\n",
    "if not os.path.exists('./'+savefile):\n",
    "    os.makedirs('./'+savefile)\n",
    "for rep in range(replication):\n",
    "    RANDON_STATE = 20200430+rep+random_seed\n",
    "    X_trainval_cnn_big, X_test_cnn, y_trainval_big, y_test = train_test_split(X_cnn, y, \n",
    "                                   test_size=10000, random_state=RANDON_STATE,stratify=y)\n",
    "    X_trainval_fe_big, X_test_fe = train_test_split(X_fe, test_size=10000, \n",
    "                                                    random_state=RANDON_STATE,stratify=y)\n",
    "    start_time = time.time()\n",
    "    print('\\n','&'*20,rep+1,'replication','&'*20,'\\n\\n')\n",
    "    idx_list = [np.where(np.argmax(y_test,axis=1)==i)[0] for i in range(9)]\n",
    "    for n_trnval in n_trnval_list:\n",
    "        # Sampling\n",
    "        print('\\n','@'*20,rep+1,'replication',n_trnval,'@'*20,'\\n\\n')\n",
    "        global fn\n",
    "        fn = './'+savefile+'/result_{rep}_{ts:04d}_{model}.png'\n",
    "        np.random.seed(20200321+n_trnval*(rep+random_seed))\n",
    "        rand_id = np.random.choice(len(X_trainval_fe_big), n_trnval, replace=False)\n",
    "        X_trainval_cnn = X_trainval_cnn_big[rand_id]\n",
    "        X_trainval_fe = X_trainval_fe_big[rand_id]\n",
    "\n",
    "        y_trainval = y_trainval_big[rand_id]\n",
    "        # Split\n",
    "        X_train_cnn, X_val_cnn, y_train, y_val= train_test_split(X_trainval_cnn, \n",
    "                                                y_trainval, test_size=0.2, random_state=RANDON_STATE)\n",
    "        X_train_fe, X_val_fe = train_test_split(X_trainval_fe, test_size=0.2, random_state=RANDON_STATE)\n",
    "\n",
    "        mean, std = np.mean(X_train_fe,axis=0), np.std(X_train_fe,axis=0)\n",
    "        X_train_fe_n, X_val_fe_n, X_test_fe_n, X_trainval_fe_n = (X_train_fe-mean)/std, (X_val_fe-mean)/std, (X_test_fe-mean)/std, (X_trainval_fe-mean)/std\n",
    "\n",
    "        # Train and Evaluate Each Model\n",
    "        result_dict = {'macro':[],'micro':[]}\n",
    "        label_list = list(set(np.argmax(y_trainval,axis=1)))\n",
    "        print('label_list',list(set(np.argmax(y_trainval,axis=1))))\n",
    "        print('label_list',list(set(np.argmax(y_train,axis=1))))\n",
    "\n",
    "        result_dict, cm, model1 = create_model1(X_train_cnn, y_train, X_val_cnn, y_val, \n",
    "                                          X_test_cnn, y_test,result_dict, n_trnval, rep)\n",
    "        result_dict, cm, model2 = create_model2(X_trainval_fe, y_trainval, \n",
    "                                          X_test_fe, y_test, result_dict, n_trnval, rep)\n",
    "        result_dict, cm ,model3= create_model3(X_train_fe_n, y_train, X_val_fe_n, y_val, \n",
    "                                         X_test_fe_n, y_test, result_dict,  n_trnval, rep)\n",
    "        result_dict, cm, model4= create_model4(X_train_cnn, X_train_fe_n, y_train, X_val_cnn, X_val_fe_n, y_val, \n",
    "                                         X_test_cnn, X_test_fe_n, y_test, result_dict, n_trnval, rep)\n",
    "        result_dict, cm, model5, prob_test_concat5 = create_model5(model1, model2, X_trainval_cnn, X_trainval_fe, y_trainval, \n",
    "                                         X_test_cnn, X_test_fe, y_test, result_dict, n_trnval, rep)\n",
    "        result_dict, cm, coeff, model6, prob_test_concat6 = create_model6(model1, model3, X_trainval_cnn, X_trainval_fe_n, \n",
    "                     y_trainval, X_test_cnn, X_test_fe_n, y_test, result_dict, n_trnval, rep)\n",
    "\n",
    "        for pattern_num in pattern_list:\n",
    "            for model in model_list:\n",
    "                if model == 'model2':\n",
    "                    y_hat = np.argmax(model2.predict_proba(X_test_fe[idx_list[pattern_num]]),axis=1)\n",
    "                elif model == 'model4':\n",
    "                    y_hat = np.argmax(model4.predict([X_test_cnn[idx_list[pattern_num]], \n",
    "                                   X_test_fe_n[idx_list[pattern_num]]]),axis=1)\n",
    "                elif model == 'model6':\n",
    "                    y_hat = np.argmax(model6.predict(prob_test_concat6[idx_list[pattern_num]]),axis=1)    \n",
    "                elif model =='model1':\n",
    "                    y_hat = np.argmax(model1.predict(X_test_cnn[idx_list[pattern_num]]),axis=1)\n",
    "                elif model == 'model3':\n",
    "                    y_hat = np.argmax(model3.predict(X_test_fe_n[idx_list[pattern_num]]),axis=1)\n",
    "                elif model == 'model5':\n",
    "                    y_hat = np.argmax(model5.predict(prob_test_concat5[idx_list[pattern_num]]),axis=1)\n",
    "                y_true = np.argmax(y_test[idx_list[pattern_num]],axis=1)\n",
    "                fscore = np.max(f1_score(y_true, y_hat, average=None))\n",
    "                f1_dict[n_trnval][pattern_num][str(model)].append(fscore)\n",
    "\n",
    "        model6_list.append(model6)\n",
    "        coeff_dict[n_trnval].append(coeff)\n",
    "        # Record result\n",
    "        with open(savefile+'.csv', 'a', newline='') as csvfile:\n",
    "            fieldnames = ['training_size', \n",
    "                          'model1_macro','model2_macro','model3_macro',\n",
    "                          'model4_macro','model5_macro','model6_macro',\n",
    "                          'model1_micro','model2_micro','model3_micro',\n",
    "                          'model4_micro','model5_micro','model6_micro']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writerow({'training_size': n_trnval, \n",
    "                             'model1_macro': result_dict['macro'][0],'model2_macro': result_dict['macro'][1],\n",
    "                             'model3_macro': result_dict['macro'][2],'model4_macro': result_dict['macro'][3],\n",
    "                             'model5_macro': result_dict['macro'][4],'model6_macro': result_dict['macro'][5],\n",
    "                             'model1_micro': result_dict['micro'][0],'model2_micro': result_dict['micro'][1],\n",
    "                             'model3_micro': result_dict['micro'][2],'model4_micro': result_dict['micro'][3],\n",
    "                             'model5_micro': result_dict['micro'][4],'model6_micro': result_dict['micro'][5],\n",
    "                             })\n",
    "\n",
    "    print('\\n\\n',(time.time()-start_time)/60,'min per replication\\n\\n')\n",
    "for n_trnval in n_trnval_list:\n",
    "    for pattern in pattern_list:\n",
    "        for model in model_list:\n",
    "            f1_dict[n_trnval][pattern][model] = np.mean(f1_dict[n_trnval][pattern][model])\n",
    "with open(savefile+'_2.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['pattern', \n",
    "                  'model1','model2','model3','model4','model5','model6']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for n_trnval in n_trnval_list:\n",
    "        writer.writerow({'pattern':n_trnval})\n",
    "        for pattern in pattern_list:\n",
    "            writer.writerow({'pattern': pattern,\n",
    "                             'model1':f1_dict[n_trnval][pattern]['model1'],\n",
    "                             'model2':f1_dict[n_trnval][pattern]['model2'],\n",
    "                             'model3':f1_dict[n_trnval][pattern]['model3'],\n",
    "                             'model4':f1_dict[n_trnval][pattern]['model4'],\n",
    "                             'model5':f1_dict[n_trnval][pattern]['model5'],\n",
    "                             'model6':f1_dict[n_trnval][pattern]['model6']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T01:33:01.376435Z",
     "start_time": "2020-04-09T01:32:58.177181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162946\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_size_list = [500,5000,50000,162946]\n",
    "\n",
    "\n",
    "for data_size in data_size_list:\n",
    "    coeff_sum = coeff_dict[data_size][9]\n",
    "    for i in range(9):\n",
    "        coeff_sum = np.add(coeff_sum, coeff_dict[data_size][i])\n",
    "    coeff_mean = np.divide(coeff_sum,10)\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows = 3, ncols = 3, figsize=(20, 20))\n",
    "    ax = ax.ravel(order='C')\n",
    "    for rep in range(9):\n",
    "        if rep != 4:\n",
    "            coeff = np.array(coeff_dict[data_size])[rep]\n",
    "            co_list = []\n",
    "            for k in range(9):\n",
    "                co_list.append(coeff[k][k])\n",
    "                co_list.append(coeff[k][k+9])\n",
    "\n",
    "            bar_width = 0.4\n",
    "            ax[rep].bar(np.arange(9), co_list[:9],bar_width, color='b')\n",
    "            ax[rep].bar(np.arange(9)+bar_width, co_list[9:],bar_width, color='r')\n",
    "            ax[rep].title.set_text(str(rep)+'rep')\n",
    "            ax[rep].set_ylim(-1,2)\n",
    "        else:\n",
    "            \n",
    "            coeff = np.array(coeff_mean)\n",
    "            co_list = []\n",
    "            for k in range(9):\n",
    "                co_list.append(coeff[k][k])\n",
    "                co_list.append(coeff[k][k+9])\n",
    "\n",
    "            bar_width = 0.4\n",
    "            ax[rep].bar(np.arange(9), co_list[:9],bar_width, color='b')\n",
    "            ax[rep].bar(np.arange(9)+bar_width, co_list[9:],bar_width, color='r')\n",
    "            ax[rep].title.set_text('Mean')\n",
    "            ax[rep].set_ylim(-1,2)\n",
    "            \n",
    "    print(data_size)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T01:34:25.761779Z",
     "start_time": "2020-04-09T01:34:25.372818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAP9ElEQVR4nO3de4zlZX3H8ffH3fWGVqxMCy67gpEU0VaRCUJJGiKYgDVsL5hAUkWjmcRIxcakoZpg6l+aNNpaiGQrVLTES5Dq1q6lKhg1jZTZlftK3NLWnbItA+gi9UJXv/1jfrTjzJnZmTm/nXN2n/crOZnf5Znf9+G3u595eM5zfpOqQpJ09HvaqDsgSVofBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiOGDvwkz0zyz0nuSnJfkj8d0OYZST6TZG+S25OcNGxdSdLq9DHC/ynwmqp6BfBK4IIkZy1o81bg+1X1EuDDwAd7qCtJWoWhA7/mPNHtbupeCz/NtQ24odu+CTgvSYatLUlauY19XCTJBmAX8BLgmqq6fUGTzcA+gKo6mOQA8ALgkQXXmQKmAI455pgzTj311D66J0mjsWvX2r7vjDOGKLnrkaqaGHSul8Cvqp8Br0xyLPC3SV5eVffOazJoNL/omQ5VtR3YDjA5OVnT09N9dE+SRmOtExlDZF+Sf1/qXK+rdKrqB8DXgAsWnJoBtnSd2Qg8D3isz9qSpOX1sUpnohvZk+RZwPnAdxY02wFc1m1fDNxaPrVNktZVH1M6JwA3dPP4TwM+W1VfTPJ+YLqqdgDXAZ9Mspe5kf0lPdSVJK3C0IFfVXcDpw84ftW87Z8Abxi2liRp7fykrSQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRvTxS8y3JLktyZ4k9yW5YkCbc5McSHJn97pq0LUkSYdPH7/E/CDw7qraneS5wK4kX66q+xe0+0ZVvb6HepKkNRh6hF9V+6tqd7f9Q2APsHnY60qS+tXrHH6Sk4DTgdsHnD47yV1JvpTkZX3WlSQdWh9TOgAkeQ7wOeBdVfX4gtO7gRdV1RNJXgd8HjhlwDWmgCmArVu39tU1SRI9jfCTbGIu7G+sqpsXnq+qx6vqiW57J7ApyXED2m2vqsmqmpyYmOija5KkTh+rdAJcB+ypqg8t0eb4rh1JzuzqPjpsbUnSyvUxpXMO8EbgniR3dsfeA2wFqKprgYuBtyc5CPwYuKSqqofakqQVGjrwq+qbQA7R5mrg6mFrSZLWzk/aSlIjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0YOvCTbElyW5I9Se5LcsWANknykSR7k9yd5FXD1pUkrc7Qv8QcOAi8u6p2J3kusCvJl6vq/nltLgRO6V6vBj7afZUkrZOhR/hVtb+qdnfbPwT2AJsXNNsGfKLmfAs4NskJw9aWJK1cr3P4SU4CTgduX3BqM7Bv3v4Mi38okGQqyXSS6dnZ2T67JknN6y3wkzwH+Bzwrqp6fOHpAd9Siw5Uba+qyaqanJiY6KtrkiR6Cvwkm5gL+xur6uYBTWaALfP2TwQe6qO2JGll+lilE+A6YE9VfWiJZjuAN3Wrdc4CDlTV/mFrS5JWro9VOucAbwTuSXJnd+w9wFaAqroW2Am8DtgL/Ah4Sw91JUmrMHTgV9U3GTxHP79NAe8YtpYkae38pK0kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEb0EvhJrk/ycJJ7lzh/bpIDSe7sXlf1UVeStHJ9/BJzgI8DVwOfWKbNN6rq9T3VkyStUi8j/Kr6OvBYH9eSJB0e6zmHf3aSu5J8KcnLBjVIMpVkOsn07OzsOnZNko5+6xX4u4EXVdUrgL8EPj+oUVVtr6rJqpqcmJhYp65JUhvWJfCr6vGqeqLb3glsSnLcetSWJM1Zl8BPcnySdNtndnUfXY/akqQ5vazSSfIp4FzguCQzwPuATQBVdS1wMfD2JAeBHwOXVFX1UVuStDK9BH5VXXqI81czt2xTkjQiftJWkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1Ijegn8JNcneTjJvUucT5KPJNmb5O4kr+qjriRp5foa4X8cuGCZ8xcCp3SvKeCjPdWVJK1QL4FfVV8HHlumyTbgEzXnW8CxSU7oo7YkaWXWaw5/M7Bv3v5Md+wXJJlKMp1kenZ2dp26JkltWK/Az4BjtehA1faqmqyqyYmJiXXoliS1Y70CfwbYMm//ROChdaotSWL9An8H8KZutc5ZwIGq2r9OtSVJwMY+LpLkU8C5wHFJZoD3AZsAqupaYCfwOmAv8CPgLX3UlSStXC+BX1WXHuJ8Ae/oo5YkaW38pK0kNaKXEb6ko0cGralbgVq07k7jxhG+JDXCwJekRhj4ktQIA1+SGuGbtjq0nt/FG6c3BcepL9Lh5ghfkhph4EtSI5zSkdQP58fGnoEvrYXhpiOQgS9Jh7Dmn+/9dmNozuFLUiMMfElqhIEvSY0w8CWpEQa+JDXCVTo6crgUUhpKLyP8JBckeSDJ3iRXDjj/5iSzSe7sXm/ro64kaeWGHuEn2QBcA7wWmAHuSLKjqu5f0PQzVXX5sPVW3q+1fZ+DQUlHqz5G+GcCe6vqwap6Evg0sK2H60qSetRH4G8G9s3bn+mOLfT7Se5OclOSLYMulGQqyXSS6dnZ2R66Jkl6Sh+BP2jyZOHEyN8BJ1XVbwBfAW4YdKGq2l5Vk1U1OTEx0UPXRi9Z20uS+tZH4M8A80fsJwIPzW9QVY9W1U+73b8CzuihriRpFfoI/DuAU5KcnOTpwCXAjvkNkpwwb/ciYE8PdSVJqzD0Kp2qOpjkcuAWYANwfVXdl+T9wHRV7QDemeQi4CDwGPDmYetKklYnNabrECcnJ2t6enrN37/2x5mu4RuXuYdHxfLQcfmdtmv5s1mmH+PWl3HhPVnsSLonSXZV1eSgcz5aQZIaYeBLUiMMfElqhA9Pk45kR8WbRFovjvAlqREGviQ1wimdhqx9aZnWw1r+fPyz0WoY+OPKuVlJPXNKR5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCZZmSxpark/vlCF+SGmHgS1IjDHxJakQvgZ/kgiQPJNmb5MoB55+R5DPd+duTnNRHXUnSyg0d+Ek2ANcAFwKnAZcmOW1Bs7cC36+qlwAfBj44bF1J0ur0McI/E9hbVQ9W1ZPAp4FtC9psA27otm8CzkvW+v67JGkt+liWuRnYN29/Bnj1Um2q6mCSA8ALgEfmN0oyBUwBbN26dahOrX1ZVr/rucalHzA+fRmXfsDR0Jdx6QeMVV/W9KzppYuN0z0ZRh8j/EF3duF/5UraUFXbq2qyqiYnJiZ66Jok6Sl9BP4MsGXe/onAQ0u1SbIReB7wWA+1JUkr1Efg3wGckuTkJE8HLgF2LGizA7is274YuLXKz8JJ0noaeg6/m5O/HLgF2ABcX1X3JXk/MF1VO4DrgE8m2cvcyP6SYetKklanl2fpVNVOYOeCY1fN2/4J8IY+akmS1sZP2kpSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJasRQgZ/kl5N8Ocl3u6/PX6Ldz5Lc2b0W/oJzSdI6GHaEfyXw1ao6Bfhqtz/Ij6vqld3roiFrSpLWYNjA3wbc0G3fAPzOkNeTJB0mwwb+r1bVfoDu668s0e6ZSaaTfCuJPxQkaQQ2HqpBkq8Axw849d5V1NlaVQ8leTFwa5J7qupfBtSaAqYAtm7duorLS5IO5ZCBX1XnL3UuyX8lOaGq9ic5AXh4iWs81H19MMnXgNOBRYFfVduB7QCTk5O1ov8CSdKKDDulswO4rNu+DPjCwgZJnp/kGd32ccA5wP1D1pUkrdKwgf8B4LVJvgu8ttsnyWSSj3VtXgpMJ7kLuA34QFUZ+JK0zg45pbOcqnoUOG/A8Wngbd32PwG/PkwdSdLw/KStJDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1IihAj/JG5Lcl+TnSSaXaXdBkgeS7E1y5TA1JUlrM+wI/17g94CvL9UgyQbgGuBC4DTg0iSnDVlXkrRKG4f55qraA5BkuWZnAnur6sGu7aeBbcD9w9SWJK3OUIG/QpuBffP2Z4BXD2qYZAqY6nafSPLAYerTccAjh+naRyrvyWLek8WO3nuy/MB1OeN2T1601IlDBn6SrwDHDzj13qr6wgqKD7qLNahhVW0Htq/gmkNJMl1VS77n0CLvyWLek8W8J4sdSffkkIFfVecPWWMG2DJv/0TgoSGvKUlapfVYlnkHcEqSk5M8HbgE2LEOdSVJ8wy7LPN3k8wAZwN/n+SW7vgLk+wEqKqDwOXALcAe4LNVdd9w3R7aYZ82OgJ5TxbznizmPVnsiLknqRo4nS5JOsr4SVtJaoSBL0mNaCrwfcTDL0qyJcltSfZ0j8i4YtR9GhdJNiT5dpIvjrov4yLJsUluSvKd7u/M2aPu06gl+aPu3869ST6V5Jmj7tNymgl8H/Ew0EHg3VX1UuAs4B3ek/9zBXOLDPT//gL4h6o6FXgFjd+fJJuBdwKTVfVyYANzqxDHVjOBz7xHPFTVk8BTj3hoVlXtr6rd3fYPmfsHvHm0vRq9JCcCvw18bNR9GRdJfgn4LeA6gKp6sqp+MNpejYWNwLOSbASezZh/xqilwB/0iIfmw+0pSU4CTgduH21PxsKfA38M/HzUHRkjLwZmgb/upro+luSYUXdqlKrqP4A/A74H7AcOVNU/jrZXy2sp8Ff8iIfWJHkO8DngXVX1+Kj7M0pJXg88XFW7Rt2XMbMReBXw0ao6HfhvoOn3wZI8n7lZgpOBFwLHJPmD0fZqeS0Fvo94GCDJJubC/saqunnU/RkD5wAXJfk35qb9XpPkb0bbpbEwA8xU1VP/B3gTcz8AWnY+8K9VNVtV/wPcDPzmiPu0rJYC30c8LJC551pfB+ypqg+Nuj/joKr+pKpOrKqTmPs7cmtVjfWobT1U1X8C+5L8WnfoPHzE+feAs5I8u/u3dB5j/kb2ejweeSxU1cEkTz3iYQNw/Rg84mHUzgHeCNyT5M7u2HuqaucI+6Tx9YfAjd2A6UHgLSPuz0hV1e1JbgJ2M7fi7duM+WMWfLSCJDWipSkdSWqagS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5Ia8b+KnTYl+PPkdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data_size in data_size_list:\n",
    "    coeff_sum = coeff_dict[data_size][9]\n",
    "    for i in range(9):\n",
    "        coeff_sum = np.add(coeff_sum, coeff_dict[data_size][i])\n",
    "    coeff = np.divide(coeff_sum,10)\n",
    "    co_list = []\n",
    "    for k in range(9):\n",
    "        co_list.append(coeff[k][k])\n",
    "        co_list.append(coeff[k][k+9])\n",
    "    r,c = rep % 3 , (rep- r) // 3\n",
    "\n",
    "    bar_width = 0.4\n",
    "    plt.bar(np.arange(9), co_list[:9],bar_width, color='b')\n",
    "    plt.bar(np.arange(9)+bar_width, co_list[9:],bar_width, color='r')\n",
    "    plt.ylim(-1,3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "471.333px",
    "left": "47px",
    "top": "88px",
    "width": "371.563px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
